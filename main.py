# Load environment variables from .env file
from dotenv import load_dotenv
load_dotenv()

from fastapi import FastAPI, HTTPException, Request, Query, Body, UploadFile, File, Form, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse, RedirectResponse, HTMLResponse, FileResponse, JSONResponse, Response
from starlette.status import HTTP_308_PERMANENT_REDIRECT
from pydantic import BaseModel, EmailStr
from typing import Optional, List
from email.header import Header
from collections import defaultdict

# Database imports
import sqlite3
from database import (
    init_database, init_support_user, get_user, authenticate_user,
    list_all_users, get_user_stats, create_user, update_user,
    get_guide_progress, init_guide_progress,
    update_video_progress, complete_guide,
    mark_onboarding_completed, mark_videos_completed, check_user_access,
    send_support_message, get_user_messages,
    get_all_support_conversations, mark_messages_as_read,
    get_unread_messages_count, delete_conversation, mark_conversation_resolved,
    get_resolved_today_count, toggle_user_active, delete_user_completely, DB_PATH
)

# Configuration s√©curis√©e
import config
import time
import glob
import threading

# Scheduler pour backup automatique
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

# Backend QE imports
from QE.Backend.auth import hash_password, verify_password
from QE.Backend.coach_access import get_entrepreneurs_for_coach
from QE.Backend.monday_sync import sync_vente_to_monday, update_monday_column, find_monday_item_by_soumission, get_monday_credentials, update_monday_text_column

# D√©finition locale pour √©viter probl√®me de cache avec la fonction import√©e
def get_all_entrepreneurs():
    """Retourne tous les entrepreneurs actifs qui ont un coach assign√© (sans doublons)"""
    try:
        import sqlite3
        from database import get_database_path
        DB_PATH = get_database_path()
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            # Ne prendre QUE les entrepreneurs avec un coach assign√©
            cursor.execute("""
                SELECT username FROM users
                WHERE role = 'entrepreneur'
                AND is_active = 1
                AND assigned_coach IS NOT NULL
                AND assigned_coach != ''
            """)
            return [row[0] for row in cursor.fetchall()]
    except Exception as e:
        print(f"[ERROR] get_all_entrepreneurs: {e}")
        return []
from QE.Backend.project_manager import (
    load_user_projects, create_project, update_project,
    delete_project, get_project,
    load_global_parameters, save_global_parameters,
    check_user_permission
)
from QE.Backend.facturationqe import (
    get_clients_facturation_qe, get_statuts_client_facturation_qe,
    update_statut_client_facturation_qe, get_status_columns_facturation_qe,
    get_description_statut_client_facturation_qe, marquer_depot_traite_facturation_qe,
    envoyer_au_comptable_facturation_qe, get_historique_client_facturation_qe,
    ajouter_historique_client_facturation_qe, get_clients_count_facturation_qe
)

# PDF QE imports
from QE.PDF.generate_pdf import generate_pdf
from QE.PDF.generate_gqp_pdf import generate_gqp_pdf
from QE.PDF.generate_gqp_html import generate_gqp_html
from QE.PDF.generate_pdf_facture import generate_facture_pdf
from QE.PDF.generate_pdf_calcul import generate_calcul_pdf
import uuid

import base64
from io import BytesIO
import subprocess
import os
import sys
import logging
import json
from datetime import datetime, timedelta, timezone
import urllib.parse
import requests
import uuid
import datetime as dt
import shutil
import re
import asyncio

from PyPDF2 import PdfReader, PdfWriter

# Gamification system
import gamification
from reportlab.pdfgen import canvas as rl_canvas
from reportlab.lib.pagesizes import letter
from reportlab.lib.utils import ImageReader

# D√©tection automatique de l'environnement (DEV ou PROD)
# V√©rifier d'abord si on est en d√©veloppement local
if os.getenv("RENDER_EXTERNAL_URL"):
    # Sur Render (production ou dev)
    BASE_URL = os.getenv("RENDER_EXTERNAL_URL")
else:
    # En local - d√©tecter le port utilis√©
    # Par d√©faut localhost:8080, ou utiliser une variable d'env LOCAL_PORT
    local_port = os.getenv("LOCAL_PORT", "8080")
    BASE_URL = f"http://localhost:{local_port}"
    print(f"[LOCAL] Mode d√©veloppement local d√©tect√© - BASE_URL: {BASE_URL}")

# D√©tection OS pour chemins de fichiers
import sys
if sys.platform == 'win32':
    # Windows - chemin relatif
    base_cloud = os.path.join(os.path.dirname(__file__), 'data')
else:
    # Unix/Linux (Production sur Render)
    # Utiliser la variable d'environnement STORAGE_PATH si d√©finie, sinon /mnt/cloud
    base_cloud = os.getenv("STORAGE_PATH", "/mnt/cloud")

os.makedirs(os.path.join(base_cloud, "tokens"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "soumissions_completes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "travaux_a_completer"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "soumission_signee_facturation_qe"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "pdfcalcul"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "emails"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "blacklist"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "factures_completes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "prospects"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "facturations_urgentes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "facturations_en_cours"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "facturations_traitees"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "facturation_qe_statuts"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "facturation_qe_historique"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "gqp"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "gqp_images"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "soumissions_signees"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "plaintes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "chiffre_affaires"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "travaux_a_completer"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "travaux_completes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "total_signees"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "reviews"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "ficheremployer"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "ficherlegal"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "fichermarketing"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "ficherprocessus"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "projects"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "parameters"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "signatures"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "employes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "themes"), exist_ok=True)
os.makedirs(os.path.join(base_cloud, "cheques"), exist_ok=True)

# Nouveaux dossiers pour gestion ventes (travaux.html)
os.makedirs(f"{base_cloud}/ventes_attente", exist_ok=True)
os.makedirs(f"{base_cloud}/ventes_acceptees", exist_ok=True)
os.makedirs(f"{base_cloud}/ventes_produit", exist_ok=True)




from pathlib import Path
BASE_DIR = Path(__file__).resolve().parent
app = FastAPI()

@app.get("/healthz")
def health_check():
    return {"status": "ok"}

# Variables globales pour les sessions photo mobile
mobile_photo_sessions = {}
mobile_photo_waiters = {}

# Note: Les utilisateurs en ligne sont maintenant persist√©s dans la table 'online_users' en SQLite
# pour survivre aux red√©ploiements et fonctionner en production sur Render

app.mount("/cloud/factures", StaticFiles(directory=f"{base_cloud}/factures_completes"), name="factures")
app.mount("/cloud/soumissions_completes", StaticFiles(directory=f"{base_cloud}/soumissions_completes"), name="soumissions_completes")
app.mount("/cloud/soumissions_signees", StaticFiles(directory=f"{base_cloud}/soumissions_signees"), name="soumissions_signees")
app.mount("/cloud/pdfcalcul", StaticFiles(directory=f"{base_cloud}/pdfcalcul"), name="pdfcalcul")
app.mount("/cloud/travaux_a_completer", StaticFiles(directory=f"{base_cloud}/travaux_a_completer"), name="travaux_a_completer")
app.mount("/cloud/travaux_completes", StaticFiles(directory=f"{base_cloud}/travaux_completes"), name="travaux_completes")
app.mount("/cloud/reviews", StaticFiles(directory=f"{base_cloud}/reviews"), name="reviews")
app.mount("/cloud/gqp", StaticFiles(directory=f"{base_cloud}/gqp"), name="gqp")
app.mount("/cloud/ventes_attente", StaticFiles(directory=f"{base_cloud}/ventes_attente"), name="ventes_attente")
app.mount("/cloud/ventes_acceptees", StaticFiles(directory=f"{base_cloud}/ventes_acceptees"), name="ventes_acceptees")
app.mount("/cloud/ventes_produit", StaticFiles(directory=f"{base_cloud}/ventes_produit"), name="ventes_produit")
app.mount("/cloud/ficheremployer", StaticFiles(directory=f"{base_cloud}/ficheremployer"), name="ficheremployer")
app.mount("/cloud/ficherlegal", StaticFiles(directory=f"{base_cloud}/ficherlegal"), name="ficherlegal_files") 
app.mount("/cloud/fichermarketing", StaticFiles(directory=f"{base_cloud}/fichermarketing"), name="fichermarketing")
app.mount("/cloud/ficherprocessus", StaticFiles(directory=f"{base_cloud}/ficherprocessus"), name="ficherprocessus")
app.mount("/cloud/signatures", StaticFiles(directory=f"{base_cloud}/signatures"), name="signatures")
app.mount("/cloud/cheques", StaticFiles(directory=f"{base_cloud}/cheques"), name="cheques")
app.mount("/cloud/plaintes", StaticFiles(directory=f"{base_cloud}/plaintes"), name="plaintes")
app.mount("/cloud/facturation_qe_statuts", StaticFiles(directory=f"{base_cloud}/facturation_qe_statuts"), name="facturation_qe_statuts")
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/frontend", StaticFiles(directory="QE/Frontend"), name="frontend")

# Cr√©er le dossier uploads s'il n'existe pas (utiliser le disque persistant sur Render)
os.makedirs(os.path.join(base_cloud, "uploads"), exist_ok=True)
app.mount("/uploads", StaticFiles(directory=os.path.join(base_cloud, "uploads")), name="uploads")


# ============================================
# INITIALISATION GAMIFICATION
# ============================================

def run_gdrive_backup():
    """Ex√©cute le backup vers Google Drive"""
    import subprocess
    from datetime import datetime

    print(f"[BACKUP] D√©marrage du backup - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # Configuration rclone
        rclone_config_dir = os.path.expanduser("~/.config/rclone")
        rclone_config_file = os.path.join(rclone_config_dir, "rclone.conf")
        os.makedirs(rclone_config_dir, exist_ok=True)

        # Cr√©er le fichier config rclone depuis les variables d'environnement
        client_id = os.getenv("GDRIVE_CLIENT_ID", "")
        client_secret = os.getenv("GDRIVE_CLIENT_SECRET", "")
        token = os.getenv("GDRIVE_TOKEN", "")

        if not all([client_id, client_secret, token]):
            print("[BACKUP] Variables GDRIVE_* manquantes - backup annul√©")
            return

        config_content = f"""[gdrive]
type = drive
client_id = {client_id}
client_secret = {client_secret}
scope = drive
token = {token}
team_drive =
"""
        with open(rclone_config_file, 'w') as f:
            f.write(config_content)

        # Installer rclone si n√©cessaire
        home = os.path.expanduser("~")
        rclone_bin = os.path.join(home, "rclone")

        if not os.path.exists(rclone_bin):
            print("[BACKUP] Installation de rclone...")
            subprocess.run(["curl", "-L", "https://downloads.rclone.org/rclone-current-linux-amd64.zip", "-o", f"{home}/rclone.zip"], check=True)
            subprocess.run(["unzip", "-o", f"{home}/rclone.zip", "-d", home], check=True)
            for item in os.listdir(home):
                if item.startswith("rclone-") and item.endswith("-linux-amd64"):
                    subprocess.run(["cp", f"{home}/{item}/rclone", rclone_bin], check=True)
                    break
            subprocess.run(["chmod", "+x", rclone_bin], check=True)

        # Cr√©er le backup
        date_str = datetime.now().strftime("%Y-%m-%d_%H%M")
        backup_file = f"/tmp/backup_{date_str}.tar.gz"

        print(f"[BACKUP] Cr√©ation de {backup_file}...")
        # Ignorer l'erreur "file changed as we read it" (exit code 1) - le backup est quand m√™me cr√©√©
        result = subprocess.run(["tar", "-czf", backup_file, "-C", "/mnt/cloud", "."])
        if result.returncode not in [0, 1]:  # 0 = OK, 1 = fichiers modifi√©s pendant backup (OK)
            raise Exception(f"tar failed with exit code {result.returncode}")

        # Upload sur Google Drive
        print("[BACKUP] Upload vers Google Drive...")
        subprocess.run([rclone_bin, "copy", backup_file, "gdrive:Backups_Render/", "-v"], check=True)

        # Nettoyer
        os.remove(backup_file)

        # Supprimer les vieux backups (> 7 jours)
        subprocess.run([rclone_bin, "delete", "gdrive:Backups_Render/", "--min-age", "7d"], check=True)

        print(f"[BACKUP] Backup termin√© avec succ√®s - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        print(f"[BACKUP] Erreur: {e}")


@app.on_event("startup")
async def startup_event():
    """Initialise les dossiers n√©cessaires et les tables de gamification au d√©marrage"""

    # Cr√©er tous les dossiers n√©cessaires
    print("[STARTUP] Cr√©ation des dossiers de donn√©es...")
    required_dirs = [
        os.path.join(base_cloud, 'accounts'),
        os.path.join(base_cloud, 'blacklist'),
        os.path.join(base_cloud, 'clients_perdus'),
        os.path.join(base_cloud, 'emails'),
        os.path.join(base_cloud, 'employes'),
        os.path.join(base_cloud, 'equipe'),
        os.path.join(base_cloud, 'ficheremployer'),
        os.path.join(base_cloud, 'ficherformations'),
        os.path.join(base_cloud, 'ficherlegal'),
        os.path.join(base_cloud, 'fichermarketing'),
        os.path.join(base_cloud, 'ficherprocessus'),
        os.path.join(base_cloud, 'gqp'),
        os.path.join(base_cloud, 'projets'),
        os.path.join(base_cloud, 'prospects'),
        os.path.join(base_cloud, 'reviews'),
        os.path.join(base_cloud, 'rpo'),
        os.path.join(base_cloud, 'rpo_why'),
        os.path.join(base_cloud, 'signatures'),
        os.path.join(base_cloud, 'soumissions_completes'),
        os.path.join(base_cloud, 'soumissions_signees'),
        os.path.join(base_cloud, 'stats'),
        os.path.join(base_cloud, 'support_attachments'),
        os.path.join(base_cloud, 'templates'),
        os.path.join(base_cloud, 'total_signees'),
        os.path.join(base_cloud, 'travaux_a_completer'),
        os.path.join(base_cloud, 'ventes_acceptees'),
        os.path.join(base_cloud, 'ventes_attente'),
        os.path.join(base_cloud, 'ventes_produit'),
    ]

    for directory in required_dirs:
        os.makedirs(directory, exist_ok=True)

    print(f"[STARTUP] {len(required_dirs)} dossiers cr√©√©s/v√©rifi√©s")  # 28 dossiers

    print("[STARTUP] Initialisation du syst√®me de gamification...")
    gamification.init_gamification_tables()
    print("[STARTUP] Syst√®me de gamification initialis√©")

    # Initialiser le scheduler pour le backup automatique (seulement en production)
    if os.path.exists("/mnt/cloud"):
        print("[STARTUP] Configuration du backup automatique Google Drive...")
        try:
            scheduler = BackgroundScheduler(timezone="America/Montreal")
            scheduler.add_job(
                run_gdrive_backup,
                CronTrigger(hour=3, minute=30),  # Tous les jours √† 3h30
                id="gdrive_backup",
                replace_existing=True
            )
            scheduler.start()
            print("[STARTUP] Backup automatique programm√© pour 3h30 chaque jour")
        except Exception as e:
            print(f"[STARTUP] Erreur configuration backup: {e}")


@app.post("/api/admin/backup-gdrive")
async def trigger_gdrive_backup(request: Request):
    """D√©clenche manuellement un backup vers Google Drive (admin uniquement)"""
    # V√©rifier que c'est un admin/direction
    auth_header = request.headers.get("Authorization", "")
    if "direction" not in auth_header.lower() and "admin" not in auth_header.lower():
        # Accepter quand m√™me pour les tests
        pass

    if not os.path.exists("/mnt/cloud"):
        return {"status": "error", "message": "Pas en production"}

    import threading
    # Lancer le backup dans un thread pour ne pas bloquer
    thread = threading.Thread(target=run_gdrive_backup)
    thread.start()

    return {"status": "started", "message": "Backup d√©marr√© en arri√®re-plan"}


# ==========================================
# MODE MAINTENANCE
# ==========================================

MAINTENANCE_FILE = "/mnt/cloud/maintenance.json" if os.name != 'nt' else os.path.join(os.path.dirname(__file__), 'data', 'maintenance.json')

@app.get("/api/maintenance")
async def get_maintenance_status():
    """V√©rifie si le mode maintenance est actif"""
    try:
        if os.path.exists(MAINTENANCE_FILE):
            with open(MAINTENANCE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return {"active": True, "message": data.get("message", "Maintenance en cours")}
        return {"active": False}
    except:
        return {"active": False}

@app.post("/api/admin/maintenance/start")
async def start_maintenance(message: str = "Mise √† jour importante en cours. Veuillez quitter l'application jusqu'√† demain matin 6h."):
    """Active le mode maintenance - Lance depuis Render shell"""
    try:
        os.makedirs(os.path.dirname(MAINTENANCE_FILE), exist_ok=True)
        with open(MAINTENANCE_FILE, 'w', encoding='utf-8') as f:
            json.dump({"active": True, "message": message, "started_at": datetime.now().isoformat()}, f)
        return {"status": "ok", "message": "Mode maintenance activ√©"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/api/admin/maintenance/stop")
async def stop_maintenance():
    """D√©sactive le mode maintenance"""
    try:
        if os.path.exists(MAINTENANCE_FILE):
            os.remove(MAINTENANCE_FILE)
        return {"status": "ok", "message": "Mode maintenance d√©sactiv√©"}
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.get("/onboarding", include_in_schema=False)
def onboarding_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "onboarding.html"))

@app.get("/guide", include_in_schema=False)
def guide_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "guide.html"))

@app.get("/guide-content", include_in_schema=False)
def guide_content_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "guide-content.html"))

@app.get("/entrepreneur-selector.css", include_in_schema=False)
def entrepreneur_selector_css():
    """CSS partag√© pour le s√©lecteur entrepreneur (Coach/Direction)"""
    return FileResponse(
        os.path.join(BASE_DIR, "QE", "Frontend", "Common", "entrepreneur-selector.css"),
        media_type="text/css"
    )

@app.get("/entrepreneur-selector.js", include_in_schema=False)
def entrepreneur_selector_js():
    """JavaScript partag√© pour le s√©lecteur entrepreneur (Coach/Direction)"""
    return FileResponse(
        os.path.join(BASE_DIR, "QE", "Frontend", "Common", "entrepreneur-selector.js"),
        media_type="application/javascript"
    )

@app.get("/dashboard", include_in_schema=False)
def dashboard_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Dashboard", "dashboard_user.html"))

@app.get("/apppc", include_in_schema=False)
def apppc_file():
    """Application SPA avec menu et header centralises"""
    response = FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "apppc.html"))
    # Forcer le navigateur a ne pas mettre en cache pour toujours avoir la derniere version
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    return response

@app.get("/support-admin", include_in_schema=False)
def support_admin_file():
    """Page d'administration du support - Acc√®s restreint au r√¥le support"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "support-admin.html"))

@app.get("/users-online", include_in_schema=False)
def users_online_file():
    """Page affichant les utilisateurs en ligne en temps r√©el"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "users_online.html"))

@app.get("/apppcdirection", include_in_schema=False)
def apppcdirection_file():
    """Application SPA pour utilisateurs avec role direction (administration)"""
    response = FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "apppcdirection.html"))
    # Forcer le navigateur a ne pas mettre en cache pour toujours avoir la derniere version
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    return response

@app.get("/apppccoach", include_in_schema=False)
def apppccoach_file():
    """Application SPA pour utilisateurs avec role coach"""
    response = FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "apppccoach.html"))
    # Forcer le navigateur a ne pas mettre en cache pour toujours avoir la derniere version
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    return response

@app.get("/coach_travaux", include_in_schema=False)
def coach_travaux_file():
    """Page de gestion des ventes pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_travaux.html"))

@app.get("/coach_gestionemployes", include_in_schema=False)
def coach_gestionemployes_file():
    """Page de gestion des employ√©s pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_gestionemployes.html"))

@app.get("/coach_facturationqe", include_in_schema=False)
def coach_facturationqe_file():
    """Page de facturation QE pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_facturationqe.html"))

@app.get("/coach_avis", include_in_schema=False)
def coach_avis_file():
    """Page de gestion des avis clients pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_avis.html"))

@app.get("/coach_parametres", include_in_schema=False)
def coach_parametres_file():
    """Page de param√®tres pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_parametres.html"))

@app.get("/coach_dashboard", include_in_schema=False)
def coach_dashboard_file():
    """Page dashboard pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "coach_dashboard.html"))

@app.get("/coach_central", include_in_schema=False)
def coach_central_file():
    """Page centrale de communication pour les coachs (La Centrale)"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_centrale.html"))

@app.get("/coach_centralevue", include_in_schema=False)
def coach_centralevue_file():
    """Centrale du coach (vue principale)"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_centralevue.html"))

@app.get("/coach_validation_employes", include_in_schema=False)
def coach_validation_employes_file():
    """Page de validation des employ√©s pour le coach"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_validation_employes.html"))

@app.get("/direction_facturation", include_in_schema=False)
def direction_facturation_file():
    """Page de facturation pour la direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "direction_facturation.html"))

@app.get("/suivicoach", include_in_schema=False)
def suivi_coach_file():
    """Page de suivi des coachs pour la direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "suivicoach.html"))

@app.get("/coach_inactivation_employes", include_in_schema=False)
def coach_inactivation_employes_file():
    """Page des demandes d'inactivation pour le coach"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "coach_inactivation_employes.html"))

@app.get("/coach_mon_equipe", include_in_schema=False)
def coach_mon_equipe_file():
    """Page Mon √©quipe pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "mon_equipe_coach.html"))

@app.get("/coach_rpo", include_in_schema=False)
def coach_rpo_file():
    """Page RPO pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "coach_rpo.html"))

@app.get("/coach_plaintes", include_in_schema=False)
def coach_plaintes_file():
    """Page Gestion de Plaintes pour les coachs"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "coach_plaintes.html"))

@app.get("/direction_rpo", include_in_schema=False)
def direction_rpo_file():
    """Page RPO pour la direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "direction_rpo.html"))

@app.get("/entrepreneur_centralevue", include_in_schema=False)
def entrepreneur_centralevue_file():
    """Centrale des entrepreneurs (vue principale)"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "entrepreneur_centralevue.html"))

@app.get("/parametreadmin", include_in_schema=False)
def parametreadmin_file():
    """Page de parametres pour administrateurs (role direction)"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "admin_users.html"))

@app.get("/parametredirection", include_in_schema=False)
def parametredirection_file():
    """Page de parametres personnels pour direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "parametredirection.html"))

@app.get("/calcul", include_in_schema=False)
def calcul_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Calcul", "calcul.html"))

@app.get("/outilsmobile", include_in_schema=False)
def outilsmobile_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Mobile", "outils-mobile.html"))

@app.get("/gestionsmobile", include_in_schema=False)
def gestionsmobile_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Mobile", "gestions-mobile.html"))

@app.get("/app", include_in_schema=False)
def app_shell():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "apppc.html"))

@app.get("/base.css", include_in_schema=False)
def base_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "base.css"))

@app.get("/dashboard_user.css", include_in_schema=False)
def dashboard_user_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Dashboard", "dashboard_user.css"))

@app.get("/connect_agenda.css", include_in_schema=False)
def connect_agenda_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Parametres", "connect_agenda.css"))

@app.get("/rpo.css", include_in_schema=False)
def rpo_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "RPO", "rpo.css"))

@app.get("/Centralevue.css", include_in_schema=False)
def centralevue_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "La Centrale", "Centralevue.css"))

@app.get("/Centralevue.js", include_in_schema=False)
def centralevue_js_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "La Centrale", "Centralevue.js"), media_type="application/javascript")

@app.get("/gamification.css", include_in_schema=False)
def gamification_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Niveaux & trophees", "gamification.css"))

@app.get("/calcul.css", include_in_schema=False)
def calcul_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Calcul", "calcul.css"))

@app.get("/facture.css", include_in_schema=False)
def facture_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Facturation Client", "facture.css"))

@app.get("/gqp.css", include_in_schema=False)
def gqp_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "GQP", "gqp.css"))

@app.get("/soumission.css", include_in_schema=False)
def soumission_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Soumission", "soumission.css"))

@app.get("/avis.css", include_in_schema=False)
def avis_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Avis", "avis.css"))

@app.get("/gestionemployes.css", include_in_schema=False)
def gestionemployes_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Employes", "gestionemployes.css"))

@app.get("/FacturationQE.css", include_in_schema=False)
def facturation_qe_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Facturation QE", "FacturationQE.css"))

@app.get("/Ventes.css", include_in_schema=False)
def ventes_css_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Ventes", "Ventes.css"))

@app.get("/centraleadmin.css", include_in_schema=False)
def centraleadmin_css():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin.css"), media_type="text/css")

@app.get("/centraleadmin.js", include_in_schema=False)
def centraleadmin_js():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin.js"), media_type="application/javascript")

@app.get("/centraleadmin_monday.css", include_in_schema=False)
def centraleadmin_monday_css():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin_monday.css"), media_type="text/css")

@app.get("/centraleadmin_monday.js", include_in_schema=False)
def centraleadmin_monday_js():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin_monday.js"), media_type="application/javascript")

@app.get("/centraleadmin_monday_fichiers.js", include_in_schema=False)
def centraleadmin_monday_fichiers_js():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin_monday_fichiers.js"), media_type="application/javascript")

@app.get("/admin_users.css", include_in_schema=False)
def admin_users_css():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "admin_users.css"), media_type="text/css")

@app.get("/api/version")
def get_version():
    """Retourne la version actuelle de l'application pour detection de mise a jour"""
    try:
        version_file = os.path.join(BASE_DIR, "version.json")
        with open(version_file, 'r', encoding='utf-8') as f:
            version_data = json.load(f)
        return JSONResponse(content=version_data)
    except Exception as e:
        return JSONResponse(content={"version": "1.0.0", "lastUpdate": datetime.now(timezone.utc).isoformat()})

@app.get("/soumissions", include_in_schema=False)
def soumissions_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Soumission", "soumission.html"))

@app.get("/avis", include_in_schema=False)
def avis_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Avis", "avis.html"))

@app.get("/api/reviews/{username}")
def get_reviews(username: str):
    """
    R√©cup√®re les avis d'un utilisateur, cr√©e le fichier s'il n'existe pas
    """
    reviews_dir = os.path.join(base_cloud, "reviews", username)
    reviews_file = os.path.join(reviews_dir, "reviews.json")

    # Cr√©er le dossier s'il n'existe pas
    os.makedirs(reviews_dir, exist_ok=True)

    # Cr√©er le fichier vide s'il n'existe pas
    if not os.path.exists(reviews_file):
        with open(reviews_file, 'w', encoding='utf-8') as f:
            json.dump([], f)

    # Retourner les reviews
    with open(reviews_file, 'r', encoding='utf-8') as f:
        reviews = json.load(f)

    return {"reviews": reviews}

@app.get("/signer-soumission", include_in_schema=False)
def signer_soumission_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "Signer-soumission.html"))

@app.get("/connection", include_in_schema=False)
def connection_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Parametres", "connect_agenda.html"))

@app.get("/politique", include_in_schema=False)
def politique_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "politique.html"))

@app.get("/conditions", include_in_schema=False)
def conditions_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "conditions.html"))

@app.get("/support", include_in_schema=False)
def support_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "support.html"))

@app.get("/test-functions", include_in_schema=False)
def test_functions_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "test_functions.html"))

@app.get("/politiquepublic", include_in_schema=False)
def politique_public_file():
    return FileResponse(os.path.join(BASE_DIR, "Qwota", "Frontend", "politiquepublic.html"))

@app.get("/conditionspublic", include_in_schema=False)
def conditions_public_file():
    return FileResponse(os.path.join(BASE_DIR, "Qwota", "Frontend", "conditionspublic.html"))

@app.get("/gqp", include_in_schema=False)
def gqp_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "GQP", "gqp.html"))

@app.get("/rpo", include_in_schema=False)
def rpo_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "RPO", "rpo.html"))

@app.get("/gestionemployes", include_in_schema=False)
def gestion_employes_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Employes", "gestionemployes.html"))

@app.get("/travaux", include_in_schema=False)
def travaux_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Ventes", "Ventes.html"))

@app.get("/login")
def read_index():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "login.html"))

@app.get("/mobile-blocked")
def mobile_blocked():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "mobile-blocked.html"))

@app.get("/contact")
def read_index():
    return FileResponse(os.path.join(BASE_DIR, "Qwota", "Frontend", "contact.html"))

@app.get("/avisclient", include_in_schema=False)
def avisclient_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "reviews.html"))

@app.get("/plainte", include_in_schema=False)
def plainte_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "plainte.html"))


@app.get("/facture")
def facture_index():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Outils", "Facturation Client", "facture.html"))

@app.get("/facturationqe")
def facturationqe_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Facturation QE", "Facturation QE.html"))

@app.get("/newfacturationqe")
def newfacturationqe_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Facturation QE", "Facturation QE.html"))

@app.get("/centrale")
def centrale_index():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Ventes", "Ventes.html"))

@app.get("/ventes")
def ventes_index():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Ventes", "Ventes.html"))

@app.get("/centralevue")
def centralevue_index():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "Gestions", "Centrale", "centralevue.html"))

@app.get("/gamification")
def gamification_page():
    response = FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Niveaux & trophees", "gamification.html"))
    # Forcer le navigateur a ne pas mettre en cache pour toujours avoir la derniere version
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    return response

@app.get("/badge_assignment")
def badge_assignment_page():
    """Page d'assignation de badges pour la direction """
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "badge_assignment.html"))

@app.get("/centraleadmin")
def centrale_admin_page():
    """Page de la centrale admin pour la direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin.html"))

@app.get("/centraleadmin_monday")
def centrale_admin_monday_page():
    """Page de la centrale admin Monday.com pour la direction"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Admin", "centraleadmin_monday.html"))

@app.get("/connect-agenda")
def connect_agenda_page():
    """Page de connexion Google Calendar et Gmail"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Entrepreneurs", "General", "Parametres", "connect_agenda.html"))

@app.get("/")
def read_index():
    return FileResponse(os.path.join(BASE_DIR, "Qwota", "Frontend", "index.html"))

@app.get("/apppc")
def read_apppc():
    """Page principale pour les entrepreneurs (responsive mobile et PC)"""
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "apppc.html"))

@app.get("/favicon", include_in_schema=False)
def favicon():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "favicon.ico"))

@app.get("/common.js", include_in_schema=False)
def common_js():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "common.js"), media_type="application/javascript")

@app.get("/frontend/common.js", include_in_schema=False)
def frontend_common_js():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "common.js"), media_type="application/javascript")

@app.get("/robots.txt", include_in_schema=False)
def robots():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "robots.txt"), media_type="text/plain")

@app.get("/sitemap.xml", include_in_schema=False)
def sitemap():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Common", "sitemap.xml"), media_type="application/xml")

@app.get("/download/qwota-windows", include_in_schema=False)
def download_windows_app():
    """Route pour t√©l√©charger l'application Windows"""
    file_path = os.path.join(BASE_DIR, "static", "downloads", "Qwota-Setup.exe")
    if os.path.exists(file_path):
        return FileResponse(
            file_path,
            media_type="application/octet-stream",
            filename="Qwota-Setup.exe"
        )
    else:
        raise HTTPException(status_code=404, detail="Fichier d'installation non trouv√©")





@app.get("/dashboardcoach", include_in_schema=False)
def dashboardcoach_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "Parametrecoach.html"))

@app.get("/parametrecoach", include_in_schema=False)
def parametrecoach_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "Parametrecoach.html"))

@app.get("/gestionventescoach", include_in_schema=False)
def gestionventescoach_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "Coach", "Parametrecoach.html"))

@app.get("/template", include_in_schema=False)
def template_file():
    return FileResponse(os.path.join(BASE_DIR, "QE", "Frontend", "template.html"))


# üîê Middleware CORS s√©curis√©
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.ALLOWED_ORIGINS,  # Origines sp√©cifiques depuis config
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH"],  # M√©thodes sp√©cifiques
    allow_headers=["*"],
)

# üë§ GESTION DES UTILISATEURS
# Les utilisateurs sont maintenant g√©r√©s dans la base de donn√©es SQLite (data/qwota.db)
# Pour ajouter un utilisateur : python add_user.py
# Pour g√©rer les utilisateurs : python manage_users.py
# Pour voir les stats : python database.py
#
# Initialiser la base de donn√©es au d√©marrage
init_database()
init_support_user()

# [FILE] Mod√®les
class LoginData(BaseModel):
    username: str
    password: str

class SoumissionData(BaseModel):
    nom: str
    prenom: str
    courriel: Optional[str] = ""
    telephone: Optional[str] = ""
    adresse: Optional[str] = ""
    date: Optional[str] = ""
    date2: Optional[str] = ""
    prix: Optional[str] = ""
    depot: Optional[str] = ""
    endroit: Optional[str] = ""
    produit: Optional[str] = ""
    item: Optional[str] = ""
    part: Optional[str] = ""
    payer_par: Optional[str] = ""   # <-- Ajout ici
    num: Optional[str] = ""
    temps: Optional[str] = ""

class ProspectData(BaseModel):
    username: str
    prenom: str
    nom: str
    telephone: str
    adresse: Optional[str] = ""

class CalculateurData(BaseModel):
    username: str
    client: dict
    surfaces: dict
    endroits: dict = {}
    product: dict
    hours: dict
    costs: dict
    parameters: dict
    


def enregistrer_soumission(utilisateur: str, soumission: dict, lien_pdf: str):
    try:
        dossier = os.path.join(f"{base_cloud}/soumissions_completes", utilisateur)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "soumissions.json")

        soumission["pdf_url"] = lien_pdf

        # D√©finir "virement" comme valeur par d√©faut pour payer_par si vide ou absent
        if 'payer_par' not in soumission or not soumission['payer_par']:
            soumission['payer_par'] = "virement"
            print(f"[enregistrer_soumission] D√©fini payer_par par d√©faut: 'virement'")

        # G√©n√©rer un ID unique pour la soumission si pas d√©j√† pr√©sent
        if 'id' not in soumission or not soumission['id']:
            soumission['id'] = str(uuid.uuid4())

        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                data = json.loads(content) if content else []
        else:
            data = []

        data.append(soumission)

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"[enregistrer_soumission] Soumission enregistr√©e pour {utilisateur} dans {fichier}")

    except Exception as e:
        print(f"[enregistrer_soumission] ERREUR: {e}")
        raise e

def enregistrer_pdf_calculateur(utilisateur: str, pdf_data: dict, lien_pdf: str):
    """
    Enregistre les PDFs g√©n√©r√©s par le calculateur dans un fichier s√©par√©
    """
    try:
        dossier = os.path.join(f"{base_cloud}/pdfcalcul", utilisateur)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "pdfs_calculateur.json")

        pdf_data["pdf_url"] = lien_pdf
        pdf_data["date_creation"] = datetime.now().isoformat()

        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                data = json.loads(content) if content else []
        else:
            data = []

        data.append(pdf_data)

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"[enregistrer_pdf_calculateur] PDF calculateur enregistr√© pour {utilisateur}")

    except Exception as e:
        print(f"[enregistrer_pdf_calculateur] Erreur: {e}")

def get_valid_gmail_token(username: str) -> str:
    chemin = os.path.join(base_cloud, "emails", f"{username}.json")
    if not os.path.exists(chemin):
        raise HTTPException(status_code=401, detail="Aucun token Gmail trouv√©")

    with open(chemin, "r", encoding="utf-8") as f:
        tokens = json.load(f)

    headers = {"Authorization": f"Bearer {tokens['access_token']}"}
    test = requests.get("https://www.googleapis.com/oauth2/v1/userinfo", headers=headers)

    if test.status_code == 401 and "refresh_token" in tokens:
        refresh_response = requests.post("https://oauth2.googleapis.com/token", data={
            "client_id": CLIENT_ID,
            "client_secret": CLIENT_SECRET,
            "grant_type": "refresh_token",
            "refresh_token": tokens["refresh_token"],
        })

        if refresh_response.status_code != 200:
            raise HTTPException(status_code=401, detail="Erreur de rafra√Æchissement du token Gmail")

        refreshed = refresh_response.json()
        tokens["access_token"] = refreshed["access_token"]
        tokens["expires_in"] = refreshed.get("expires_in", 3600)

        with open(chemin, "w", encoding="utf-8") as f:
            json.dump(tokens, f, indent=2)

    return tokens["access_token"]

@app.post("/login")
def login(data: LoginData, response: Response):
    # Authentifier avec la base de donn√©es SQLite
    user_info = authenticate_user(data.username, data.password)

    if not user_info:
        raise HTTPException(status_code=401, detail="Utilisateur invalide ou mot de passe incorrect")

    accounts_dir = f"{base_cloud}/accounts"
    os.makedirs(accounts_dir, exist_ok=True)

    user_file = os.path.join(accounts_dir, f"{data.username}.json")
    if not os.path.exists(user_file):
        user_json = {
            "username": data.username,
            "role": user_info["role"],
            "password": user_info.get("password_hash") or user_info.get("password", "")  # hash√©
        }
        with open(user_file, "w", encoding="utf-8") as f:
            json.dump(user_json, f, indent=2, ensure_ascii=False)

    # D√©finir un cookie avec le username pour l'authentification
    response.set_cookie(
        key="username",
        value=data.username,
        max_age=7*24*60*60,  # 7 jours
        httponly=False,  # Permet l'acc√®s depuis JavaScript
        samesite="lax"
    )

    # D√©finir la redirection selon le r√¥le
    if user_info["role"] == "entrepreneur":
        redirect_url = "/dashboard"
    elif user_info["role"] == "coach":
        redirect_url = "/apppccoach"
    elif user_info["role"] == "direction":
        redirect_url = "/apppcdirection"
    else:
        redirect_url = "/"

    return {
        "message": "Connexion r√©ussie [OK]",
        "username": data.username,
        "role": user_info["role"],
        "redirect_url": redirect_url
    }

# Route pour lister les utilisateurs avec leurs r√¥les (√† prot√©ger en prod !)
@app.get("/admin/users")
def list_users_route(include_inactive: bool = False):
    """Liste tous les utilisateurs avec option d'inclure les inactifs"""
    users_list = list_all_users(include_inactive=include_inactive)
    return users_list  # Retourne tous les champs incluant id, email, created_at, last_login, is_active, prenom, nom, etc.

@app.get("/api/user/profile")
async def get_user_profile(username: str):
    """R√©cup√®re le profil d'un utilisateur"""
    print(f"[PROFILE DEBUG] START - username={username}, DB_PATH={DB_PATH}", flush=True)
    try:
        print(f"[PROFILE DEBUG] Opening DB connection...", flush=True)
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            print(f"[PROFILE DEBUG] Executing SQL query for username={username}...", flush=True)
            cursor.execute("""
                SELECT username, prenom, nom, role, email
                FROM users
                WHERE username = ?
            """, (username,))
            result = cursor.fetchone()
            print(f"[PROFILE DEBUG] SQL result: {result}", flush=True)

            if result:
                print(f"[PROFILE DEBUG] User FOUND, returning data...", flush=True)
                return {
                    "success": True,
                    "user": {
                        "username": result[0] or "",
                        "first_name": result[1] or "",
                        "last_name": result[2] or "",
                        "role": result[3] or "",
                        "email": result[4] or ""
                    }
                }
            else:
                raise HTTPException(status_code=404, detail="User not found")
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Error getting user profile: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/user/{username}")
def get_user_info(username: str):
    """R√©cup√®re les informations d'un utilisateur sp√©cifique"""
    print(f"[USER INFO DEBUG] START - username={username}, DB_PATH={DB_PATH}", flush=True)
    try:
        print(f"[USER INFO DEBUG] Opening DB connection...", flush=True)
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            print(f"[USER INFO DEBUG] Executing SQL query for username={username}...", flush=True)
            cursor.execute("""
                SELECT username, prenom, nom, role, email
                FROM users
                WHERE username = ? AND is_active = 1
            """, (username,))
            user = cursor.fetchone()
            print(f"[USER INFO DEBUG] SQL result: {user}", flush=True)

            if user:
                print(f"[USER INFO DEBUG] User FOUND, returning data...", flush=True)
                return {
                    "username": user[0] or "",
                    "prenom": user[1] or "",
                    "nom": user[2] or "",
                    "first_name": user[1] or "",  # Alias pour compatibilit√©
                    "last_name": user[2] or "",   # Alias pour compatibilit√©
                    "role": user[3] or "",
                    "email": user[4] or ""
                }
            else:
                print(f"[USER INFO DEBUG] User NOT FOUND in database", flush=True)
                raise HTTPException(status_code=404, detail="User not found")
    except HTTPException:
        # Re-raise HTTPException as-is (don't convert to 500)
        raise
    except Exception as e:
        print(f"[ERROR] Error fetching user info: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/get-user-info/{username}")
def get_user_info_alias(username: str):
    """Alias pour r√©cup√©rer les informations d'un utilisateur (utilis√© par le frontend)"""
    return get_user_info(username)

@app.get("/api/user/{username}/profile-photo")
def get_user_profile_photo(username: str):
    """R√©cup√®re l'URL de la photo de profil la plus r√©cente pour un utilisateur"""
    try:
        photos_dir = os.path.join(BASE_DIR, "static", "profile_photos")
        if not os.path.exists(photos_dir):
            return {"photo_url": None}

        # Chercher toutes les photos pour cet utilisateur
        matching_files = []
        for ext in ['.png', '.jpg', '.jpeg']:
            pattern = f"{username}_*{ext}"
            files = glob.glob(os.path.join(photos_dir, pattern))
            matching_files.extend(files)

        # Aussi chercher sans timestamp
        for ext in ['.png', '.jpg', '.jpeg']:
            simple_file = os.path.join(photos_dir, f"{username}{ext}")
            if os.path.exists(simple_file):
                matching_files.append(simple_file)

        if not matching_files:
            return {"photo_url": None}

        # Trier par date de modification (le plus r√©cent en premier)
        matching_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        most_recent = matching_files[0]

        # Retourner le chemin relatif
        photo_filename = os.path.basename(most_recent)
        return {"photo_url": f"/static/profile_photos/{photo_filename}"}
    except Exception as e:
        print(f"[ERROR] Error fetching profile photo: {e}", flush=True)
        return {"photo_url": None}

@app.get("/api/entrepreneurs")
def get_entrepreneurs_list_api(
    period: str = "all",
    start: str = None,
    end: str = None
):
    """Retourne tous les utilisateurs avec le r√¥le entrepreneur ou beta avec leurs stats dashboard

    Supporte les filtres de p√©riode:
    - period: all, week, month, year, 90, 30, 14
    - start/end: dates personnalis√©es au format YYYY-MM-DD
    """
    from datetime import datetime, timedelta, timezone

    # Calculer start_date et end_date selon la p√©riode
    now = datetime.now(timezone.utc)
    start_date = None
    end_date = now

    if start and end:
        try:
            start_date = datetime.fromisoformat(start).replace(tzinfo=timezone.utc)
            end_date = datetime.fromisoformat(end).replace(hour=23, minute=59, second=59, tzinfo=timezone.utc)
        except ValueError:
            start_date = None
            end_date = now
    elif period == "today":
        start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "week":
        days_since_monday = now.weekday()
        start_date = (now - timedelta(days=days_since_monday)).replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "month":
        start_date = now - timedelta(days=30)
    elif period == "year":
        start_date = now - timedelta(days=365)
    elif period.isdigit():
        start_date = now - timedelta(days=int(period))

    try:
        print(f"[DEBUG] [CLASSEMENT] Chargement des entrepreneurs avec p√©riode: {period}, start: {start_date}, end: {end_date}", flush=True)
        entrepreneurs = []

        # R√©cup√©rer tous les utilisateurs de la base de donn√©es
        all_users = list_all_users()

        for user_data in all_users:
            username = user_data.get("username", "")
            role = user_data.get("role", "")
            if role in ["entrepreneur", "beta"]:
                try:
                    # Calculer les stats dashboard pour cet entrepreneur avec filtrage par p√©riode
                    stats = calculate_dashboard_stats(username, start_date, end_date)

                    # Charger le pr√©nom, nom et grade depuis user_info.json
                    prenom = ""
                    nom = ""
                    grade = ""
                    info_file = os.path.join(base_cloud, "signatures", username, "user_info.json")
                    try:
                        if os.path.exists(info_file):
                            with open(info_file, 'r', encoding='utf-8') as f:
                                user_info = json.load(f)
                                prenom = user_info.get("prenom", "")
                                nom = user_info.get("nom", "")
                                grade = user_info.get("grade", "")
                    except Exception as e:
                        print(f"[WARNING] Erreur lecture user_info pour {username}: {e}", flush=True)

                    # Cr√©er le nom complet: "Pr√©nom Nom" ou username si pas d'info
                    nom_complet = f"{prenom} {nom}".strip() if (prenom or nom) else username

                    print(f"[CLASSEMENT] {username} -> {nom_complet} - Stats OK", flush=True)

                    # ========================================
                    # DONN√âES RPO - Source unique de v√©rit√©
                    # ========================================
                    # Toutes les donn√©es viennent du JSON RPO:
                    # - annual: totaux de l'ann√©e (quand period=all)
                    # - weekly: donn√©es par semaine (quand period sp√©cifique)
                    # Les m√©triques sont calcul√©es automatiquement

                    dollar_reel = 0
                    contract_reel = 0
                    estimation_reel = 0
                    hr_pap_reel = 0
                    produit_reel = 0
                    prod_horaire_rpo = 0

                    rpo_file = os.path.join(base_cloud, "rpo", f"{username}_rpo.json")
                    if os.path.exists(rpo_file):
                        try:
                            with open(rpo_file, 'r', encoding='utf-8') as f:
                                rpo_data = json.load(f)

                                # Donn√©es weekly pour filtrage par p√©riode ou fallback
                                weekly_data = rpo_data.get("weekly", {})

                                # Si p√©riode sp√©cifique: calculer depuis weekly filtr√©es
                                # Si period=all: utiliser annual directement
                                if start_date:
                                    # Filtrer weekly par p√©riode
                                    weekly_data = filter_rpo_weekly_by_period(weekly_data, start_date, end_date)

                                    # Agr√©ger depuis weekly filtr√©es
                                    for month_key, weeks in weekly_data.items():
                                        try:
                                            if int(month_key) < 0:
                                                continue
                                        except:
                                            continue

                                        for week_key, week_data in weeks.items():
                                            # Dollar et contract
                                            d = week_data.get("dollar", 0)
                                            if d and d != "-":
                                                dollar_reel += float(d)
                                            c = week_data.get("contract", 0)
                                            if c and c != "-":
                                                contract_reel += int(c)
                                            # Estimation
                                            e = week_data.get("estimation", 0)
                                            if e and e != "-":
                                                estimation_reel += int(e)
                                            # Heures PAP
                                            h = week_data.get("h_marketing", "-")
                                            if h and h != "-":
                                                try:
                                                    hr_pap_reel += float(h)
                                                except:
                                                    pass
                                            # Produit
                                            p = week_data.get("produit", 0)
                                            if p and p != "-":
                                                produit_reel += float(p)
                                else:
                                    # Utiliser annual (totaux de l'ann√©e)
                                    annual = rpo_data.get("annual", {})
                                    dollar_reel = annual.get("dollar_reel", 0) or 0
                                    contract_reel = annual.get("contract_reel", 0) or 0
                                    estimation_reel = annual.get("estimation_reel", 0) or 0
                                    hr_pap_reel = annual.get("hr_pap_reel", 0) or 0

                                    # Produit depuis weekly (pas dans annual)
                                    for month_key, weeks in weekly_data.items():
                                        try:
                                            if int(month_key) < 0:
                                                continue
                                        except:
                                            continue
                                        for week_key, week_data in weeks.items():
                                            p = week_data.get("produit", 0)
                                            if p and p != "-":
                                                produit_reel += float(p)

                                    # Fallback: si annual est 0, calculer depuis weekly
                                    if dollar_reel == 0 and contract_reel == 0:
                                        for m_key, weeks in weekly_data.items():
                                            try:
                                                if int(m_key) < 0:
                                                    continue
                                            except:
                                                continue
                                            for w_key, w_data in weeks.items():
                                                d = w_data.get("dollar", 0)
                                                if d and d != "-":
                                                    dollar_reel += float(d)
                                                c = w_data.get("contract", 0)
                                                if c and c != "-":
                                                    contract_reel += int(c)
                                                e = w_data.get("estimation", 0)
                                                if e and e != "-":
                                                    estimation_reel += int(e)
                                                h = w_data.get("h_marketing", "-")
                                                if h and h != "-":
                                                    try:
                                                        hr_pap_reel += float(h)
                                                    except:
                                                        pass

                                # Prod horaire: moyenne des valeurs saisies (mai-septembre)
                                total_prod_horaire = 0
                                nombre_semaines_prod_horaire = 0
                                for month_key, weeks in weekly_data.items():
                                    try:
                                        month_index = int(month_key)
                                        if 4 <= month_index <= 8:  # Mai √† septembre
                                            for week_key, week_data in weeks.items():
                                                prod_h = week_data.get("prod_horaire")
                                                if prod_h is not None and prod_h != 0 and prod_h != "-":
                                                    try:
                                                        total_prod_horaire += float(prod_h)
                                                        nombre_semaines_prod_horaire += 1
                                                    except:
                                                        pass
                                    except:
                                        pass

                                if nombre_semaines_prod_horaire > 0:
                                    prod_horaire_rpo = round(total_prod_horaire / nombre_semaines_prod_horaire)

                        except Exception as e:
                            print(f"[WARNING] Erreur lecture RPO pour {username}: {e}", flush=True)

                    # ========================================
                    # M√âTRIQUES CALCUL√âES AUTOMATIQUEMENT
                    # ========================================
                    # nb_estimations = estimation_reel du RPO annual (source unique de v√©rit√©)
                    # Fallback: signees + perdues si RPO non disponible
                    nb_estimations = estimation_reel if estimation_reel > 0 else (stats["status_soumissions"]["signees"] + stats["status_soumissions"]["perdus"])

                    # Contrat moyen = dollar_reel / contract_reel
                    contrat_moyen = round(dollar_reel / contract_reel, 2) if contract_reel > 0 else 0

                    # Taux de vente = contract_reel / nb_estimations * 100
                    # Formule: Sign√©s avec paiement / (Sign√©s + Perdus)
                    taux_vente = round((contract_reel / nb_estimations) * 100, 2) if nb_estimations > 0 else 0

                    # Taux marketing = nb_estimations / hr_pap_reel (estimations par heure)
                    taux_marketing = round(nb_estimations / hr_pap_reel, 2) if hr_pap_reel > 0 else 0

                    entrepreneur_data = {
                        "username": nom_complet,
                        "login_username": username,
                        "role": role,
                        "grade": grade,
                        # Donn√©es RPO directes
                        "dollar_reel": dollar_reel,
                        "contract_reel": contract_reel,
                        "estimation_reel": estimation_reel,
                        "hr_pap_reel": hr_pap_reel,
                        "produit_reel": produit_reel,
                        # Alias pour compatibilit√©
                        "ca_actuel": dollar_reel,
                        "heures_pap": hr_pap_reel,
                        "montant_produit": produit_reel,
                        "objectif": stats["chiffre_affaires"]["objectif"],
                        # M√©triques calcul√©es
                        "contrat_moyen": contrat_moyen,
                        "taux_vente": taux_vente,
                        "taux_marketing": taux_marketing,
                        "prod_horaire": prod_horaire_rpo if prod_horaire_rpo > 0 else stats["metriques"]["prod_horaire"],
                        # Soumissions (pour compatibilit√©)
                        "soumissions_signees": stats["status_soumissions"]["signees"],
                        "soumissions_en_attente": stats["status_soumissions"]["signees"] - contract_reel,  # Sign√©s sans paiement
                        "soumissions_perdues": stats["status_soumissions"]["perdus"],
                        "nb_estimations": nb_estimations,  # sign√©s + perdus
                        # Satisfaction
                        "etoiles": stats["satisfaction"]["etoiles_moyennes"],
                        "satisfactions": stats["satisfaction"]["nombre_avis"],
                        "plaintes": stats["satisfaction"]["plaintes_actuel"],
                    }

                    print(f"   [DATA] Donnees ajoutees pour: {nom_complet}", flush=True)
                    entrepreneurs.append(entrepreneur_data)
                except Exception as e:
                    print(f"[ERROR] Erreur traitement entrepreneur {username}: {str(e)[:100]}", flush=True)
                    continue

        print(f"[OK] [CLASSEMENT] Total entrepreneurs: {len(entrepreneurs)}", flush=True)
        return entrepreneurs
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[ERROR] FATAL dans /api/entrepreneurs: {error_detail}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")


@app.get("/api/coaches")
def get_coaches_list_api(
    period: str = "all",
    start: str = None,
    end: str = None
):
    """Retourne tous les coaches avec leurs stats d'√©quipe

    SIMPLIFI√â: Lit directement le JSON RPO du coach (d√©j√† agr√©g√©)
    Les m√©triques sont calcul√©es automatiquement

    Supporte les filtres de p√©riode:
    - period: all, week, month, year, 90, 30, 14
    - start/end: dates personnalis√©es au format YYYY-MM-DD
    """
    from datetime import datetime, timedelta, timezone

    # Calculer start_date et end_date selon la p√©riode
    now = datetime.now(timezone.utc)
    start_date = None
    end_date = now

    if start and end:
        try:
            start_date = datetime.fromisoformat(start).replace(tzinfo=timezone.utc)
            end_date = datetime.fromisoformat(end).replace(hour=23, minute=59, second=59, tzinfo=timezone.utc)
        except ValueError:
            start_date = None
            end_date = now
    elif period == "today":
        start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "week":
        days_since_monday = now.weekday()
        start_date = (now - timedelta(days=days_since_monday)).replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "month":
        start_date = now - timedelta(days=30)
    elif period == "year":
        start_date = now - timedelta(days=365)
    elif period.isdigit():
        start_date = now - timedelta(days=int(period))

    try:
        print(f"[DEBUG] [COACHES] Chargement des coaches avec p√©riode: {period}", flush=True)
        coaches_list = []

        # R√©cup√©rer tous les utilisateurs de la base de donn√©es
        all_users = list_all_users()

        for user_data in all_users:
            username = user_data.get("username", "")
            role = user_data.get("role", "")
            if role == "coach":
                try:
                    # ========================================
                    # DONN√âES RPO DU COACH - Source unique
                    # ========================================
                    # Le JSON du coach contient d√©j√† les donn√©es agr√©g√©es
                    # de tous ses entrepreneurs (via sync_coach_rpo)

                    dollar_reel = 0
                    contract_reel = 0
                    estimation_reel = 0
                    hr_pap_reel = 0
                    produit_reel = 0

                    rpo_file = os.path.join(base_cloud, "rpo", f"{username}_rpo.json")
                    if os.path.exists(rpo_file):
                        with open(rpo_file, 'r', encoding='utf-8') as f:
                            rpo_data = json.load(f)

                        weekly_data = rpo_data.get("weekly", {})

                        # Filtrer par p√©riode si d√©finie
                        if start_date:
                            weekly_data = filter_rpo_weekly_by_period(weekly_data, start_date, end_date)

                        # Agr√©ger depuis weekly
                        for month_key, weeks in weekly_data.items():
                            try:
                                if int(month_key) < 0:
                                    continue
                            except:
                                continue

                            for week_key, week_data in weeks.items():
                                # Dollar
                                d = week_data.get("dollar", 0)
                                if d and d != "-":
                                    dollar_reel += float(d)
                                # Contract
                                c = week_data.get("contract", 0)
                                if c and c != "-":
                                    contract_reel += int(float(c))
                                # Estimation
                                e = week_data.get("estimation", 0)
                                if e and e != "-":
                                    estimation_reel += int(float(e))
                                # Heures PAP
                                h = week_data.get("h_marketing", 0)
                                if h and h != "-":
                                    try:
                                        hr_pap_reel += float(h)
                                    except:
                                        pass
                                # Produit
                                p = week_data.get("produit", 0)
                                if p and p != "-":
                                    produit_reel += float(p)

                    # prod_horaire vient directement du JSON RPO (pas calcul√© ici)
                    prod_horaire = 0
                    if 'annual' in rpo_data:
                        prod_horaire = rpo_data['annual'].get('prod_horaire', 0)

                    # R√©cup√©rer nb entrepreneurs
                    team_members = get_entrepreneurs_for_coach(username)
                    nb_entrepreneurs = len(team_members) if team_members else 0

                    # R√©cup√©rer objectif depuis coach_previsions
                    team_objectif = 0
                    if 'coach_previsions' in rpo_data:
                        team_objectif = rpo_data['coach_previsions'].get('totalObjectif', 0)

                    # Agr√©ger stats depuis entrepreneurs (satisfaction + soumissions)
                    team_etoiles_total = 0
                    team_satisfactions_total = 0
                    team_soumissions_signees = 0
                    team_soumissions_perdues = 0
                    if team_members:
                        for member in team_members:
                            try:
                                member_stats = calculate_dashboard_stats(member['username'], start_date, end_date)
                                # Satisfaction
                                team_etoiles_total += member_stats["satisfaction"]["etoiles_moyennes"] * member_stats["satisfaction"]["nombre_avis"]
                                team_satisfactions_total += member_stats["satisfaction"]["nombre_avis"]
                                # Soumissions (pour nb_estimations = sign√©es + perdues)
                                team_soumissions_signees += member_stats["status_soumissions"]["signees"]
                                team_soumissions_perdues += member_stats["status_soumissions"]["perdus"]
                            except:
                                pass
                    etoiles_moyennes = team_etoiles_total / team_satisfactions_total if team_satisfactions_total > 0 else 0
                    # nb_estimations = sign√©es + perdues (comme pour entrepreneur)
                    nb_estimations_cumule = team_soumissions_signees + team_soumissions_perdues

                    # ========================================
                    # M√âTRIQUES CALCUL√âES AUTOMATIQUEMENT
                    # ========================================
                    # Contrat moyen = dollar_reel / contract_reel
                    contrat_moyen = round(dollar_reel / contract_reel, 2) if contract_reel > 0 else 0

                    # Taux de vente = contract_reel / estimation_reel * 100
                    # Formule: Sign√©s avec paiement / Nb estimations (depuis RPO)
                    taux_vente = round((contract_reel / estimation_reel) * 100, 2) if estimation_reel > 0 else 0

                    # Taux marketing = estimation_reel / hr_pap_reel (estimations par heure)
                    taux_marketing = round(estimation_reel / hr_pap_reel, 2) if hr_pap_reel > 0 else 0

                    # Photo de profil
                    photo_profil = None
                    import glob
                    photos_dir = os.path.join(BASE_DIR, "static", "profile_photos")
                    pattern = os.path.join(photos_dir, f"{username}_*.*")
                    matching_files = glob.glob(pattern)
                    if matching_files:
                        photo_file = max(matching_files, key=os.path.getmtime)
                        photo_filename = os.path.basename(photo_file)
                        photo_profil = f"/static/profile_photos/{photo_filename}"

                    # Prenom et nom
                    prenom = ""
                    nom = ""
                    with sqlite3.connect(DB_PATH) as conn:
                        cursor = conn.cursor()
                        cursor.execute("SELECT prenom, nom FROM users WHERE username = ?", (username,))
                        coach_info = cursor.fetchone()
                        if coach_info:
                            prenom = coach_info[0] or ""
                            nom = coach_info[1] or ""

                    # Structure de r√©ponse (format identique √† entrepreneur)
                    coach_data = {
                        "username": username,
                        "login_username": username,
                        "prenom": prenom,
                        "nom": nom,
                        "role": "coach",
                        "photo": photo_profil,
                        "grade": "coach",
                        "nb_entrepreneurs": nb_entrepreneurs,
                        # Donn√©es RPO directes (cumul√©es)
                        "dollar_reel": dollar_reel,
                        "contract_reel": contract_reel,
                        "hr_pap_reel": hr_pap_reel,
                        "produit_reel": produit_reel,
                        # Soumissions cumul√©es (pour nb_estimations = sign√©es + perdues)
                        "soumissions_signees": team_soumissions_signees,
                        "soumissions_perdues": team_soumissions_perdues,
                        # Alias pour compatibilit√© avec entrepreneur
                        "ca_actuel": dollar_reel,
                        "heures_pap": hr_pap_reel,
                        "montant_produit": produit_reel,
                        "nb_estimations": estimation_reel,  # Depuis RPO estimation_reel (agr√©g√©)
                        "objectif": team_objectif,
                        # M√©triques calcul√©es
                        "contrat_moyen": contrat_moyen,
                        "taux_vente": taux_vente,
                        "taux_marketing": taux_marketing,
                        "prod_horaire": prod_horaire,
                        # Satisfaction
                        "etoiles": round(etoiles_moyennes, 2),
                        "satisfactions": team_satisfactions_total,
                    }

                    print(f"   [DATA] Coach {username}: dollar={dollar_reel}, contract={contract_reel}, estimation={estimation_reel}, hr_pap={hr_pap_reel}", flush=True)
                    coaches_list.append(coach_data)

                except Exception as e:
                    print(f"[ERROR] Erreur traitement coach {username}: {str(e)[:100]}", flush=True)
                    continue

        print(f"[OK] [COACHES] Total coaches: {len(coaches_list)}", flush=True)
        return coaches_list
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[ERROR] FATAL dans /api/coaches: {error_detail}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")


# ================================================================
# DASHBOARD - Syst√®me de stockage centralis√© des stats
# ================================================================

# Dossier de stockage des donn√©es dashboard
if sys.platform == 'win32':
    DASHBOARD_DATA_DIR = os.path.join(os.path.dirname(__file__), 'data', 'dashboard')
else:
    DASHBOARD_DATA_DIR = f"{base_cloud}/dashboard"

os.makedirs(DASHBOARD_DATA_DIR, exist_ok=True)


def get_user_dashboard_file(username: str) -> str:
    """Retourne le chemin du fichier dashboard pour un utilisateur"""
    user_dir = os.path.join(DASHBOARD_DATA_DIR, username)
    os.makedirs(user_dir, exist_ok=True)
    return os.path.join(user_dir, "stats.json")


def load_user_dashboard_data(username: str) -> dict:
    """Charge les donn√©es dashboard d'un utilisateur"""
    filepath = get_user_dashboard_file(username)

    if not os.path.exists(filepath):
        # Structure par d√©faut
        return {
            "status_soumissions": {
                "signees": 0,
                "en_attente": 0,
                "perdus": 0
            },
            "chiffre_affaires": {
                "objectif": 0,
                "ca_actuel": 0,
                "pourcentage": 0
            },
            "satisfaction": {
                "etoiles_moyennes": 0.0,
                "nombre_avis": 0,
                "plaintes_actuel": 0
            },
            "metriques": {
                "contrat_moyen": 0,
                "taux_marketing": 0,
                "taux_vente": 0,
                "prod_horaire": 0
            },
            "last_updated": None
        }

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"[ERROR] Erreur chargement dashboard {username}: {e}")
        return {
            "status_soumissions": {"signees": 0, "en_attente": 0, "perdus": 0},
            "chiffre_affaires": {"objectif": 0, "ca_actuel": 0, "pourcentage": 0},
            "satisfaction": {"etoiles_moyennes": 0.0, "nombre_avis": 0, "plaintes_actuel": 0},
            "metriques": {"contrat_moyen": 0, "taux_marketing": 0, "taux_vente": 0, "prod_horaire": 0},
            "last_updated": None
        }


def save_user_dashboard_data(username: str, data: dict) -> bool:
    """Sauvegarde les donn√©es dashboard d'un utilisateur"""
    filepath = get_user_dashboard_file(username)

    try:
        data['last_updated'] = datetime.now().isoformat()
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"[ERROR] Erreur sauvegarde dashboard {username}: {e}")
        return False


def calculate_dashboard_stats(username: str, start_date=None, end_date=None) -> dict:
    """
    Calcule automatiquement toutes les statistiques du dashboard
    √† partir des donn√©es existantes (soumissions, ventes, etc.)

    Args:
        username: Username de l'entrepreneur
        start_date: Date de d√©but pour le filtrage (datetime object, optionnel)
        end_date: Date de fin pour le filtrage (datetime object, optionnel)
    """
    stats = {
        "status_soumissions": {"signees": 0, "en_attente": 0, "perdus": 0},
        "chiffre_affaires": {"objectif": 0, "ca_actuel": 0, "pourcentage": 0},
        "satisfaction": {"etoiles_moyennes": 0.0, "nombre_avis": 0, "plaintes_actuel": 0},
        "metriques": {"contrat_moyen": 0, "taux_marketing": 0, "taux_vente": 0, "prod_horaire": 0}
    }

    try:
        # 1. STATUS SOUMISSIONS
        signees_path = os.path.join(base_cloud, "soumissions_signees", username, "soumissions.json")
        if os.path.exists(signees_path):
            with open(signees_path, 'r', encoding='utf-8') as f:
                signees = json.load(f)
                # Filtrer par p√©riode si n√©cessaire
                if start_date:
                    filtered = []
                    for s in signees:
                        date_obj = parse_date_flexible(s.get("date", ""))
                        if date_obj and start_date <= date_obj <= end_date:
                            filtered.append(s)
                    signees = filtered
                stats["status_soumissions"]["signees"] = len(signees)

        attente_path = os.path.join(base_cloud, "ventes_attente", username, "ventes.json")
        if os.path.exists(attente_path):
            with open(attente_path, 'r', encoding='utf-8') as f:
                attente = json.load(f)
                # Filtrer par p√©riode si n√©cessaire
                if start_date:
                    filtered = []
                    for a in attente:
                        date_obj = parse_date_flexible(a.get("date", ""))
                        if date_obj and start_date <= date_obj <= end_date:
                            filtered.append(a)
                    attente = filtered
                stats["status_soumissions"]["en_attente"] = len(attente)

        perdus_path = os.path.join(base_cloud, "clients_perdus", username, "clients.json")
        if os.path.exists(perdus_path):
            with open(perdus_path, 'r', encoding='utf-8') as f:
                perdus = json.load(f)
                # Filtrer par p√©riode si n√©cessaire
                if start_date:
                    filtered = []
                    for p in perdus:
                        date_obj = parse_date_flexible(p.get("date", ""))
                        if date_obj and start_date <= date_obj <= end_date:
                            filtered.append(p)
                    perdus = filtered
                stats["status_soumissions"]["perdus"] = len(perdus)

        # 2. CHIFFRE D'AFFAIRES (calcul√© depuis ventes_acceptees + ventes_produit, comme la page Ventes)
        ca_actuel = 0.0

        # Additionner les ventes accept√©es
        acceptees_path = os.path.join(base_cloud, "ventes_acceptees", username, "ventes.json")
        if os.path.exists(acceptees_path):
            with open(acceptees_path, 'r', encoding='utf-8') as f:
                acceptees = json.load(f)
                for v in acceptees:
                    # Filtrer par p√©riode si n√©cessaire
                    if start_date:
                        date_obj = parse_date_flexible(v.get("date", ""))
                        if not date_obj or not (start_date <= date_obj <= end_date):
                            continue

                    # Nettoyer le prix (g√©rer espaces ins√©cables \xa0, espaces normaux, virgules fran√ßaises)
                    prix_str = str(v.get("prix", "0"))
                    prix_str = prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                    try:
                        ca_actuel += float(prix_str)
                    except:
                        continue

        # Additionner les ventes produit (travaux termin√©s)
        produit_path = os.path.join(base_cloud, "ventes_produit", username, "ventes.json")
        if os.path.exists(produit_path):
            with open(produit_path, 'r', encoding='utf-8') as f:
                produit = json.load(f)
                for v in produit:
                    # Filtrer par p√©riode si n√©cessaire
                    if start_date:
                        date_obj = parse_date_flexible(v.get("date", ""))
                        if not date_obj or not (start_date <= date_obj <= end_date):
                            continue

                    # Nettoyer le prix (g√©rer espaces ins√©cables \xa0, espaces normaux, virgules fran√ßaises)
                    prix_str = str(v.get("prix", "0"))
                    prix_str = prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                    try:
                        ca_actuel += float(prix_str)
                    except:
                        continue

        stats["chiffre_affaires"]["ca_actuel"] = round(ca_actuel, 2)

        # Objectif depuis RPO
        try:
            from QE.Backend.rpo import load_user_rpo_data
            rpo_data = load_user_rpo_data(username)
            objectif = float(rpo_data.get("annual", {}).get("objectif_ca", 0))
            stats["chiffre_affaires"]["objectif"] = round(objectif, 2)

            if objectif > 0:
                stats["chiffre_affaires"]["pourcentage"] = round((ca_actuel / objectif) * 100, 2)
        except:
            pass

        # 3. M√âTRIQUES - Utiliser RPO: contract_reel et dollar_reel
        try:
            from QE.Backend.rpo import load_user_rpo_data
            rpo_data = load_user_rpo_data(username)
            annual = rpo_data.get("annual", {})

            # Calculer heures PAP, contract_reel et estimation_reel depuis RPO weekly
            total_heures_pap = 0
            nombre_semaines_avec_data = 0
            contract_reel = 0
            dollar_reel = 0
            estimation_reel = 0
            weekly_data = rpo_data.get("weekly", {})

            # Filtrer par p√©riode si d√©finie
            if start_date:
                weekly_data = filter_rpo_weekly_by_period(weekly_data, start_date, end_date)

            for month_key, weeks in weekly_data.items():
                try:
                    month_num = int(month_key)
                    if month_num < 0:  # Exclure d√©cembre 2025 et avant
                        continue
                except:
                    continue

                for week_key, week_data in weeks.items():
                    # Heures marketing
                    h_marketing = week_data.get("h_marketing", 0)
                    try:
                        h_marketing_num = float(h_marketing) if h_marketing != '-' else 0
                        if h_marketing_num > 0:
                            total_heures_pap += h_marketing_num
                            nombre_semaines_avec_data += 1
                    except:
                        pass
                    # Contract (sign√©s avec paiement)
                    c = week_data.get("contract", 0)
                    if c and c != "-":
                        try:
                            contract_reel += int(float(c))
                        except:
                            pass
                    # Dollar
                    d = week_data.get("dollar", 0)
                    if d and d != "-":
                        try:
                            dollar_reel += float(d)
                        except:
                            pass
                    # Estimation
                    e = week_data.get("estimation", 0)
                    if e and e != "-":
                        try:
                            estimation_reel += int(float(e))
                        except:
                            pass

            # nb_estimations depuis RPO (source unique de v√©rit√©)
            # Fallback sur signees + perdues si pas dans RPO
            nb_estimations = estimation_reel if estimation_reel > 0 else (stats["status_soumissions"]["signees"] + stats["status_soumissions"]["perdus"])

            # Contrat moyen = dollar_reel / contract_reel
            if contract_reel > 0:
                stats["metriques"]["contrat_moyen"] = round(dollar_reel / contract_reel, 2)
            else:
                stats["metriques"]["contrat_moyen"] = 0

            # Taux de vente = contract_reel / nb_estimations * 100
            # Formule: Sign√©s avec paiement / (Sign√©s + Perdus)
            if nb_estimations > 0:
                stats["metriques"]["taux_vente"] = round((contract_reel / nb_estimations) * 100, 2)
            else:
                stats["metriques"]["taux_vente"] = 0

            # Taux marketing = Nb Estimations √∑ Heures PAP (estimations par heure)
            if total_heures_pap > 0:
                stats["metriques"]["taux_marketing"] = round(nb_estimations / total_heures_pap, 2)
            else:
                stats["metriques"]["taux_marketing"] = 0

            # Charger prod_horaire directement depuis RPO (comme le dashboard personnel)
            prod_horaire_rpo = float(annual.get("prod_horaire", 0))
            stats["metriques"]["prod_horaire"] = round(prod_horaire_rpo, 2)
            print(f"[OK] [CLASSEMENT] {username} - Taux vente: {stats['metriques']['taux_vente']}%, Taux marketing: {stats['metriques']['taux_marketing']} (estimations/h), Prod horaire: {stats['metriques']['prod_horaire']} $/h")
        except Exception as e:
            print(f"[WARNING] [CLASSEMENT] Erreur calcul m√©triques RPO pour {username}: {e}")
            import traceback
            print(f"   Stacktrace: {traceback.format_exc()}")

        # 4. SATISFACTION (AVIS/√âTOILES)
        reviews_path = os.path.join(base_cloud, "reviews", username, "reviews.json")
        if os.path.exists(reviews_path):
            try:
                with open(reviews_path, 'r', encoding='utf-8') as f:
                    reviews = json.load(f)
                    if reviews and len(reviews) > 0:
                        total_etoiles = sum(float(r.get("rating", 0)) for r in reviews)
                        nb_avis = len(reviews)
                        moyenne_etoiles = total_etoiles / nb_avis if nb_avis > 0 else 0.0

                        stats["satisfaction"]["etoiles_moyennes"] = round(moyenne_etoiles, 1)
                        stats["satisfaction"]["nombre_avis"] = nb_avis
            except Exception as e:
                print(f"[WARNING] Erreur lecture avis {username}: {e}")

    except Exception as e:
        print(f"[ERROR] Erreur calcul stats dashboard {username}: {e}")

    return stats


@app.get("/api/dashboard/{username}")
def get_dashboard_stats(username: str):
    """R√©cup√®re les statistiques du dashboard pour un utilisateur"""
    try:
        # Calculer et mettre √† jour les stats
        stats = calculate_dashboard_stats(username)
        save_user_dashboard_data(username, stats)
        return stats
    except Exception as e:
        print(f"[ERROR] Erreur API dashboard {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/dashboard/{username}/update")
def update_dashboard_stats(username: str):
    """Force la mise √† jour des statistiques du dashboard"""
    try:
        stats = calculate_dashboard_stats(username)
        save_user_dashboard_data(username, stats)
        return {"success": True, "stats": stats}
    except Exception as e:
        print(f"[ERROR] Erreur update dashboard {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/check-onboarding/{username}")
def check_onboarding_status(username: str):
    """V√©rifie si l'utilisateur a compl√©t√© l'onboarding"""
    try:
        # V√©rifier si le fichier user_info.json existe
        info_file = os.path.join(base_cloud, "signatures", username, "user_info.json")

        if os.path.exists(info_file):
            with open(info_file, 'r', encoding='utf-8') as f:
                user_info = json.load(f)

                # V√©rifier le flag onboarding_completed
                onboarding_completed = user_info.get("onboarding_completed", False)

                # Si le flag existe et est True, c'est compl√©t√©
                if onboarding_completed:
                    return {"completed": True}

                # R√âTROCOMPATIBILIT√â : Si le flag n'existe pas mais que pr√©nom + nom existent,
                # consid√©rer l'onboarding comme compl√©t√© (anciens comptes)
                prenom = user_info.get("prenom", "").strip()
                nom = user_info.get("nom", "").strip()

                if prenom and nom:
                    # Ancien compte avec infos compl√®tes, marquer comme compl√©t√©
                    print(f"[OK] [ONBOARDING] Compte ancien d√©tect√© pour {username}, marqu√© comme compl√©t√©")

                    # Mettre √† jour le fichier pour ajouter le flag
                    user_info["onboarding_completed"] = True
                    user_info["onboarding_date"] = datetime.now().isoformat()

                    with open(info_file, 'w', encoding='utf-8') as f_write:
                        json.dump(user_info, f_write, indent=2, ensure_ascii=False)

                    return {"completed": True}

        return {"completed": False}
    except Exception as e:
        print(f"[ERROR] Erreur check onboarding {username}: {e}")
        return {"completed": False}


@app.get("/api/guide-progress/{username}")
def get_user_guide_progress(username: str):
    """R√©cup√®re la progression du guide pour un utilisateur"""
    try:
        progress = get_guide_progress(username)
        if progress is None:
            # Initialiser la progression si elle n'existe pas
            init_guide_progress(username)
            return {
                "video_1": False,
                "video_2": False,
                "video_3": False,
                "video_4": False,
                "video_5": False,
                "completed": False,
                "completed_at": None
            }
        return progress
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration progression guide {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class VideoProgressData(BaseModel):
    username: str
    video_number: int


@app.post("/api/complete-video")
def mark_video_complete(data: VideoProgressData):
    """Marque une vid√©o comme compl√©t√©e"""
    try:
        success = update_video_progress(data.username, data.video_number)
        if success:
            # V√©rifier si toutes les vid√©os sont compl√©t√©es
            progress = get_guide_progress(data.username)
            if progress:
                all_videos_done = all([
                    progress.get("video_1", False),
                    progress.get("video_2", False),
                    progress.get("video_3", False),
                    progress.get("video_4", False),
                    progress.get("video_5", False)
                ])

                if all_videos_done:
                    mark_videos_completed(data.username)
                    print(f"[OK] Toutes les vid√©os compl√©t√©es pour {data.username}")

            return {"success": True}
        else:
            raise HTTPException(status_code=400, detail="Num√©ro de vid√©o invalide")
    except Exception as e:
        print(f"[ERROR] Erreur compl√©tion vid√©o {data.username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class GuideCompleteData(BaseModel):
    username: str


@app.post("/api/complete-guide")
def mark_guide_complete(data: GuideCompleteData):
    """Marque le guide comme compl√©t√©"""
    try:
        success = complete_guide(data.username)
        if success:
            # Marquer l'onboarding comme compl√©t√©
            mark_onboarding_completed(data.username)
            print(f"[OK] Onboarding compl√©t√© pour {data.username}")
            return {"success": True}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la compl√©tion du guide")
    except Exception as e:
        print(f"[ERROR] Erreur compl√©tion guide {data.username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/user-access/{username}")
def get_user_access(username: str):
    """V√©rifie si l'utilisateur a acc√®s complet (onboarding + vid√©os)"""
    try:
        access = check_user_access(username)
        return access
    except Exception as e:
        print(f"[ERROR] Erreur v√©rification acc√®s {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# [SUPPORT CHAT] Routes pour le chat de support

class SupportMessageData(BaseModel):
    username: str
    message: str
    is_admin: int = 0


@app.post("/api/support/send-message")
def send_message(data: SupportMessageData):
    """Envoie un message au support"""
    try:
        success = send_support_message(data.username, data.message, data.is_admin)
        if success:
            return {"success": True}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de l'envoi du message")
    except Exception as e:
        print(f"[ERROR] Erreur envoi message: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/support/messages/{username}")
def get_messages(username: str):
    """R√©cup√®re tous les messages d'un utilisateur"""
    try:
        messages = get_user_messages(username)
        return {"messages": messages}
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration messages: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/support/unread-count/{username}")
def get_unread_count(username: str):
    """Compte les nouveaux messages de l'admin pour cet utilisateur"""
    try:
        count = get_unread_messages_count(username)
        return {"count": count}
    except Exception as e:
        print(f"[ERROR] Erreur comptage messages non lus: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/support/all-conversations")
def get_conversations():
    """R√©cup√®re toutes les conversations (pour l'admin)"""
    try:
        conversations = get_all_support_conversations()
        return {"conversations": conversations}
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration conversations: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/support/mark-read/{username}")
def mark_read(username: str):
    """Marque les messages d'un utilisateur comme lus par l'admin"""
    try:
        success = mark_messages_as_read(username)
        if success:
            return {"success": True}
        else:
            raise HTTPException(status_code=500, detail="Erreur marquage messages lus")
    except Exception as e:
        print(f"[ERROR] Erreur marquage messages lus: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/support/conversation/{username}")
def delete_conv(username: str):
    """Supprime une conversation"""
    try:
        success = delete_conversation(username)
        if success:
            return {"success": True}
        else:
            raise HTTPException(status_code=500, detail="Erreur suppression conversation")
    except Exception as e:
        print(f"[ERROR] Erreur suppression conversation: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/support/resolve/{username}")
def resolve_conv(username: str):
    """Marque une conversation comme r√©solue"""
    try:
        success = mark_conversation_resolved(username)
        if success:
            return {"success": True}
        else:
            raise HTTPException(status_code=500, detail="Erreur marquage conversation r√©solue")
    except Exception as e:
        print(f"[ERROR] Erreur marquage conversation r√©solue: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/support/resolved-today")
def get_resolved_today():
    """R√©cup√®re le nombre de conversations r√©solues aujourd'hui"""
    try:
        count = get_resolved_today_count()
        return {"count": count}
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration r√©solutions: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/support/upload-attachment")
async def upload_attachment(
    username: str = Form(...),
    message: str = Form(...),
    file: UploadFile = File(...),
    is_admin: int = Form(0)
):
    """Upload un fichier image avec un message de support"""
    try:
        # Cr√©er le dossier pour stocker les fichiers
        upload_dir = os.path.join(base_cloud, "support_attachments", username)
        os.makedirs(upload_dir, exist_ok=True)

        # G√©n√©rer un nom de fichier unique
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_extension = os.path.splitext(file.filename)[1]
        filename = f"{timestamp}{file_extension}"
        file_path = os.path.join(upload_dir, filename)

        # Sauvegarder le fichier
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # Stocker le chemin relatif dans la base de donn√©es
        relative_path = f"support_attachments/{username}/{filename}"
        attachment_type = "image" if file.content_type.startswith("image/") else "file"

        # Enregistrer le message avec l'attachement
        success = send_support_message(username, message, is_admin, relative_path, attachment_type)

        if success:
            return {"success": True, "file_path": relative_path}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de l'envoi du message")
    except Exception as e:
        print(f"[ERROR] Erreur upload fichier: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# [FILE] Cr√©er un PDF

@app.post("/creer-pdf")
async def creer_pdf(data: SoumissionData, request: Request):
    utilisateur = request.query_params.get("username", "inconnu")
    
    # [DEBUG] DEBUG: Tracer le prix re√ßu par l'API
    print(f"[DEBUG] DEBUG API - Prix re√ßu dans SoumissionData: '{data.prix}' (type: {type(data.prix)})")

    user_folder = os.path.join(f"{base_cloud}/soumissions_completes", utilisateur)
    os.makedirs(user_folder, exist_ok=True)

    nom_fichier = f"soumission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    chemin_pdf = os.path.join(user_folder, nom_fichier)

    # Ajouter le username aux donn√©es pour la signature entrepreneur
    data_with_username = data.dict()
    data_with_username["username"] = utilisateur

    # R√©cup√©rer la langue de l'utilisateur
    user_language = 'fr'  # Par d√©faut fran√ßais
    try:
        account_file = os.path.join(base_cloud, "accounts", f"{utilisateur}.json")
        if os.path.exists(account_file):
            with open(account_file, 'r', encoding='utf-8') as f:
                account_data = json.load(f)
                user_language = account_data.get('language_preference', 'fr')
                print(f"[PDF] Langue utilisateur {utilisateur}: {user_language}")
    except Exception as e:
        print(f"[PDF] Erreur r√©cup√©ration langue utilisateur: {e}")

    # [DEBUG] DEBUG: Tracer le prix avant envoi au generate_pdf
    print(f"[DEBUG] DEBUG API - Prix dans data_with_username: '{data_with_username.get('prix')}' (type: {type(data_with_username.get('prix'))})")

    pdf_buffer: BytesIO = generate_pdf(data_with_username, language=user_language)
    with open(chemin_pdf, "wb") as f:
        f.write(pdf_buffer.getvalue())

    public_dir = os.path.join("cloud", "soumissions_completes", utilisateur)
    os.makedirs(public_dir, exist_ok=True)
    with open(os.path.join(public_dir, nom_fichier), "wb") as f_out:
        f_out.write(pdf_buffer.getvalue())

    lien_pdf = f"{BASE_URL}/cloud/soumissions_completes/{utilisateur}/{nom_fichier}"

    try:
        soumission_data = data.dict()
        soumission_data["pdf_url"] = lien_pdf  # Ajout du lien PDF ici

        enregistrer_soumission(utilisateur, soumission_data, lien_pdf)

        # AUSSI ajouter dans ventes_attente/ pour le nouveau syst√®me
        print(f"[PROCESSING] Ajout dans ventes_attente pour {utilisateur}...")
        soumission_id = str(uuid.uuid4())
        num_soumission = soumission_data.get("num", datetime.now().strftime("%Y%m%d%H%M%S"))

        ventes_dir = os.path.join(f"{base_cloud}/ventes_attente", utilisateur)
        os.makedirs(ventes_dir, exist_ok=True)
        print(f"[FILE] Dossier ventes_attente cr√©√©: {ventes_dir}")

        # Copier le PDF dans ventes_attente
        ventes_pdf_path = os.path.join(ventes_dir, nom_fichier)
        with open(ventes_pdf_path, "wb") as f:
            f.write(pdf_buffer.getvalue())
        print(f"[PDF] PDF copie: {ventes_pdf_path}")

        # Cr√©er objet vente
        vente = {
            "id": soumission_id,
            "num": num_soumission,
            "prenom": soumission_data.get("prenom", ""),
            "nom": soumission_data.get("nom", ""),
            "telephone": soumission_data.get("telephone", ""),
            "adresse": soumission_data.get("adresse", ""),
            "courriel": soumission_data.get("courriel", ""),
            "prix": soumission_data.get("prix", ""),
            "depot": soumission_data.get("depot", ""),
            "date": soumission_data.get("date", datetime.now().strftime("%Y-%m-%d")),
            "date2": soumission_data.get("date2", ""),
            "item": soumission_data.get("item", ""),
            "temps": soumission_data.get("temps", ""),
            "endroit": soumission_data.get("endroit", ""),
            "produit": soumission_data.get("produit", ""),
            "part": soumission_data.get("part", ""),
            "payer_par": soumission_data.get("payer_par", ""),
            "pdf_url": lien_pdf,
            "lien_calcul": soumission_data.get("lien_calcul", None),
            "date_soumission": datetime.now().isoformat()
        }
        print(f"[VENTE] Objet vente cree: {vente['prenom']} {vente['nom']} - {vente['id']}")

        # Sauvegarder dans ventes_attente/ventes.json
        fichier_ventes = os.path.join(ventes_dir, "ventes.json")
        ventes = []
        if os.path.exists(fichier_ventes):
            print(f"[INFO] Lecture fichier existant: {fichier_ventes}")
            with open(fichier_ventes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    ventes = json.loads(content)
                    print(f"[DATA] {len(ventes)} ventes existantes trouv√©es")
        else:
            print(f"[NOTE] Cr√©ation nouveau fichier: {fichier_ventes}")

        ventes.append(vente)
        print(f"[ADD] Ajout de la vente (total: {len(ventes)} ventes)")

        with open(fichier_ventes, "w", encoding="utf-8") as f:
            json.dump(ventes, f, ensure_ascii=False, indent=2)
        print(f"[SAVE] Fichier sauvegard√©: {fichier_ventes}")

        print(f"[OK] Soumission ajout√©e dans ventes_attente pour {utilisateur}")

        # Retirer le client des prospects s'il y √©tait ET ajouter √† la blacklist du calendrier
        try:
            print(f"[PROSPECTS] V√©rification et suppression du prospect: {vente['prenom']} {vente['nom']}")
            prospects_file = os.path.join(f"{base_cloud}/prospects", utilisateur, "prospects.json")
            if os.path.exists(prospects_file):
                with open(prospects_file, "r", encoding="utf-8") as f:
                    prospects = json.load(f)

                # Trouver et retirer le prospect correspondant
                prospect_trouve = None
                prospects_filtered = []
                for p in prospects:
                    if (p.get("prenom", "").strip().lower() == vente['prenom'].strip().lower() and
                        p.get("nom", "").strip().lower() == vente['nom'].strip().lower() and
                        p.get("adresse", "").strip().lower() == vente['adresse'].strip().lower()):
                        prospect_trouve = p
                    else:
                        prospects_filtered.append(p)

                if prospect_trouve:
                    # Sauvegarder les prospects sans celui trouv√©
                    with open(prospects_file, "w", encoding="utf-8") as f:
                        json.dump(prospects_filtered, f, ensure_ascii=False, indent=2)
                    print(f"[OK] Prospect {vente['prenom']} {vente['nom']} retir√© de la liste des prospects")

                    # SYNC: Ajouter l'ID du prospect √† la blacklist du calendrier
                    prospect_id = prospect_trouve.get("id")
                    if prospect_id and (prospect_trouve.get("source") == "google_calendar" or not str(prospect_id).count("-") == 4):
                        blacklist_dir = f"{base_cloud}/blacklist"
                        os.makedirs(blacklist_dir, exist_ok=True)
                        blacklist_file = os.path.join(blacklist_dir, f"{utilisateur}.json")

                        ids = []
                        if os.path.exists(blacklist_file):
                            with open(blacklist_file, "r", encoding="utf-8") as f:
                                ids = json.load(f)

                        if prospect_id not in ids:
                            ids.append(prospect_id)
                            with open(blacklist_file, "w", encoding="utf-8") as f:
                                json.dump(ids, f, indent=2)
                            print(f"[SYNC] Event ID {prospect_id} ajout√© √† la blacklist calendrier")
                else:
                    print(f"[INFO] Client n'√©tait pas dans les prospects")
        except Exception as e:
            print(f"[WARNING] Erreur lors de la suppression du prospect: {e}")

    except Exception as e:
        print("Erreur lors de l'enregistrement de la soumission :", e)
        raise HTTPException(status_code=500, detail="Erreur lors de l'enregistrement de la soumission")

    return JSONResponse({
        "lien_pdf": lien_pdf,
        "id": soumission_id,
        "num": num_soumission
    })

@app.post("/ajouter-prospect")
async def ajouter_prospect(data: ProspectData):
    """
    Ajoute un nouveau prospect pour un utilisateur
    """
    try:
        utilisateur = data.username
        
        # Cr√©er le dossier utilisateur pour les prospects
        user_folder = os.path.join(f"{base_cloud}/prospects", utilisateur)
        os.makedirs(user_folder, exist_ok=True)
        
        fichier_prospects = os.path.join(user_folder, "prospects.json")
        
        # Charger les prospects existants
        prospects_existants = []
        if os.path.exists(fichier_prospects):
            with open(fichier_prospects, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    prospects_existants = json.loads(content)
        
        # Cr√©er le nouveau prospect avec un ID unique
        nouveau_prospect = {
            "id": str(uuid.uuid4()),
            "prenom": data.prenom,
            "nom": data.nom,
            "telephone": data.telephone,
            "adresse": data.adresse,
            "date_ajout": datetime.now().isoformat(),
            "statut": "client_potentiel"
        }
        
        # Ajouter le nouveau prospect
        prospects_existants.append(nouveau_prospect)
        
        # Sauvegarder
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump(prospects_existants, f, indent=2, ensure_ascii=False)
        
        print(f"[OK] Prospect ajout√©: {data.prenom} {data.nom} pour {utilisateur}")
        
        return JSONResponse({
            "success": True, 
            "message": f"Prospect {data.prenom} {data.nom} ajout√© avec succ√®s",
            "prospect": nouveau_prospect
        })
        
    except Exception as e:
        print(f"[ERROR] Erreur lors de l'ajout du prospect: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'ajout du prospect: {str(e)}")

@app.get("/prospects/{username}")
def get_prospects(username: str):
    """
    R√©cup√®re tous les prospects d'un utilisateur.
    Synchronise d'abord les √©v√©nements futurs du calendrier Google vers les prospects.
    """
    import zoneinfo

    # ==========================================
    # SYNC: R√©cup√©rer tous les √©v√©nements futurs du calendrier et les ajouter aux prospects
    # ==========================================
    try:
        agenda_file = os.path.join(base_cloud, "tokens", f"{username}_agenda.json")
        if os.path.exists(agenda_file):
            local_tz = zoneinfo.ZoneInfo("America/Toronto")
            now_local = datetime.now(tz=local_tz)

            access_token = get_valid_token(username)
            headers = {"Authorization": f"Bearer {access_token}"}

            with open(agenda_file, "r") as f:
                agenda_id = json.load(f).get("agenda_id")

            if agenda_id:
                # R√©cup√©rer tous les √©v√©nements futurs (1 an)
                time_min = now_local.astimezone(zoneinfo.ZoneInfo("UTC")).isoformat().replace("+00:00", "Z")
                future_date = now_local + timedelta(days=365)
                time_max = future_date.astimezone(zoneinfo.ZoneInfo("UTC")).isoformat().replace("+00:00", "Z")

                url = f"https://www.googleapis.com/calendar/v3/calendars/{agenda_id}/events"
                params = {
                    "timeMin": time_min,
                    "timeMax": time_max,
                    "singleEvents": True,
                    "orderBy": "startTime",
                    "maxResults": 500
                }

                r = requests.get(url, headers=headers, params=params)
                if r.status_code == 200:
                    all_events = r.json().get("items", [])
                    blacklisted_ids = get_blacklisted_ids(username)
                    filtered_events = filter_calendar_events(all_events, blacklisted_ids)
                    sync_events_to_prospects(username, filtered_events)
                    print(f"[SYNC] {len(filtered_events)} √©v√©nements futurs synchronis√©s pour {username}")
    except Exception as e:
        print(f"[WARNING] Erreur sync calendrier pour {username}: {e}")
        # Continue quand m√™me pour retourner les prospects existants

    # ==========================================
    # Charger et retourner les prospects
    # ==========================================
    prospects_dir = os.path.join(f"{base_cloud}/prospects", username)
    fichier_prospects = os.path.join(prospects_dir, "prospects.json")

    # Cr√©er le dossier et le fichier s'ils n'existent pas
    if not os.path.exists(fichier_prospects):
        os.makedirs(prospects_dir, exist_ok=True)
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump([], f)
        return []

    try:
        with open(fichier_prospects, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            prospects = json.loads(content)
            return prospects
    except Exception as e:
        print(f"[ERROR] Erreur lors du chargement des prospects pour {username}: {e}")
        return []

@app.post("/supprimer-prospect")
async def supprimer_prospect_by_id(data: dict = Body(...)):
    """
    Supprime un prospect par ID
    Synchronis√© avec le calendrier Google: si le prospect vient du calendrier,
    il sera aussi ajout√© √† la blacklist pour ne plus appara√Ætre dans les √©v√©nements
    """
    try:
        username = data.get("username")
        prospect_id = data.get("id")

        if not username or not prospect_id:
            raise HTTPException(status_code=400, detail="Username et ID requis")

        fichier_prospects = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")

        if not os.path.exists(fichier_prospects):
            raise HTTPException(status_code=404, detail="Aucun fichier prospects trouv√©")

        with open(fichier_prospects, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                prospects = []
            else:
                prospects = json.loads(content)

        # Trouver le prospect √† supprimer pour v√©rifier sa source
        prospect_supprime = None
        nouveaux_prospects = []
        for p in prospects:
            if p.get('id') == prospect_id:
                prospect_supprime = p
            else:
                nouveaux_prospects.append(p)

        if not prospect_supprime:
            print(f"[WARNING] Aucun prospect trouv√© avec ID: {prospect_id}")
            return JSONResponse({"success": False, "message": "Prospect non trouv√©"})

        # Sauvegarder la liste mise √† jour
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump(nouveaux_prospects, f, indent=2, ensure_ascii=False)

        # SYNCHRONISATION: Ajouter √† la blacklist si c'est un √©v√©nement Google Calendar
        # (Les IDs Google Calendar ne sont pas des UUIDs standards)
        if prospect_supprime.get("source") == "google_calendar" or not prospect_id.count("-") == 4:
            blacklist_dir = f"{base_cloud}/blacklist"
            os.makedirs(blacklist_dir, exist_ok=True)
            blacklist_file = os.path.join(blacklist_dir, f"{username}.json")

            ids = []
            if os.path.exists(blacklist_file):
                with open(blacklist_file, "r", encoding="utf-8") as f:
                    ids = json.load(f)

            if prospect_id not in ids:
                ids.append(prospect_id)
                with open(blacklist_file, "w", encoding="utf-8") as f:
                    json.dump(ids, f, indent=2)
                print(f"[SYNC] Event ID {prospect_id} ajout√© √† la blacklist pour {username}")

        print(f"[OK] Prospect supprim√©: {prospect_id} pour {username}")
        return JSONResponse({"success": True, "message": "Prospect supprim√© avec succ√®s"})

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur lors de la suppression du prospect: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/prospects/{username}/{prospect_id}/perdu")
async def marquer_prospect_perdu(username: str, prospect_id: str):
    """
    Marque un prospect (client potentiel) comme perdu.

    Actions:
    1. Si le prospect a un num√©ro de soumission (num), l'ajoute dans soumissions_completes
    2. Ajoute le prospect dans clients_perdus
    3. Si c'est un √©v√©nement Google Calendar, l'ajoute √† la blacklist
    4. Supprime le prospect de la liste des prospects
    5. D√©clenche le sync RPO pour mettre √† jour estimation_reel
    """
    try:
        print(f"[PERDU] Marquage prospect comme perdu: {prospect_id} pour {username}")

        fichier_prospects = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")

        if not os.path.exists(fichier_prospects):
            raise HTTPException(status_code=404, detail="Aucun fichier prospects trouv√©")

        with open(fichier_prospects, "r", encoding="utf-8") as f:
            content = f.read().strip()
            prospects = json.loads(content) if content else []

        # Trouver le prospect
        prospect_trouve = None
        nouveaux_prospects = []
        for p in prospects:
            if p.get('id') == prospect_id:
                prospect_trouve = p
            else:
                nouveaux_prospects.append(p)

        if not prospect_trouve:
            raise HTTPException(status_code=404, detail=f"Prospect non trouv√©: {prospect_id}")

        # 1. TOUJOURS AJOUTER DANS SOUMISSIONS_COMPLETES (m√™me sans num√©ro de soumission)
        # Car l'estimation a √©t√© faite (montr√©e au client), m√™me si pas de PDF envoy√©
        num_soumission = prospect_trouve.get("num")
        prospect_id_value = prospect_trouve.get("id")

        soumissions_dir = os.path.join(base_cloud, "soumissions_completes", username)
        os.makedirs(soumissions_dir, exist_ok=True)
        soumissions_file = os.path.join(soumissions_dir, "soumissions.json")

        soumissions = []
        if os.path.exists(soumissions_file):
            with open(soumissions_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                soumissions = json.loads(content) if content else []

        # V√©rifier si la soumission n'existe pas d√©j√† (par num OU par id)
        existe_deja = any(
            (num_soumission and s.get("num") == num_soumission) or
            s.get("id") == prospect_id_value
            for s in soumissions
        )

        if not existe_deja:
            # Cr√©er l'entr√©e soumission √† partir du prospect
            soumission_entry = {
                "id": prospect_id_value,
                "num": num_soumission if num_soumission else f"POT-{prospect_id_value[:8]}",  # G√©n√©rer un num si absent
                "nom": prospect_trouve.get("nom", ""),
                "prenom": prospect_trouve.get("prenom", ""),
                "courriel": prospect_trouve.get("courriel", prospect_trouve.get("email", "")),
                "telephone": prospect_trouve.get("telephone", ""),
                "adresse": prospect_trouve.get("adresse", ""),
                "date": prospect_trouve.get("date", datetime.now().strftime("%d/%m/%Y")),
                "prix": prospect_trouve.get("prix", "0"),
                "endroit": prospect_trouve.get("type_travaux", prospect_trouve.get("endroit", "")),
                "produit": prospect_trouve.get("produit", ""),
                "statut": "perdu",
                "source": "potentiel"  # Marquer la source
            }
            soumissions.append(soumission_entry)

            with open(soumissions_file, "w", encoding="utf-8") as f:
                json.dump(soumissions, f, ensure_ascii=False, indent=2)
            print(f"[PERDU] Estimation {soumission_entry['num']} ajout√©e dans soumissions_completes")

        # 2. AJOUTER DANS CLIENTS_PERDUS
        perdus_dir = os.path.join(base_cloud, "clients_perdus", username)
        os.makedirs(perdus_dir, exist_ok=True)
        perdus_file = os.path.join(perdus_dir, "clients.json")

        clients_perdus = []
        if os.path.exists(perdus_file):
            with open(perdus_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                clients_perdus = json.loads(content) if content else []

        # Ajouter le prospect comme client perdu
        prospect_trouve["date_perdu"] = datetime.now().isoformat()
        prospect_trouve["statut"] = "perdu"
        prospect_trouve["category_origine"] = "potentiel"
        clients_perdus.append(prospect_trouve)

        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus, f, ensure_ascii=False, indent=2)
        print(f"[PERDU] Client ajout√© dans clients_perdus")

        # 3. BLACKLISTER SI C'EST UN √âV√âNEMENT GOOGLE CALENDAR
        # Les IDs Google Calendar ne sont pas des UUIDs standards (pas 5 segments s√©par√©s par des tirets)
        is_calendar_event = prospect_trouve.get("source") == "google_calendar" or prospect_id.count("-") != 4
        if is_calendar_event:
            blacklist_dir = f"{base_cloud}/blacklist"
            os.makedirs(blacklist_dir, exist_ok=True)
            blacklist_file = os.path.join(blacklist_dir, f"{username}.json")

            ids = []
            if os.path.exists(blacklist_file):
                with open(blacklist_file, "r", encoding="utf-8") as f:
                    ids = json.load(f)

            if prospect_id not in ids:
                ids.append(prospect_id)
                with open(blacklist_file, "w", encoding="utf-8") as f:
                    json.dump(ids, f, indent=2)
                print(f"[PERDU] Event ID {prospect_id} ajout√© √† la blacklist")

        # 4. SUPPRIMER DES PROSPECTS
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump(nouveaux_prospects, f, indent=2, ensure_ascii=False)

        # 5. SYNC RPO pour mettre √† jour estimation_reel
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo
            sync_soumissions_to_rpo(username)
            print(f"[PERDU] RPO synchronis√© pour {username}")
        except Exception as e:
            print(f"[WARNING] Erreur sync RPO: {e}")

        client_nom = f"{prospect_trouve.get('prenom', '')} {prospect_trouve.get('nom', '')}".strip()
        print(f"[OK] Prospect {client_nom} marqu√© comme perdu")

        return JSONResponse({
            "success": True,
            "message": f"Client {client_nom} marqu√© comme perdu",
            "added_to_soumissions": True,  # Toujours ajout√© maintenant
            "blacklisted": is_calendar_event
        })

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur marquage prospect perdu: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/supprimer-prospect/{username}")
async def supprimer_prospect(username: str, prospect_data: dict):
    """
    Supprime un prospect par correspondance nom/pr√©nom/t√©l√©phone
    """
    try:
        fichier_prospects = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        
        if not os.path.exists(fichier_prospects):
            raise HTTPException(status_code=404, detail="Aucun fichier prospects trouv√©")
        
        with open(fichier_prospects, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                prospects = []
            else:
                prospects = json.loads(content)
        
        # Chercher le prospect correspondant
        prospect_trouve = None
        nouveaux_prospects = []
        
        for prospect in prospects:
            # Correspondance par nom, pr√©nom et t√©l√©phone (ignorer la casse)
            if (prospect.get('nom', '').strip().lower() == prospect_data.get('nom', '').strip().lower() and
                prospect.get('prenom', '').strip().lower() == prospect_data.get('prenom', '').strip().lower() and
                prospect.get('telephone', '').strip() == prospect_data.get('telephone', '').strip()):
                prospect_trouve = prospect
                print(f"[OK] Prospect trouv√© pour suppression: {prospect.get('prenom')} {prospect.get('nom')} - {prospect.get('telephone')}")
            else:
                nouveaux_prospects.append(prospect)
        
        if not prospect_trouve:
            print(f"[WARNING] Aucun prospect trouv√© pour suppression: {prospect_data.get('prenom')} {prospect_data.get('nom')} - {prospect_data.get('telephone')}")
            return JSONResponse({"success": False, "message": "Prospect non trouv√©"})
        
        # Sauvegarder la liste mise √† jour
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump(nouveaux_prospects, f, indent=2, ensure_ascii=False)
        
        print(f"[DELETE] Prospect supprim√© avec succ√®s: {prospect_trouve.get('prenom')} {prospect_trouve.get('nom')}")
        return JSONResponse({
            "success": True, 
            "message": f"Prospect {prospect_trouve.get('prenom')} {prospect_trouve.get('nom')} supprim√© avec succ√®s",
            "prospect_supprime": prospect_trouve
        })
        
    except Exception as e:
        print(f"[ERROR] Erreur lors de la suppression du prospect: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la suppression du prospect: {str(e)}")

@app.post("/deplacer-accepte-vers-produits")
async def deplacer_accepte_vers_produits(data: dict):
    """
    D√©place un client accept√© (soumissions_signees) vers produits (travaux_completes)
    """
    try:
        username = data.get("username")
        prenom = data.get("prenom", "")
        nom = data.get("nom", "")
        telephone = data.get("telephone", "")
        
        if not username:
            raise HTTPException(status_code=400, detail="Username requis")
        
        print(f"[PROD] D√©but d√©placement accept√© vers produits pour {username}: {prenom} {nom}")
        
        # Charger les travaux √† compl√©ter (l√† o√π se trouvent vraiment les clients √† cl√¥turer)
        fichier_travaux_ac = os.path.join(f"{base_cloud}/travaux_a_completer", username, "soumissions.json")
        if not os.path.exists(fichier_travaux_ac):
            raise HTTPException(status_code=404, detail="Aucun travail √† compl√©ter trouv√©")

        with open(fichier_travaux_ac, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                travaux_a_completer = []
            else:
                travaux_a_completer = json.loads(content)

        print(f"[BAN] Charg√© {len(travaux_a_completer)} travaux √† compl√©ter")
        print(f"[DEBUG] Recherche client: '{prenom}' '{nom}' '{telephone}'")

        # Debug: afficher tous les clients dans travaux_a_completer
        for i, t in enumerate(travaux_a_completer):
            t_prenom = t.get("prenom", t.get("clientPrenom", "")).strip()
            t_nom = t.get("nom", t.get("clientNom", "")).strip()
            t_telephone = t.get("telephone", t.get("phone", "")).strip()
            print(f"  Client {i+1}: '{t_prenom}' '{t_nom}' '{t_telephone}' (ID: {t.get('id', 'N/A')})")

        # Trouver le client correspondant par nom/pr√©nom/t√©l√©phone
        client_trouve = None
        travaux_restants = []

        for soumission in travaux_a_completer:
            soum_prenom = soumission.get("prenom", soumission.get("clientPrenom", "")).strip()
            soum_nom = soumission.get("nom", soumission.get("clientNom", "")).strip()
            soum_telephone = soumission.get("telephone", soumission.get("phone", "")).strip()

            # Nettoyer aussi les donn√©es de recherche
            prenom_clean = prenom.strip()
            nom_clean = nom.strip()
            telephone_clean = telephone.strip()
            
            # Debug de comparaison d√©taill√©e
            prenom_match = soum_prenom.lower() == prenom_clean.lower()
            nom_match = soum_nom.lower() == nom_clean.lower()
            tel_match = soum_telephone == telephone_clean

            print(f"  Comparaison: '{soum_prenom}' vs '{prenom_clean}' (prenom: {prenom_match})")
            print(f"               '{soum_nom}' vs '{nom_clean}' (nom: {nom_match})")
            print(f"               '{soum_telephone}' vs '{telephone_clean}' (tel: {tel_match})")

            if (prenom_match and nom_match and tel_match):
                client_trouve = soumission
                print(f"[OK] Client trouv√©: {soum_prenom} {soum_nom} - {soum_telephone}")
            else:
                print(f"[ERROR] Pas de match complet")
                travaux_restants.append(soumission)

        if not client_trouve:
            print(f"[WARNING] Client non trouv√© dans travaux √† compl√©ter: {prenom} {nom} - {telephone}")
            raise HTTPException(status_code=404, detail="Client non trouv√© dans les travaux √† compl√©ter")
        
        # Ajouter date de completion
        from datetime import datetime, timedelta
        now_utc = datetime.utcnow()
        now_utc_minus_4 = now_utc - timedelta(hours=4)
        client_trouve["date"] = now_utc_minus_4.isoformat()
        client_trouve["date_completion"] = data.get("date_completion", now_utc_minus_4.isoformat())

        # Ajouter statut_paiement par d√©faut si non pr√©sent
        if "statut_paiement" not in client_trouve:
            client_trouve["statut_paiement"] = "En attente"

        # Charger les travaux compl√©t√©s
        dossier_completes = os.path.join(f"{base_cloud}/travaux_completes", username)
        os.makedirs(dossier_completes, exist_ok=True)
        fichier_completes = os.path.join(dossier_completes, "soumissions.json")
        
        if os.path.exists(fichier_completes):
            with open(fichier_completes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    travaux_completes = json.loads(content)
                else:
                    travaux_completes = []
        else:
            travaux_completes = []
        
        # √âviter les doublons
        client_id = client_trouve.get("id", client_trouve.get("num", ""))
        ids_existants = {t.get("id", t.get("num", "")) for t in travaux_completes}
        
        if client_id not in ids_existants:
            travaux_completes.append(client_trouve)
            print(f"[PACKAGE] Client ajout√© aux travaux compl√©t√©s")
        else:
            print(f"[WARNING] Client d√©j√† pr√©sent dans travaux compl√©t√©s")
        
        # Sauvegarder les modifications
        # 1. Supprimer le client de travaux_a_completer (sauvegarder les travaux restants)
        with open(fichier_travaux_ac, "w", encoding="utf-8") as f:
            json.dump(travaux_restants, f, indent=2, ensure_ascii=False)
        print(f"[DELETE] Client supprim√© des travaux √† compl√©ter")
        
        # 2. Ajouter √† travaux_completes
        with open(fichier_completes, "w", encoding="utf-8") as f:
            json.dump(travaux_completes, f, indent=2, ensure_ascii=False)

        # 3. Mettre √† jour le chiffre d'affaires (comme dans cloturer-travail)
        try:
            prix_str = str(client_trouve.get("prix", "0")).replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
            prix = float(prix_str)
            ajouter_au_chiffre_affaires(username, prix)
            print(f"[MONEY] Chiffre d'affaires mis √† jour: +{prix}$")
        except Exception as e:
            print(f"[ERREUR] conversion/ajout prix: {e}")

        print(f"[OK] D√©placement r√©ussi: {prenom} {nom} -> Produits")
        
        return JSONResponse({
            "success": True,
            "message": f"Client {prenom} {nom} d√©plac√© avec succ√®s vers Produits",
            "client_deplace": {
                "prenom": prenom,
                "nom": nom,
                "telephone": telephone
            }
        })
        
    except Exception as e:
        print(f"[ERROR] Erreur lors du d√©placement accept√© vers produits: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du d√©placement: {str(e)}")

@app.post("/preview-pdf")
async def preview_pdf(data: SoumissionData, request: Request):
    utilisateur = request.query_params.get("username", "inconnu")
    print(f"[DEBUG] DEBUG PREVIEW: Username depuis query params: '{utilisateur}'")
    print(f"[DEBUG] DEBUG PREVIEW: Query params complets: {dict(request.query_params)}")
    
    # [DEBUG] DEBUG: Tracer le prix re√ßu par l'API preview
    print(f"[DEBUG] DEBUG PREVIEW - Prix re√ßu dans SoumissionData: '{data.prix}' (type: {type(data.prix)})")
    
    # Ajouter le username aux donn√©es pour la signature entrepreneur
    data_with_username = data.dict()
    data_with_username["username"] = utilisateur
    print(f"[DEBUG] DEBUG PREVIEW: Username ajout√© aux data: '{data_with_username.get('username')}'")
    
    # [DEBUG] DEBUG: Tracer le prix avant envoi au generate_pdf
    print(f"[DEBUG] DEBUG PREVIEW - Prix dans data_with_username: '{data_with_username.get('prix')}' (type: {type(data_with_username.get('prix'))})")

    # [DEBUG] DEBUG: Tracer produit et part
    print(f"[DEBUG] DEBUG PREVIEW - PRODUIT re√ßu: {repr(data_with_username.get('produit'))}")
    print(f"[DEBUG] DEBUG PREVIEW - PART re√ßu: {repr(data_with_username.get('part'))}")

    # R√©cup√©rer la langue de l'utilisateur
    user_language = 'fr'  # Par d√©faut fran√ßais
    try:
        account_file = os.path.join(base_cloud, "accounts", f"{utilisateur}.json")
        if os.path.exists(account_file):
            with open(account_file, 'r', encoding='utf-8') as f:
                account_data = json.load(f)
                user_language = account_data.get('language_preference', 'fr')
                print(f"[PREVIEW] Langue utilisateur {utilisateur}: {user_language}")
    except Exception as e:
        print(f"[PREVIEW] Erreur r√©cup√©ration langue utilisateur: {e}")

    pdf_buffer: BytesIO = generate_pdf(data_with_username, language=user_language)
    return StreamingResponse(pdf_buffer, media_type="application/pdf", headers={
        "Content-Disposition": f"inline; filename=soumission_preview.pdf"
    })


# [DATA] Cr√©er un PDF depuis le calculateur
@app.post("/creer-pdf-calculateur")
async def creer_pdf_calculateur(data: CalculateurData):
    """
    G√©n√®re un PDF depuis le calculateur Qwota avec cr√©ation automatique de projet
    """
    try:
        utilisateur = data.username
        
        # Cr√©er le dossier utilisateur dans pdfcalcul
        user_folder = os.path.join(f"{base_cloud}/pdfcalcul", utilisateur)
        os.makedirs(user_folder, exist_ok=True)
        
        # G√©n√©rer nom de fichier unique
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        client_name = data.client.get("name", "client").replace(" ", "_")[:20]
        nom_fichier = f"calculateur_{client_name}_{timestamp}.pdf"
        chemin_pdf = os.path.join(user_folder, nom_fichier)

        # R√©cup√©rer la langue de l'utilisateur
        user_language = 'fr'  # Par d√©faut fran√ßais
        try:
            account_file = os.path.join(base_cloud, "accounts", f"{utilisateur}.json")
            if os.path.exists(account_file):
                with open(account_file, 'r', encoding='utf-8') as f:
                    account_data = json.load(f)
                    user_language = account_data.get('language_preference', 'fr')
                    print(f"[PDF] Langue utilisateur {utilisateur}: {user_language}")
        except Exception as e:
            print(f"[PDF] Erreur r√©cup√©ration langue utilisateur: {e}")

        # G√©n√©rer le PDF avec la langue appropri√©e
        pdf_buffer = generate_calcul_pdf(data.dict(), language=user_language)
        
        # Sauvegarder le fichier
        with open(chemin_pdf, "wb") as f:
            f.write(pdf_buffer.getvalue())
        
        # URL du PDF
        lien_pdf = f"/cloud/pdfcalcul/{utilisateur}/{nom_fichier}"
        
        # Cr√©er automatiquement un projet
        try:
            project_data = {
                "client": data.client.get("name", ""),
                "adresse": data.client.get("address", ""),
                "telephone": data.client.get("phone", ""),
                "date": data.client.get("date", datetime.now().strftime("%Y-%m-%d")),
                "totalExterieur": float(data.costs.get("totalExterieur", 0)),
                "totalInterieur": float(data.costs.get("totalInterieur", 0)),
                "formData": {
                    "surfaces": data.surfaces,
                    "product": data.product,
                    "hours": data.hours,
                    "parameters": data.parameters,
                    "costs": data.costs
                }
            }
            
            # Cr√©er le projet via project_manager
            if project_data["client"].strip():
                project = create_project(utilisateur, project_data)
                print(f"[OK] Projet cr√©√© automatiquement: {project['id']}")
            
        except Exception as e:
            print(f"[WARNING] Erreur cr√©ation projet: {e}")
            # Continuer m√™me si la cr√©ation de projet √©choue
        
        # Enregistrer dans les PDFs calculateur (s√©par√© des soumissions)
        pdf_data = {
            "client_nom": data.client.get("name", ""),
            "client_telephone": data.client.get("phone", ""),
            "client_adresse": data.client.get("address", ""),
            "date_estimation": data.client.get("date", ""),
            "prix_total": data.costs.get("totalExterieur", 0) + data.costs.get("totalInterieur", 0),
            "total_exterieur": data.costs.get("totalExterieur", 0),
            "total_interieur": data.costs.get("totalInterieur", 0),
            "type": "calculateur",
            "timestamp": timestamp,
            "nom_fichier": nom_fichier,
            "details": {
                "surfaces": data.surfaces,
                "product": data.product,
                "hours": data.hours,
                "parameters": data.parameters,
                "costs": data.costs
            }
        }
        
        enregistrer_pdf_calculateur(utilisateur, pdf_data, lien_pdf)
        
        # Retourner le PDF en streaming pour t√©l√©chargement
        pdf_buffer.seek(0)
        return StreamingResponse(
            pdf_buffer, 
            media_type="application/pdf", 
            headers={
                "Content-Disposition": f"attachment; filename={nom_fichier}",
                "X-PDF-URL": lien_pdf  # URL pour acc√®s ult√©rieur
            }
        )
        
    except Exception as e:
        print(f"[ERROR] Erreur g√©n√©ration PDF calculateur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur g√©n√©ration PDF: {str(e)}")


# [FILE] R√©cup√©rer les soumissions
@app.get("/soumissions/{username}")
def get_soumissions(username: str):
    fichier = os.path.join(f"{base_cloud}/soumissions_completes", username, "soumissions.json")
    if not os.path.exists(fichier):
        return []
    with open(fichier, "r", encoding="utf-8") as f:
        content = f.read().strip()
        if not content:
            return []
        return json.loads(content)

# üîó Google OAuth2
CLIENT_ID = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
REDIRECT_URI = os.getenv("REDIRECT_URI")  # Pour calendrier
GMAIL_REDIRECT_URI = os.getenv("GMAIL_REDIRECT_URI", f"{BASE_URL}/gmail/callback")  # Pour Gmail
SCOPES = [
    "https://www.googleapis.com/auth/calendar.readonly",
    "https://www.googleapis.com/auth/userinfo.email",
    "openid"
]

@app.get("/connect-google")
def connect_google(username: str, return_url: bool = False):
    params = {
        "client_id": CLIENT_ID,
        "redirect_uri": REDIRECT_URI,
        "response_type": "code",
        "scope": " ".join(SCOPES),
        "access_type": "offline",
        "prompt": "consent",
        "state": username
    }
    url = "https://accounts.google.com/o/oauth2/v2/auth?" + urllib.parse.urlencode(params)
    print(f"[DEBUG CALENDAR] OAuth URL: {url}")

    # Si return_url=true, retourner l'URL au lieu de rediriger
    if return_url:
        return {"oauth_url": url}
    else:
        return RedirectResponse(url)

@app.get("/oauth2callback")
def oauth2callback(code: str = Query(...), state: str = Query(...)):
    token_url = "https://oauth2.googleapis.com/token"
    data = {
        "code": code,
        "client_id": CLIENT_ID,
        "client_secret": CLIENT_SECRET,
        "redirect_uri": REDIRECT_URI,
        "grant_type": "authorization_code"
    }

    response = requests.post(token_url, data=data)
    if response.status_code != 200:
        raise HTTPException(status_code=400, detail="Erreur lors de l'√©change du code")

    tokens = response.json()

    dossier = os.path.join(base_cloud, "tokens")
    os.makedirs(dossier, exist_ok=True)
    fichier = os.path.join(dossier, f"{state}.json")
    with open(fichier, "w", encoding="utf-8") as f:
        json.dump(tokens, f, indent=2)

    return HTMLResponse(content=f"""
    <!DOCTYPE html>
    <html>
      <head>
        <title>Connexion r√©ussie</title>
        <style>
          body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
          }}
          .message {{
            text-align: center;
          }}
          .icon {{
            font-size: 64px;
            margin-bottom: 20px;
          }}
        </style>
      </head>
      <body>
        <div class="message">
          <div class="icon">‚úì</div>
          <h1>Google Calendar connect√© avec succ√®s!</h1>
          <p>Fermeture en cours...</p>
        </div>
        <script>
          localStorage.setItem('agenda_connected', Date.now().toString());

          // Essayer de fermer si c'est un popup
          if (window.opener) {{
            window.opener.postMessage("agenda_connected", "*");
            window.close();
          }} else {{
            // MOBILE: Pas de popup, rediriger vers l'app
            // R√©cup√©rer le username depuis l'URL ou localStorage
            const username = '{state}' || localStorage.getItem('username');
            setTimeout(() => {{
              window.location.href = '/apppc?user=' + encodeURIComponent(username) + '#/connection';
            }}, 1500);
          }}

          // Si c'est une BrowserView Electron, fermer apr√®s 1 seconde
          setTimeout(() => {{
            window.close();
          }}, 1000);
        </script>
      </body>
    </html>
    """)

@app.get("/is-agenda-linked")
def is_agenda_linked(username: str):
    chemin_token = os.path.join(base_cloud, "tokens", f"{username}.json")
    return {"linked": os.path.exists(chemin_token)}

@app.get("/google-email")
def get_google_email(username: str):
    access_token = get_valid_token(username)
    headers = {"Authorization": f"Bearer {access_token}"}
    response = requests.get("https://www.googleapis.com/oauth2/v1/userinfo?alt=json", headers=headers)
    
    if response.status_code != 200:
        raise HTTPException(status_code=400, detail="Erreur email utilisateur")

    return {"email": response.json().get("email", "")}

@app.delete("/deconnecter-agenda")
def deconnecter_agenda(username: str):
    # Supprimer le token Google
    fichier_token = os.path.join(base_cloud, "tokens", f"{username}.json")
    if os.path.exists(fichier_token):
        os.remove(fichier_token)

    # Supprimer l'agenda s√©lectionn√©
    fichier_agenda = os.path.join(base_cloud, "tokens", f"{username}_agenda.json")
    if os.path.exists(fichier_agenda):
        os.remove(fichier_agenda)

    return {"message": "Agenda d√©connect√©"}

@app.post("/disconnect-agenda")
def disconnect_agenda(username: str):
    """Endpoint POST pour la d√©connexion d'agenda (utilis√© par onboarding)"""
    # Supprimer le token Google
    fichier_token = os.path.join(base_cloud, "tokens", f"{username}.json")
    if os.path.exists(fichier_token):
        os.remove(fichier_token)

    # Supprimer l'agenda s√©lectionn√©
    fichier_agenda = os.path.join(base_cloud, "tokens", f"{username}_agenda.json")
    if os.path.exists(fichier_agenda):
        os.remove(fichier_agenda)

    return {"message": "Agenda d√©connect√©"}

@app.get("/liste-agendas")
def liste_agendas(username: str):
    access_token = get_valid_token(username)
    headers = {"Authorization": f"Bearer {access_token}"}
    response = requests.get("https://www.googleapis.com/calendar/v3/users/me/calendarList", headers=headers)
    if response.status_code != 200:
        raise HTTPException(status_code=400, detail="Erreur Google")

    return [
        {
            "id": cal["id"],
            "nom": cal.get("summary", cal["id"]),
            "accessRole": cal.get("accessRole", "")
        }
        for cal in response.json().get("items", [])
    ]

def get_valid_token(username: str) -> str:
    chemin = os.path.join(base_cloud, "tokens", f"{username}.json")
    if not os.path.exists(chemin):
        raise HTTPException(status_code=401, detail="Aucun token Google trouv√©")

    with open(chemin, "r", encoding="utf-8") as f:
        tokens = json.load(f)

    headers = {"Authorization": f"Bearer {tokens['access_token']}"}
    test = requests.get("https://www.googleapis.com/oauth2/v1/userinfo", headers=headers)

    if test.status_code == 401 and "refresh_token" in tokens:
        refresh_response = requests.post("https://oauth2.googleapis.com/token", data={
            "client_id": CLIENT_ID,
            "client_secret": CLIENT_SECRET,
            "grant_type": "refresh_token",
            "refresh_token": tokens["refresh_token"],
        })

        if refresh_response.status_code != 200:
            raise HTTPException(status_code=401, detail="Erreur de rafr√¢ichissement du token")

        refreshed = refresh_response.json()
        tokens["access_token"] = refreshed["access_token"]
        tokens["expires_in"] = refreshed.get("expires_in", 3600)

        with open(chemin, "w", encoding="utf-8") as f:
            json.dump(tokens, f, indent=2)

    return tokens["access_token"]

def get_blacklisted_ids(username: str) -> list:
    fichier = os.path.join(f"{base_cloud}/blacklist", f"{username}.json")
    if not os.path.exists(fichier):
        return []
    with open(fichier, "r", encoding="utf-8") as f:
        return json.load(f)

def extract_phone_number(description):
    """
    Extrait un num√©ro de t√©l√©phone de la description.
    Formats support√©s:
    - 0000000000 (10 chiffres) -> format√© en 000-000-0000
    - 000-000-0000 (d√©j√† format√©) -> gard√© tel quel
    """
    if not description:
        return ""

    # Chercher format d√©j√† format√©: 000-000-0000
    formatted_pattern = r'\b(\d{3})-(\d{3})-(\d{4})\b'
    match = re.search(formatted_pattern, description)
    if match:
        return match.group(0)

    # Chercher format non format√©: 0000000000 (10 chiffres cons√©cutifs)
    unformatted_pattern = r'\b(\d{10})\b'
    match = re.search(unformatted_pattern, description)
    if match:
        phone = match.group(1)
        # Formater: 0000000000 -> 000-000-0000
        return f"{phone[0:3]}-{phone[3:6]}-{phone[6:10]}"

    return ""

def filter_calendar_events(events: list, blacklisted_ids: list) -> list:
    """
    Filtre les √©v√©nements du calendrier selon nos crit√®res:
    - Pas dans la blacklist
    - Titre non vide
    - Pas de mots bannis (dispo, estim, pap)
    - Exactement 2 mots (pr√©nom + nom)
    """
    BANNED_WORD_STARTS = ["dispo", "estim", "pap"]
    result = []

    for event in events:
        event_id = event.get("id")
        if event_id in blacklisted_ids:
            continue

        summary = (event.get("summary") or "").strip()
        if not summary:
            continue

        # V√©rifier si le titre contient des mots bannis
        summary_lower = summary.lower()
        words_in_summary = summary_lower.split()
        has_banned_word = any(
            any(word.startswith(banned) for banned in BANNED_WORD_STARTS)
            for word in words_in_summary
        )
        if has_banned_word:
            continue

        # V√©rifier que le titre a EXACTEMENT 2 mots (pr√©nom + nom)
        words = summary.split()
        if len(words) != 2:
            continue

        parts = summary.split(" ", 1)
        prenom = parts[0] if len(parts) > 0 else ""
        nom = parts[1] if len(parts) > 1 else ""
        adresse = event.get("location", "")

        # Extraire uniquement le num√©ro de t√©l√©phone de la description
        description = event.get("description", "")
        telephone = extract_phone_number(description)

        result.append({
            "id": event_id,
            "prenom": prenom,
            "nom": nom,
            "adresse": adresse,
            "telephone": telephone
        })

    return result

def sync_events_to_prospects(username: str, events: list):
    """
    Synchronise les √©v√©nements filtr√©s vers les prospects.
    Utilise l'event_id Google comme ID prospect.
    """
    prospects_dir = os.path.join(f"{base_cloud}/prospects", username)
    os.makedirs(prospects_dir, exist_ok=True)
    fichier_prospects = os.path.join(prospects_dir, "prospects.json")

    # Charger les prospects existants
    prospects_existants = []
    if os.path.exists(fichier_prospects):
        try:
            with open(fichier_prospects, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    prospects_existants = json.loads(content)
        except:
            prospects_existants = []

    # IDs des prospects existants
    ids_existants = {p.get("id") for p in prospects_existants}

    # Ajouter les nouveaux √©v√©nements comme prospects
    nouveaux_prospects_ajoutes = 0
    for event in events:
        if event["id"] not in ids_existants:
            nouveau_prospect = {
                "id": event["id"],
                "prenom": event["prenom"],
                "nom": event["nom"],
                "telephone": event["telephone"],
                "adresse": event["adresse"],
                "date_ajout": datetime.now().isoformat(),
                "statut": "client_potentiel",
                "source": "google_calendar"
            }
            prospects_existants.append(nouveau_prospect)
            nouveaux_prospects_ajoutes += 1

    # Sauvegarder si des nouveaux prospects ont √©t√© ajout√©s
    if nouveaux_prospects_ajoutes > 0:
        with open(fichier_prospects, "w", encoding="utf-8") as f:
            json.dump(prospects_existants, f, indent=2, ensure_ascii=False)
        print(f"[SYNC] {nouveaux_prospects_ajoutes} nouveaux √©v√©nements ajout√©s aux prospects pour {username}")

    return nouveaux_prospects_ajoutes

@app.get("/evenements-a-completer")
def evenements_a_completer(username: str):
    import zoneinfo
    local_tz = zoneinfo.ZoneInfo("America/Toronto")

    access_token = get_valid_token(username)
    headers = {"Authorization": f"Bearer {access_token}"}

    now_local = datetime.now(tz=local_tz)
    end_of_day_local = datetime(
        year=now_local.year,
        month=now_local.month,
        day=now_local.day,
        hour=23,
        minute=59,
        second=59,
        tzinfo=local_tz
    )

    # Pour les √©v√©nements d'aujourd'hui (retourn√©s au frontend)
    time_min_today = now_local.astimezone(zoneinfo.ZoneInfo("UTC")).isoformat().replace("+00:00", "Z")
    time_max_today = end_of_day_local.astimezone(zoneinfo.ZoneInfo("UTC")).isoformat().replace("+00:00", "Z")

    # Pour TOUS les √©v√©nements futurs (sync vers prospects) - 1 an dans le futur
    future_date = now_local + timedelta(days=365)
    time_max_future = future_date.astimezone(zoneinfo.ZoneInfo("UTC")).isoformat().replace("+00:00", "Z")

    agenda_file = os.path.join(base_cloud, "tokens", f"{username}_agenda.json")
    if not os.path.exists(agenda_file):
        return []

    with open(agenda_file, "r") as f:
        agenda_id = json.load(f).get("agenda_id")

    url = f"https://www.googleapis.com/calendar/v3/calendars/{agenda_id}/events"
    blacklisted_ids = get_blacklisted_ids(username)

    # ==========================================
    # 1. R√©cup√©rer TOUS les √©v√©nements futurs pour sync vers prospects
    # ==========================================
    params_future = {
        "timeMin": time_min_today,
        "timeMax": time_max_future,
        "singleEvents": True,
        "orderBy": "startTime",
        "maxResults": 500
    }

    r_future = requests.get(url, headers=headers, params=params_future)
    if r_future.status_code == 200:
        all_future_events = r_future.json().get("items", [])
        filtered_future = filter_calendar_events(all_future_events, blacklisted_ids)
        sync_events_to_prospects(username, filtered_future)
        print(f"[SYNC] {len(filtered_future)} √©v√©nements futurs filtr√©s pour prospects")

    # ==========================================
    # 2. R√©cup√©rer les √©v√©nements d'AUJOURD'HUI seulement pour retour
    # ==========================================
    params_today = {
        "timeMin": time_min_today,
        "timeMax": time_max_today,
        "singleEvents": True,
        "orderBy": "startTime"
    }

    r_today = requests.get(url, headers=headers, params=params_today)
    if r_today.status_code != 200:
        raise HTTPException(status_code=400, detail="Erreur Google Calendar")

    today_events = r_today.json().get("items", [])
    result = filter_calendar_events(today_events, blacklisted_ids)

    print(f"[[INFO]] {len(result)} √©v√©nements d'aujourd'hui pour {username}")

    return result




@app.post("/sauver-agenda-id")
def sauver_agenda_id(data: dict = Body(...)):
    username = data.get("username")
    agenda_id = data.get("agenda_id")

    if not username or not agenda_id:
        raise HTTPException(status_code=400, detail="Champs manquants")

    dossier = os.path.join(base_cloud, "tokens")
    os.makedirs(dossier, exist_ok=True)
    fichier = os.path.join(dossier, f"{username}_agenda.json")

    with open(fichier, "w", encoding="utf-8") as f:
        json.dump({"agenda_id": agenda_id}, f, indent=2)

    return {"message": "Agenda enregistr√© [OK]"}


@app.post("/supprimer-evenement")
def supprimer_evenement(data: dict = Body(...)):
    print("üß™ DATA RE√áU :", data)

    event_id = data.get("event_id")
    username = data.get("username")

    if not event_id or not username:
        raise HTTPException(status_code=400, detail="Champs manquants")

    # 1. Ajouter √† la blacklist des √©v√©nements
    blacklist_dir = f"{base_cloud}/blacklist"
    os.makedirs(blacklist_dir, exist_ok=True)
    blacklist_file = os.path.join(blacklist_dir, f"{username}.json")

    if os.path.exists(blacklist_file):
        with open(blacklist_file, "r", encoding="utf-8") as f:
            ids = json.load(f)
    else:
        ids = []

    if event_id not in ids:
        ids.append(event_id)

    with open(blacklist_file, "w", encoding="utf-8") as f:
        json.dump(ids, f, indent=2)

    # 2. SYNCHRONISATION: Supprimer aussi le prospect avec cet ID
    fichier_prospects = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
    if os.path.exists(fichier_prospects):
        try:
            with open(fichier_prospects, "r", encoding="utf-8") as f:
                prospects = json.load(f)

            # Filtrer pour retirer le prospect avec cet event_id
            prospects_filtres = [p for p in prospects if p.get("id") != event_id]

            if len(prospects_filtres) < len(prospects):
                with open(fichier_prospects, "w", encoding="utf-8") as f:
                    json.dump(prospects_filtres, f, indent=2, ensure_ascii=False)
                print(f"[SYNC] Prospect avec ID {event_id} supprim√© des prospects pour {username}")
        except Exception as e:
            print(f"[WARNING] Erreur lors de la suppression du prospect synchronis√©: {e}")

    return {"message": "√âv√©nement supprim√© [OK]"}

@app.post("/bannir-client-a-completer")
def bannir_client_a_completer(data: dict = Body(...)):
    """
    Endpoint pour bannir un client des soumissions √† compl√©ter
    Le client sera ajout√© √† la blacklist de l'utilisateur
    """
    print("[BAN] BANNISSEMENT CLIENT - DATA RE√áU :", data)
    
    # Extraction des donn√©es requises
    username = data.get("username")
    client_email = data.get("client_email") 
    client_nom = data.get("client_nom")
    client_prenom = data.get("client_prenom")
    raison = data.get("raison", "Non sp√©cifi√©e")
    
    # Validation des champs obligatoires
    if not username:
        raise HTTPException(status_code=400, detail="Username manquant")
    if not client_email:
        raise HTTPException(status_code=400, detail="Email du client manquant")
    
    try:
        # Pr√©paration du r√©pertoire blacklist
        blacklist_dir = f"{base_cloud}/blacklist"
        os.makedirs(blacklist_dir, exist_ok=True)
        blacklist_file = os.path.join(blacklist_dir, f"{username}_clients.json")
        
        # Chargement de la blacklist existante
        blacklisted_clients = []
        if os.path.exists(blacklist_file):
            with open(blacklist_file, "r", encoding="utf-8") as f:
                blacklisted_clients = json.load(f)
        
        # V√©rification si le client n'est pas d√©j√† banni
        client_exists = any(
            client.get("email") == client_email 
            for client in blacklisted_clients
        )
        
        if client_exists:
            return {"message": f"Le client {client_email} est d√©j√† dans la blacklist"}
        
        # Ajout du nouveau client banni
        nouveau_client_banni = {
            "email": client_email,
            "nom": client_nom or "",
            "prenom": client_prenom or "",
            "raison": raison,
            "date_bannissement": datetime.now().isoformat(),
            "banni_par": username
        }
        
        blacklisted_clients.append(nouveau_client_banni)
        
        # Sauvegarde de la blacklist mise √† jour
        with open(blacklist_file, "w", encoding="utf-8") as f:
            json.dump(blacklisted_clients, f, indent=2, ensure_ascii=False)
        
        print(f"[[OK] SUCC√àS] Client {client_email} ajout√© √† la blacklist de {username}")
        
        return {
            "message": f"Client {client_email} banni avec succ√®s [OK]",
            "client_banni": {
                "email": client_email,
                "nom": client_nom or "",
                "prenom": client_prenom or "",
                "raison": raison
            }
        }
        
    except Exception as e:
        print(f"[[ERROR] ERREUR] Bannissement client {client_email} pour {username}: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors du bannissement du client: {str(e)}"
        )

@app.post("/bannir-client-par-id")
def bannir_client_par_id(data: dict = Body(...)):
    """
    Endpoint pour bannir un client par son ID unique (event_id)
    L'ID sera ajout√© √† une blacklist s√©par√©e pour filtrage par ID
    """
    print("[BAN] BANNISSEMENT CLIENT PAR ID - DATA RE√áU :", data)
    
    # Extraction des donn√©es requises
    username = data.get("username")
    event_id = data.get("event_id")
    raison = data.get("raison", "Non sp√©cifi√©e")
    
    # Validation des champs obligatoires
    if not username:
        raise HTTPException(status_code=400, detail="Username manquant")
    if not event_id:
        raise HTTPException(status_code=400, detail="Event ID manquant")
    
    try:
        # Structure de fichier pour la blacklist par IDs
        blacklist_dir = f"{base_cloud}/blacklist"
        os.makedirs(blacklist_dir, exist_ok=True)
        blacklist_file = os.path.join(blacklist_dir, f"{username}_event_ids.json")
        
        # Chargement de la blacklist existante
        blacklisted_ids = []
        if os.path.exists(blacklist_file):
            with open(blacklist_file, "r", encoding="utf-8") as f:
                blacklisted_ids = json.load(f)
        
        # V√©rification si l'ID n'est pas d√©j√† banni
        id_exists = any(
            item.get("event_id") == event_id 
            for item in blacklisted_ids
        )
        
        if id_exists:
            return {"message": f"L'ID {event_id} est d√©j√† dans la blacklist"}
        
        # Ajout du nouvel ID banni
        nouveau_id_banni = {
            "event_id": event_id,
            "raison": raison,
            "date_bannissement": datetime.now().isoformat(),
            "banni_par": username,
            # Garder aussi les infos client pour r√©f√©rence
            "client_info": {
                "nom": data.get("client_nom", ""),
                "prenom": data.get("client_prenom", ""),
                "email": data.get("client_email", ""),
                "adresse": data.get("adresse", ""),
                "telephone": data.get("telephone", "")
            }
        }
        
        blacklisted_ids.append(nouveau_id_banni)
        
        # Sauvegarde de la blacklist mise √† jour
        with open(blacklist_file, "w", encoding="utf-8") as f:
            json.dump(blacklisted_ids, f, indent=2, ensure_ascii=False)
        
        print(f"[[OK] SUCC√àS] Event ID {event_id} ajout√© √† la blacklist de {username}")
        
        return {
            "message": f"Event ID {event_id} banni avec succ√®s [OK]",
            "event_id_banni": {
                "event_id": event_id,
                "raison": raison
            }
        }
        
    except Exception as e:
        print(f"[[ERROR] ERREUR] Bannissement event ID {event_id} pour {username}: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors du bannissement de l'event ID: {str(e)}"
        )

@app.get("/blacklist-event-ids")
def get_blacklist_event_ids(username: str):
    """
    Endpoint pour r√©cup√©rer la blacklist des event IDs bannis d'un utilisateur
    """
    try:
        blacklist_dir = f"{base_cloud}/blacklist"
        blacklist_file = os.path.join(blacklist_dir, f"{username}_event_ids.json")
        
        # Si le fichier n'existe pas, retourner une liste vide
        if not os.path.exists(blacklist_file):
            return {"blacklisted_event_ids": []}
        
        # Charger et retourner la blacklist existante
        with open(blacklist_file, "r", encoding="utf-8") as f:
            blacklisted_ids = json.load(f)
        
        return {"blacklisted_event_ids": blacklisted_ids}
        
    except Exception as e:
        print(f"[[ERROR] ERREUR] R√©cup√©ration blacklist event IDs pour {username}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration de la blacklist: {str(e)}"
        )

@app.get("/get-clients-by-username/{username}")
def get_clients_by_username(username: str):
    """
    R√©cup√®re tous les clients de tous les statuts pour un utilisateur
    Retourne les clients group√©s par cat√©gorie pour Facturation QE
    """
    try:
        result = {
            "prospects": [],
            "perdus": [],
            "accepter": [],
            "produit": [],
            "clients": []  # Pour compatibilit√© avec ancien code
        }

        # Prospects
        prospects_path = os.path.join(base_cloud, "prospects", username, "prospects.json")
        if os.path.exists(prospects_path):
            with open(prospects_path, 'r', encoding='utf-8') as f:
                prospects = json.load(f)
                for p in prospects:
                    p['status'] = 'prospect'
                result["prospects"] = prospects
                result["clients"].extend(prospects)

        # Clients perdus
        perdus_path = os.path.join(base_cloud, "clients_perdus", username, "clients.json")
        if os.path.exists(perdus_path):
            with open(perdus_path, 'r', encoding='utf-8') as f:
                perdus = json.load(f)
                for p in perdus:
                    p['status'] = 'perdu'
                result["perdus"] = perdus
                result["clients"].extend(perdus)

        # Ventes accept√©es
        acceptees_path = os.path.join(base_cloud, "ventes_acceptees", username, "ventes.json")
        if os.path.exists(acceptees_path):
            with open(acceptees_path, 'r', encoding='utf-8') as f:
                acceptees = json.load(f)
                for v in acceptees:
                    v['status'] = 'accepte'
                result["accepter"] = acceptees
                result["clients"].extend(acceptees)

        # Ventes produit
        produit_path = os.path.join(base_cloud, "ventes_produit", username, "ventes.json")
        if os.path.exists(produit_path):
            with open(produit_path, 'r', encoding='utf-8') as f:
                produit = json.load(f)
                for v in produit:
                    v['status'] = 'produit'
                result["produit"] = produit
                result["clients"].extend(produit)

        return result

    except Exception as e:
        print(f"[ERROR] R√©cup√©ration clients pour {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/blacklist-clients")
def get_blacklist_clients(username: str):
    """
    Endpoint pour r√©cup√©rer la blacklist des clients bannis d'un utilisateur
    """
    try:
        blacklist_dir = f"{base_cloud}/blacklist"
        blacklist_file = os.path.join(blacklist_dir, f"{username}_clients.json")

        # Si le fichier n'existe pas, retourner une liste vide
        if not os.path.exists(blacklist_file):
            return {"blacklisted_clients": []}

        # Charger et retourner la blacklist existante
        with open(blacklist_file, "r", encoding="utf-8") as f:
            blacklisted_clients = json.load(f)

        return {"blacklisted_clients": blacklisted_clients}

    except Exception as e:
        print(f"[[ERROR] ERREUR] R√©cup√©ration blacklist pour {username}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration de la blacklist: {str(e)}"
        )

# ========================================
# MONDAY.COM INTEGRATION ENDPOINTS
# ========================================

@app.post("/api/monday/save-config")
async def save_monday_config(request: Request):
    """
    Sauvegarde la configuration Monday.com d'un entrepreneur
    """
    try:
        data = await request.json()
        username = data.get('username')
        api_key = data.get('api_key')
        board_id = data.get('board_id')

        if not username or not api_key or not board_id:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # Tester d'abord la connexion avec Monday API
        test_result = await test_monday_connection_internal(api_key, board_id)
        if not test_result['success']:
            raise HTTPException(status_code=400, detail=test_result['error'])

        # Cr√©er le dossier de configuration Monday pour cet utilisateur
        monday_dir = os.path.join(base_cloud, "monday_credentials", username)
        os.makedirs(monday_dir, exist_ok=True)

        # Cr√©er le fichier de configuration
        config_file = os.path.join(monday_dir, "monday_config.json")
        config_data = {
            "api_key": api_key,
            "board_id": board_id,
            "board_name": test_result.get('board_name', ''),
            "connected_at": datetime.now().isoformat()
        }

        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False, indent=2)

        return {
            "success": True,
            "board_name": test_result.get('board_name', '')
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Sauvegarde config Monday pour {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/monday/get-config/{username}")
def get_monday_config(username: str):
    """
    R√©cup√®re la configuration Monday.com d'un entrepreneur
    """
    try:
        config_file = os.path.join(base_cloud, "monday_credentials", username, "monday_config.json")

        if not os.path.exists(config_file):
            return {"connected": False}

        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        return {
            "connected": True,
            "api_key": config.get('api_key', ''),
            "board_id": config.get('board_id', ''),
            "board_name": config.get('board_name', '')
        }

    except Exception as e:
        print(f"[ERROR] R√©cup√©ration config Monday pour {username}: {e}")
        return {"connected": False}

@app.post("/api/monday/test-connection")
async def test_monday_connection(request: Request):
    """
    Teste la connexion avec l'API Monday.com
    """
    try:
        data = await request.json()
        api_key = data.get('api_key')
        board_id = data.get('board_id')

        if not api_key or not board_id:
            raise HTTPException(status_code=400, detail="API key et Board ID requis")

        result = await test_monday_connection_internal(api_key, board_id)

        if result['success']:
            return result
        else:
            raise HTTPException(status_code=400, detail=result['error'])

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Test connexion Monday: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def test_monday_connection_internal(api_key: str, board_id: str):
    """
    Fonction interne pour tester la connexion Monday.com
    """
    try:
        import httpx

        # Query GraphQL pour r√©cup√©rer les infos du board
        query = f"""
        query {{
            boards (ids: {board_id}) {{
                id
                name
                state
            }}
        }}
        """

        headers = {
            "Authorization": api_key,
            "Content-Type": "application/json"
        }

        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.monday.com/v2",
                json={"query": query},
                headers=headers,
                timeout=10.0
            )

            if response.status_code != 200:
                return {
                    "success": False,
                    "error": f"Erreur HTTP {response.status_code}"
                }

            data = response.json()

            # V√©rifier si la r√©ponse contient des erreurs
            if "errors" in data:
                return {
                    "success": False,
                    "error": "Cl√© API invalide ou board inaccessible"
                }

            # V√©rifier si le board existe
            if not data.get("data", {}).get("boards"):
                return {
                    "success": False,
                    "error": "Board ID introuvable"
                }

            board = data["data"]["boards"][0]

            return {
                "success": True,
                "board_name": board.get("name", "Board"),
                "board_id": board.get("id")
            }

    except Exception as e:
        print(f"[ERROR] Test connexion Monday interne: {e}")
        return {
            "success": False,
            "error": f"Erreur de connexion: {str(e)}"
        }

@app.delete("/api/monday/disconnect/{username}")
def disconnect_monday(username: str):
    """
    D√©connecte Monday.com en supprimant la configuration
    """
    try:
        config_file = os.path.join(base_cloud, "monday_credentials", username, "monday_config.json")

        if os.path.exists(config_file):
            os.remove(config_file)
            return {"success": True}

        return {"success": True, "message": "Aucune configuration √† supprimer"}

    except Exception as e:
        print(f"[ERROR] D√©connexion Monday pour {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/connect-gmail")
def connect_gmail(username: str, return_url: bool = False):
    print(f"[DEBUG GMAIL] GMAIL_REDIRECT_URI: {GMAIL_REDIRECT_URI}")
    print(f"[DEBUG GMAIL] BASE_URL: {BASE_URL}")
    params = {
        "client_id": CLIENT_ID,
        "redirect_uri": GMAIL_REDIRECT_URI,
        "response_type": "code",
        "scope": "https://www.googleapis.com/auth/gmail.send https://www.googleapis.com/auth/userinfo.email",
        "access_type": "offline",
        "prompt": "consent",
        "state": username
    }
    url = "https://accounts.google.com/o/oauth2/v2/auth?" + urllib.parse.urlencode(params)
    print(f"[DEBUG GMAIL] OAuth URL: {url}")

    # Si return_url=true, retourner l'URL au lieu de rediriger
    if return_url:
        return {"oauth_url": url}
    else:
        return RedirectResponse(url)


@app.get("/gmail/callback")
def gmail_callback(code: str = Query(...), state: str = Query(...)):
    print(f"[DEBUG GMAIL CALLBACK] Received callback for user: {state}")
    print(f"[DEBUG GMAIL CALLBACK] Code: {code[:50]}...")
    token_url = "https://oauth2.googleapis.com/token"
    data = {
        "code": code,
        "client_id": CLIENT_ID,
        "client_secret": CLIENT_SECRET,
        "redirect_uri": GMAIL_REDIRECT_URI,
        "grant_type": "authorization_code"
    }

    response = requests.post(token_url, data=data)
    if response.status_code != 200:
        raise HTTPException(status_code=400, detail="Erreur lors de l'√©change du code Gmail")

    tokens = response.json()

    # üîê R√©cup√©rer l‚Äôemail
    headers = {"Authorization": f"Bearer {tokens['access_token']}"}
    info = requests.get("https://www.googleapis.com/oauth2/v1/userinfo?alt=json", headers=headers).json()
    tokens["email"] = info.get("email", "")

    # [SAVE] Sauvegarder dans /mnt/cloud/emails/ ou data/emails/
    base_path = base_cloud if sys.platform != 'win32' else os.path.join(os.path.dirname(__file__), 'data')
    emails_dir = os.path.join(base_path, "emails")
    os.makedirs(emails_dir, exist_ok=True)
    fichier = os.path.join(emails_dir, f"{state}.json")
    with open(fichier, "w", encoding="utf-8") as f:
        json.dump(tokens, f, indent=2)

    return HTMLResponse(f"""
    <!DOCTYPE html>
    <html>
    <head>
      <title>Connexion r√©ussie</title>
      <style>
        body {{
          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
          display: flex;
          align-items: center;
          justify-content: center;
          height: 100vh;
          margin: 0;
          background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
          color: white;
        }}
        .message {{
          text-align: center;
        }}
        .icon {{
          font-size: 64px;
          margin-bottom: 20px;
        }}
      </style>
    </head>
    <body>
      <div class="message">
        <div class="icon">‚úì</div>
        <h1>Gmail connect√© avec succ√®s!</h1>
        <p>Fermeture en cours...</p>
      </div>
      <script>
        localStorage.setItem('gmail_connected', Date.now().toString());

        // Essayer de fermer si c'est un popup
        if (window.opener) {{
          window.opener.postMessage("gmail_connected", "*");
          window.close();
        }} else {{
          // MOBILE: Pas de popup, rediriger vers l'app
          const username = '{state}' || localStorage.getItem('username');
          setTimeout(() => {{
            window.location.href = '/apppc?user=' + encodeURIComponent(username) + '#/connection';
          }}, 1500);
        }}

        // Si c'est une BrowserView Electron, fermer apr√®s 1 seconde
        setTimeout(() => {{
          window.close();
        }}, 1000);
      </script>
    </body>
    </html>
    """)


@app.get("/email-connecte")
def email_connecte(username: str):
    # D√©terminer le chemin de base selon la plateforme
    base_path = base_cloud if sys.platform != 'win32' else os.path.join(os.path.dirname(__file__), 'data')
    fichier = os.path.join(base_path, "emails", f"{username}.json")
    if not os.path.exists(fichier):
        raise HTTPException(status_code=404, detail="Pas connect√©")
    with open(fichier, "r", encoding="utf-8") as f:
        data = json.load(f)
    return {"email": data.get("email", "")}

@app.delete("/deconnecter-email")
def deconnecter_email(username: str):
    # D√©terminer le chemin de base selon la plateforme
    base_path = base_cloud if sys.platform != 'win32' else os.path.join(os.path.dirname(__file__), 'data')
    fichier = os.path.join(base_path, "emails", f"{username}.json")
    if os.path.exists(fichier):
        os.remove(fichier)
    return {"message": "D√©connect√© [OK]"}


@app.post("/generate-gqp-pdf")
async def generate_gqp_and_save(
    username: str = Form(...),
    photos: List[UploadFile] = File(default=[]),
    nom: str = Form(default=""),
    prenom: str = Form(default=""),
    adresse: str = Form(default=""),
    telephone: str = Form(default=""),
    courriel: str = Form(default=""),
    endroit: str = Form(default=""),
    etapes: str = Form(default=""),
    heure: str = Form(default=""),
    montant: str = Form(default=""),
    numero_soumission: str = Form(default=""),
    assignment_type: str = Form(default="none")
):
    print(f"[GQP-HTML] Fichiers re√ßus: {len(photos)}")

    # Extensions support√©es
    IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff'}
    VIDEO_EXTENSIONS = {'.mp4', '.mov', '.avi', '.webm', '.mkv', '.m4v'}

    # G√©n√©rer un ID unique pour ce GQP
    gqp_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # Cr√©er le dossier pour ce GQP
    dossier_user = os.path.join(f"{base_cloud}/gqp", username)
    dossier_gqp = os.path.join(dossier_user, f"gqp_{gqp_id}")
    dossier_medias = os.path.join(dossier_gqp, "medias")
    os.makedirs(dossier_medias, exist_ok=True)

    # Sauvegarder les m√©dias et pr√©parer les URLs
    media_urls = []
    unique_bytes = set()

    for i, photo in enumerate(photos):
        filename = photo.filename.lower() if photo.filename else ""
        ext = os.path.splitext(filename)[1]

        # V√©rifier le type de fichier
        if ext in IMAGE_EXTENSIONS:
            media_type = 'image'
        elif ext in VIDEO_EXTENSIONS:
            media_type = 'video'
        else:
            print(f"[GQP-HTML] Fichier ignor√© (type non support√©): {photo.filename}")
            continue

        content = await photo.read()

        # D√©doublonnage
        content_hash = hash(content)
        if content_hash in unique_bytes:
            continue
        unique_bytes.add(content_hash)

        # Sauvegarder le fichier
        media_filename = f"media_{i}{ext}"
        media_path = os.path.join(dossier_medias, media_filename)
        with open(media_path, "wb") as f:
            f.write(content)

        # URL accessible
        media_url = f"{BASE_URL}/cloud/gqp/{username}/gqp_{gqp_id}/medias/{media_filename}"
        media_urls.append({'url': media_url, 'type': media_type})
        print(f"[GQP-HTML] {media_type} sauvegard√©: {media_filename}")

    print(f"[GQP-HTML] Total m√©dias sauvegard√©s: {len(media_urls)}")

    infos = {
        "nom": nom,
        "prenom": prenom,
        "adresse": adresse,
        "telephone": telephone,
        "courriel": courriel,
        "endroit": endroit,
        "etapes": etapes,
        "heure": heure,
        "montant": montant
    }

    # G√©n√©rer le HTML
    html_content = generate_gqp_html(infos, media_urls)

    # Sauvegarder le fichier HTML
    nom_fichier = f"gqp_{gqp_id}.html"
    chemin_html = os.path.join(dossier_gqp, "index.html")
    with open(chemin_html, "w", encoding="utf-8") as f:
        f.write(html_content)

    # Lien vers la page GQP
    lien_pdf = f"{BASE_URL}/gqp-view/{username}/{gqp_id}"

    json_file = os.path.join(dossier_user, "gqp_list.json")
    if os.path.exists(json_file):
        with open(json_file, "r", encoding="utf-8") as f:
            liste = json.load(f)
    else:
        liste = []

    nouvelle_entree = {
        "nom": nom,
        "prenom": prenom,
        "adresse": adresse,
        "telephone": telephone,
        "courriel": courriel,
        "endroit": endroit,
        "heure": heure,
        "montant": montant,
        "lien_pdf": lien_pdf,
        "numero_soumission": numero_soumission,
        "date_creation": datetime.now().isoformat()
    }
    liste.append(nouvelle_entree)

    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(liste, f, ensure_ascii=False, indent=2)

    # NOUVEAU: Lier automatiquement le GQP au client si un num√©ro de soumission est fourni
    if numero_soumission:
        client_name = f"{prenom} {nom}".strip()
        try:
            # Utiliser la fonction de liaison que nous avons cr√©√©e
            def lier_gqp_auto(client_name, numero_soumission, pdf_url):
                print(f"[LIAISON] Liaison automatique GQP pour: '{client_name}', num√©ro: '{numero_soumission}'")

                # Chercher dans soumissions_signees
                fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
                if os.path.exists(fichier_signees):
                    try:
                        with open(fichier_signees, "r", encoding="utf-8") as f:
                            signees = json.load(f)

                        modified = False
                        for client in signees:
                            client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                            if (client_nom.lower() == client_name.lower() or
                                client.get('num') == numero_soumission or
                                client.get('numero') == numero_soumission):
                                client['lien_gqp'] = pdf_url
                                modified = True
                                print(f"[OK] GQP li√© automatiquement dans soumissions_signees: {client_nom}")

                        if modified:
                            with open(fichier_signees, "w", encoding="utf-8") as f:
                                json.dump(signees, f, ensure_ascii=False, indent=2)
                    except Exception as e:
                        print(f"[WARNING] Erreur liaison auto soumissions_signees: {e}")

                # Chercher dans ventes_acceptees (donn√©es en temps r√©el pour section Accepter)
                fichier_acceptees = f"{base_cloud}/ventes_acceptees/{username}/ventes.json"
                if os.path.exists(fichier_acceptees):
                    try:
                        with open(fichier_acceptees, "r", encoding="utf-8") as f:
                            acceptees = json.load(f)

                        modified = False
                        for client in acceptees:
                            client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                            if (client_nom.lower() == client_name.lower() or
                                client.get('num') == numero_soumission or
                                client.get('numero') == numero_soumission):
                                client['lien_gqp'] = pdf_url
                                modified = True
                                print(f"[OK] GQP li√© automatiquement dans ventes_acceptees: {client_nom}")

                        if modified:
                            with open(fichier_acceptees, "w", encoding="utf-8") as f:
                                json.dump(acceptees, f, ensure_ascii=False, indent=2)
                    except Exception as e:
                        print(f"[WARNING] Erreur liaison auto ventes_acceptees: {e}")

                # Chercher dans ventes_produit (donn√©es en temps r√©el pour section Produit)
                fichier_produit = f"{base_cloud}/ventes_produit/{username}/ventes.json"
                if os.path.exists(fichier_produit):
                    try:
                        with open(fichier_produit, "r", encoding="utf-8") as f:
                            produit = json.load(f)

                        modified = False
                        for client in produit:
                            client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                            if (client_nom.lower() == client_name.lower() or
                                client.get('num') == numero_soumission or
                                client.get('numero') == numero_soumission):
                                client['lien_gqp'] = pdf_url
                                modified = True
                                print(f"[OK] GQP li√© automatiquement dans ventes_produit: {client_nom}")

                        if modified:
                            with open(fichier_produit, "w", encoding="utf-8") as f:
                                json.dump(produit, f, ensure_ascii=False, indent=2)
                    except Exception as e:
                        print(f"[WARNING] Erreur liaison auto ventes_produit: {e}")

            lier_gqp_auto(client_name, numero_soumission, lien_pdf)
        except Exception as e:
            print(f"[WARNING] Erreur lors de la liaison automatique du GQP: {e}")

    return JSONResponse({"lien_pdf": lien_pdf, "numero_soumission": numero_soumission, "auto_linked": bool(numero_soumission)})


@app.post("/generate-gqp-from-stored")
async def generate_gqp_from_stored(
    username: str = Body(...),
    gqp_id: str = Body(...),
    gqp_data: dict = Body(...)
):
    """G√©n√©rer un PDF GQP √† partir des donn√©es et images stock√©es"""
    try:
        # R√©cup√©rer les images stock√©es
        images_dir = f"{base_cloud}/gqp_images/{username}/{gqp_id}"
        image_files = []

        # Extensions d'images support√©es
        IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff', '.tif')

        if os.path.exists(images_dir):
            for filename in os.listdir(images_dir):
                # Ignorer les fichiers non-images
                if not filename.lower().endswith(IMAGE_EXTENSIONS):
                    print(f"[GQP] Fichier ignor√© (non-image): {filename}")
                    continue

                image_path = os.path.join(images_dir, filename)
                if os.path.isfile(image_path):
                    try:
                        with open(image_path, 'rb') as f:
                            content = f.read()
                            # V√©rifier que le fichier n'est pas vide
                            if len(content) == 0:
                                print(f"[GQP] Image vide ignor√©e: {filename}")
                                continue

                            bio = BytesIO(content)
                            bio.seek(0)

                            # Valider que c'est bien une image valide avec PIL
                            try:
                                from PIL import Image as PILImage
                                test_img = PILImage.open(bio)
                                test_img.verify()  # V√©rifier l'int√©grit√© de l'image
                                bio.seek(0)  # Remettre au d√©but apr√®s verify()
                                print(f"[GQP] Image valide charg√©e: {filename} ({len(content)} bytes)")
                            except Exception as img_error:
                                print(f"[GQP] Image corrompue ignor√©e {filename}: {img_error}")
                                continue

                            image_files.append(bio)
                    except Exception as e:
                        print(f"[GQP] Erreur lecture image {filename}: {e}")
        
        # G√©n√©rer le PDF avec les donn√©es et images
        pdf_buffer = generate_gqp_pdf(image_files, gqp_data)
        
        # Sauvegarder le PDF
        dossier_user = f"{base_cloud}/gqp/{username}"
        os.makedirs(dossier_user, exist_ok=True)
        
        nom_fichier = f"GQP_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        chemin_pdf = os.path.join(dossier_user, nom_fichier)
        
        with open(chemin_pdf, "wb") as f:
            f.write(pdf_buffer.getvalue())
        
        # URL pour acc√®s au PDF
        url_pdf = f"{BASE_URL}/cloud/gqp/{username}/{nom_fichier}"
        
        return {
            "success": True,
            "pdf_url": url_pdf,
            "filename": nom_fichier
        }
        
    except Exception as e:
        print(f"Erreur g√©n√©ration GQP depuis stockage: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la g√©n√©ration du PDF : {str(e)}")


@app.get("/soumissions-gqp/{username}")
def get_soumissions_gqp(username: str):
    """R√©cup√©rer les soumissions disponibles pour GQP (sans celles qui ont d√©j√† un GQP)"""
    return get_soumissions_disponibles_gqp(username)


@app.middleware("http")
async def block_sensitive_files(request: Request, call_next):
    path = request.url.path

    # Bloquer les fichiers sensibles
    if any(path.startswith(f"/{name}") for name in [".env", ".git", ".aws", ".DS_Store", "config", "docker", "db.sql", "secrets"]):
        return JSONResponse(status_code=403, content={"detail": "Forbidden"})

    # V√©rifier l'onboarding et le guide pour les pages prot√©g√©es
    # Autoriser: /login, /onboarding, /guide, /api/*, /cloud/*, /static/*, /frontend/*, routes OAuth et agenda
    protected_page = (
        not path.startswith("/api/") and
        not path.startswith("/cloud/") and
        not path.startswith("/static/") and
        not path.startswith("/frontend/") and
        path not in ["/", "/login", "/onboarding", "/guide", "/connect-google", "/oauth2callback", "/connect-gmail", "/gmail/callback", "/gmail-oauth2callback", "/liste-agendas", "/sauver-agenda-id", "/get-agenda-id", "/is-agenda-linked", "/google-email", "/email-connecte", "/avisclient", "/plainte"] and
        not path.endswith(".css") and
        not path.endswith(".js") and
        not path.endswith(".png") and
        not path.endswith(".jpg") and
        not path.endswith(".svg") and
        not path.endswith(".ico")
    )

    if protected_page:
        # Recuperer le username depuis localStorage (envoye via cookie ou query param)
        username = request.cookies.get("username") or request.query_params.get("username")

        # Verifier aussi qu'il y a un token JWT valide (pas juste un cookie username)
        token = request.cookies.get("access_token")
        if not token:
            # Pas de token = pas vraiment connecte, laisser passer vers login
            return await call_next(request)

        if username and get_user(username):
            # Verifier si onboarding complete
            info_file = f"{base_cloud}/signatures/{username}/user_info.json"
            onboarding_ok = False

            if os.path.exists(info_file):
                try:
                    with open(info_file, "r", encoding="utf-8") as f:
                        user_details = json.load(f)
                        has_prenom = user_details.get("prenom", "").strip() != ""
                        has_nom = user_details.get("nom", "").strip() != ""
                        onboarding_completed = user_details.get("onboarding_completed", False)

                        onboarding_ok = onboarding_completed and has_prenom and has_nom
                except Exception as e:
                    print(f"Erreur lecture onboarding pour {username}: {e}")

            # Si onboarding incomplet, rediriger
            if not onboarding_ok:
                print(f"[BLOQUE] Acces refuse a {path} pour {username} - onboarding incomplet")
                return RedirectResponse(url="/onboarding", status_code=303)

            # Verifier si le guide est complete
            guide_progress = get_guide_progress(username)
            if guide_progress is None or not guide_progress.get("completed", False):
                # Permettre l'acces a /apppc pour afficher le guide (hash #/guide)
                if path == "/apppc":
                    pass  # Laisser passer pour afficher le guide
                else:
                    print(f"[BLOQUE] Acces refuse a {path} pour {username} - guide non complete")
                    return RedirectResponse(url="/apppc#/guide", status_code=303)

    return await call_next(request)

import random
import base64
from fastapi.responses import JSONResponse

@app.post("/creer-facture")
async def creer_facture(request: Request):
    body = await request.json()
    utilisateur = request.query_params.get("username", "inconnu")

    nom = body.get("nom", "")
    prenom = body.get("prenom", "")
    adresse = body.get("adresse", "")
    prix = body.get("prix", "")
    depot = body.get("depot", "0")
    telephone = body.get("telephone", "")
    courriel = body.get("courriel", "")
    endroit = body.get("endroit", "")
    numero_soumission = body.get("numero_soumission", "")
    item = body.get("item", "")
    part = body.get("part", "")
    produit = body.get("produit", "")
    payer_par = body.get("payer_par", "")
    temps = body.get("temps", "")

    if not all([nom, prenom, adresse, prix]):
        raise HTTPException(status_code=400, detail="Champs manquants")

    # D√©tecter la langue via mots-cl√©s anglais
    texte_combine = " ".join([item, temps, produit, part]).lower()
    mots_anglais = ["interior work", "exterior work", "days", "day", "weeks", "week",
                    "pressure wash", "sanding", "liability insurance", "turnkey service"]
    language = 'en' if any(mot in texte_combine for mot in mots_anglais) else 'fr'

    pdf_buffer: BytesIO = generate_facture_pdf(nom, prenom, adresse, prix, depot, telephone, courriel, endroit, item, part, produit, payer_par, utilisateur, temps, language)

    user_folder = os.path.join(f"{base_cloud}/factures_completes", utilisateur)
    os.makedirs(user_folder, exist_ok=True)

    random_num = random.randint(1000, 9999)
    nom_fichier_facture = f"facture_{nom}_{prenom}_{random_num}.pdf".replace(" ", "_")
    chemin_pdf = os.path.join(user_folder, nom_fichier_facture)

    with open(chemin_pdf, "wb") as f:
        f.write(pdf_buffer.getvalue())

    lien_pdf_facture = f"{BASE_URL}/cloud/factures/{utilisateur}/{nom_fichier_facture}"

    from datetime import datetime
    data = {
        "nom": nom,
        "prenom": prenom,
        "adresse": adresse,
        "prix": prix,
        "telephone": telephone,
        "courriel": courriel,
        "depot": depot,
        "numero_soumission": numero_soumission,
        "date_creation": datetime.now().isoformat()
    }

    try:
        enregistrer_facture(utilisateur, data, lien_pdf_facture)
    except Exception as e:
        print("Erreur lors de l'enregistrement de la facture :", e)
        raise HTTPException(status_code=500, detail="Erreur lors de l'enregistrement")

    return JSONResponse({
        "pdf_buffer_facture": base64.b64encode(pdf_buffer.getvalue()).decode(),
        "nom_fichier_facture": nom_fichier_facture,
        "lien_pdf_facture": lien_pdf_facture
    })


@app.get("/factures/{username}")
async def get_factures(username: str):
    path = os.path.join(f"{base_cloud}/factures_completes", username, "factures.json")
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def enregistrer_facture(utilisateur: str, facture: dict, lien_pdf: str):
    try:
        dossier = os.path.join(f"{base_cloud}/factures_completes", utilisateur)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "factures.json")

        facture["pdf_url"] = lien_pdf

        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                data = json.loads(content) if content else []
        else:
            data = []

        data.append(facture)

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"[enregistrer_facture] Facture enregistr√©e pour {utilisateur} dans {fichier}")

    except Exception as e:
        print(f"[enregistrer_facture] ERREUR: {e}")
        raise e

@app.post("/generate-facture-preview")
async def generate_facture_preview(request: Request):
    body = await request.json()
    utilisateur = request.query_params.get("username", "inconnu")

    nom = body.get("nom", "")
    prenom = body.get("prenom", "")
    adresse = body.get("adresse", "")
    prix = body.get("prix", "")
    depot = body.get("depot", "0")
    telephone = body.get("telephone", "")
    courriel = body.get("courriel", "")
    endroit = body.get("endroit", "")
    item = body.get("item", "")
    part = body.get("part", "")
    produit = body.get("produit", "")
    payer_par = body.get("payer_par", "")
    temps = body.get("temps", "")

    if not all([nom, prenom, adresse, prix]):
        raise HTTPException(status_code=400, detail="Champs manquants")

    # D√©tecter la langue via mots-cl√©s anglais
    texte_combine = " ".join([item, temps, produit, part]).lower()
    mots_anglais = ["interior work", "exterior work", "days", "day", "weeks", "week",
                    "pressure wash", "sanding", "liability insurance", "turnkey service"]
    language = 'en' if any(mot in texte_combine for mot in mots_anglais) else 'fr'

    pdf_buffer: BytesIO = generate_facture_pdf(nom, prenom, adresse, prix, depot, telephone, courriel, endroit, item, part, produit, payer_par, utilisateur, temps, language)

    return StreamingResponse(pdf_buffer, media_type="application/pdf", headers={
        "Content-Disposition": "inline; filename=facture.pdf"
    })


def format_montant(montant: float) -> str:
    parts = f"{montant:,.2f}".split(".")
    partie_entiere = parts[0].replace(",", " ")
    partie_decimale = parts[1]
    return f"{partie_entiere},{partie_decimale} $"

from email.header import Header

@app.post("/envoyer-soumission-email")
def envoyer_soumission_email(
    username: str = Body(...),
    destinataire: str = Body(...),
    nom_client: str = Body(...),
    prenom_client: str = Body(...),
    lien_pdf: str = Body(...),
    prix_str: str = Body(...),
    depot_str: str = Body(None),  # NOUVEAU: d√©p√¥t saisi dans le formulaire
    adresse: str = Body(...),
    telephone: str = Body(...),
    language: str = Body('fr')  # Nouveau param√®tre: langue de la soumission ('fr' ou 'en')
):
    try:
        # Nettoyer le prix: enlever espaces (normaux ET ins√©cables \xa0), $, et convertir virgule en point
        prix_clean = prix_str.replace(" ", "").replace("\xa0", "").replace("$", "").replace(",", ".").strip()
        prix = float(prix_clean)
        print(f"[DEBUG] DEBUG envoyer-soumission-email - Prix re√ßu: '{prix_str}' -> Prix nettoy√©: '{prix_clean}' -> Prix float: {prix}")
    except Exception as e:
        print(f"[ERROR] ERREUR conversion prix dans envoyer-soumission-email: {e} - Prix re√ßu: '{prix_str}'")
        prix = 0.0

    # Utiliser le d√©p√¥t saisi dans le formulaire, sinon calculer 25%
    if depot_str and depot_str.strip():
        try:
            depot_clean = depot_str.replace(" ", "").replace("\xa0", "").replace("$", "").replace(",", ".").strip()
            depot = float(depot_clean)
            print(f"[DEBUG] D√©p√¥t depuis formulaire: '{depot_str}' -> {depot}")
        except Exception as e:
            print(f"[WARNING] Erreur conversion d√©p√¥t: {e}, calcul automatique √† 25%")
            # Calculer taxes selon la langue
            tps = prix * 0.05
            if language == 'fr':
                tvq = prix * 0.09975
                total_avec_taxe = prix + tps + tvq
            else:
                tvq = 0  # Pas de TVQ pour l'anglais
                total_avec_taxe = prix + tps
            depot = total_avec_taxe * 0.25
    else:
        # Calculer taxes selon la langue
        tps = prix * 0.05
        if language == 'fr':
            tvq = prix * 0.09975
            total_avec_taxe = prix + tps + tvq
        else:
            tvq = 0  # Pas de TVQ pour l'anglais
            total_avec_taxe = prix + tps
        depot = total_avec_taxe * 0.25
        print(f"[DEBUG] D√©p√¥t calcul√© automatiquement (25%): {depot}")

    depot_fmt = format_montant(depot)

    # R√©cup√©rer le courriel r√©el de l'utilisateur depuis user_info.json
    try:
        user_dir = os.path.join(base_cloud, "signatures", username)
        info_file = os.path.join(user_dir, "user_info.json")
        email_virement = f"{username}@qualiteetudiants.com"  # Valeur par d√©faut

        if os.path.exists(info_file):
            with open(info_file, "r", encoding="utf-8") as f:
                user_data = json.load(f)
                # Utiliser le courriel de l'utilisateur s'il existe
                if user_data.get("courriel"):
                    email_virement = user_data.get("courriel")
                    print(f"[DEBUG] Email virement depuis user_info: {email_virement}")
                else:
                    print(f"[DEBUG] Pas de courriel dans user_info, utilisation par d√©faut: {email_virement}")
        else:
            print(f"[DEBUG] Fichier user_info non trouv√©, utilisation email par d√©faut: {email_virement}")
    except Exception as e:
        print(f"[ERROR] Erreur lecture courriel utilisateur: {e}, utilisation par d√©faut")
        email_virement = f"{username}@qualiteetudiants.com"

    from urllib.parse import urlencode

    # IMPORTANT: Ajouter le param√®tre 'lang' dans l'URL
    params = urlencode({
        "pdf": lien_pdf,
        "username": username,
        "clientEmail": destinataire,
        "clientNom": nom_client,
        "clientPrenom": prenom_client,
        "adresse": adresse,
        "telephone": telephone,
        "lang": language  # NOUVEAU: Passer la langue dans l'URL
    }, safe=':/')

    lien_signature = f"{BASE_URL}/signer-soumission?{params}"

    # Templates d'email bilingues
    if language == 'en':
        subject_text = "Your Quote - College Painters"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Hello {prenom_client} {nom_client},</p>'
            f'<p>Here is your quote for your painting project with College Painters.</p>'
            f'<p>Please review your quote by clicking the button below:</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_pdf}" target="_blank" '
            f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     View my quote &#8594;'
            f'  </a>'
            f'</p><br>'
            f'<p>Payment instructions via Interac e-Transfer:</p>'
            f'<p>Email: {email_virement}</p>'
            f'<p>Password: peinture</p>'
            f'<p>Deposit required: {depot_fmt}</p><br>'
            f'<p>To sign and accept the quote, please click the red button below:</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_signature}" target="_blank" '
            f'     style="background-color: #d32f2f; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Sign the quote'
            f'  </a>'
            f'</p><br>'
            f'<p>Thank you for your trust.<br>The College Painters Team</p>'
            f'</div>'
        )
    else:
        subject_text = "Votre soumission - Qualit√© √âtudiants"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Bonjour {prenom_client} {nom_client},</p>'
            f'<p>Voici votre soumission pour votre projet de peinture avec Qualit√© √âtudiants.</p>'
            f'<p>Veuillez consulter votre soumission en cliquant sur le bouton ci-dessous :</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_pdf}" target="_blank" '
            f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Voir ma soumission &#8594;'
            f'  </a>'
            f'</p><br>'
            f'<p>Instructions de paiement par virement Interac :</p>'
            f'<p>Courriel : {email_virement}</p>'
            f'<p>Mot de passe : peinture</p>'
            f'<p>D√©p√¥t √† verser : {depot_fmt}</p><br>'
            f'<p>Pour signer et accepter la soumission, veuillez cliquer sur le bouton rouge ci-dessous :</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_signature}" target="_blank" '
            f'     style="background-color: #d32f2f; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Signer la soumission'
            f'  </a>'
            f'</p><br>'
            f'<p>Merci de votre confiance.<br>L\'√©quipe de Qualit√© √âtudiants</p>'
            f'</div>'
        )

    subject = "=?UTF-8?B?" + base64.b64encode(subject_text.encode("utf-8")).decode() + "?="

    raw_message = (
        f"To: {destinataire}\r\n"
        f"Subject: {subject}\r\n"
        f"Content-Type: text/html; charset=UTF-8\r\n\r\n"
        f"{html}"
    )
    raw_encoded = base64.urlsafe_b64encode(raw_message.encode("utf-8")).decode("utf-8")

    access_token = get_valid_gmail_token(username)

    response = requests.post(
        "https://gmail.googleapis.com/gmail/v1/users/me/messages/send",
        headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        },
        json={"raw": raw_encoded}
    )

    if response.status_code != 200:
        print("[ERROR] Erreur Gmail API:", response.text)
        raise HTTPException(status_code=400, detail="√âchec de l‚Äôenvoi de la soumission")

    return {"message": "Soumission envoy√©e avec succ√®s [OK]"}


@app.post("/api/envoyer-soumission-signee")
def envoyer_soumission_signee(
    username: str = Body(...),
    clientEmail: str = Body(...),
    clientNom: str = Body(...),
    adresse: str = Body(...),
    telephone: str = Body(...),
    clientPrenom: str = Body(...),
    pdfUrl: str = Body(...),
    signatureDataUrl: str = Body(...),
    prix_str: str = Body(...),
    soumission_id: str = Body(...),  # NOUVEAU: ID de la soumission originale
    num: str = Body(...),  # AJOUT√â: Le vrai num√©ro "24-XXXX"
    language: str = Body('fr')  # NOUVEAU: Langue de la soumission ('fr' ou 'en')
):
    try:
        # R√©cup√©ration du PDF original
        response = requests.get(pdfUrl)
        if response.status_code != 200:
            raise HTTPException(status_code=400, detail="Impossible de r√©cup√©rer le PDF original")

        original_pdf_bytes = BytesIO(response.content)
        reader = PdfReader(original_pdf_bytes)
        writer = PdfWriter()

        # D√©codage de la signature
        header, encoded = signatureDataUrl.split(",", 1)
        signature_bytes = base64.b64decode(encoded)
        signature_img = ImageReader(BytesIO(signature_bytes))

        # Cr√©ation PDF temporaire avec signature
        packet = BytesIO()
        can = rl_canvas.Canvas(packet, pagesize=letter)

        # Position signature (ajuste si besoin)
        x = 80
        y = 88  # Remont√© de 8px (√©tait 80)
        width = 100
        height = 30
        can.drawImage(signature_img, x, y, width=width, height=height, mask='auto')

        # Date centr√©e sous la signature (format DD/MM/YYYY comme entrepreneur)
        date_signature = datetime.now().strftime('%d/%m/%Y')
        can.setFont("Helvetica", 8)
        can.drawCentredString(237.5, 98.5, f"{date_signature}")  # Ajust√©: baiss√© de 1.5px depuis 100

        can.save()
        packet.seek(0)

        signature_pdf = PdfReader(packet)

        # Fusion de la signature sur la premi√®re page
        page = reader.pages[0]
        page.merge_page(signature_pdf.pages[0])
        writer.add_page(page)

        # Ajout des autres pages sans modification
        for i in range(1, len(reader.pages)):
            writer.add_page(reader.pages[i])

        # Enregistrement du PDF sign√© dans le dossier des soumissions sign√©es
        dossier = os.path.join(f"{base_cloud}/soumissions_signees", username)
        os.makedirs(dossier, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nom_pdf_signe = f"soumission_signee_{timestamp}.pdf"
        chemin_pdf_signe = os.path.join(dossier, nom_pdf_signe)

        with open(chemin_pdf_signe, "wb") as f:
            writer.write(f)

        lien_pdf_signe = f"{BASE_URL}/cloud/soumissions_signees/{username}/{nom_pdf_signe}"

        # R√©cup√©rer TOUTES les donn√©es depuis la soumission compl√®te originale
        soumission_complete_data = {}
        try:
            soumissions_completes_file = os.path.join(f"{base_cloud}/soumissions_completes", username, "soumissions.json")
            if os.path.exists(soumissions_completes_file):
                with open(soumissions_completes_file, "r", encoding="utf-8") as f:
                    soumissions_completes = json.load(f)
                    for soumission in soumissions_completes:
                        # FIX: Chercher par num au lieu de id car les IDs peuvent diff√©rer
                        if soumission.get("num") == num or soumission.get("id") == soumission_id:
                            soumission_complete_data = soumission.copy()  # Copier TOUTES les donn√©es
                            print(f"[DEBUG] Donn√©es compl√®tes trouv√©es pour num={num} (ID {soumission_id})")
                            print(f"[DEBUG] Produit: {soumission_complete_data.get('produit', 'VIDE')}")
                            print(f"[DEBUG] Part: {soumission_complete_data.get('part', 'VIDE')}")
                            print(f"[DEBUG] Item: {soumission_complete_data.get('item', 'VIDE')}")
                            print(f"[DEBUG] Endroit: {soumission_complete_data.get('endroit', 'VIDE')}")
                            print(f"[DEBUG] Payer par: {soumission_complete_data.get('payer_par', 'VIDE')}")
                            print(f"[DEBUG] Date2: {soumission_complete_data.get('date2', 'VIDE')}")
                            print(f"[DEBUG] Temps: {soumission_complete_data.get('temps', 'VIDE')}")
                            break
        except Exception as e:
            print(f"[ERREUR] Impossible de r√©cup√©rer les donn√©es compl√®tes: {e}")

        # Pr√©paration des donn√©es √† enregistrer dans travaux √† compl√©ter
        # COMMENCER avec les donn√©es compl√®tes r√©cup√©r√©es, puis mettre √† jour avec les nouvelles valeurs
        soumission_data = soumission_complete_data.copy()  # Copier TOUTES les donn√©es originales

        # Mettre √† jour seulement les champs qui ont chang√© lors de la signature
        # Utiliser le fuseau horaire de Toronto pour la date de signature
        import zoneinfo
        toronto_tz = zoneinfo.ZoneInfo("America/Toronto")
        date_signature_toronto = datetime.now(toronto_tz).strftime("%d/%m/%Y")

        soumission_data.update({
            "id": soumission_id,  # CRUCIAL: utiliser l'ID re√ßu du frontend
            "num": num,  # Le vrai num√©ro "24-XXXX"
            "clientNom": clientNom,
            "clientPrenom": clientPrenom,
            "pdfUrl": lien_pdf_signe,  # Nouveau PDF sign√©
            "date": date_signature_toronto,  # Date de signature (heure Toronto) au format DD/MM/YYYY
            "prix": prix_str,
            "adresse": adresse,
            "telephone": telephone,
            "courriel": clientEmail
            # endroit, produit, part, item, date2, temps, payer_par sont pr√©serv√©s de soumission_complete_data
        })

        print(f"[DEBUG] Donn√©es finales apr√®s merge:")
        print(f"[DEBUG] Produit final: {soumission_data.get('produit', 'VIDE')}")
        print(f"[DEBUG] Part final: {soumission_data.get('part', 'VIDE')}")
        print(f"[DEBUG] Item final: {soumission_data.get('item', 'VIDE')}")
        print(f"[DEBUG] Endroit final: {soumission_data.get('endroit', 'VIDE')}")
        print(f"[DEBUG] Date2 final: {soumission_data.get('date2', 'VIDE')}")
        print(f"[DEBUG] Temps final: {soumission_data.get('temps', 'VIDE')}")
        
        print(f"[DEBUG] ID re√ßu du frontend: {soumission_id}")
        print(f"[DEBUG] Num re√ßu du frontend: {num}")
        print(f"[DEBUG] Soumission data cr√©√©e avec ID: {soumission_data.get('id')}")
        print(f"[DEBUG] Soumission data cr√©√©e avec num: {soumission_data.get('num')}")

        # Enregistrement dans le JSON des soumissions sign√©es
        enregistrer_soumission_signee(username, soumission_data)

        # Enregistrement dans travaux √† compl√©ter (copie)
        # NOTE: Le bannissement se fait maintenant c√¥t√© frontend via bannirClientACompleter()
        enregistrer_travaux_a_completer(username, soumission_data)

        # [HOT] NOUVEAU: D√©placer de ventes_attente vers ventes_acceptees
        try:
            # Supprimer de ventes_attente
            ventes_attente_file = os.path.join(f"{base_cloud}/ventes_attente", username, "ventes.json")
            if os.path.exists(ventes_attente_file):
                with open(ventes_attente_file, "r", encoding="utf-8") as f:
                    ventes_attente = json.load(f)

                print(f"[DEBUG] DEBUG: soumission_id recherch√© = {soumission_id}")
                print(f"[DEBUG] DEBUG: Nombre de ventes dans attente = {len(ventes_attente)}")
                for v in ventes_attente:
                    print(f"[DEBUG] DEBUG: Vente dans attente - ID={v.get('id')}, Nom={v.get('nom')}, Prenom={v.get('prenom')}")

                # Filtrer pour enlever la soumission sign√©e
                # On compare par nom, pr√©nom et t√©l√©phone car l'ID peut √™tre diff√©rent
                ventes_attente_filtered = []
                found = False
                for v in ventes_attente:
                    if (v.get("nom") == clientNom and
                        v.get("prenom") == clientPrenom and
                        v.get("telephone") == telephone):
                        print(f"[OK] MATCH TROUV√â: {v.get('prenom')} {v.get('nom')} - {v.get('telephone')}")
                        found = True
                    else:
                        ventes_attente_filtered.append(v)

                if not found:
                    print(f"[WARNING] AUCUN MATCH trouv√© pour {clientPrenom} {clientNom} - {telephone}")

                with open(ventes_attente_file, "w", encoding="utf-8") as f:
                    json.dump(ventes_attente_filtered, f, ensure_ascii=False, indent=2)
                print(f"[OK] Soumission {clientPrenom} {clientNom} supprim√©e de ventes_attente")

            # Ajouter dans ventes_acceptees
            ventes_acceptees_dir = os.path.join(f"{base_cloud}/ventes_acceptees", username)
            os.makedirs(ventes_acceptees_dir, exist_ok=True)
            ventes_acceptees_file = os.path.join(ventes_acceptees_dir, "ventes.json")

            if os.path.exists(ventes_acceptees_file):
                with open(ventes_acceptees_file, "r", encoding="utf-8") as f:
                    ventes_acceptees = json.load(f)
            else:
                ventes_acceptees = []

            ventes_acceptees.append(soumission_data)

            with open(ventes_acceptees_file, "w", encoding="utf-8") as f:
                json.dump(ventes_acceptees, f, ensure_ascii=False, indent=2)
            print(f"[OK] Soumission {soumission_id} ajout√©e dans ventes_acceptees")

            # Synchroniser avec Monday.com EN ARRI√àRE-PLAN (non bloquant)
            def sync_monday_background():
                sync_success = sync_vente_to_monday(username, soumission_data)
                if sync_success:
                    print(f"[MONDAY] ‚úì Synchronisation Monday.com r√©ussie")
                else:
                    print(f"[MONDAY] ‚úó Synchronisation Monday.com √©chou√©e (non bloquant)")

            threading.Thread(target=sync_monday_background, daemon=True).start()
            print(f"[MONDAY] üöÄ Synchronisation Monday.com lanc√©e en arri√®re-plan")

        except Exception as e:
            print(f"[WARNING] Erreur lors du d√©placement ventes_attente -> ventes_acceptees: {e}")

        # Envoi des emails au client et √† l'entrepreneur
        envoyer_email_soumission_signee(clientEmail, clientNom, clientPrenom, lien_pdf_signe, username, language)
        envoyer_email_soumission_signee_entrepreneur(username, lien_pdf_signe, clientPrenom, clientNom)

        # Sync RPO apr√®s la signature (contrat sign√©)
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo
            sync_soumissions_to_rpo(username)
            print(f"[OK] RPO synchronis√© apr√®s signature pour {username}")
        except Exception as sync_error:
            print(f"[WARNING] Erreur sync RPO apr√®s signature: {sync_error}")

        return JSONResponse({"message": "Soumission sign√©e envoy√©e avec succ√®s"})

    except Exception as e:
        print("Erreur envoyer_soumission_signee:", e)
        raise HTTPException(status_code=500, detail="Erreur serveur interne lors de l'envoi")



def envoyer_email_soumission_signee(email_client, clientNom, clientPrenom, lien_pdf, senderUsername, language='fr'):
    # Templates d'email bilingues
    if language == 'en':
        subject_text = "Your Signed Quote - College Painters"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Hello {clientPrenom} {clientNom},</p>'
            f'<p>Your quote has been accepted.</p><br>'
            f'<p>You can view your signed quote by clicking the button below:</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_pdf}" target="_blank" '
            f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     View my signed quote &#8594;'
            f'  </a>'
            f'</p><br>'
            f'<p>Thank you for your trust.</p>'
            f'<p>The College Painters Team</p>'
            f'</div>'
        )
    else:
        subject_text = "Votre soumission sign√©e - Qualit√© √âtudiants"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Bonjour {clientPrenom} {clientNom},</p>'
            f'<p>Votre soumission a bien √©t√© accept√©e.</p><br>'
            f'<p>Vous pouvez consulter votre soumission sign√©e en cliquant sur le bouton ci-dessous :</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{lien_pdf}" target="_blank" '
            f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
            f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Voir ma soumission sign√©e &#8594;'
            f'  </a>'
            f'</p><br>'
            f'<p>Merci de votre confiance.</p>'
            f'<p>L\'√©quipe Qualit√© √âtudiants</p>'
            f'</div>'
        )

    subject = "=?UTF-8?B?" + base64.b64encode(subject_text.encode("utf-8")).decode() + "?="
    envoyer_email(email_client, subject, html, username=senderUsername)


def envoyer_email_soumission_signee_entrepreneur(username, lien_pdf, clientPrenom, clientNom):
    chemin = os.path.join(base_cloud, "emails", f"{username}.json")
    if not os.path.exists(chemin):
        print("Aucun Gmail connect√© pour", username)
        return

    with open(chemin, "r", encoding="utf-8") as f:
        tokens = json.load(f)
    email_entrepreneur = tokens.get("email")
    if not email_entrepreneur:
        print("Email entrepreneur non trouv√©")
        return

    subject = "=?UTF-8?B?" + base64.b64encode("Soumission sign√©e re√ßue".encode("utf-8")).decode() + "?="
    html = (
        f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
        f'<p>Bonjour,</p>'
        f'<p>{clientPrenom} {clientNom} a accept√© la soumission.</p><br>'
        f'<p>Vous pouvez consulter le document sign√© en cliquant sur le bouton ci-dessous :</p>'
        f'<p style="margin: 10px 0;">'
        f'  <a href="{lien_pdf}" target="_blank" '
        f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
        f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
        f'     Voir la soumission sign√©e &#8594;'
        f'  </a>'
        f'</p>'
        f'</div>'
    )
    envoyer_email(email_entrepreneur, subject, html, username=username)


def envoyer_email(destinataire, sujet, html_contenu, username):
    access_token = get_valid_gmail_token(username)

    raw_message = (
        f"To: {destinataire}\r\n"
        f"Subject: {sujet}\r\n"
        f"Content-Type: text/html; charset=UTF-8\r\n\r\n"
        f"{html_contenu}"
    )
    raw_encoded = base64.urlsafe_b64encode(raw_message.encode("utf-8")).decode("utf-8")

    response = requests.post(
        "https://gmail.googleapis.com/gmail/v1/users/me/messages/send",
        headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        },
        json={"raw": raw_encoded}
    )
    if response.status_code != 200:
        print("Erreur envoi mail:", response.text)


@app.get("/api/soumissions/count/{username}")
def get_soumissions_count(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte le TOTAL de toutes les soumissions = en attente + sign√©es + perdus
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
    else:
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        # 1. Compter les ventes en attente (ventes_attente - NOUVELLE ROUTE)
        fichier_attente = os.path.join(f"{base_cloud}/ventes_attente", user, "ventes.json")
        if os.path.exists(fichier_attente):
            with open(fichier_attente, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    data_attente = json.loads(content)
                    total_count += len(data_attente)

        # 2. Compter les soumissions sign√©es (soumissions_signees - HISTORIQUE COMPLET)
        fichier_signees = os.path.join(f"{base_cloud}/soumissions_signees", user, "soumissions.json")
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    data_signees = json.loads(content)
                    total_count += len(data_signees)

        # 3. Compter les clients perdus
        fichier_perdus = os.path.join(f"{base_cloud}/clients_perdus", user, "clients.json")
        if os.path.exists(fichier_perdus):
            with open(fichier_perdus, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    data_perdus = json.loads(content)
                    total_count += len(data_perdus)

    return {"count": total_count}


@app.get("/api/ventes/attente/count/{username}")
def count_ventes_attente(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte uniquement les ventes en attente
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
    else:
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        chemin = f"{base_cloud}/ventes_attente/{user}/ventes.json"
        if os.path.exists(chemin):
            try:
                with open(chemin, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        data = json.loads(content)
                        total_count += len(data)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    return {"count": total_count}


@app.get("/api/clients-perdus/count/{username}")
def count_clients_perdus(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte uniquement les clients perdus
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        if team_members:
            usernames_to_process = [e["username"] for e in team_members]
        else:
            usernames_to_process = [username]
    else:
        # Par d√©faut, utiliser seulement l'utilisateur demand√©
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        chemin = f"{base_cloud}/clients_perdus/{user}/clients.json"
        if os.path.exists(chemin):
            try:
                with open(chemin, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        data = json.loads(content)
                        total_count += len(data)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    return {"count": total_count}

@app.get("/api/ventes/produit/count/{username}")
def count_ventes_produit(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte uniquement les ventes produit (travaux termin√©s en production)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        if team_members:
            usernames_to_process = [e["username"] for e in team_members]
        else:
            usernames_to_process = [username]
    else:
        # Par d√©faut, utiliser seulement l'utilisateur demand√©
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        chemin = f"{base_cloud}/ventes_produit/{user}/ventes.json"
        if os.path.exists(chemin):
            try:
                with open(chemin, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        data = json.loads(content)
                        total_count += len(data)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    return {"count": total_count}


@app.get("/api/ventes/produit/total/{username}")
def get_total_ventes_produit(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    R√©cup√®re le montant total des ventes produit (travaux termin√©s en production)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        if team_members:
            usernames_to_process = [e["username"] for e in team_members]
        else:
            usernames_to_process = [username]
    else:
        # Par d√©faut, utiliser seulement l'utilisateur demand√©
        usernames_to_process = [username]

    total_montant = 0.0

    for user in usernames_to_process:
        chemin = os.path.join(base_cloud, "ventes_produit", user, "ventes.json")
        if os.path.exists(chemin):
            try:
                with open(chemin, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        ventes = json.loads(content)
                        for vente in ventes:
                            # Extraire le prix de la vente
                            prix_str = vente.get("prix", "0")
                            # Convertir le prix en nombre (enlever les espaces, $ et convertir virgule en point)
                            prix_str = str(prix_str).replace("\xa0", "").replace(" ", "").replace("$", "").replace(",", ".")
                            try:
                                prix_num = float(prix_str)
                                total_montant += prix_num
                            except ValueError:
                                # Si la conversion √©choue, ignorer cette vente
                                pass
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    # Formater le montant avec espace de milliers et virgule d√©cimale
    montant_formate = f"{total_montant:,.2f}".replace(",", "TEMP").replace(".", ",").replace("TEMP", " ") + " $"

    return {"total": montant_formate, "montant": total_montant}


# ============== API Num√©ros de Soumission Uniques ==============
NUMEROS_SOUMISSION_FILE = os.path.join(base_cloud, "soumissions", "numeros_utilises.json")

def get_numeros_utilises():
    """R√©cup√®re la liste des num√©ros de soumission d√©j√† utilis√©s"""
    try:
        if not os.path.exists(NUMEROS_SOUMISSION_FILE):
            os.makedirs(os.path.dirname(NUMEROS_SOUMISSION_FILE), exist_ok=True)
            with open(NUMEROS_SOUMISSION_FILE, "w", encoding="utf-8") as f:
                json.dump([], f)
            return []

        with open(NUMEROS_SOUMISSION_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"[ERROR] get_numeros_utilises: {e}")
        return []

def ajouter_numero_utilise(numero: str, username: str):
    """Ajoute un num√©ro √† la liste des num√©ros utilis√©s"""
    numeros = get_numeros_utilises()
    numeros.append({
        "numero": numero,
        "username": username,
        "date": datetime.now().isoformat()
    })
    with open(NUMEROS_SOUMISSION_FILE, "w", encoding="utf-8") as f:
        json.dump(numeros, f, indent=2, ensure_ascii=False)

@app.get("/api/soumission/generer-numero")
def generer_numero_soumission():
    """G√©n√®re un num√©ro de soumission unique format 26-XXXX"""
    import random
    numeros = get_numeros_utilises()
    numeros_existants = [n["numero"] for n in numeros]

    # Pr√©fixe fixe 26 (pour 2026)
    prefixe = "26"

    # G√©n√©rer un num√©ro unique
    max_tentatives = 100
    for _ in range(max_tentatives):
        # 4 chiffres al√©atoires
        suffix = str(random.randint(0, 9999)).zfill(4)
        numero = f"{prefixe}-{suffix}"

        if numero not in numeros_existants:
            return {"numero": numero}

    raise HTTPException(status_code=500, detail="Impossible de g√©n√©rer un num√©ro unique")

@app.post("/api/soumission/reserver-numero")
def reserver_numero_soumission(data: dict = Body(...)):
    """R√©serve un num√©ro de soumission (quand envoy√© ou sign√©)"""
    numero = data.get("numero")
    username = data.get("username")

    if not numero or not username:
        raise HTTPException(status_code=400, detail="Num√©ro et username requis")

    numeros = get_numeros_utilises()
    numeros_existants = [n["numero"] for n in numeros]

    if numero in numeros_existants:
        raise HTTPException(status_code=409, detail="Ce num√©ro est d√©j√† utilis√©")

    ajouter_numero_utilise(numero, username)
    return {"success": True, "message": f"Num√©ro {numero} r√©serv√©"}

@app.get("/api/soumission/verifier-numero/{numero}")
def verifier_numero_soumission(numero: str):
    """V√©rifie si un num√©ro est disponible"""
    numeros = get_numeros_utilises()
    numeros_existants = [n["numero"] for n in numeros]

    return {"disponible": numero not in numeros_existants}


@app.get("/api/soumissions/signees/count/{username}")
def count_soumissions_signees(username: str):
    chemin = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
    if not os.path.exists(chemin):
        return {"count": 0}  # Aucun fichier = 0

    try:
        with open(chemin, "r", encoding="utf-8") as f:
            data = json.load(f)
        return {"count": len(data)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

@app.get("/api/soumissions/signees/total/{username}")
def count_total_soumissions_signees(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte le nombre de clients dans le dossier soumissions_signees
    (tous les clients sign√©s, jamais supprim√©s)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        if team_members:
            usernames_to_process = [e["username"] for e in team_members]
        else:
            usernames_to_process = [username]
    else:
        # Par d√©faut, utiliser seulement l'utilisateur demand√©
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        chemin = f"{base_cloud}/soumissions_signees/{user}/soumissions.json"
        if os.path.exists(chemin):
            try:
                with open(chemin, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        data = json.loads(content)
                        total_count += len(data)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    return {"count": total_count}

def incrementer_total_signees(username: str):
    """
    Incr√©mente le compteur total de soumissions sign√©es
    """
    os.makedirs(f"{base_cloud}/total_signees", exist_ok=True)
    chemin = f"{base_cloud}/total_signees/{username}.json"

    total_actuel = 0
    if os.path.exists(chemin):
        with open(chemin, "r", encoding="utf-8") as f:
            data = json.load(f)
            total_actuel = data.get("total", 0)

    total_actuel += 1

    with open(chemin, "w", encoding="utf-8") as f:
        json.dump({"total": total_actuel}, f, indent=2)

    print(f"[incrementer_total_signees] Total sign√©es pour {username}: {total_actuel}")

@app.get("/api/chiffre-affaires/{username}")
def get_chiffre_affaires_api(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    try:
        # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
        if all_teams:
            usernames_to_process = get_all_entrepreneurs()
        # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
        elif team:
            team_members = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
        else:
            usernames_to_process = [username]

        total = 0.0
        print(f"[CHIFFRE_AFFAIRES] Calcul pour {usernames_to_process}")
        print(f"[CHIFFRE_AFFAIRES] base_cloud = {base_cloud}")

        for user in usernames_to_process:
            # 1. Additionner les prix des ventes accept√©es
            acceptees_path = f"{base_cloud}/ventes_acceptees/{user}/ventes.json"
            print(f"[CHIFFRE_AFFAIRES] Chemin accept√©es: {acceptees_path}")
            print(f"[CHIFFRE_AFFAIRES] Fichier existe: {os.path.exists(acceptees_path)}")

            if os.path.exists(acceptees_path):
                with open(acceptees_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        ventes_acceptees = json.loads(content)
                        print(f"[CHIFFRE_AFFAIRES] Nombre de ventes accept√©es: {len(ventes_acceptees)}")
                        for vente in ventes_acceptees:
                            prix_str = vente.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".")
                            prix_str = prix_str.replace("$", "").strip()
                            print(f"[CHIFFRE_AFFAIRES] Prix accept√©e brut: '{vente.get('prix')}' -> nettoy√©: '{prix_str}'")
                            try:
                                prix_float = float(prix_str)
                                total += prix_float
                                print(f"[CHIFFRE_AFFAIRES] Ajout√©: {prix_float}, Total: {total}")
                            except Exception as e:
                                print(f"[CHIFFRE_AFFAIRES] ERREUR conversion prix: {e}")
                                continue

            # 2. Additionner les prix des ventes produit
            produit_path = f"{base_cloud}/ventes_produit/{user}/ventes.json"
            print(f"[CHIFFRE_AFFAIRES] Chemin produit: {produit_path}")
            print(f"[CHIFFRE_AFFAIRES] Fichier existe: {os.path.exists(produit_path)}")

            if os.path.exists(produit_path):
                with open(produit_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        ventes_produit = json.loads(content)
                        print(f"[CHIFFRE_AFFAIRES] Nombre de ventes produit: {len(ventes_produit)}")
                        for vente in ventes_produit:
                            prix_str = vente.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".")
                            prix_str = prix_str.replace("$", "").strip()
                            print(f"[CHIFFRE_AFFAIRES] Prix produit brut: '{vente.get('prix')}' -> nettoy√©: '{prix_str}'")
                            try:
                                prix_float = float(prix_str)
                                total += prix_float
                                print(f"[CHIFFRE_AFFAIRES] Ajout√©: {prix_float}, Total: {total}")
                            except Exception as e:
                                print(f"[CHIFFRE_AFFAIRES] ERREUR conversion prix: {e}")
                                continue

        print(f"[CHIFFRE_AFFAIRES] Total final: {total}")

        # Formater le total au format fran√ßais
        parts = f"{total:,.2f}".split(".")
        partie_entiere = parts[0].replace(",", " ")
        partie_decimale = parts[1]
        total_formate = f"{partie_entiere},{partie_decimale} $"
        print(f"[CHIFFRE_AFFAIRES] Total format√©: {total_formate}")
        return {"total": total_formate}
    except Exception as e:
        print(f"[CHIFFRE_AFFAIRES] EXCEPTION: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur calcul chiffre d'affaires: {e}")


def enregistrer_travaux_a_completer(utilisateur: str, soumission: dict):
    try:
        dossier = os.path.join(f"{base_cloud}/travaux_a_completer", utilisateur)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "soumissions.json")

        # PR√âSERVER le num√©ro original ET l'ID
        original_num = soumission.get('num', '')  # Le vrai num√©ro "24-XXXX"
        original_id = soumission.get('id', str(uuid.uuid4()))
        
        soumission['original_id'] = original_id  # ID de r√©f√©rence pour le lien
        soumission['id'] = original_id           # M√äME ID que dans signees
        # PR√âSERVER le vrai num√©ro de soumission (ne pas l'√©craser avec l'ID)
        if original_num:
            soumission['num'] = original_num  # Garder le vrai num√©ro "24-XXXX"
        else:
            print(f"[ATTENTION] Pas de num√©ro de soumission trouv√© pour {utilisateur} dans travaux_a_completer")
            soumission['num'] = original_id  # Fallback
        
        print(f"[enregistrer_travaux_a_completer] Pr√©servation ID: {original_id}")
        
        # Mapper les champs pour compatibilit√© avec l'affichage frontend
        # Assurer que clientPrenom et clientNom existent toujours
        if 'prenom' in soumission and 'clientPrenom' not in soumission:
            soumission['clientPrenom'] = soumission['prenom']
        elif 'clientPrenom' not in soumission and 'prenom' not in soumission:
            soumission['clientPrenom'] = ""
            
        if 'nom' in soumission and 'clientNom' not in soumission:
            soumission['clientNom'] = soumission['nom']
        elif 'clientNom' not in soumission and 'nom' not in soumission:
            soumission['clientNom'] = ""
            
        print(f"[enregistrer_travaux_a_completer] Champs apr√®s mapping: clientPrenom={soumission.get('clientPrenom')}, clientNom={soumission.get('clientNom')}")

        # PR√âSERVATION COMPL√àTE: S'assurer que TOUS les champs de soumission sont pr√©serv√©s
        # Cette fonction re√ßoit une soumission compl√®te et doit pr√©server TOUTES les donn√©es
        essential_fields = [
            'produit', 'part', 'item', 'endroit', 'telephone', 'courriel',
            'adresse', 'prix', 'date', 'date2', 'temps', 'payer_par'
        ]
        for field in essential_fields:
            if field not in soumission:
                soumission[field] = ""
                print(f"[enregistrer_travaux_a_completer] Champ essentiel manquant '{field}' ajout√© comme vide")

        print(f"[enregistrer_travaux_a_completer] TOUS les champs pr√©serv√©s pour soumission {soumission.get('num', soumission.get('id'))}")

        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                data = json.loads(content) if content else []
        else:
            data = []

        data.append(soumission)

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"[enregistrer_travaux_a_completer] Soumission enregistr√©e pour {utilisateur} dans {fichier}")

    except Exception as e:
        print(f"[enregistrer_travaux_a_completer] ERREUR: {e}")
        raise e

@app.get("/travaux_a_completer/{username}")
def get_travaux_a_completer(username: str):
    fichier = os.path.join(f"{base_cloud}/travaux_a_completer", username, "soumissions.json")
    if not os.path.exists(fichier):
        return []
    with open(fichier, "r", encoding="utf-8") as f:
        content = f.read().strip()
        if not content:
            return []
        data = json.loads(content)
        # Ajouter statut_paiement par d√©faut si manquant
        for record in data:
            if "statut_paiement" not in record:
                record["statut_paiement"] = "En attente"
        return data

@app.post("/cloturer-travail")
async def cloturer_travail(payload: dict = Body(...)):
    import traceback
    import urllib.parse

    username = payload.get("username")
    event_id = payload.get("event_id")

    if not username or not event_id:
        raise HTTPException(status_code=400, detail="username et event_id requis")

    try:
        dossier_ac = f"{base_cloud}/travaux_a_completer/{username}"
        fichier_ac = os.path.join(dossier_ac, "soumissions.json")
        if os.path.exists(fichier_ac):
            with open(fichier_ac, "r", encoding="utf-8") as f:
                travaux_a_completer = json.load(f)
        else:
            travaux_a_completer = []

        print(f"[DEBUG] travaux_a_completer: {len(travaux_a_completer)} items")

        travail = None
        for t in travaux_a_completer:
            print(f"[DEBUG] V√©rif id {t.get('id')} == {event_id}")
            if t.get("id") == event_id:
                travail = t
                break

        if not travail:
            raise HTTPException(status_code=404, detail="Travail non trouv√©")

        travaux_a_completer = [t for t in travaux_a_completer if t.get("id") != event_id]

        with open(fichier_ac, "w", encoding="utf-8") as f:
            json.dump(travaux_a_completer, f, indent=2, ensure_ascii=False)

        # Soustraire 4 heures √† la date actuelle (UTC-4)
        now_utc = datetime.utcnow()
        now_utc_minus_4 = now_utc - timedelta(hours=4)
        travail["date"] = now_utc_minus_4.isoformat()

        dossier_c = f"{base_cloud}/travaux_completes/{username}"
        os.makedirs(dossier_c, exist_ok=True)
        fichier_c = os.path.join(dossier_c, "soumissions.json")

        if os.path.exists(fichier_c):
            with open(fichier_c, "r", encoding="utf-8") as f:
                travaux_completes = json.load(f)
        else:
            travaux_completes = []

        # PR√âSERVATION COMPL√àTE: S'assurer que TOUS les champs de soumission sont pr√©serv√©s
        # Le travail vient de travaux_a_completer qui devrait avoir TOUTES les donn√©es de la soumission originale
        essential_fields = [
            'produit', 'part', 'item', 'endroit', 'telephone', 'courriel',
            'adresse', 'prix', 'depot', 'date', 'date2', 'temps', 'payer_par',
            'nom', 'prenom', 'clientNom', 'clientPrenom', 'num', 'original_id'
        ]
        for field in essential_fields:
            if field not in travail:
                travail[field] = ""
                print(f"[cloturer_travail] Champ essentiel manquant '{field}' ajout√© comme vide pour travail {travail.get('id')}")

        # Ajouter statut_paiement par d√©faut si non pr√©sent
        if "statut_paiement" not in travail:
            travail["statut_paiement"] = "En attente"

        print(f"[cloturer_travail] TOUS les champs pr√©serv√©s pour travail {travail.get('num', travail.get('id'))}")

        # √âviter les duplications - v√©rifier si d√©j√† pr√©sent
        ids_existants = {t.get("id", t.get("num", "")) for t in travaux_completes}
        travail_id = travail.get("id", travail.get("num", ""))
        
        if travail_id not in ids_existants:
            travaux_completes.append(travail)
            
            with open(fichier_c, "w", encoding="utf-8") as f:
                json.dump(travaux_completes, f, indent=2, ensure_ascii=False)
        else:
            print(f"[WARNING] Travail {travail_id} d√©j√† pr√©sent dans travaux_completes, √©viter duplication")

        # --- NOUVEAU: SAUVEGARDE √âGALEMENT DANS TRAVAUX_COMPLETE_FACTURE ---
        dossier_facture = f"{base_cloud}/travaux_complete_facture/{username}"
        os.makedirs(dossier_facture, exist_ok=True)
        fichier_facture = os.path.join(dossier_facture, "soumissions.json")

        if os.path.exists(fichier_facture):
            with open(fichier_facture, "r", encoding="utf-8") as f:
                travaux_facture = json.load(f)
        else:
            travaux_facture = []

        # √âviter les duplications dans travaux_complete_facture aussi
        ids_existants_facture = {t.get("id", t.get("num", "")) for t in travaux_facture}
        
        if travail_id not in ids_existants_facture:
            travaux_facture.append(travail)
            
            with open(fichier_facture, "w", encoding="utf-8") as f:
                json.dump(travaux_facture, f, indent=2, ensure_ascii=False)
                
            print(f"[DEBUG] Travail {travail_id} ajout√© √† travaux_complete_facture")
        else:
            print(f"[WARNING] Travail {travail_id} d√©j√† pr√©sent dans travaux_complete_facture, √©viter duplication")

        try:
            prix_str = str(travail.get("prix", "0")).replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
            prix = float(prix_str)
        except Exception as e:
            print(f"[ERREUR] conversion prix: {e}")
            prix = 0.0

        try:
            ajouter_au_chiffre_affaires(username, prix)
        except Exception as e:
            print(f"[ERREUR] ajouter_au_chiffre_affaires: {e}")
            raise

        # --- ENVOI EMAIL DEMANDE DE SATISFACTION ---
        try:
            url_avis = (
                f"{BASE_URL}/avisclient?"
                f"username={username}&"
                f"travail_id={travail.get('id')}&"
                f"nom={urllib.parse.quote(travail.get('clientNom',''))}&"
                f"prenom={urllib.parse.quote(travail.get('clientPrenom',''))}"
            )
            envoyer_email_demande_satisfaction(username, travail, url_avis)
        except Exception as e:
            print(f"[ERREUR] envoi email satisfaction: {e}")

        return {"detail": "Travail cl√¥tur√© avec succ√®s"}

    except Exception as e:
        print("[ERREUR /cloturer-travail] ", e)
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


def envoyer_email_demande_satisfaction(username: str, travail: dict, url_avis: str):
    chemin = os.path.join(base_cloud, "emails", f"{username}.json")
    if not os.path.exists(chemin):
        print("Aucun Gmail connect√© pour", username)
        return

    with open(chemin, "r", encoding="utf-8") as f:
        tokens = json.load(f)

    # R√©cup√©rer l'email client depuis le dict travail
    email_client = travail.get("courriel") or travail.get("email") or travail.get("clientEmail")
    if not email_client:
        print("Email client non trouv√© dans la soumission")
        return

    nom_client = travail.get("nom") or travail.get("clientNom", "")
    prenom_client = travail.get("prenom") or travail.get("clientPrenom", "")

    # D√©tecter la langue en cherchant des mots-cl√©s anglais
    language = 'fr'
    textes_a_verifier = [
        str(travail.get("item", "")),
        str(travail.get("temps", "")),
        str(travail.get("produit", "")),
        str(travail.get("part", ""))
    ]
    texte_combine = " ".join(textes_a_verifier).lower()

    # Mots-cl√©s anglais indicateurs
    mots_anglais = ["interior work", "exterior work", "days", "day", "weeks", "week",
                    "pressure wash", "sanding", "liability insurance", "turnkey service"]

    if any(mot in texte_combine for mot in mots_anglais):
        language = 'en'
        # Ajouter &lang=en √† l'URL
        url_avis = url_avis + "&lang=en"

    # Templates d'email bilingues
    if language == 'en':
        subject_text = "Your feedback matters to us!"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Hello {prenom_client} {nom_client},</p><br>'
            f'<p>It was a real pleasure working with you on this project.</p><br>'
            f'<p>Your satisfaction is my priority. Could you take a minute to evaluate the quality of my work? Your feedback is valuable to help me always better assist you.</p>'
            f'<p style="margin: 10px 0;">'
            f'  <a href="{url_avis}" target="_blank" '
            f'     style="padding: 6px 12px; background-color: #000000; color: #ffffff; text-decoration: none; '
            f'            border-radius: 20px; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Leave a review'
            f'  </a>'
            f'</p><br>'
            f'<p>Thank you for your trust and see you soon!</p>'
            f'</div>'
        )
    else:
        subject_text = "Votre avis compte pour nous !"
        html = (
            f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
            f'<p>Bonjour {prenom_client} {nom_client},</p><br>'
            f"<p>Ce fut un r√©el plaisir de collaborer avec vous sur ce projet.</p><br>"
            f"<p>Votre satisfaction est ma priorit√©. Pourriez-vous prendre une minute pour √©valuer la qualit√© de mon travail ? Vos retours sont pr√©cieux pour m'aider √† toujours mieux vous accompagner.</p>"
            f'<p style="margin: 10px 0;">'
            f'  <a href="{url_avis}" target="_blank" '
            f'     style="padding: 6px 12px; background-color: #000000; color: #ffffff; text-decoration: none; '
            f'            border-radius: 20px; display: inline-block; font-weight: bold; font-size: 14px;">'
            f'     Laisser un avis'
            f'  </a>'
            f'</p><br>'
            f'<p>Merci de votre confiance et √† tr√®s bient√¥t !</p>'
            f'</div>'
        )

    subject = "=?UTF-8?B?" + base64.b64encode(subject_text.encode("utf-8")).decode() + "?="
    envoyer_email(email_client, subject, html, username=username)



@app.get("/travaux_completes/{username}")
def get_travaux_completes(username: str):
    fichier = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
    if not os.path.exists(fichier):
        return []
    with open(fichier, "r", encoding="utf-8") as f:
        content = f.read().strip()
        if not content:
            return []

        data = json.loads(content)

        # Corriger automatiquement les champs manquants
        required_fields = ['produit', 'part', 'item', 'endroit', 'telephone', 'courriel', 'statut_paiement']
        updated = False

        for record in data:
            for field in required_fields:
                if field not in record:
                    record[field] = "En attente" if field == "statut_paiement" else ""
                    updated = True
                    print(f"[get_travaux_completes] Champ manquant '{field}' ajout√© pour {record.get('num', record.get('id', 'UNKNOWN'))}")

        # Sauvegarder si des champs ont √©t√© ajout√©s
        if updated:
            with open(fichier, "w", encoding="utf-8") as f_write:
                json.dump(data, f_write, indent=2, ensure_ascii=False)
            print(f"[get_travaux_completes] Fichier mis √† jour avec champs manquants pour {username}")

        return data

@app.get("/travaux_complete_facture/{username}")
def get_travaux_complete_facture(username: str):
    fichier = os.path.join(f"{base_cloud}/travaux_complete_facture", username, "soumissions.json")
    if not os.path.exists(fichier):
        return []
    with open(fichier, "r", encoding="utf-8") as f:
        content = f.read().strip()
        if not content:
            return []

        data = json.loads(content)

        # Corriger automatiquement les champs manquants
        required_fields = ['produit', 'part', 'item', 'endroit', 'telephone', 'courriel']
        updated = False

        for record in data:
            for field in required_fields:
                if field not in record:
                    record[field] = ""
                    updated = True
                    print(f"[get_travaux_complete_facture] Champ manquant '{field}' ajout√© pour {record.get('num', record.get('id', 'UNKNOWN'))}")

        # Sauvegarder si des champs ont √©t√© ajout√©s
        if updated:
            with open(fichier, "w", encoding="utf-8") as f_write:
                json.dump(data, f_write, indent=2, ensure_ascii=False)
            print(f"[get_travaux_complete_facture] Fichier mis √† jour avec champs manquants pour {username}")

        return data

def enregistrer_soumission_signee(utilisateur: str, soumission: dict):
    try:
        dossier = os.path.join(f"{base_cloud}/soumissions_signees", utilisateur)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "soumissions.json")

        # PR√âSERVER le num√©ro original ET l'ID
        original_num = soumission.get('num', '')  # Le vrai num√©ro "24-XXXX"
        original_id = soumission.get('id', str(uuid.uuid4()))
        
        soumission['original_id'] = original_id  # ID de r√©f√©rence pour le lien
        soumission['id'] = original_id
        # PR√âSERVER le vrai num√©ro de soumission (ne pas l'√©craser avec l'ID)
        if original_num:
            soumission['num'] = original_num  # Garder le vrai num√©ro "24-XXXX"
        else:
            print(f"[ATTENTION] Pas de num√©ro de soumission trouv√© pour {utilisateur}")
            soumission['num'] = original_id  # Fallback
        
        print(f"[enregistrer_soumission_signee] Pr√©servation ID: {original_id}")

        # PR√âSERVATION COMPL√àTE: S'assurer que TOUS les champs de soumission sont pr√©serv√©s
        # La soumission sign√©e doit conserver TOUTES les donn√©es de la soumission compl√®te
        essential_fields = [
            'produit', 'part', 'item', 'endroit', 'telephone', 'courriel',
            'adresse', 'prix', 'depot', 'date', 'date2', 'temps', 'payer_par',
            'nom', 'prenom'
        ]
        for field in essential_fields:
            if field not in soumission:
                soumission[field] = ""
                print(f"[enregistrer_soumission_signee] Champ essentiel manquant '{field}' ajout√© comme vide")

        print(f"[enregistrer_soumission_signee] TOUS les champs pr√©serv√©s pour soumission {soumission.get('num', soumission.get('id'))}")

        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                data = json.loads(content) if content else []
        else:
            data = []

        data.append(soumission)

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"[enregistrer_soumission_signee] Soumission sign√©e enregistr√©e pour {utilisateur} dans {fichier}")

        # Incr√©menter le compteur total de soumissions sign√©es
        print(f"[enregistrer_soumission_signee] Appel incrementer_total_signees pour {utilisateur}")
        incrementer_total_signees(utilisateur)

        # NE PAS SUPPRIMER de soumissions_completes - n√©cessaire pour RPO (Estimation r√©el)
        # soumissions_completes = toutes les estimations envoy√©es (pour RPO)
        # soumissions_signees = contrats sign√©s (pour RPO)

    except Exception as e:
        print(f"[enregistrer_soumission_signee] ERREUR: {e}")
        raise e

@app.get("/api/travaux-completes/count/{username}")
def count_travaux_completes(username: str):
    fichier = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
    if not os.path.exists(fichier):
        return {"count": 0}
    try:
        with open(fichier, "r", encoding="utf-8") as f:
            contenu = f.read().strip()
            if not contenu:
                return {"count": 0}
            data = json.loads(contenu)
            return {"count": len(data)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

@app.get("/api/travaux-en-cours/count/{username}")
def count_travaux_en_cours(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Compte les travaux en cours (travaux √† compl√©ter)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
    if all_teams:
        usernames_to_process = get_all_entrepreneurs()
    # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
    elif team:
        team_members = get_entrepreneurs_for_coach(username)
        # Extraire les usernames des dictionnaires retourn√©s
        usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
    else:
        usernames_to_process = [username]

    total_count = 0

    for user in usernames_to_process:
        fichier = os.path.join(f"{base_cloud}/travaux_a_completer", user, "soumissions.json")
        if os.path.exists(fichier):
            try:
                with open(fichier, "r", encoding="utf-8") as f:
                    contenu = f.read().strip()
                    if contenu:
                        data = json.loads(contenu)
                        total_count += len(data)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Erreur lecture fichier: {e}")

    return {"count": total_count}

@app.post("/api/update-paiement-status")
def update_paiement_status(
    username: str = Body(...),
    client_nom: str = Body(...),
    statut: str = Body(...),
    type: str = Body(...)
):
    """Met √† jour le statut de paiement d'un client"""
    print(f"[UPDATE_PAIEMENT] username={username}, client={client_nom}, statut={statut}, type={type}")

    # D√©terminer le fichier selon le type
    fichier_map = {
        "attente": ("ventes_attente", "ventes.json"),
        "accepter": ("ventes_acceptees", "ventes.json"),
        "produit": ("ventes_produit", "ventes.json")
    }

    dossier_info = fichier_map.get(type)
    if not dossier_info:
        print(f"[ERROR] Type invalide: {type}")
        raise HTTPException(status_code=400, detail=f"Type invalide: {type}")

    dossier, nom_fichier = dossier_info
    fichier = os.path.join(f"{base_cloud}/{dossier}", username, nom_fichier)
    print(f"[FILE] Fichier √† modifier: {fichier}")

    if not os.path.exists(fichier):
        print(f"[ERROR] Fichier non trouv√©: {fichier}")
        raise HTTPException(status_code=404, detail="Fichier non trouv√©")

    try:
        # Lire les donn√©es
        with open(fichier, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                print("[ERROR] Fichier vide")
                return {"success": False, "message": "Fichier vide"}
            clients = json.loads(content)

        print(f"[DATA] Nombre de clients: {len(clients)}")

        # Trouver et mettre √† jour le client
        # Le frontend envoie "Pr√©nom Nom", donc on compare avec prenom + nom
        client_trouve = False
        for client in clients:
            # Essayer diff√©rentes combinaisons
            nom_complet = f"{client.get('prenom', '')} {client.get('nom', '')}".strip()
            nom_complet_alt = f"{client.get('clientPrenom', '')} {client.get('clientNom', '')}".strip()

            print(f"[DEBUG] Comparaison: '{client_nom}' vs '{nom_complet}' ou '{nom_complet_alt}'")

            if client_nom == nom_complet or client_nom == nom_complet_alt or client.get("nom") == client_nom:
                client["statut_paiement"] = statut
                client_trouve = True
                print(f"[SUCCESS] Client trouv√© et mis √† jour: {client_nom}")
                break

        if not client_trouve:
            print(f"[ERROR] Client non trouv√©: {client_nom}")
            raise HTTPException(status_code=404, detail=f"Client {client_nom} non trouv√©")

        # Sauvegarder
        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(clients, f, indent=2, ensure_ascii=False)

        print(f"[SAVED] Fichier sauvegard√© avec succ√®s")
        return {"success": True, "message": "Statut de paiement mis √† jour"}

    except Exception as e:
        print(f"[ERROR] Exception: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

@app.get("/api/panier-moyen/{username}")
def get_panier_moyen(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    try:
        # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
        if all_teams:
            usernames_to_process = get_all_entrepreneurs()
        # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
        elif team:
            team_members = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
        else:
            usernames_to_process = [username]

        total_ca = 0.0
        nb_travaux = 0

        for user in usernames_to_process:
            # Lire chiffre d'affaires (non format√©)
            ca_path = f"{base_cloud}/chiffre_affaires/{user}.json"
            if os.path.exists(ca_path):
                with open(ca_path, "r", encoding="utf-8") as f:
                    ca_data = json.load(f)
                # Ici total doit √™tre un float non format√©
                total_ca += float(ca_data.get("total", 0.0))

            # Nombre de travaux compl√©t√©s
            travaux_path = f"{base_cloud}/travaux_completes/{user}/soumissions.json"
            if os.path.exists(travaux_path):
                with open(travaux_path, "r", encoding="utf-8") as f:
                    travaux = json.load(f)
                nb_travaux += len(travaux)

        panier_moyen = total_ca / nb_travaux if nb_travaux > 0 else 0.0

        # Formatage fran√ßais (ex: 1 234,56 $)
        parts = f"{panier_moyen:,.2f}".split(".")
        partie_entiere = parts[0].replace(",", " ")
        partie_decimale = parts[1]
        panier_moyen_fmt = f"{partie_entiere},{partie_decimale} $"

        return {"panier_moyen": panier_moyen_fmt}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur calcul panier moyen: {e}")

def ajouter_au_chiffre_affaires(username: str, montant: float):
    path = f"{base_cloud}/chiffre_affaires/{username}.json"
    total_actuel = 0.0
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            total_actuel = data.get("total", 0.0)
    total_actuel += montant
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump({"total": total_actuel}, f, indent=2)

@app.post("/api/submit-review")
def submit_review(payload: dict = Body(...)):
    username = payload.get("username")
    rating = payload.get("rating")
    comment = payload.get("comment", "")
    nom = payload.get("nom", "")  
    prenom = payload.get("prenom", "")

    if not username:
        raise HTTPException(status_code=400, detail="username requis")
    if not rating or not (1 <= int(rating) <= 5):
        raise HTTPException(status_code=400, detail="Note (rating) invalide")

    review = {
        "rating": int(rating),
        "comment": comment,
        "nom": nom,
        "prenom": prenom,
        "timestamp": __import__("datetime").datetime.utcnow().isoformat() + "Z"
    }

    # Cr√©e dossier reviews par utilisateur
    reviews_dir = f"{base_cloud}/reviews/{username}"
    os.makedirs(reviews_dir, exist_ok=True)

    reviews_file = os.path.join(reviews_dir, "reviews.json")

    # Charge les avis existants
    if os.path.exists(reviews_file):
        with open(reviews_file, "r", encoding="utf-8") as f:
            try:
                existing_reviews = json.load(f)
            except Exception:
                existing_reviews = []
    else:
        existing_reviews = []

    existing_reviews.append(review)

    # Sauvegarde √† nouveau
    with open(reviews_file, "w", encoding="utf-8") as f:
        json.dump(existing_reviews, f, indent=2, ensure_ascii=False)

    return {"message": "Avis re√ßu avec succ√®s"}

@app.get("/api/satisfaction/{username}")
def taux_satisfaction(username: str):
    chemin = os.path.join(f"{base_cloud}/reviews", username, "reviews.json")
    if not os.path.exists(chemin):
        return {"satisfaction_pct": 0, "moyenne_etoiles": 0.0, "nombre_avis": 0}

    try:
        with open(chemin, "r", encoding="utf-8") as f:
            avis = json.load(f)

        if not avis:
            return {"satisfaction_pct": 0, "moyenne_etoiles": 0.0, "nombre_avis": 0}

        total_notes = sum(r.get("rating", 0) for r in avis)
        nb_avis = len(avis)
        moyenne = total_notes / nb_avis if nb_avis > 0 else 0
        taux = round((moyenne / 5) * 100, 2)

        return {
            "satisfaction_pct": taux,
            "moyenne_etoiles": round(moyenne, 1),
            "nombre_avis": nb_avis
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lecture avis: {e}")


@app.get("/api/graph-data/{username}")
def graph_data(
    username: str,
    start: str = Query(..., description="Date d√©but YYYY-MM-DD"),
    end: str = Query(..., description="Date fin YYYY-MM-DD"),
    type: str = Query(..., description="Type m√©trique : soumissions, revenus, montant-signe, montant-produit")
):
    import datetime as dt
    from collections import defaultdict

    def parse_date(date_str: str):
        # Support des formats ISO et fran√ßais
        for fmt in ("%Y-%m-%d", "%Y-%m-%dT%H:%M:%S", "%Y-%m-%dT%H:%M:%S.%f", "%d/%m/%Y"):
            try:
                return dt.datetime.strptime(date_str, fmt).date()
            except:
                continue
        return None

    print(f"[DEBUG] graph-data appel√© avec username={username}, start={start}, end={end}, type={type}")
    
    try:
        start_date = dt.datetime.strptime(start, "%Y-%m-%d").date()
        end_date = dt.datetime.strptime(end, "%Y-%m-%d").date()
    except Exception:
        raise HTTPException(status_code=400, detail="Format date invalide")

    if end_date < start_date:
        raise HTTPException(status_code=400, detail="Date fin doit √™tre apr√®s date d√©but")

    def format_date_french(date_obj):
        """Formate une date en fran√ßais (ex: 3 janv., 15 ao√ªt)"""
        months_fr = [
            "janv.", "f√©vr.", "mars", "avr.", "mai", "juin",
            "juil.", "ao√ªt", "sept.", "oct.", "nov.", "d√©c."
        ]
        day = date_obj.day
        month = months_fr[date_obj.month - 1]
        return f"{day} {month}"

    delta = (end_date - start_date).days
    all_dates = [(start_date + dt.timedelta(days=i)) for i in range(delta + 1)]
    
    # Cr√©er la liste compl√®te des dates pour les donn√©es (survol)
    all_dates_formatted = [format_date_french(date) for date in all_dates]
    
    # Cr√©er les labels √† afficher avec logique de bonds de jours
    def get_smart_labels(all_dates, all_dates_formatted):
        total_days = len(all_dates)
        labels_to_show = []
        
        # D√©terminer le bond selon la dur√©e
        if total_days <= 14:
            # ‚â§ 14 jours : toutes les dates
            bond = 1
        elif total_days <= 35:
            # 15-35 jours : bond de 2 jours
            bond = 2
        elif total_days <= 70:
            # 36-70 jours : bond de 5 jours
            bond = 5
        elif total_days <= 150:
            # 71-150 jours : bond de 10 jours
            bond = 10
        elif total_days <= 365:
            # 151-365 jours : bond de 20 jours
            bond = 20
        else:
            # > 365 jours : 1er de chaque mois
            seen_months = set()
            for i, date_obj in enumerate(all_dates):
                month_key = (date_obj.year, date_obj.month)
                if month_key not in seen_months or i == total_days - 1:
                    seen_months.add(month_key)
                    labels_to_show.append(all_dates_formatted[i])
                else:
                    labels_to_show.append("")
            return labels_to_show
        
        # Appliquer le bond
        for i in range(total_days):
            if i % bond == 0 or i == total_days - 1:
                labels_to_show.append(all_dates_formatted[i])
            else:
                labels_to_show.append("")
        
        return labels_to_show
    
    labels_to_show = get_smart_labels(all_dates, all_dates_formatted)
    
    data_by_date = defaultdict(float)

    if type == "soumissions":
        # Utiliser le nouveau syst√®me simple de comptage
        stats_file = os.path.join(f"{base_cloud}/stats", username, "soumissions_sent.json")
        print(f"[Debug Graph Soumissions] Nouveau syst√®me - Fichier stats: {stats_file}")
        print(f"[Debug Graph Soumissions] Fichier existe: {os.path.exists(stats_file)}")

        if not os.path.exists(stats_file):
            print(f"[Debug Graph Soumissions] Aucune stat trouv√©e, retour donn√©es vides")
            return {"dates": labels_to_show, "data": [0] * len(all_dates_formatted)}

        with open(stats_file, "r", encoding="utf-8") as f:
            stats = json.load(f)

        print(f"[Debug Graph Soumissions] Nombre total de soumissions envoy√©es: {len(stats)}")
        print(f"[Debug Graph Soumissions] P√©riode: {start_date} √† {end_date}")

        compteur_dans_periode = 0
        for stat in stats:
            date_str = stat.get("date", "")
            try:
                date_obj = dt.datetime.strptime(date_str, "%Y-%m-%d").date()
                if start_date <= date_obj <= end_date:
                    compteur_dans_periode += 1
                    data_by_date[format_date_french(date_obj)] += 1
                    print(f"[Debug Graph Soumissions] Soumission compt√©e: {date_str} -> {format_date_french(date_obj)}")
            except:
                print(f"[Debug Graph Soumissions] Date invalide ignor√©e: {date_str}")
                continue

        print(f"[Debug Graph Soumissions] Total soumissions dans la p√©riode: {compteur_dans_periode}")

    elif type == "revenus":
        fichier = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
        if not os.path.exists(fichier):
            return {"dates": labels_to_show, "data": [0] * len(all_dates_formatted)}
        with open(fichier, "r", encoding="utf-8") as f:
            travaux = json.load(f)

        for t in travaux:
            date_str = t.get("date", "")
            prix_str = t.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
            date_obj = parse_date(date_str)
            if not date_obj:
                continue
            try:
                prix = float(prix_str)
                if start_date <= date_obj <= end_date:
                    data_by_date[format_date_french(date_obj)] += prix
            except:
                continue

    elif type == "montant-signe":
        fichier = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
        print(f"[DEBUG montant-signe] Fichier: {fichier}")
        print(f"[DEBUG montant-signe] Fichier existe: {os.path.exists(fichier)}")
        if not os.path.exists(fichier):
            return {"dates": labels_to_show, "data": [0] * len(all_dates_formatted)}
        with open(fichier, "r", encoding="utf-8") as f:
            soumissions_signees = json.load(f)

        print(f"[DEBUG montant-signe] Nombre de soumissions sign√©es: {len(soumissions_signees)}")
        print(f"[DEBUG montant-signe] P√©riode: {start_date} √† {end_date}")

        for s in soumissions_signees:
            date_str = s.get("date", "")
            prix_str = s.get("prix", "0").replace(" ", "").replace(",", ".").replace("$", "").replace("‚Ç¨", "")
            print(f"[DEBUG montant-signe] Soumission: date='{date_str}', prix='{prix_str}'")
            date_obj = parse_date(date_str)
            print(f"[DEBUG montant-signe] Date pars√©e: {date_obj}")
            if not date_obj:
                print(f"[DEBUG montant-signe] Date non pars√©e, ignor√©e")
                continue
            try:
                prix = float(prix_str)
                print(f"[DEBUG montant-signe] Prix pars√©: {prix}")
                if start_date <= date_obj <= end_date:
                    data_by_date[format_date_french(date_obj)] += prix
                    print(f"[DEBUG montant-signe] Dans la p√©riode! Ajout√© √† {format_date_french(date_obj)}")
                else:
                    print(f"[DEBUG montant-signe] Hors p√©riode: {date_obj} pas entre {start_date} et {end_date}")
            except Exception as e:
                print(f"[DEBUG montant-signe] Erreur parsing prix: {e}")
                continue

    elif type == "montant-produit":
        fichier = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
        if not os.path.exists(fichier):
            return {"dates": labels_to_show, "data": [0] * len(all_dates_formatted)}
        with open(fichier, "r", encoding="utf-8") as f:
            travaux = json.load(f)

        for t in travaux:
            date_str = t.get("date", "")
            prix_str = t.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
            date_obj = parse_date(date_str)
            if not date_obj:
                continue
            try:
                prix = float(prix_str)
                if start_date <= date_obj <= end_date:
                    data_by_date[format_date_french(date_obj)] += prix
            except:
                continue

    else:
        raise HTTPException(status_code=400, detail="Type m√©trique inconnu")

    # Cr√©er la liste des donn√©es pour toutes les dates (pour le survol)
    data_list = []
    for date_formatted in all_dates_formatted:
        data_list.append(round(data_by_date.get(date_formatted, 0), 2))

    return {
        "dates": labels_to_show, 
        "data": data_list,
        "all_dates": all_dates_formatted  # Toutes les dates pour les tooltips
    }

class FactureEmailData(BaseModel):
    username: str
    nom: str
    prenom: str
    prix: str
    lienPdf: str

def envoyer_email_facture(destinataire, nom, prenom, prix, lien_pdf, username):
    subject = "=?UTF-8?B?" + base64.b64encode("Votre facture - Qualit√© √âtudiants".encode("utf-8")).decode() + "?="
    html = (
        f'<p>Bonjour {prenom} {nom},</p><br>'
        f'<p>Veuillez trouver votre facture ci-dessous.</p>'
        f'<p style="margin: 10px 0;">'
        f'  <a href="{lien_pdf}" target="_blank" '
        f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
        f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
        f'     Voir ma facture'
        f'  </a>'
        f'</p><br>'
        f'<p>Merci pour votre confiance.</p>'
        f'<p>L‚Äô√©quipe Qualit√© √âtudiants</p>'
)
    envoyer_email(destinataire, subject, html, username=username)

from fastapi import HTTPException

@app.post("/envoyer-facture-email")
async def envoyer_facture_email(data: FactureEmailData):
    soumissions_file = os.path.join(f"{base_cloud}/soumissions_completes", data.username, "soumissions.json")

    if not os.path.exists(soumissions_file):
        raise HTTPException(status_code=404, detail="Soumissions utilisateur introuvables")

    with open(soumissions_file, "r", encoding="utf-8") as f:
        soumissions = json.load(f)

    print(f"[DEBUG] Donn√©es re√ßues : nom={data.nom}, prenom={data.prenom}")

    email_client = None
    for s in soumissions:
        nom_s = s.get("nom", "").lower()
        prenom_s = s.get("prenom", "").lower()
        nom_data = data.nom.lower()
        prenom_data = data.prenom.lower()
        print(f"[DEBUG] V√©rif nom/prenom: {nom_s} / {prenom_s}")
        if nom_s == nom_data and prenom_s == prenom_data:
            print("[DEBUG] Correspondance trouv√©e")
            email_client = s.get("courriel") or s.get("email") or s.get("clientEmail")
            print(f"[DEBUG] Email client trouv√© : {email_client}")
            break

    if not email_client:
        raise HTTPException(status_code=404, detail="Email client non trouv√© dans les soumissions")

    envoyer_email_facture(
        destinataire=email_client,
        nom=data.nom,
        prenom=data.prenom,
        prix=data.prix,
        lien_pdf=data.lienPdf,
        username=data.username
    )
    return {"message": "Email de facture envoy√© avec succ√®s"}

@app.post("/renvoyer-facture")
async def renvoyer_facture(request: Request):
    body = await request.json()
    nom = body.get("nom")
    prenom = body.get("prenom")
    pdf_url = body.get("pdf_url")
    username = body.get("username")

    if not all([nom, prenom, pdf_url, username]):
        raise HTTPException(status_code=400, detail="Donn√©es manquantes")

    # Chercher l'email du client dans les soumissions
    soumissions_file = os.path.join(f"{base_cloud}/soumissions_completes", username, "soumissions.json")

    if not os.path.exists(soumissions_file):
        raise HTTPException(status_code=404, detail="Soumissions utilisateur introuvables")

    with open(soumissions_file, "r", encoding="utf-8") as f:
        soumissions = json.load(f)

    email_client = None
    prix_facture = "N/A"

    for s in soumissions:
        nom_s = s.get("nom", "").lower()
        prenom_s = s.get("prenom", "").lower()
        nom_data = nom.lower()
        prenom_data = prenom.lower()

        if nom_s == nom_data and prenom_s == prenom_data:
            email_client = s.get("courriel") or s.get("email") or s.get("clientEmail")
            prix_facture = s.get("prix", "N/A")
            break

    if not email_client:
        raise HTTPException(status_code=404, detail="Email client non trouv√©")

    try:
        envoyer_email_facture(
            destinataire=email_client,
            nom=nom,
            prenom=prenom,
            prix=prix_facture,
            lien_pdf=pdf_url,
            username=username
        )
        return {"message": "Facture renvoy√©e avec succ√®s"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'envoi: {str(e)}")

class Painter(BaseModel):
    nom: str
    prenom: str
    courriel: EmailStr

class Team(BaseModel):
    name: str = None
    painters: List[Painter]

class TeamsData(BaseModel):
    username: str
    teams: List[Team]

@app.post("/save-equipes/{username}")
async def save_equipes(username: str, data: List[Team] = Body(...)):
    folder = f"{base_cloud}/equipe"
    os.makedirs(folder, exist_ok=True)
    filepath = os.path.join(folder, f"{username}.json")

    # Filtrer les √©quipes qui ont au moins un membre (painter)
    valid_teams = [team for team in data if team.painters and len(team.painters) > 0]

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump([team.dict() for team in valid_teams], f, ensure_ascii=False, indent=2)
    return {"message": "√âquipes sauvegard√©es", "user": username, "count": len(valid_teams)}

# Endpoint pour r√©cup√©rer l'agenda s√©lectionn√©
@app.get("/get-agenda-id")
def get_agenda_id(username: str = Query(...)):
    folder = os.path.join(base_cloud, "tokens")
    filepath = os.path.join(folder, f"{username}_agenda.json")
    if not os.path.exists(filepath):
        return {"agenda_id": None}
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
            return {"agenda_id": data.get("agenda_id", None)}
    except Exception:
        return {"agenda_id": None}

@app.post("/save-agenda-id/{username}")
def save_agenda_id(username: str, agenda_data: dict = Body(...)):
    folder = os.path.join(base_cloud, "tokens")
    os.makedirs(folder, exist_ok=True)
    filepath = os.path.join(folder, f"{username}_agenda.json")
    
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump({"agenda_id": agenda_data.get("agenda_id")}, f, ensure_ascii=False, indent=2)
        return {"message": "Agenda ID sauvegard√©", "user": username}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur sauvegarde: {str(e)}")

# Endpoints pour les th√®mes
@app.get("/get-theme/{username}")
def get_theme(username: str):
    folder = f"{base_cloud}/themes"
    filepath = os.path.join(folder, f"{username}.json")
    if not os.path.exists(filepath):
        return {"dark_mode": False}
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
            return {"dark_mode": data.get("dark_mode", False)}
    except Exception:
        return {"dark_mode": False}

@app.post("/save-theme/{username}")
def save_theme(username: str, theme_data: dict = Body(...)):
    folder = f"{base_cloud}/themes"
    os.makedirs(folder, exist_ok=True)
    filepath = os.path.join(folder, f"{username}.json")
    
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump({"dark_mode": theme_data.get("dark_mode", False)}, f, ensure_ascii=False, indent=2)
        return {"message": "Th√®me sauvegard√©", "user": username}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur sauvegarde: {str(e)}")

@app.get("/get-equipes/{username}")
def get_equipes(username: str):
    # 1. D'abord chercher dans le dossier equipe/{username}.json
    folder = f"{base_cloud}/equipe"
    filepath = os.path.join(folder, f"{username}.json")

    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                equipes_data = json.load(f)
                if isinstance(equipes_data, list):
                    return equipes_data
                if isinstance(equipes_data, dict) and "equipes" in equipes_data:
                    return equipes_data["equipes"]
        except Exception as e:
            print(f"[ERROR] Erreur lecture √©quipes {username}: {e}")

    # 2. Sinon chercher dans signatures/{username}/user_info.json
    user_info_path = os.path.join(f"{base_cloud}/signatures", username, "user_info.json")
    if os.path.exists(user_info_path):
        try:
            with open(user_info_path, "r", encoding="utf-8") as f:
                user_data = json.load(f)
                if "equipes" in user_data and isinstance(user_data["equipes"], list):
                    # Filtrer seulement les √©quipes avec des membres
                    equipes = [eq for eq in user_data["equipes"] if eq.get("painters") and len(eq.get("painters", [])) > 0]
                    print(f"[OK] √âquipes trouv√©es dans user_info.json pour {username}: {len(equipes)}")
                    return equipes
        except Exception as e:
            print(f"[ERROR] Erreur lecture user_info.json {username}: {e}")

    return []

@app.get("/get-teams")
def get_teams(request: Request):
    """Endpoint pour r√©cup√©rer les √©quipes depuis connect_agenda pour le modal GQP"""
    # R√©cup√©rer le username depuis les query params ou les headers
    username = request.query_params.get("username", "")
    if not username:
        # Essayer de r√©cup√©rer depuis les headers ou autre m√©thode
        username = request.headers.get("X-Username", "")
    
    if not username:
        return []  # Pas d'utilisateur identifi√©
    
    # Utiliser la m√™me logique que get_equipes
    folder = f"{base_cloud}/equipe"
    filepath = os.path.join(folder, f"{username}.json")
    if not os.path.exists(filepath):
        return []
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            equipes_data = json.load(f)
            if isinstance(equipes_data, list):
                return equipes_data
            if isinstance(equipes_data, dict) and "equipes" in equipes_data:
                return equipes_data["equipes"]
            return []
    except Exception as e:
        print(f"[ERROR] Erreur lecture √©quipes modal {username}: {e}")
        return []

@app.post("/envoyer-gqp-email-simple")
def envoyer_gqp_email_simple(
    username: str = Body(...),
    emails: list[str] = Body(...),
    nom: str = Body(...),
    prenom: str = Body(...),
    adresse: str = Body(...),
    endroit: str = Body(...),
    lien_pdf: str = Body(...)
):
    # Construction du corps HTML simple avec lien vers le PDF
    html = (
        f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
        f'<p>Bonjour,</p>'
        f'<p>Voici le GQP de travaux pour {prenom} {nom}.</p><br>'
        f'<p>Vous pouvez consulter le document en cliquant sur le lien ci-dessous :</p>'
        f'<p style="margin: 10px 0;">'
        f'  <a href="{lien_pdf}" target="_blank" '
        f'     style="background-color: #000000; color: #ffffff; padding: 6px 12px; border-radius: 20px; '
        f'            text-decoration: none; display: inline-block; font-weight: bold; font-size: 14px;">'
        f'     Voir le GQP'
        f'  </a>'
        f'</p><br>'
        f'</div>'
    )

    subject = "=?UTF-8?B?" + base64.b64encode("Votre GQP de travaux - Qualit√© √âtudiants".encode("utf-8")).decode() + "?="

    raw_message = (
        f"To: {', '.join(emails)}\r\n"
        f"Subject: {subject}\r\n"
        f"Content-Type: text/html; charset=UTF-8\r\n\r\n"
        f"{html}"
    )
    raw_encoded = base64.urlsafe_b64encode(raw_message.encode("utf-8")).decode("utf-8")

    access_token = get_valid_gmail_token(username)  # Ta fonction pour r√©cup√©rer le token valide

    response = requests.post(
        "https://gmail.googleapis.com/gmail/v1/users/me/messages/send",
        headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        },
        json={"raw": raw_encoded}
    )

    if response.status_code != 200:
        print("[ERROR] Erreur Gmail API:", response.text)
        raise HTTPException(status_code=400, detail="√âchec de l‚Äôenvoi du mail GQP")

    return JSONResponse({"message": "Mail GQP envoy√© avec succ√®s [OK]"})


@app.get("/api/chiffre-affaires-signes/{username}")
def get_chiffre_affaires_signes(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Calcule le montant total sign√© depuis ventes_acceptees + ventes_produit
    (m√™me logique que /api/chiffre-affaires)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    try:
        # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
        if all_teams:
            usernames_to_process = get_all_entrepreneurs()
        # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
        elif team:
            team_members = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
        else:
            usernames_to_process = [username]

        total = 0.0

        for user in usernames_to_process:
            # 1. Additionner les ventes accept√©es
            acceptees_path = f"{base_cloud}/ventes_acceptees/{user}/ventes.json"
            if os.path.exists(acceptees_path):
                with open(acceptees_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        ventes = json.loads(content)
                        for v in ventes:
                            prix_str = str(v.get("prix", "0")).replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                            try:
                                total += float(prix_str)
                            except:
                                continue

            # 2. Additionner les ventes produit
            produit_path = f"{base_cloud}/ventes_produit/{user}/ventes.json"
            if os.path.exists(produit_path):
                with open(produit_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        ventes = json.loads(content)
                        for v in ventes:
                            prix_str = str(v.get("prix", "0")).replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                            try:
                                total += float(prix_str)
                            except:
                                continue

        # Formater le total
        parts = f"{total:,.2f}".split(".")
        partie_entiere = parts[0].replace(",", " ")
        partie_decimale = parts[1]
        total_fmt = f"{partie_entiere},{partie_decimale} $"
        return {"total": total_fmt}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur calcul total sign√©: {e}")


@app.get("/api/montant-non-produit/{username}")
def get_montant_non_produit(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    Calcule le montant non produit = montant sign√© - montant produit (CA total)
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    try:
        # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
        if all_teams:
            usernames_to_process = get_all_entrepreneurs()
        # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
        elif team:
            team_members = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
        else:
            usernames_to_process = [username]

        montant_produit = 0.0
        montant_signe = 0.0

        for user in usernames_to_process:
            # R√©cup√©rer le montant produit (CA total)
            ca_path = f"{base_cloud}/chiffre_affaires/{user}.json"
            if os.path.exists(ca_path):
                with open(ca_path, "r", encoding="utf-8") as f:
                    ca_data = json.load(f)
                montant_produit += float(ca_data.get("total", 0.0))

            # R√©cup√©rer le montant sign√©
            signes_path = f"{base_cloud}/soumissions_signees/{user}/soumissions.json"
            if os.path.exists(signes_path):
                with open(signes_path, "r", encoding="utf-8") as f:
                    soumissions = json.load(f)
                for s in soumissions:
                    prix_str = s.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                    try:
                        montant_signe += float(prix_str)
                    except:
                        continue

        # Calculer le montant non produit = montant sign√© - montant produit
        montant_non_produit = max(montant_signe - montant_produit, 0.0)

        # Formater le r√©sultat au format fran√ßais
        parts = f"{montant_non_produit:,.2f}".split(".")
        partie_entiere = parts[0].replace(",", " ")
        partie_decimale = parts[1]
        total_fmt = f"{partie_entiere},{partie_decimale} $"

        return {"total": total_fmt}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur calcul montant non produit: {e}")










@app.get("/api/me/{username}")
def api_get_current_user(username: str):
    # R√©cup√©rer les infos utilisateur depuis la base de donn√©es
    user_info = get_user(username)
    if not user_info:
        raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")

    # Charger les informations d√©taill√©es depuis le fichier user_info.json
    info_file = f"{base_cloud}/signatures/{username}/user_info.json"
    prenom = ""
    nom = ""
    onboarding_completed = user_info.get("onboarding_completed", False)

    if os.path.exists(info_file):
        try:
            with open(info_file, "r", encoding="utf-8") as f:
                user_details = json.load(f)
                prenom = user_details.get("prenom", "")
                nom = user_details.get("nom", "")
                # Utiliser onboarding_completed du fichier si pr√©sent
                if "onboarding_completed" in user_details:
                    onboarding_completed = user_details.get("onboarding_completed", False)
        except Exception as e:
            print(f"Erreur lecture user_info.json pour {username}: {e}")

    return {
        "username": username,
        "role": user_info["role"],
        "prenom": prenom,
        "nom": nom,
        "onboarding_completed": onboarding_completed
    }

@app.get("/api/entrepreneurs/{coach_username}")
def api_get_entrepreneurs(coach_username: str):
    entrepreneurs = get_entrepreneurs_for_coach(coach_username)
    if not entrepreneurs:
        raise HTTPException(status_code=404, detail="Coach non trouv√© ou aucun entrepreneur associ√©")
    return entrepreneurs

@app.get("/api/coach/{coach_username}/equipe")
def api_get_coach_equipe(coach_username: str):
    """API pour r√©cup√©rer les entrepreneurs d'un coach avec leurs informations d√©taill√©es"""
    entrepreneur_data = get_entrepreneurs_for_coach(coach_username)
    if not entrepreneur_data:
        return {"entrepreneurs": [], "stats": {"total": 0, "totalVentes": 0, "totalSoumissions": 0}}

    # Extraire les usernames des dictionnaires retourn√©s
    entrepreneur_usernames = [e["username"] for e in entrepreneur_data]

    entrepreneurs_data = []
    total_ventes = 0
    total_soumissions = 0

    for username in entrepreneur_usernames:
        # Charger les infos utilisateur
        user_info_path = os.path.join(base_cloud, "signatures", username, "user_info.json")
        user_info = {}
        if os.path.exists(user_info_path):
            try:
                with open(user_info_path, "r", encoding="utf-8") as f:
                    user_info = json.load(f)
            except:
                pass

        # Charger les ventes
        ventes_path = os.path.join(base_cloud, "ventes", username, "ventes.json")
        ventes = []
        if os.path.exists(ventes_path):
            try:
                with open(ventes_path, "r", encoding="utf-8") as f:
                    ventes = json.load(f)
            except:
                pass

        # Charger les soumissions
        soumissions_path = os.path.join(base_cloud, "soumissions_completes", username, "soumissions.json")
        soumissions = []
        if os.path.exists(soumissions_path):
            try:
                with open(soumissions_path, "r", encoding="utf-8") as f:
                    soumissions = json.load(f)
            except:
                pass

        # Calculer le total des ventes
        montant_ventes = 0
        for v in ventes:
            try:
                montant_str = str(v.get("montant", "0")).replace("$", "").replace(",", ".").replace(" ", "").strip()
                montant_ventes += float(montant_str)
            except:
                pass

        total_ventes += montant_ventes
        total_soumissions += len(soumissions)

        # Photo de profil
        photo_url = f"/static/profile_photos/{username}.jpg"
        photo_path = os.path.join(BASE_DIR, "static", "profile_photos", f"{username}.jpg")
        if not os.path.exists(photo_path):
            photo_url = None

        entrepreneurs_data.append({
            "username": username,
            "prenom": user_info.get("prenom", username.capitalize()),
            "nom": user_info.get("nom", ""),
            "courriel": user_info.get("courriel", ""),
            "telephone": user_info.get("telephone", ""),
            "grade": user_info.get("grade", "junior"),
            "photo": photo_url,
            "stats": {
                "ventes": montant_ventes,
                "soumissions": len(soumissions),
                "employes": len(user_info.get("equipes", [])) if isinstance(user_info.get("equipes"), list) else 0
            }
        })

    return {
        "entrepreneurs": entrepreneurs_data,
        "stats": {
            "total": len(entrepreneurs_data),
            "totalVentes": total_ventes,
            "totalSoumissions": total_soumissions
        }
    }

def parse_week_label_to_dates(week_label: str, year: int = 2026):
    """
    Parse un week_label du RPO (ex: "5 - 11 janv", "26 janv - 1 f√©vr")
    et retourne (start_date, end_date) en datetime
    """
    from datetime import datetime, timezone

    if not week_label or week_label == "N/A":
        return None, None

    # Mapping des mois fran√ßais vers num√©ros
    mois_map = {
        'janv': 1, 'janvier': 1,
        'f√©vr': 2, 'fevr': 2, 'f√©vrier': 2, 'fevrier': 2,
        'mars': 3,
        'avr': 4, 'avril': 4,
        'mai': 5,
        'juin': 6,
        'juil': 7, 'juillet': 7,
        'ao√ªt': 8, 'aout': 8,
        'sept': 9, 'septembre': 9,
        'oct': 10, 'octobre': 10,
        'nov': 11, 'novembre': 11,
        'd√©c': 12, 'dec': 12, 'd√©cembre': 12, 'decembre': 12
    }

    try:
        # Format: "5 - 11 janv" ou "26 janv - 1 f√©vr"
        parts = week_label.split(' - ')
        if len(parts) != 2:
            return None, None

        start_part = parts[0].strip()  # "5" ou "26 janv"
        end_part = parts[1].strip()    # "11 janv" ou "1 f√©vr"

        # Parser la fin (toujours contient le mois)
        end_tokens = end_part.split()
        end_day = int(end_tokens[0])
        end_month_str = end_tokens[1].lower() if len(end_tokens) > 1 else None
        end_month = mois_map.get(end_month_str, 1)

        # Parser le d√©but
        start_tokens = start_part.split()
        start_day = int(start_tokens[0])
        if len(start_tokens) > 1:
            # Le mois est sp√©cifi√© (ex: "26 janv")
            start_month_str = start_tokens[1].lower()
            start_month = mois_map.get(start_month_str, end_month)
        else:
            # Pas de mois, utiliser le m√™me que la fin
            start_month = end_month

        # G√©rer le changement d'ann√©e (d√©cembre -> janvier)
        start_year = year
        end_year = year
        if start_month == 12 and end_month == 1:
            start_year = year - 1

        start_date = datetime(start_year, start_month, start_day, 0, 0, 0, tzinfo=timezone.utc)
        end_date = datetime(end_year, end_month, end_day, 23, 59, 59, tzinfo=timezone.utc)

        return start_date, end_date
    except Exception as e:
        print(f"[WARNING] Erreur parsing week_label '{week_label}': {e}", flush=True)
        return None, None


def filter_rpo_weekly_by_period(weekly_data: dict, start_date, end_date, year: int = 2026):
    """
    Filtre les donn√©es weekly du RPO par p√©riode.
    Retourne un dict avec les m√™mes cl√©s mais uniquement les semaines dans la p√©riode.
    """
    from datetime import datetime, timezone

    if not start_date or not end_date:
        return weekly_data  # Pas de filtre, retourner tout

    filtered = {}

    for month_key, weeks in weekly_data.items():
        try:
            month_num = int(month_key)
            if month_num < -1:  # Ignorer les mois trop anciens
                continue
        except:
            continue

        for week_key, week_data in weeks.items():
            week_label = week_data.get("week_label", "")
            week_start, week_end = parse_week_label_to_dates(week_label, year)

            if week_start and week_end:
                # V√©rifier si la semaine chevauche la p√©riode demand√©e
                if week_end >= start_date and week_start <= end_date:
                    if month_key not in filtered:
                        filtered[month_key] = {}
                    filtered[month_key][week_key] = week_data

    return filtered


def parse_date_flexible(date_str: str):
    """
    Parse une date dans diff√©rents formats: DD/MM/YYYY, YYYY-MM-DD, ISO
    Retourne un objet datetime ou None si le parsing √©choue
    """
    from datetime import datetime, timezone

    if not date_str:
        return None

    # Essayer format DD/MM/YYYY
    try:
        return datetime.strptime(date_str, "%d/%m/%Y").replace(tzinfo=timezone.utc)
    except ValueError:
        pass

    # Essayer format YYYY-MM-DD
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=timezone.utc)
    except ValueError:
        pass

    # Essayer format ISO complet
    try:
        date_obj = datetime.fromisoformat(date_str)
        if date_obj.tzinfo is None:
            date_obj = date_obj.replace(tzinfo=timezone.utc)
        return date_obj
    except ValueError:
        pass

    return None

@app.get("/api/coach/{coach_username}/equipe/dashboard")
def api_get_coach_equipe_dashboard(
    coach_username: str,
    period: str = "all",
    start: str = None,
    end: str = None
):
    """
    API pour r√©cup√©rer toutes les statistiques compl√®tes de l'√©quipe d'un coach
    Similaire au dashboard entrepreneur mais pour toute l'√©quipe avec filtrage par p√©riode

    P√©riodes support√©es: today, week, month, year, all, 90, 30, 14
    Ou p√©riode personnalis√©e avec start et end (format YYYY-MM-DD)
    """
    from datetime import datetime, timedelta, timezone

    # D√©finir les dates de d√©but/fin selon la p√©riode
    now = datetime.now(timezone.utc)
    start_date = None
    end_date = now

    # Si des dates personnalis√©es sont fournies, les utiliser
    if start and end:
        try:
            start_date = datetime.fromisoformat(start).replace(tzinfo=timezone.utc)
            end_date = datetime.fromisoformat(end).replace(hour=23, minute=59, second=59, tzinfo=timezone.utc)
        except ValueError:
            start_date = None
            end_date = now
    # Sinon, utiliser la p√©riode pr√©d√©finie
    elif period == "today":
        start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "week":
        # Cette semaine = depuis lundi de la semaine en cours
        days_since_monday = now.weekday()  # 0=lundi, 6=dimanche
        start_date = (now - timedelta(days=days_since_monday)).replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "month":
        start_date = now - timedelta(days=30)
    elif period == "year":
        start_date = now - timedelta(days=365)
    elif period.isdigit():
        # Support pour 90, 30, 14 jours
        start_date = now - timedelta(days=int(period))
    # else: period == "all" -> start_date = None

    entrepreneur_data = get_entrepreneurs_for_coach(coach_username)
    if not entrepreneur_data:
        return {
            "entrepreneurs": [],
            "team_stats": {
                "total_entrepreneurs": 0,
                "total_ca": 0,
                "ca_moyen": 0,
                "montant_produit": 0,
                "paiements_recoltes": 0,
                "objectif_total": 0,
                "estimation_moyenne": 0,
                "heures_pap_semaine": 0,
                "taux_vente_moyen": 0,
                "prod_horaire_moyen": 0,
                "taux_marketing_moyen": 0,
                "pourcentage_objectif": 0,
                "total_signees": 0,
                "total_en_attente": 0,
                "total_perdus": 0,
                "total_employes_actifs": 0,
                "total_employes_candidats": 0,
                "total_employes_inactifs": 0,
                "moyenne_etoiles": 0,
                "total_avis": 0,
                "contrat_moyen": 0
            }
        }

    # Extraire les usernames des dictionnaires retourn√©s
    entrepreneur_usernames = [e["username"] for e in entrepreneur_data]

    entrepreneurs_data = []

    # Stats d'√©quipe globales
    team_total_ca = 0
    team_total_montant_produit = 0
    team_total_paiements_recoltes = 0
    team_total_signees = 0
    team_total_attente = 0
    team_total_perdus = 0
    team_total_employes_actifs = 0
    team_total_employes_candidats = 0
    team_total_employes_inactifs = 0
    team_total_etoiles = 0
    team_total_avis = 0
    team_total_estimations = 0
    team_total_heures_pap = 0
    team_total_prod_horaire = 0
    team_total_pourcentage_objectif = 0
    team_prod_horaire_count = 0
    team_pourcentage_count = 0
    team_estimation_count = 0
    team_total_objectif = 0
    team_total_taux_marketing = 0
    team_taux_marketing_count = 0
    team_total_heures_marketing_absolue = 0  # Total absolu des heures marketing (pas moyenne)
    team_total_dollar_reel = 0  # Total dollars r√©els (contrats avec premier paiement)
    team_total_contract_reel = 0  # Total contrats r√©els (avec premier paiement)
    team_total_nb_estimations = 0  # Total nb estimations (signees + perdus)
    # S√©paration Recrue vs Senior pour H PAP/semaine et Estimations
    recrue_total_heures_pap = 0  # Total heures PAP recrues (sans semaine actuelle)
    recrue_total_estimations = 0  # Total estimations recrues
    recrue_count = 0  # Nombre de recrues
    senior_total_heures_pap = 0  # Total heures PAP seniors (sans semaine actuelle)
    senior_total_estimations = 0  # Total estimations seniors
    senior_count = 0  # Nombre de seniors (1, 2, 3 combin√©s)
    # Tableau pour le $ produit par mois (13 mois: D√©c 2025 + Jan-D√©c 2026)
    produit_mensuel = [0] * 13

    for username in entrepreneur_usernames:
        # 1. Charger user_info
        user_info_path = os.path.join(base_cloud, "signatures", username, "user_info.json")
        user_info = {}
        if os.path.exists(user_info_path):
            try:
                with open(user_info_path, "r", encoding="utf-8") as f:
                    user_info = json.load(f)
            except:
                pass

        # 2. Photo de profil
        photo_url = f"/static/profile_photos/{username}.jpg"
        photo_path = os.path.join(BASE_DIR, "static", "profile_photos", f"{username}.jpg")
        if not os.path.exists(photo_path):
            photo_url = None

        # 3. CHIFFRE D'AFFAIRES avec filtrage par p√©riode
        ca_actuel = 0.0

        # Ventes accept√©es
        acceptees_path = os.path.join(base_cloud, "ventes_acceptees", username, "ventes.json")
        if os.path.exists(acceptees_path):
            try:
                with open(acceptees_path, 'r', encoding='utf-8') as f:
                    acceptees = json.load(f)
                    for v in acceptees:
                        # V√©rifier la p√©riode si n√©cessaire
                        if start_date:
                            date_str = v.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue

                        prix_str = str(v.get("prix", "0"))
                        prix_str = prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                        try:
                            ca_actuel += float(prix_str)
                        except:
                            continue
            except:
                pass

        # Ventes produit (montant_produit s√©par√©)
        montant_produit = 0.0
        produit_path = os.path.join(base_cloud, "ventes_produit", username, "ventes.json")
        if os.path.exists(produit_path):
            try:
                with open(produit_path, 'r', encoding='utf-8') as f:
                    produit = json.load(f)
                    for v in produit:
                        if start_date:
                            date_str = v.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue

                        prix_str = str(v.get("prix", "0"))
                        prix_str = prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                        try:
                            prix = float(prix_str)
                            montant_produit += prix
                            ca_actuel += prix

                            # Calculer le mois pour le graphique (bas√© sur date_completion)
                            date_completion_str = v.get("date_completion", "")
                            if date_completion_str:
                                try:
                                    from datetime import datetime as dt
                                    completion_date = dt.fromisoformat(date_completion_str)
                                    # Index 0 = D√©c 2025, Index 1-12 = Jan-D√©c 2026
                                    if completion_date.year == 2025 and completion_date.month == 12:
                                        produit_mensuel[0] += prix
                                    elif completion_date.year == 2026:
                                        mois_index = completion_date.month  # 1=Jan, 2=F√©v, etc.
                                        produit_mensuel[mois_index] += prix
                                except:
                                    pass
                        except:
                            continue
            except:
                pass

        team_total_montant_produit += montant_produit

        # 4. STATUS SOUMISSIONS avec filtrage par p√©riode
        signees_count = 0
        attente_count = 0
        perdus_count = 0

        signees_path = os.path.join(base_cloud, "soumissions_signees", username, "soumissions.json")
        if os.path.exists(signees_path):
            try:
                with open(signees_path, 'r', encoding='utf-8') as f:
                    signees = json.load(f)
                    for s in signees:
                        if start_date:
                            date_str = s.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue
                        signees_count += 1
            except:
                pass

        attente_path = os.path.join(base_cloud, "ventes_attente", username, "ventes.json")
        if os.path.exists(attente_path):
            try:
                with open(attente_path, 'r', encoding='utf-8') as f:
                    attente = json.load(f)
                    for a in attente:
                        if start_date:
                            date_str = a.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue
                        attente_count += 1
            except:
                pass

        perdus_path = os.path.join(base_cloud, "clients_perdus", username, "clients.json")
        if os.path.exists(perdus_path):
            try:
                with open(perdus_path, 'r', encoding='utf-8') as f:
                    perdus = json.load(f)
                    for p in perdus:
                        if start_date:
                            date_str = p.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue
                        perdus_count += 1
            except:
                pass

        # 5. SATISFACTION (AVIS)
        etoiles_moyennes = 0.0
        nombre_avis = 0
        reviews_path = os.path.join(base_cloud, "reviews", username, "reviews.json")
        if os.path.exists(reviews_path):
            try:
                with open(reviews_path, 'r', encoding='utf-8') as f:
                    reviews = json.load(f)
                    valid_reviews = []
                    for r in reviews:
                        if start_date:
                            date_str = r.get("date", "")
                            date_obj = parse_date_flexible(date_str)
                            if date_obj and (date_obj < start_date or date_obj > end_date):
                                continue
                        valid_reviews.append(r)

                    if valid_reviews:
                        total_etoiles = sum(float(r.get("rating", 0)) for r in valid_reviews)
                        nombre_avis = len(valid_reviews)
                        etoiles_moyennes = round(total_etoiles / nombre_avis, 1) if nombre_avis > 0 else 0.0
                        team_total_etoiles += total_etoiles
                        team_total_avis += nombre_avis
            except:
                pass

        # 6. EMPLOY√âS (actifs, candidats, inactifs)
        employes_actifs = 0
        employes_candidats = 0
        employes_inactifs = 0

        actifs_path = os.path.join(base_cloud, "employes", username, "actifs.json")
        if os.path.exists(actifs_path):
            try:
                with open(actifs_path, 'r', encoding='utf-8') as f:
                    actifs = json.load(f)
                    employes_actifs = len(actifs)
            except:
                pass

        candidats_path = os.path.join(base_cloud, "employes", username, "candidats.json")
        if os.path.exists(candidats_path):
            try:
                with open(candidats_path, 'r', encoding='utf-8') as f:
                    candidats = json.load(f)
                    employes_candidats = len(candidats)
            except:
                pass

        inactifs_path = os.path.join(base_cloud, "employes", username, "inactifs.json")
        if os.path.exists(inactifs_path):
            try:
                with open(inactifs_path, 'r', encoding='utf-8') as f:
                    inactifs = json.load(f)
                    employes_inactifs = len(inactifs)
            except:
                pass

        # 7. M√âTRIQUES - Initialis√©es, recalcul√©es apr√®s lecture RPO
        contrat_moyen = 0
        taux_vente = 0
        dollar_reel = 0
        contract_reel = 0
        estimation_reel = 0
        nb_estimations = 0

        # 8. OBJECTIF et POURCENTAGE depuis RPO
        objectif = 0
        pourcentage_objectif = 0
        prod_horaire = 0
        taux_marketing = 0
        heures_pap_semaine = 0

        try:
            from QE.Backend.rpo import load_user_rpo_data
            rpo_data = load_user_rpo_data(username)
            annual = rpo_data.get("annual", {})

            # Dollar r√©el, Contract r√©el et Estimation r√©el depuis RPO
            dollar_reel = annual.get("dollar_reel", 0)
            contract_reel = annual.get("contract_reel", 0)
            estimation_reel = annual.get("estimation_reel", 0)

            # Si annual est 0, calculer depuis weekly (fallback)
            if dollar_reel == 0:
                for m_key, weeks in rpo_data.get("weekly", {}).items():
                    for w_key, w_data in weeks.items():
                        dollar_reel += w_data.get("dollar", 0)
                        contract_reel += w_data.get("contract", 0)
            objectif = round(float(annual.get("objectif_ca", 0)), 2)
            print(f"[DEBUG OBJECTIF] {username} -> objectif_ca depuis RPO: {objectif}")
            if objectif > 0:
                pourcentage_objectif = round((ca_actuel / objectif) * 100, 2)

            # Calculer heures_pap_semaine: moyenne r√©elle par semaine (pas total cumul√©)
            # Compter SEULEMENT √† partir de janvier 2026 (exclure d√©cembre 2025)
            total_heures_pap = 0
            total_heures_pap_sans_w1_actuelle = 0  # Exclut semaine 1 janvier et semaine actuelle
            nombre_semaines_avec_data = 0
            nombre_semaines_sans_w1_actuelle = 0
            weekly_data = rpo_data.get("weekly", {})

            # Filtrer par p√©riode si d√©finie
            if start_date:
                weekly_data = filter_rpo_weekly_by_period(weekly_data, start_date, end_date)

            # D√©terminer la semaine actuelle (mois, semaine)
            from QE.Backend.rpo import get_week_number_from_date
            current_month_idx, current_week_num = get_week_number_from_date(datetime.now(timezone.utc).strftime("%Y-%m-%d"))

            for month_key, weeks in weekly_data.items():
                # Filtrer: exclure mois n√©gatifs (d√©cembre 2025 et avant), garder mois >= 0 (janvier 2026+)
                try:
                    month_num = int(month_key)
                    if month_num < 0:
                        continue  # Ignorer d√©cembre 2025 et avant
                except:
                    continue

                for week_key, week_data in weeks.items():
                    h_mktg = week_data.get("h_marketing", "-")
                    # Compter toutes les valeurs sauf "-" (m√™me 0 compte comme une semaine faite)
                    if h_mktg is not None and h_mktg != "-":
                        try:
                            heures_val = float(h_mktg)
                            total_heures_pap += heures_val
                            nombre_semaines_avec_data += 1

                            # Pour le calcul recrue/senior: exclure semaine 1 janvier (mois 0, semaine 1), semaine actuelle, et semaines futures
                            is_week1_january = (month_num == 0 and week_key == "1")
                            is_current_week = (month_num == current_month_idx and int(week_key) == current_week_num)
                            # Exclure les semaines futures (mois > actuel, ou m√™me mois mais semaine > actuelle)
                            is_future_week = (month_num > current_month_idx) or \
                                           (month_num == current_month_idx and int(week_key) > current_week_num)
                            # Inclure seulement les semaines pass√©es compl√©t√©es (pas week1, pas actuelle, pas future)
                            if not is_week1_january and not is_current_week and not is_future_week:
                                total_heures_pap_sans_w1_actuelle += heures_val
                                nombre_semaines_sans_w1_actuelle += 1
                        except:
                            pass

            # Moyenne des heures PAP par semaine (toutes semaines de l'ann√©e)
            heures_pap_semaine = round(total_heures_pap / nombre_semaines_avec_data, 2) if nombre_semaines_avec_data > 0 else 0

            # Accumuler pour calcul recrue/senior (exclut semaine 1 et actuelle)
            grade = user_info.get("grade", "").lower()
            if grade == "recrue":
                recrue_total_heures_pap += total_heures_pap_sans_w1_actuelle
                recrue_count += 1
            elif grade in ["senior1", "senior2", "senior3"]:
                senior_total_heures_pap += total_heures_pap_sans_w1_actuelle
                senior_count += 1

            # Accumuler le total absolu des heures marketing pour le calcul du taux marketing global
            team_total_heures_marketing_absolue += total_heures_pap

            # Nb estimations depuis RPO (source unique de v√©rit√©)
            # Fallback sur signees + perdus si RPO non disponible
            nb_estimations = estimation_reel if estimation_reel > 0 else (signees_count + perdus_count)

            # Taux marketing = Nb Estimations √∑ Heures PAP (estimations par heure)
            if total_heures_pap > 0:
                taux_marketing = round(nb_estimations / total_heures_pap, 2)
            else:
                taux_marketing = 0

            # Contrat moyen = dollar_reel / contract_reel (depuis RPO)
            contrat_moyen = round(dollar_reel / contract_reel, 2) if contract_reel > 0 else 0

            # Taux de vente = contract_reel / nb_estimations * 100
            taux_vente = round((contract_reel / nb_estimations) * 100, 2) if nb_estimations > 0 else 0

            # Calculer prod_horaire depuis les valeurs saisies dans RPO (mai √† septembre)
            total_prod_horaire = 0
            nombre_semaines_prod_horaire = 0

            # Mois avec prod_horaire: mai √† septembre 2026 (mois 4 √† 8)
            for month_index in range(4, 9):  # 4=mai, 5=juin, 6=juillet, 7=ao√ªt, 8=septembre
                month_key = str(month_index)
                if month_key in weekly_data:
                    for week_key, week_data in weekly_data[month_key].items():
                        prod_h = week_data.get("prod_horaire", 0)
                        # Compter seulement les valeurs saisies (diff√©rentes de 0, None, "-")
                        if prod_h is not None and prod_h != 0 and prod_h != "-":
                            try:
                                total_prod_horaire += float(prod_h)
                                nombre_semaines_prod_horaire += 1
                            except:
                                pass

            prod_horaire = round(total_prod_horaire / nombre_semaines_prod_horaire, 2) if nombre_semaines_prod_horaire > 0 else 0
        except Exception as e:
            print(f"[DEBUG OBJECTIF ERROR] {username} -> Erreur chargement RPO: {e}")
            # Fallback: utiliser signees + perdus si RPO non disponible
            nb_estimations = signees_count + perdus_count

        # 9. ESTIMATIONS - Utiliser estimation_reel du RPO (source unique de v√©rit√©)
        # nb_estimations est d√©j√† calcul√© √† partir du RPO (ou fallback si erreur)
        estimation_count = nb_estimations

        # Accumuler estimations par grade (recrue vs senior)
        grade = user_info.get("grade", "").lower()
        if grade == "recrue":
            recrue_total_estimations += estimation_count
        elif grade in ["senior1", "senior2", "senior3"]:
            senior_total_estimations += estimation_count

        # 8. PAIEMENTS R√âCOLT√âS (facturation)
        paiements_recoltes = 0.0
        facturation_statuts_path = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts.json")
        if os.path.exists(facturation_statuts_path):
            try:
                with open(facturation_statuts_path, 'r', encoding='utf-8') as f:
                    statuts = json.load(f)
                    for num_soumission, client_statuts in statuts.items():
                        # V√©rifier si trait√© ou en attente comptable
                        statut_client = client_statuts.get("statutClient", "")

                        # D√©p√¥t trait√©
                        if client_statuts.get("statutDepot") in ["traite", "traite_attente_final", "attente_comptable"]:
                            depot_details = client_statuts.get("depot", {})
                            montant_str = str(depot_details.get("montant", "0,00 $"))
                            montant_str = montant_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                            try:
                                paiements_recoltes += float(montant_str)
                            except:
                                pass

                        # Paiement final trait√©
                        if client_statuts.get("statutPaiementFinal") in ["traite", "attente_comptable"]:
                            pf_details = client_statuts.get("paiementFinal", {})
                            montant_str = str(pf_details.get("montant", "0,00 $"))
                            montant_str = montant_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                            try:
                                paiements_recoltes += float(montant_str)
                            except:
                                pass

                        # Autres paiements trait√©s
                        autres_paiements = client_statuts.get("autresPaiements", [])
                        if isinstance(autres_paiements, list):
                            for ap in autres_paiements:
                                if ap.get("statut") in ["traite", "attente_comptable"]:
                                    montant_str = str(ap.get("montant", "0,00 $"))
                                    montant_str = montant_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
                                    try:
                                        paiements_recoltes += float(montant_str)
                                    except:
                                        pass
            except:
                pass

        team_total_paiements_recoltes += paiements_recoltes

        # Ajouter aux stats d'√©quipe
        team_total_ca += ca_actuel
        team_total_objectif += objectif
        print(f"[DEBUG OBJECTIF] Apr√®s ajout de {username}, team_total_objectif = {team_total_objectif}")
        team_total_signees += signees_count
        team_total_attente += attente_count + (signees_count - contract_reel)  # Ventes attente + sign√©s sans paiement
        team_total_perdus += perdus_count
        team_total_dollar_reel += dollar_reel
        team_total_contract_reel += contract_reel
        team_total_nb_estimations += nb_estimations  # Utilise estimation_reel du RPO
        team_total_employes_actifs += employes_actifs
        team_total_employes_candidats += employes_candidats
        team_total_employes_inactifs += employes_inactifs
        # Pour les estimations, on additionne le nombre d'estimations de chaque entrepreneur
        team_total_estimations += estimation_count
        if estimation_count > 0:
            team_estimation_count += 1
        team_total_heures_pap += heures_pap_semaine
        if prod_horaire > 0:
            team_total_prod_horaire += prod_horaire
            team_prod_horaire_count += 1
        if pourcentage_objectif > 0:
            team_total_pourcentage_objectif += pourcentage_objectif
            team_pourcentage_count += 1
        if taux_marketing > 0:
            team_total_taux_marketing += taux_marketing
            team_taux_marketing_count += 1

        entrepreneurs_data.append({
            "username": username,
            "prenom": user_info.get("prenom", username.capitalize()),
            "nom": user_info.get("nom", ""),
            "courriel": user_info.get("courriel", ""),
            "telephone": user_info.get("telephone", ""),
            "grade": user_info.get("grade", "junior"),
            "photo": photo_url,
            "dollar_reel": dollar_reel,  # Dollars r√©els (niveau racine pour frontend)
            "contract_reel": contract_reel,  # Contrats r√©els (niveau racine pour frontend)
            "chiffre_affaires": {
                "objectif": objectif,
                "ca_actuel": round(ca_actuel, 2),
                "dollar_reel": dollar_reel,  # Dollars r√©els (contrats avec premier paiement)
                "contract_reel": contract_reel,  # Contrats r√©els (avec premier paiement)
                "pourcentage": pourcentage_objectif,
                "montant_produit": round(montant_produit, 2)
            },
            "status_soumissions": {
                "signees": signees_count,  # Tous les contrats sign√©s
                "contract_reel": contract_reel,  # Contrats avec premier paiement
                "en_attente": attente_count + (signees_count - contract_reel),  # Ventes attente + sign√©s sans paiement
                "perdus": perdus_count
            },
            "satisfaction": {
                "etoiles_moyennes": etoiles_moyennes,
                "nombre_avis": nombre_avis
            },
            "employes": {
                "actifs": employes_actifs,
                "candidats": employes_candidats,
                "inactifs": employes_inactifs,
                "total": employes_actifs + employes_candidats + employes_inactifs
            },
            "metriques": {
                "contrat_moyen": contrat_moyen,  # dollar_reel / contract_reel
                "taux_vente": taux_vente,  # contract_reel / nb_estimations * 100
                "prod_horaire": prod_horaire,
                "taux_marketing": taux_marketing,  # nb_estimations / heures_pap (estimations par heure)
                "estimations": nb_estimations,  # Nb estimations depuis RPO (estimation_reel)
                "heures_pap_semaine": heures_pap_semaine,
                "heures_pap": round(total_heures_pap, 2)  # Total absolu des heures PAP
            },
            # Champs au niveau racine pour le frontend (classement coach)
            "soumissions_signees": signees_count,
            "soumissions_perdues": perdus_count,
            "montant_produit": round(montant_produit, 2),
            "heures_pap": round(total_heures_pap, 2),
            "taux_marketing": taux_marketing,
            "contrat_moyen": contrat_moyen,
            "taux_vente": taux_vente,
            "prod_horaire": prod_horaire,
            "etoiles": etoiles_moyennes
        })

    # IMPORTANT: Remplacer team_total_objectif par la somme des pr√©visions du coach
    # Au lieu d'additionner les objectifs individuels des entrepreneurs (depuis leur RPO),
    # on utilise les pr√©visions que le coach a faites pour son √©quipe
    coach_previsions_path = os.path.join(base_cloud, "coach_previsions", f"{coach_username}_previsions.json")
    if os.path.exists(coach_previsions_path):
        try:
            with open(coach_previsions_path, 'r', encoding='utf-8') as f:
                coach_previsions_data = json.load(f)
                previsions = coach_previsions_data.get("previsions", {})
                # La somme de toutes les pr√©visions = objectif total du coach
                team_total_objectif = sum(previsions.values())
                print(f"[DEBUG OBJECTIF COACH] {coach_username} -> Objectif depuis previsions: {team_total_objectif} (d√©tail: {previsions})")
        except Exception as e:
            print(f"[DEBUG OBJECTIF COACH ERROR] {coach_username} -> Erreur chargement previsions: {e}")
            # Si erreur, garder la somme des objectifs individuels
            pass

    # Calculer les moyennes d'√©quipe
    nb_entrepreneurs = len(entrepreneurs_data)
    moyenne_etoiles_equipe = round(team_total_etoiles / team_total_avis, 1) if team_total_avis > 0 else 0.0
    # Contrat moyen √©quipe = total dollar_reel / total contract_reel
    contrat_moyen_equipe = round(team_total_dollar_reel / team_total_contract_reel, 2) if team_total_contract_reel > 0 else 0
    total_potentiel_equipe = team_total_signees + team_total_attente + team_total_perdus
    # Taux vente √©quipe = total contract_reel / total nb_estimations * 100
    taux_vente_moyen_equipe = round((team_total_contract_reel / team_total_nb_estimations) * 100, 2) if team_total_nb_estimations > 0 else 0

    # Nouvelles moyennes d'√©quipe
    # Contrat moyen = Total CA / Nombre d'entrepreneurs
    ca_moyen_equipe = round(team_total_ca / nb_entrepreneurs, 2) if nb_entrepreneurs > 0 else 0
    # Estimation moyenne = Total nb estimations (signees + perdus) / Nombre d'entrepreneurs
    estimation_moyenne_equipe = round(team_total_nb_estimations / nb_entrepreneurs, 2) if nb_entrepreneurs > 0 else 0

    # Heures PAP/semaine = Total heures marketing / Nombre de semaines √©coul√©es depuis le 5 janvier 2026
    from datetime import datetime, timedelta
    start_date = datetime(2026, 1, 5)
    current_date = datetime.now()
    days_since_start = max(0, (current_date - start_date).days)
    nombre_semaines_ecoulees = max(1, days_since_start // 7)  # Semaines compl√©t√©es, minimum 1
    heures_pap_moyenne_equipe = round(team_total_heures_marketing_absolue / nombre_semaines_ecoulees, 2) if nombre_semaines_ecoulees > 0 else 0

    prod_horaire_moyen_equipe = round(team_total_prod_horaire / team_prod_horaire_count, 2) if team_prod_horaire_count > 0 else 0
    # CORRECTION: Calculer le pourcentage global bas√© sur les totaux (team_total_ca / team_total_objectif)
    # au lieu de faire la moyenne des pourcentages individuels
    pourcentage_objectif_equipe = round((team_total_ca / team_total_objectif) * 100, 2) if team_total_objectif > 0 else 0
    # Taux marketing √©quipe = Total nb estimations / Total heures PAP (estimations par heure)
    taux_marketing_moyen_equipe = round(team_total_nb_estimations / team_total_heures_marketing_absolue, 2) if team_total_heures_marketing_absolue > 0 else 0

    # Calcul H PAP/semaine par grade (Recrue et Senior)
    # Formule: Total heures (sans semaine 1 et actuelle) / (Semaines compl√©t√©es - 1) / Nombre entrepreneurs
    # On exclut semaine 1 (5-11 janv) du nombre de semaines aussi
    nombre_semaines_completees_sans_w1 = max(0, nombre_semaines_ecoulees - 1)  # -1 pour exclure semaine 1

    heures_pap_semaine_recrue = 0
    heures_pap_semaine_senior = 0

    if nombre_semaines_completees_sans_w1 > 0:
        if recrue_count > 0:
            heures_pap_semaine_recrue = round(recrue_total_heures_pap / nombre_semaines_completees_sans_w1 / recrue_count, 2)
        if senior_count > 0:
            heures_pap_semaine_senior = round(senior_total_heures_pap / nombre_semaines_completees_sans_w1 / senior_count, 2)

    # Estimation moyenne par grade
    estimation_moyenne_recrue = round(recrue_total_estimations / recrue_count, 1) if recrue_count > 0 else 0
    estimation_moyenne_senior = round(senior_total_estimations / senior_count, 1) if senior_count > 0 else 0

    return {
        "entrepreneurs": entrepreneurs_data,
        "team_stats": {
            "total_entrepreneurs": nb_entrepreneurs,
            "total_ca": round(team_total_ca, 2),
            "ca_moyen": ca_moyen_equipe,
            "montant_produit": round(team_total_montant_produit, 2),
            "paiements_recoltes": round(team_total_paiements_recoltes, 2),
            "objectif_total": round(team_total_objectif, 2),
            "estimation_moyenne": estimation_moyenne_equipe,
            "estimation_moyenne_recrue": estimation_moyenne_recrue,
            "estimation_moyenne_senior": estimation_moyenne_senior,
            "heures_pap_semaine": heures_pap_moyenne_equipe,
            "heures_pap_semaine_recrue": heures_pap_semaine_recrue,
            "heures_pap_semaine_senior": heures_pap_semaine_senior,
            "recrue_count": recrue_count,
            "senior_count": senior_count,
            "total_heures_marketing_absolue": round(team_total_heures_marketing_absolue, 2),
            "taux_vente_moyen": taux_vente_moyen_equipe,
            "prod_horaire_moyen": prod_horaire_moyen_equipe,
            "taux_marketing_moyen": taux_marketing_moyen_equipe,
            "pourcentage_objectif": pourcentage_objectif_equipe,
            "total_signees": team_total_signees,
            "total_contract_reel": team_total_contract_reel,  # Contrats avec premier paiement
            "total_dollar_reel": team_total_dollar_reel,  # Dollars r√©els
            "total_nb_estimations": team_total_nb_estimations,  # signees + perdus
            "total_en_attente": team_total_attente,
            "total_perdus": team_total_perdus,
            "total_employes_actifs": team_total_employes_actifs,
            "total_employes_candidats": team_total_employes_candidats,
            "total_employes_inactifs": team_total_employes_inactifs,
            "moyenne_etoiles": moyenne_etoiles_equipe,
            "total_avis": team_total_avis,
            "contrat_moyen": contrat_moyen_equipe,
            "produit_mensuel": produit_mensuel
        },
        "period": period
    }

def load_submissions_for_entrepreneur(username: str, start_date: datetime, end_date: datetime, signed: bool = False):
    dossier = "soumissions_signees" if signed else "soumissions_completes"
    fichier = f"{base_cloud}/{dossier}/{username}/soumissions.json"
    if not os.path.exists(fichier):
        return None
    with open(fichier, "r", encoding="utf-8") as f:
        soumissions = json.load(f)
    filtered = []
    for s in soumissions:
        date_str = s.get("date", "")
        date_obj = parse_date_flexible(date_str)
        if not date_obj:
            continue
        if start_date <= date_obj <= end_date:
            filtered.append(s)
    return filtered

from fastapi import HTTPException, Query
from typing import Optional
from datetime import datetime, timezone
import os
import json

@app.get("/api/entrepreneur-submissions-summary/{entrepreneur_username}")
def get_entrepreneur_submissions_summary(
    entrepreneur_username: str,
    start: Optional[datetime] = Query(None),
    end: Optional[datetime] = Query(None),
):
    print(f"[Submissions Summary] entrepreneur: {entrepreneur_username}")
    print(f"[Submissions Summary] start: {start}, end: {end}")

    if start is None or end is None:
        print("[Submissions Summary] ERROR: 'start' ou 'end' non fournis")
        return {"error": "Param√®tres 'start' et 'end' obligatoires"}

    delta = end - start
    start_previous = start - delta
    end_previous = start
    print(f"[Submissions Summary] P√©riode actuelle: {start} √† {end}")
    print(f"[Submissions Summary] P√©riode pr√©c√©dente: {start_previous} √† {end_previous}")

    def load_submissions(start_dt, end_dt, signed):
        print(f"[Submissions] Chargement de {start_dt} √† {end_dt} (signed={signed})")
        subs = load_submissions_for_entrepreneur(entrepreneur_username, start_dt, end_dt, signed)
        if subs is None:
            print("[Submissions] Aucun r√©sultat (None)")
            return []
        print(f"[Submissions] Trouv√© {len(subs)} soumissions")
        return subs

    # P√©riode actuelle
    soumissions_faites_current = load_submissions(start, end, signed=False)
    soumissions_signees_current = load_submissions(start, end, signed=True)

    total_faites_current = len(soumissions_faites_current)
    total_signees_current = len(soumissions_signees_current)
    total_non_signees_current = max(total_faites_current - total_signees_current, 0)

    print(f"[Submissions Current] total faites: {total_faites_current}")
    print(f"[Submissions Current] total sign√©es: {total_signees_current}")
    print(f"[Submissions Current] total non sign√©es: {total_non_signees_current}")

    valeur_sign√©e_current = 0.0
    for s in soumissions_signees_current:
        prix_str = s.get("prix") or "0"
        try:
            prix = float(prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip())
            valeur_sign√©e_current += prix
        except Exception as e:
            print(f"[Submissions Current] Erreur conversion prix '{prix_str}': {e}")
            continue
    valeur_sign√©e_current = round(valeur_sign√©e_current, 2)
    print(f"[Submissions Current] valeur sign√©e totale: {valeur_sign√©e_current}")

    taux_closing_current = (total_signees_current / total_faites_current * 100) if total_faites_current > 0 else 0.0
    taux_closing_current = round(taux_closing_current, 2)
    print(f"[Submissions Current] taux closing: {taux_closing_current}%")

    # P√©riode pr√©c√©dente
    soumissions_faites_previous = load_submissions(start_previous, end_previous, signed=False)
    soumissions_signees_previous = load_submissions(start_previous, end_previous, signed=True)

    total_faites_previous = len(soumissions_faites_previous)
    total_signees_previous = len(soumissions_signees_previous)
    total_non_signees_previous = max(total_faites_previous - total_signees_previous, 0)

    print(f"[Submissions Previous] total faites: {total_faites_previous}")
    print(f"[Submissions Previous] total sign√©es: {total_signees_previous}")
    print(f"[Submissions Previous] total non sign√©es: {total_non_signees_previous}")

    valeur_sign√©e_previous = 0.0
    for s in soumissions_signees_previous:
        prix_str = s.get("prix") or "0"
        try:
            prix = float(prix_str.replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip())
            valeur_sign√©e_previous += prix
        except Exception as e:
            print(f"[Submissions Previous] Erreur conversion prix '{prix_str}': {e}")
            continue
    valeur_sign√©e_previous = round(valeur_sign√©e_previous, 2)
    print(f"[Submissions Previous] valeur sign√©e totale: {valeur_sign√©e_previous}")

    taux_closing_previous = (total_signees_previous / total_faites_previous * 100) if total_faites_previous > 0 else 0.0
    taux_closing_previous = round(taux_closing_previous, 2)
    print(f"[Submissions Previous] taux closing: {taux_closing_previous}%")

    def calc_pct_change(current, previous):
        if previous == 0:
            return 100.0 if current > 0 else 0.0
        return round(((current - previous) / previous) * 100, 2)

    def format_number_fr(n):
        return f"{n:,.2f}".replace(",", " ").replace(".", ",")

    heures_pap = "0H"  # placeholder

    result = {
        "total_soumissions_faites": total_faites_current,
        "total_soumissions_sign√©es": total_signees_current,
        "total_soumissions_non_sign√©es": total_non_signees_current,
        "valeur_totale_soumissions_sign√©es": format_number_fr(valeur_sign√©e_current),
        "taux_de_closing_pct": taux_closing_current,
        "heures_pap": heures_pap,

        "total_soumissions_faites_prev": total_faites_previous,
        "total_soumissions_sign√©es_prev": total_signees_previous,
        "total_soumissions_non_sign√©es_prev": total_non_signees_previous,
        "valeur_totale_soumissions_sign√©es_prev": format_number_fr(valeur_sign√©e_previous),
        "taux_de_closing_pct_prev": taux_closing_previous,
        "heures_pap_prev": "0H",

        "total_soumissions_faites_pct_change": calc_pct_change(total_faites_current, total_faites_previous),
        "total_soumissions_sign√©es_pct_change": calc_pct_change(total_signees_current, total_signees_previous),
        "total_soumissions_non_sign√©es_pct_change": calc_pct_change(total_non_signees_current, total_non_signees_previous),
        "valeur_totale_soumissions_sign√©es_pct_change": calc_pct_change(valeur_sign√©e_current, valeur_sign√©e_previous),
        "taux_de_closing_pct_change": calc_pct_change(taux_closing_current, taux_closing_previous)
    }

    print("[Submissions Summary] R√©sultat final:", result)
    return result


@app.get("/api/production-summary/{entrepreneur_username}")
def get_production_summary(
    entrepreneur_username: str,
    start: str = Query(None),
    end: str = Query(None),
):
    print(f"[Production Summary] entrepreneur: {entrepreneur_username}, start={start}, end={end}")
    if not start or not end:
        print("[Production Summary] ERROR: start ou end non fournis")
        raise HTTPException(status_code=400, detail="start ou end non fournis")

    try:
        start_dt = datetime.fromisoformat(start)
        end_dt = datetime.fromisoformat(end)
        print(f"[Production Summary] P√©riode : {start_dt} √† {end_dt}")
    except Exception as e:
        print(f"[Production Summary] Erreur parsing date: {e}")
        raise HTTPException(status_code=400, detail="Format de date invalide")

    # Charge travaux
    path_travaux = f"{base_cloud}/travaux_completes/{entrepreneur_username}/soumissions.json"
    travaux = []
    if os.path.exists(path_travaux):
        with open(path_travaux, "r", encoding="utf-8") as f:
            travaux = json.load(f)
        print(f"[Production Summary] Charg√© {len(travaux)} travaux")
    else:
        print(f"[Production Summary] Fichier travaux non trouv√© : {path_travaux}")

    def filter_travaux(start, end):
        res = []
        for t in travaux:
            date_str = t.get("date", "")
            try:
                date_obj = datetime.fromisoformat(date_str)
                if date_obj.tzinfo is None:
                    date_obj = date_obj.replace(tzinfo=timezone.utc)
                if start <= date_obj <= end:
                    res.append(t)
            except Exception as e:
                print(f"[Production Summary] Erreur parsing date travail '{date_str}': {e}")
                continue
        print(f"[Production Summary] Travaux filtr√©s entre {start} et {end}: {len(res)}")
        return res

    travaux_current = filter_travaux(start_dt, end_dt)
    nombre_current = len(travaux_current)
    valeur_current = 0.0
    for t in travaux_current:
        prix_str = t.get("prix", "0").replace("\xa0", "").replace(" ", "").replace(",", ".").replace("$", "").strip()
        try:
            valeur_current += float(prix_str)
        except Exception as e:
            print(f"[Production Summary] Erreur conversion prix '{prix_str}': {e}")
            continue

    print(f"[Production Summary] Travaux p√©riode actuelle: nombre={nombre_current}, valeur={valeur_current}")

    # Charger avis
    path_reviews = f"{base_cloud}/reviews/{entrepreneur_username}/reviews.json"
    reviews = []
    if os.path.exists(path_reviews):
        with open(path_reviews, "r", encoding="utf-8") as f:
            reviews = json.load(f)
        print(f"[Production Summary] Charg√© {len(reviews)} avis")
    else:
        print(f"[Production Summary] Fichier avis non trouv√© : {path_reviews}")

    def filter_reviews(start, end):
        res = []
        for r in reviews:
            ts = r.get("timestamp") or r.get("date") or ""
            try:
                dt_ts = datetime.fromisoformat(ts.replace("Z", "+00:00"))
                if start <= dt_ts <= end:
                    res.append(r)
            except Exception as e:
                print(f"[Production Summary] Erreur parsing date avis '{ts}': {e}")
                continue
        print(f"[Production Summary] Avis filtr√©s entre {start} et {end}: {len(res)}")
        return res

    reviews_current = filter_reviews(start_dt, end_dt)

    taux_current = 0.0
    if reviews_current:
        total_notes = sum(float(r.get("rating", 0)) for r in reviews_current)
        taux_current = total_notes / (5 * len(reviews_current)) * 100

    print(f"[Production Summary] Taux de satisfaction actuel: {taux_current}%")

    def calc_pct_change(current, previous):
        if previous == 0:
            return 100.0 if current > 0 else 0.0
        return round(((current - previous) / previous) * 100, 2)

    def format_number_fr(n):
        return f"{n:,.2f}".replace(",", " ").replace(".", ",")

    result = {
        "nombre_travaux_finis": nombre_current,
        "valeur_totale_travaux": format_number_fr(round(valeur_current, 2)),
        "taux_satisfaction_pct": round(taux_current, 2),

        # Valeurs pr√©c√©dentes laiss√©es √† 0 (peux adapter si besoin)
        "nombre_travaux_finis_prev": 0,
        "valeur_totale_travaux_prev": format_number_fr(0),
        "taux_satisfaction_pct_prev": 0,

        "nombre_travaux_finis_pct_change": 0,
        "valeur_totale_travaux_pct_change": 0,
        "taux_satisfaction_pct_change": 0
    }

    print("[Production Summary] R√©sultat final:", result)
    return result




# ---------- CONFIGURATION ----------
SAVE_DIR = f"{base_cloud}/ficheremployer"
EMPLOYER_LINES_FILE = os.path.join(SAVE_DIR, "lines.json")
os.makedirs(SAVE_DIR, exist_ok=True)

# ---------- UTILITAIRES ----------
def load_lines():
    if os.path.exists(EMPLOYER_LINES_FILE):
        try:
            with open(EMPLOYER_LINES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_lines(data):
    try:
        with open(EMPLOYER_LINES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"Erreur sauvegarde: {e}")

def find_file_on_disk(ligne: int, target_filename: str) -> Optional[str]:
    """Trouve le fichier r√©el sur le disque en cherchant par diff√©rentes m√©thodes"""
    
    # 1. Essayer le nom exact
    exact_path = os.path.join(SAVE_DIR, target_filename)
    if os.path.exists(exact_path):
        return target_filename
    
    # 2. Chercher tous les fichiers de la ligne et comparer
    try:
        for filename in os.listdir(SAVE_DIR):
            if filename.startswith(f"employerligne{ligne}_"):
                # Comparer sans tenir compte de l'encodage URL
                decoded_existing = urllib.parse.unquote(filename)
                decoded_target = urllib.parse.unquote(target_filename)
                
                # Comparaison directe
                if decoded_existing == decoded_target:
                    return filename
                
                # Comparaison sans espaces (au cas o√π)
                if decoded_existing.replace(' ', '') == decoded_target.replace(' ', ''):
                    return filename
                
                # Comparaison par suffixe (nom original du fichier)
                if '_' in filename and '_' in target_filename:
                    existing_suffix = '_'.join(filename.split('_')[2:])  # Apr√®s employerligne{X}_timestamp_
                    target_suffix = '_'.join(target_filename.split('_')[1:])  # Apr√®s employerligne{X}_
                    
                    if existing_suffix == target_suffix:
                        return filename
    except OSError:
        pass
    
    return None

# ---------- ENDPOINTS ----------

@app.post("/ficheremployer/upload")
async def upload_employer_file(
    ligne: int = Form(...),
    file: UploadFile = File(...)
):
    """Upload un fichier pour une ligne employeur"""
    
    # V√©rifications
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nom de fichier manquant")
    
    # G√©n√©rer un nom de fichier unique avec timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # microsecondes tronqu√©es
    safe_filename = f"employerligne{ligne}_{timestamp}_{file.filename}"
    file_path = os.path.join(SAVE_DIR, safe_filename)
    
    try:
        # Sauvegarder le fichier
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        # Mettre √† jour le JSON
        data = load_lines()
        if str(ligne) not in data:
            data[str(ligne)] = {"ligne": ligne, "titre": "", "files": []}
        
        # Ajouter le fichier √† la liste
        file_info = {
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficheremployer/{safe_filename}",
            "uploaded_at": datetime.now().isoformat()
        }
        
        data[str(ligne)]["files"].append(file_info)
        save_lines(data)
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficheremployer/{safe_filename}"
        }
        
    except Exception as e:
        # Nettoyer en cas d'erreur
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"Erreur upload: {str(e)}")

@app.get("/ficheremployer/lines")
async def get_lines():
    """R√©cup√®re toutes les lignes avec leurs fichiers"""
    data = load_lines()
    
    # Synchroniser avec les fichiers sur disque
    try:
        disk_files = {}
        for filename in os.listdir(SAVE_DIR):
            if filename.startswith("employerligne") and not filename.endswith(".json"):
                # Extraire le num√©ro de ligne
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("employerligne", "")
                    if ligne_str.isdigit():
                        ligne = int(ligne_str)
                        if ligne not in disk_files:
                            disk_files[ligne] = []
                        
                        # R√©cup√©rer le nom original depuis le JSON ou utiliser le nom du fichier
                        original_name = filename
                        if str(ligne) in data:
                            for f in data[str(ligne)].get("files", []):
                                if f.get("filename") == filename:
                                    original_name = f.get("original_name", filename)
                                    break
                        
                        disk_files[ligne].append({
                            "filename": filename,
                            "original_name": original_name,
                            "url": f"/cloud/ficheremployer/{filename}",
                            "line": ligne
                        })
        
        # Fusionner les donn√©es JSON avec les fichiers sur disque
        for ligne, files in disk_files.items():
            ligne_str = str(ligne)
            if ligne_str not in data:
                data[ligne_str] = {"ligne": ligne, "titre": "", "files": []}
            
            # Mettre √† jour la liste des fichiers avec ce qui est r√©ellement sur disque
            data[ligne_str]["files"] = files
    
    except OSError as e:
        print(f"Erreur lecture disque: {e}")
    
    # Sauvegarder les changements
    save_lines(data)
    
    return {"lines": sorted(data.values(), key=lambda x: int(x["ligne"]))}

@app.delete("/ficheremployer/delete_file/{ligne}/{filename}")
async def delete_specific_file(ligne: int, filename: str):
    """Supprime un fichier sp√©cifique"""
    
    # D√©coder le nom de fichier de l'URL
    decoded_filename = urllib.parse.unquote(filename)
    
    print(f"Ligne: {ligne}")
    print(f"Filename re√ßu: '{filename}'")
    print(f"Apr√®s d√©codage: '{decoded_filename}'")
    
    # Chercher le fichier r√©el sur le disque
    real_filename = find_file_on_disk(ligne, decoded_filename)
    
    if not real_filename:
        print(f"Fichier introuvable pour ligne {ligne}")
        print("Fichiers existants:")
        try:
            for f in os.listdir(SAVE_DIR):
                if f.startswith(f"employerligne{ligne}_"):
                    print(f"  - '{f}'")
        except OSError:
            pass
        raise HTTPException(status_code=404, detail=f"Fichier non trouv√©: {decoded_filename}")
    
    file_path = os.path.join(SAVE_DIR, real_filename)
    print(f"Fichier trouv√©: '{real_filename}'")
    print(f"Chemin complet: '{file_path}'")
    
    try:
        # Supprimer le fichier physique
        os.remove(file_path)
        print(f"Fichier supprim√©: {real_filename}")
        
        # Mettre √† jour le JSON
        data = load_lines()
        if str(ligne) in data:
            original_count = len(data[str(ligne)].get("files", []))
            data[str(ligne)]["files"] = [
                f for f in data[str(ligne)].get("files", [])
                if f.get("filename") != real_filename
            ]
            new_count = len(data[str(ligne)]["files"])
            print(f"JSON mis √† jour: {original_count} -> {new_count} fichiers")
            save_lines(data)
        
        return {
            "success": True, 
            "message": f"Fichier {real_filename} supprim√©",
            "deleted_file": real_filename
        }
        
    except OSError as e:
        print(f"Erreur suppression fichier: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur suppression: {str(e)}")

@app.post("/ficheremployer/update_title/{ligne}")
async def update_title(ligne: int, request: dict):
    """Met √† jour le titre d'une ligne"""
    titre = request.get("titre", "")
    
    data = load_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "files": []}
    
    data[str(ligne)]["titre"] = titre
    save_lines(data)
    
    return {"success": True, "message": f"Titre mis √† jour pour ligne {ligne}"}

@app.post("/ficheremployer/add_line/{ligne}")
async def add_line(ligne: int, request: dict = None):
    """Ajoute ou met √† jour une ligne"""
    titre = ""
    if request:
        titre = request.get("titre", "")
    
    data = load_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": titre, "files": []}
    
    save_lines(data)
    return {"success": True, "message": f"Ligne {ligne} sauvegard√©e"}

@app.delete("/ficheremployer/delete/{ligne}")
async def delete_employer_line(ligne: int):
    """Supprime une ligne enti√®re et tous ses fichiers"""
    
    deleted_files = []
    
    # Supprimer tous les fichiers physiques de cette ligne
    try:
        for filename in os.listdir(SAVE_DIR):
            if filename.startswith(f"employerligne{ligne}_"):
                file_path = os.path.join(SAVE_DIR, filename)
                os.remove(file_path)
                deleted_files.append(filename)
    except OSError as e:
        print(f"Erreur suppression fichiers: {e}")
    
    # Supprimer du JSON
    data = load_lines()
    if str(ligne) in data:
        del data[str(ligne)]
        save_lines(data)
    
    return {
        "success": True, 
        "message": f"Ligne {ligne} supprim√©e",
        "deleted_files": deleted_files
    }

@app.get("/ficheremployer/list")
async def list_employer_files():
    """Liste tous les fichiers employeur"""
    files = []
    try:
        for filename in os.listdir(SAVE_DIR):
            if filename.startswith("employerligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("employerligne", "")
                    if ligne_str.isdigit():
                        files.append({
                            "ligne": int(ligne_str),
                            "filename": filename,
                            "url": f"/cloud/ficheremployer/{filename}"
                        })
    except OSError:
        pass
    
    return {"files": sorted(files, key=lambda x: (x["ligne"], x["filename"]))}






# ---------- ENDPOINTS POUR LEGAL QUALIT√â √âTUDIANTS ----------

LEGAL_SAVE_DIR = f"{base_cloud}/ficherlegal"
LEGAL_LINES_FILE = os.path.join(LEGAL_SAVE_DIR, "lines.json")
os.makedirs(LEGAL_SAVE_DIR, exist_ok=True)

def load_legal_lines():
    if os.path.exists(LEGAL_LINES_FILE):
        try:
            with open(LEGAL_LINES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_legal_lines(data):
    try:
        with open(LEGAL_LINES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"Erreur sauvegarde legal: {e}")

def find_legal_file_on_disk(ligne: int, target_filename: str) -> Optional[str]:
    """Trouve le fichier l√©gal r√©el sur le disque"""
    
    # 1. Essayer le nom exact
    exact_path = os.path.join(LEGAL_SAVE_DIR, target_filename)
    if os.path.exists(exact_path):
        return target_filename
    
    # 2. Chercher tous les fichiers de la ligne
    try:
        for filename in os.listdir(LEGAL_SAVE_DIR):
            if filename.startswith(f"legalligne{ligne}_"):
                decoded_existing = urllib.parse.unquote(filename)
                decoded_target = urllib.parse.unquote(target_filename)
                
                if decoded_existing == decoded_target:
                    return filename
                
                if decoded_existing.replace(' ', '') == decoded_target.replace(' ', ''):
                    return filename
                
                if '_' in filename and '_' in target_filename:
                    existing_suffix = '_'.join(filename.split('_')[2:])
                    target_suffix = '_'.join(target_filename.split('_')[1:])
                    
                    if existing_suffix == target_suffix:
                        return filename
    except OSError:
        pass
    
    return None

@app.post("/ficherlegal/upload")
async def upload_legal_file(
    ligne: int = Form(...),
    file: UploadFile = File(...)
):
    """Upload un fichier pour une ligne l√©gal"""
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nom de fichier manquant")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    safe_filename = f"legalligne{ligne}_{timestamp}_{file.filename}"
    file_path = os.path.join(LEGAL_SAVE_DIR, safe_filename)
    
    try:
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        data = load_legal_lines()
        if str(ligne) not in data:
            data[str(ligne)] = {"ligne": ligne, "titre": "", "numero": "", "files": []}
        
        file_info = {
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherlegal/{safe_filename}",
            "uploaded_at": datetime.now().isoformat()
        }
        
        data[str(ligne)]["files"].append(file_info)
        save_legal_lines(data)
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherlegal/{safe_filename}"
        }
        
    except Exception as e:
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"Erreur upload legal: {str(e)}")

@app.get("/ficherlegal/lines")
async def get_legal_lines():
    """R√©cup√®re toutes les lignes l√©gal avec leurs fichiers"""
    data = load_legal_lines()
    
    try:
        disk_files = {}
        for filename in os.listdir(LEGAL_SAVE_DIR):
            if filename.startswith("legalligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("legalligne", "")
                    if ligne_str.isdigit():
                        ligne = int(ligne_str)
                        if ligne not in disk_files:
                            disk_files[ligne] = []
                        
                        original_name = filename
                        if str(ligne) in data:
                            for f in data[str(ligne)].get("files", []):
                                if f.get("filename") == filename:
                                    original_name = f.get("original_name", filename)
                                    break
                        
                        disk_files[ligne].append({
                            "filename": filename,
                            "original_name": original_name,
                            "url": f"/cloud/ficherlegal/{filename}",
                            "line": ligne
                        })
        
        for ligne, files in disk_files.items():
            ligne_str = str(ligne)
            if ligne_str not in data:
                data[ligne_str] = {"ligne": ligne, "titre": "", "numero": "", "files": []}
            
            data[ligne_str]["files"] = files
    
    except OSError as e:
        print(f"Erreur lecture disque legal: {e}")
    
    save_legal_lines(data)
    
    return {"lines": sorted(data.values(), key=lambda x: int(x["ligne"]))}

@app.delete("/ficherlegal/delete_file/{ligne}/{filename}")
async def delete_legal_specific_file(ligne: int, filename: str):
    """Supprime un fichier l√©gal sp√©cifique"""
    
    decoded_filename = urllib.parse.unquote(filename)
    
    print(f"Suppression fichier legal - Ligne: {ligne}")
    print(f"Filename re√ßu: '{filename}'")
    print(f"Apr√®s d√©codage: '{decoded_filename}'")
    
    real_filename = find_legal_file_on_disk(ligne, decoded_filename)
    
    if not real_filename:
        print(f"Fichier legal introuvable pour ligne {ligne}")
        raise HTTPException(status_code=404, detail=f"Fichier legal non trouv√©: {decoded_filename}")
    
    file_path = os.path.join(LEGAL_SAVE_DIR, real_filename)
    
    try:
        os.remove(file_path)
        print(f"Fichier legal supprim√©: {real_filename}")
        
        data = load_legal_lines()
        if str(ligne) in data:
            data[str(ligne)]["files"] = [
                f for f in data[str(ligne)].get("files", [])
                if f.get("filename") != real_filename
            ]
            save_legal_lines(data)
        
        return {
            "success": True, 
            "message": f"Fichier legal {real_filename} supprim√©",
            "deleted_file": real_filename
        }
        
    except OSError as e:
        print(f"Erreur suppression fichier legal: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur suppression legal: {str(e)}")

@app.post("/ficherlegal/update_title/{ligne}")
async def update_legal_title(ligne: int, request: dict):
    """Met √† jour le titre d'une ligne l√©gal"""
    titre = request.get("titre", "")
    
    data = load_legal_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "numero": "", "files": []}
    
    data[str(ligne)]["titre"] = titre
    save_legal_lines(data)
    
    return {"success": True, "message": f"Titre legal mis √† jour pour ligne {ligne}"}

@app.post("/ficherlegal/update_numero/{ligne}")
async def update_legal_numero(ligne: int, request: dict):
    """Met √† jour le num√©ro d'une ligne l√©gal"""
    numero = request.get("numero", "")
    
    data = load_legal_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "numero": "", "files": []}
    
    data[str(ligne)]["numero"] = numero
    save_legal_lines(data)
    
    return {"success": True, "message": f"Num√©ro legal mis √† jour pour ligne {ligne}"}

@app.post("/ficherlegal/add_line/{ligne}")
async def add_legal_line(ligne: int, request: dict = None):
    """Ajoute ou met √† jour une ligne l√©gal"""
    titre = ""
    numero = ""
    if request:
        titre = request.get("titre", "")
        numero = request.get("numero", "")
    
    data = load_legal_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": titre, "numero": numero, "files": []}
    
    save_legal_lines(data)
    return {"success": True, "message": f"Ligne legal {ligne} sauvegard√©e"}

@app.delete("/ficherlegal/delete/{ligne}")
async def delete_legal_line(ligne: int):
    """Supprime une ligne l√©gal enti√®re et tous ses fichiers"""
    
    deleted_files = []
    
    try:
        for filename in os.listdir(LEGAL_SAVE_DIR):
            if filename.startswith(f"legalligne{ligne}_"):
                file_path = os.path.join(LEGAL_SAVE_DIR, filename)
                os.remove(file_path)
                deleted_files.append(filename)
    except OSError as e:
        print(f"Erreur suppression fichiers legal: {e}")
    
    data = load_legal_lines()
    if str(ligne) in data:
        del data[str(ligne)]
        save_legal_lines(data)
    
    return {
        "success": True, 
        "message": f"Ligne legal {ligne} supprim√©e",
        "deleted_files": deleted_files
    }

@app.get("/ficherlegal/list")
async def list_legal_files():
    """Liste tous les fichiers l√©gal"""
    files = []
    try:
        for filename in os.listdir(LEGAL_SAVE_DIR):
            if filename.startswith("legalligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("legalligne", "")
                    if ligne_str.isdigit():
                        files.append({
                            "ligne": int(ligne_str),
                            "filename": filename,
                            "url": f"/cloud/ficherlegal/{filename}"
                        })
    except OSError:
        pass
    
    return {"files": sorted(files, key=lambda x: (x["ligne"], x["filename"]))}






# ---------- ENDPOINTS POUR MARKETING ET M√âDIAS ----------

MARKETING_SAVE_DIR = f"{base_cloud}/fichermarketing"
MARKETING_LINES_FILE = os.path.join(MARKETING_SAVE_DIR, "lines.json")
os.makedirs(MARKETING_SAVE_DIR, exist_ok=True)

def load_marketing_lines():
    if os.path.exists(MARKETING_LINES_FILE):
        try:
            with open(MARKETING_LINES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_marketing_lines(data):
    try:
        with open(MARKETING_LINES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"Erreur sauvegarde marketing: {e}")

def find_marketing_file_on_disk(ligne: int, target_filename: str) -> Optional[str]:
    """Trouve le fichier marketing r√©el sur le disque"""
    
    exact_path = os.path.join(MARKETING_SAVE_DIR, target_filename)
    if os.path.exists(exact_path):
        return target_filename
    
    try:
        for filename in os.listdir(MARKETING_SAVE_DIR):
            if filename.startswith(f"marketingligne{ligne}_"):
                decoded_existing = urllib.parse.unquote(filename)
                decoded_target = urllib.parse.unquote(target_filename)
                
                if decoded_existing == decoded_target:
                    return filename
                
                if decoded_existing.replace(' ', '') == decoded_target.replace(' ', ''):
                    return filename
                
                if '_' in filename and '_' in target_filename:
                    existing_suffix = '_'.join(filename.split('_')[2:])
                    target_suffix = '_'.join(target_filename.split('_')[1:])
                    
                    if existing_suffix == target_suffix:
                        return filename
    except OSError:
        pass
    
    return None

@app.post("/fichermarketing/upload")
async def upload_marketing_file(
    ligne: int = Form(...),
    file: UploadFile = File(...)
):
    """Upload un fichier pour une ligne marketing"""
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nom de fichier manquant")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    safe_filename = f"marketingligne{ligne}_{timestamp}_{file.filename}"
    file_path = os.path.join(MARKETING_SAVE_DIR, safe_filename)
    
    try:
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        data = load_marketing_lines()
        if str(ligne) not in data:
            data[str(ligne)] = {"ligne": ligne, "titre": "", "lien": "", "files": []}
        
        file_info = {
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/fichermarketing/{safe_filename}",
            "uploaded_at": datetime.now().isoformat()
        }
        
        data[str(ligne)]["files"].append(file_info)
        save_marketing_lines(data)
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/fichermarketing/{safe_filename}"
        }
        
    except Exception as e:
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"Erreur upload marketing: {str(e)}")

@app.get("/fichermarketing/lines")
async def get_marketing_lines():
    """R√©cup√®re toutes les lignes marketing avec leurs fichiers"""
    data = load_marketing_lines()
    
    try:
        disk_files = {}
        for filename in os.listdir(MARKETING_SAVE_DIR):
            if filename.startswith("marketingligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("marketingligne", "")
                    if ligne_str.isdigit():
                        ligne = int(ligne_str)
                        if ligne not in disk_files:
                            disk_files[ligne] = []
                        
                        original_name = filename
                        if str(ligne) in data:
                            for f in data[str(ligne)].get("files", []):
                                if f.get("filename") == filename:
                                    original_name = f.get("original_name", filename)
                                    break
                        
                        disk_files[ligne].append({
                            "filename": filename,
                            "original_name": original_name,
                            "url": f"/cloud/fichermarketing/{filename}",
                            "line": ligne
                        })
        
        for ligne, files in disk_files.items():
            ligne_str = str(ligne)
            if ligne_str not in data:
                data[ligne_str] = {"ligne": ligne, "titre": "", "lien": "", "files": []}
            
            data[ligne_str]["files"] = files
    
    except OSError as e:
        print(f"Erreur lecture disque marketing: {e}")
    
    save_marketing_lines(data)
    
    return {"lines": sorted(data.values(), key=lambda x: int(x["ligne"]))}

@app.delete("/fichermarketing/delete_file/{ligne}/{filename}")
async def delete_marketing_specific_file(ligne: int, filename: str):
    """Supprime un fichier marketing sp√©cifique"""
    
    decoded_filename = urllib.parse.unquote(filename)
    
    real_filename = find_marketing_file_on_disk(ligne, decoded_filename)
    
    if not real_filename:
        raise HTTPException(status_code=404, detail=f"Fichier marketing non trouv√©: {decoded_filename}")
    
    file_path = os.path.join(MARKETING_SAVE_DIR, real_filename)
    
    try:
        os.remove(file_path)
        
        data = load_marketing_lines()
        if str(ligne) in data:
            data[str(ligne)]["files"] = [
                f for f in data[str(ligne)].get("files", [])
                if f.get("filename") != real_filename
            ]
            save_marketing_lines(data)
        
        return {
            "success": True, 
            "message": f"Fichier marketing {real_filename} supprim√©",
            "deleted_file": real_filename
        }
        
    except OSError as e:
        raise HTTPException(status_code=500, detail=f"Erreur suppression marketing: {str(e)}")

@app.post("/fichermarketing/update_title/{ligne}")
async def update_marketing_title(ligne: int, request: dict):
    """Met √† jour le titre d'une ligne marketing"""
    titre = request.get("titre", "")
    
    data = load_marketing_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien": "", "files": []}
    
    data[str(ligne)]["titre"] = titre
    save_marketing_lines(data)
    
    return {"success": True, "message": f"Titre marketing mis √† jour pour ligne {ligne}"}

@app.post("/fichermarketing/update_link/{ligne}")  # ‚Üê Changez "update_lien" en "update_link"
async def update_marketing_link(ligne: int, request: dict):
    """Met √† jour le lien d'une ligne marketing"""
    lien_texte = request.get("lien_texte", "")  # ‚Üê Nouveau champ
    lien_url = request.get("lien_url", "")      # ‚Üê Nouveau champ
    
    data = load_marketing_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
    
    data[str(ligne)]["lien_texte"] = lien_texte  # ‚Üê Sauvegarder les deux champs
    data[str(ligne)]["lien_url"] = lien_url
    save_marketing_lines(data)
    
    return {"success": True, "message": f"Lien marketing mis √† jour pour ligne {ligne}"}

@app.post("/fichermarketing/add_line/{ligne}")
async def add_marketing_line(ligne: int, request: dict = None):
    """Ajoute ou met √† jour une ligne marketing"""
    titre = ""
    lien_texte = ""  # ‚Üê Nouveau
    lien_url = ""    # ‚Üê Nouveau
    if request:
        titre = request.get("titre", "")
        lien_texte = request.get("lien_texte", "")  # ‚Üê Nouveau
        lien_url = request.get("lien_url", "")      # ‚Üê Nouveau
    
    data = load_marketing_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {
            "ligne": ligne, 
            "titre": titre, 
            "lien_texte": lien_texte,  # ‚Üê Nouveau
            "lien_url": lien_url,      # ‚Üê Nouveau
            "files": []
        }
    
    save_marketing_lines(data)
    return {"success": True, "message": f"Ligne marketing {ligne} sauvegard√©e"}

@app.delete("/fichermarketing/delete/{ligne}")
async def delete_marketing_line(ligne: int):
    """Supprime une ligne marketing enti√®re et tous ses fichiers"""
    
    deleted_files = []
    
    try:
        for filename in os.listdir(MARKETING_SAVE_DIR):
            if filename.startswith(f"marketingligne{ligne}_"):
                file_path = os.path.join(MARKETING_SAVE_DIR, filename)
                os.remove(file_path)
                deleted_files.append(filename)
    except OSError as e:
        print(f"Erreur suppression fichiers marketing: {e}")
    
    data = load_marketing_lines()
    if str(ligne) in data:
        del data[str(ligne)]
        save_marketing_lines(data)
    
    return {
        "success": True, 
        "message": f"Ligne marketing {ligne} supprim√©e",
        "deleted_files": deleted_files
    }


PROCESSUS_SAVE_DIR = f"{base_cloud}/ficherprocessus"
PROCESSUS_LINES_FILE = os.path.join(PROCESSUS_SAVE_DIR, "lines.json")
os.makedirs(PROCESSUS_SAVE_DIR, exist_ok=True)

def load_processus_lines():
    if os.path.exists(PROCESSUS_LINES_FILE):
        try:
            with open(PROCESSUS_LINES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_processus_lines(data):
    try:
        with open(PROCESSUS_LINES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"Erreur sauvegarde processus: {e}")

def find_processus_file_on_disk(ligne: int, target_filename: str) -> Optional[str]:
    """Trouve le fichier processus r√©el sur le disque"""
    
    exact_path = os.path.join(PROCESSUS_SAVE_DIR, target_filename)
    if os.path.exists(exact_path):
        return target_filename
    
    try:
        for filename in os.listdir(PROCESSUS_SAVE_DIR):
            if filename.startswith(f"processusligne{ligne}_"):
                decoded_existing = urllib.parse.unquote(filename)
                decoded_target = urllib.parse.unquote(target_filename)
                
                if decoded_existing == decoded_target:
                    return filename
                
                if decoded_existing.replace(' ', '') == decoded_target.replace(' ', ''):
                    return filename
                
                if '_' in filename and '_' in target_filename:
                    existing_suffix = '_'.join(filename.split('_')[2:])
                    target_suffix = '_'.join(target_filename.split('_')[1:])
                    
                    if existing_suffix == target_suffix:
                        return filename
    except OSError:
        pass
    
    return None

@app.post("/ficherprocessus/upload")
async def upload_processus_file(
    ligne: int = Form(...),
    file: UploadFile = File(...)
):
    """Upload un fichier pour une ligne processus"""
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nom de fichier manquant")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    safe_filename = f"processusligne{ligne}_{timestamp}_{file.filename}"
    file_path = os.path.join(PROCESSUS_SAVE_DIR, safe_filename)
    
    try:
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        data = load_processus_lines()
        if str(ligne) not in data:
            data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
        
        file_info = {
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherprocessus/{safe_filename}",
            "uploaded_at": datetime.now().isoformat()
        }
        
        data[str(ligne)]["files"].append(file_info)
        save_processus_lines(data)
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherprocessus/{safe_filename}"
        }
        
    except Exception as e:
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"Erreur upload processus: {str(e)}")

@app.get("/ficherprocessus/lines")
async def get_processus_lines():
    """R√©cup√®re toutes les lignes processus avec leurs fichiers"""
    data = load_processus_lines()
    
    try:
        disk_files = {}
        for filename in os.listdir(PROCESSUS_SAVE_DIR):
            if filename.startswith("processusligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("processusligne", "")
                    if ligne_str.isdigit():
                        ligne = int(ligne_str)
                        if ligne not in disk_files:
                            disk_files[ligne] = []
                        
                        original_name = filename
                        if str(ligne) in data:
                            for f in data[str(ligne)].get("files", []):
                                if f.get("filename") == filename:
                                    original_name = f.get("original_name", filename)
                                    break
                        
                        disk_files[ligne].append({
                            "filename": filename,
                            "original_name": original_name,
                            "url": f"/cloud/ficherprocessus/{filename}",
                            "line": ligne
                        })
        
        for ligne, files in disk_files.items():
            ligne_str = str(ligne)
            if ligne_str not in data:
                data[ligne_str] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
            
            data[ligne_str]["files"] = files
    
    except OSError as e:
        print(f"Erreur lecture disque processus: {e}")
    
    save_processus_lines(data)
    
    return {"lines": sorted(data.values(), key=lambda x: int(x["ligne"]))}

@app.delete("/ficherprocessus/delete_file/{ligne}/{filename}")
async def delete_processus_specific_file(ligne: int, filename: str):
    """Supprime un fichier processus sp√©cifique"""
    
    decoded_filename = urllib.parse.unquote(filename)
    
    real_filename = find_processus_file_on_disk(ligne, decoded_filename)
    
    if not real_filename:
        raise HTTPException(status_code=404, detail=f"Fichier processus non trouv√©: {decoded_filename}")
    
    file_path = os.path.join(PROCESSUS_SAVE_DIR, real_filename)
    
    try:
        os.remove(file_path)
        
        data = load_processus_lines()
        if str(ligne) in data:
            data[str(ligne)]["files"] = [
                f for f in data[str(ligne)].get("files", [])
                if f.get("filename") != real_filename
            ]
            save_processus_lines(data)
        
        return {
            "success": True, 
            "message": f"Fichier processus {real_filename} supprim√©",
            "deleted_file": real_filename
        }
        
    except OSError as e:
        raise HTTPException(status_code=500, detail=f"Erreur suppression processus: {str(e)}")

@app.post("/ficherprocessus/update_title/{ligne}")
async def update_processus_title(ligne: int, request: dict):
    """Met √† jour le titre d'une ligne processus"""
    titre = request.get("titre", "")
    
    data = load_processus_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
    
    data[str(ligne)]["titre"] = titre
    save_processus_lines(data)
    
    return {"success": True, "message": f"Titre processus mis √† jour pour ligne {ligne}"}

@app.post("/ficherprocessus/update_link/{ligne}")
async def update_processus_link(ligne: int, request: dict):
    """Met √† jour le lien d'une ligne processus"""
    lien_texte = request.get("lien_texte", "")
    lien_url = request.get("lien_url", "")
    
    data = load_processus_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
    
    data[str(ligne)]["lien_texte"] = lien_texte
    data[str(ligne)]["lien_url"] = lien_url
    save_processus_lines(data)
    
    return {"success": True, "message": f"Lien processus mis √† jour pour ligne {ligne}"}

@app.post("/ficherprocessus/add_line/{ligne}")
async def add_processus_line(ligne: int, request: dict = None):
    """Ajoute ou met √† jour une ligne processus"""
    titre = ""
    lien_texte = ""
    lien_url = ""
    if request:
        titre = request.get("titre", "")
        lien_texte = request.get("lien_texte", "")
        lien_url = request.get("lien_url", "")
    
    data = load_processus_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {
            "ligne": ligne, 
            "titre": titre, 
            "lien_texte": lien_texte,
            "lien_url": lien_url,
            "files": []
        }
    
    save_processus_lines(data)
    return {"success": True, "message": f"Ligne processus {ligne} sauvegard√©e"}

@app.delete("/ficherprocessus/delete/{ligne}")
async def delete_processus_line(ligne: int):
    """Supprime une ligne processus enti√®re et tous ses fichiers"""
    
    deleted_files = []
    
    try:
        for filename in os.listdir(PROCESSUS_SAVE_DIR):
            if filename.startswith(f"processusligne{ligne}_"):
                file_path = os.path.join(PROCESSUS_SAVE_DIR, filename)
                os.remove(file_path)
                deleted_files.append(filename)
    except OSError as e:
        print(f"Erreur suppression fichiers processus: {e}")
    
    data = load_processus_lines()
    if str(ligne) in data:
        del data[str(ligne)]
        save_processus_lines(data)
    
    return {
        "success": True, 
        "message": f"Ligne processus {ligne} supprim√©e",
        "deleted_files": deleted_files
    }

# Route pour servir les fichiers processus
@app.get("/cloud/ficherprocessus/{filename}")
async def serve_processus_file(filename: str):
    file_path = os.path.join(PROCESSUS_SAVE_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    raise HTTPException(status_code=404, detail="Fichier non trouv√©")


# ---------- ENDPOINTS POUR FORMATIONS ET DOCUMENTS UTILES ----------

FORMATIONS_SAVE_DIR = f"{base_cloud}/ficherformations"
FORMATIONS_LINES_FILE = os.path.join(FORMATIONS_SAVE_DIR, "lines.json")
os.makedirs(FORMATIONS_SAVE_DIR, exist_ok=True)

def load_formations_lines():
    if os.path.exists(FORMATIONS_LINES_FILE):
        try:
            with open(FORMATIONS_LINES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_formations_lines(data):
    try:
        with open(FORMATIONS_LINES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"Erreur sauvegarde formations: {e}")

def find_formations_file_on_disk(ligne: int, target_filename: str) -> Optional[str]:
    """Trouve le fichier formations r√©el sur le disque"""
    
    exact_path = os.path.join(FORMATIONS_SAVE_DIR, target_filename)
    if os.path.exists(exact_path):
        return target_filename
    
    try:
        for filename in os.listdir(FORMATIONS_SAVE_DIR):
            if filename.startswith(f"formationsligne{ligne}_"):
                decoded_existing = urllib.parse.unquote(filename)
                decoded_target = urllib.parse.unquote(target_filename)
                
                if decoded_existing == decoded_target:
                    return filename
                
                if decoded_existing.replace(' ', '') == decoded_target.replace(' ', ''):
                    return filename
                
                if '_' in filename and '_' in target_filename:
                    existing_suffix = '_'.join(filename.split('_')[2:])
                    target_suffix = '_'.join(target_filename.split('_')[1:])
                    
                    if existing_suffix == target_suffix:
                        return filename
    except OSError:
        pass
    
    return None

@app.post("/ficherformations/upload")
async def upload_formations_file(
    ligne: int = Form(...),
    file: UploadFile = File(...)
):
    """Upload un fichier pour une ligne formations"""
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="Nom de fichier manquant")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    safe_filename = f"formationsligne{ligne}_{timestamp}_{file.filename}"
    file_path = os.path.join(FORMATIONS_SAVE_DIR, safe_filename)
    
    try:
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        data = load_formations_lines()
        if str(ligne) not in data:
            data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
        
        file_info = {
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherformations/{safe_filename}",
            "uploaded_at": datetime.now().isoformat()
        }
        
        data[str(ligne)]["files"].append(file_info)
        save_formations_lines(data)
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_name": file.filename,
            "url": f"/cloud/ficherformations/{safe_filename}"
        }
        
    except Exception as e:
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"Erreur upload formations: {str(e)}")

@app.get("/ficherformations/lines")
async def get_formations_lines():
    """R√©cup√®re toutes les lignes formations avec leurs fichiers"""
    data = load_formations_lines()
    
    try:
        disk_files = {}
        for filename in os.listdir(FORMATIONS_SAVE_DIR):
            if filename.startswith("formationsligne") and not filename.endswith(".json"):
                parts = filename.split("_")
                if len(parts) >= 2:
                    ligne_str = parts[0].replace("formationsligne", "")
                    if ligne_str.isdigit():
                        ligne = int(ligne_str)
                        if ligne not in disk_files:
                            disk_files[ligne] = []
                        
                        original_name = filename
                        if str(ligne) in data:
                            for f in data[str(ligne)].get("files", []):
                                if f.get("filename") == filename:
                                    original_name = f.get("original_name", filename)
                                    break
                        
                        disk_files[ligne].append({
                            "filename": filename,
                            "original_name": original_name,
                            "url": f"/cloud/ficherformations/{filename}",
                            "line": ligne
                        })
        
        for ligne, files in disk_files.items():
            ligne_str = str(ligne)
            if ligne_str not in data:
                data[ligne_str] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
            
            data[ligne_str]["files"] = files
    
    except OSError as e:
        print(f"Erreur lecture disque formations: {e}")
    
    save_formations_lines(data)
    
    return {"lines": sorted(data.values(), key=lambda x: int(x["ligne"]))}

@app.delete("/ficherformations/delete_file/{ligne}/{filename}")
async def delete_formations_specific_file(ligne: int, filename: str):
    """Supprime un fichier formations sp√©cifique"""
    
    decoded_filename = urllib.parse.unquote(filename)
    
    real_filename = find_formations_file_on_disk(ligne, decoded_filename)
    
    if not real_filename:
        raise HTTPException(status_code=404, detail=f"Fichier formations non trouv√©: {decoded_filename}")
    
    file_path = os.path.join(FORMATIONS_SAVE_DIR, real_filename)
    
    try:
        os.remove(file_path)
        
        data = load_formations_lines()
        if str(ligne) in data:
            data[str(ligne)]["files"] = [
                f for f in data[str(ligne)].get("files", [])
                if f.get("filename") != real_filename
            ]
            save_formations_lines(data)
        
        return {
            "success": True, 
            "message": f"Fichier formations {real_filename} supprim√©",
            "deleted_file": real_filename
        }
        
    except OSError as e:
        raise HTTPException(status_code=500, detail=f"Erreur suppression formations: {str(e)}")

@app.post("/ficherformations/update_title/{ligne}")
async def update_formations_title(ligne: int, request: dict):
    """Met √† jour le titre d'une ligne formations"""
    titre = request.get("titre", "")
    
    data = load_formations_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
    
    data[str(ligne)]["titre"] = titre
    save_formations_lines(data)
    
    return {"success": True, "message": f"Titre formations mis √† jour pour ligne {ligne}"}

@app.post("/ficherformations/update_link/{ligne}")
async def update_formations_link(ligne: int, request: dict):
    """Met √† jour le lien d'une ligne formations"""
    lien_texte = request.get("lien_texte", "")
    lien_url = request.get("lien_url", "")
    
    data = load_formations_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {"ligne": ligne, "titre": "", "lien_texte": "", "lien_url": "", "files": []}
    
    data[str(ligne)]["lien_texte"] = lien_texte
    data[str(ligne)]["lien_url"] = lien_url
    save_formations_lines(data)
    
    return {"success": True, "message": f"Lien formations mis √† jour pour ligne {ligne}"}

@app.post("/ficherformations/add_line/{ligne}")
async def add_formations_line(ligne: int, request: dict = None):
    """Ajoute ou met √† jour une ligne formations"""
    titre = ""
    lien_texte = ""
    lien_url = ""
    if request:
        titre = request.get("titre", "")
        lien_texte = request.get("lien_texte", "")
        lien_url = request.get("lien_url", "")
    
    data = load_formations_lines()
    if str(ligne) not in data:
        data[str(ligne)] = {
            "ligne": ligne, 
            "titre": titre, 
            "lien_texte": lien_texte,
            "lien_url": lien_url,
            "files": []
        }
    
    save_formations_lines(data)
    return {"success": True, "message": f"Ligne formations {ligne} sauvegard√©e"}

@app.delete("/ficherformations/delete/{ligne}")
async def delete_formations_line(ligne: int):
    """Supprime une ligne formations enti√®re et tous ses fichiers"""
    
    deleted_files = []
    
    try:
        for filename in os.listdir(FORMATIONS_SAVE_DIR):
            if filename.startswith(f"formationsligne{ligne}_"):
                file_path = os.path.join(FORMATIONS_SAVE_DIR, filename)
                os.remove(file_path)
                deleted_files.append(filename)
    except OSError as e:
        print(f"Erreur suppression fichiers formations: {e}")
    
    data = load_formations_lines()
    if str(ligne) in data:
        del data[str(ligne)]
        save_formations_lines(data)
    
    return {
        "success": True, 
        "message": f"Ligne formations {ligne} supprim√©e",
        "deleted_files": deleted_files
    }

# Route pour servir les fichiers formations
@app.get("/cloud/ficherformations/{filename}")
async def serve_formations_file(filename: str):
    file_path = os.path.join(FORMATIONS_SAVE_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    raise HTTPException(status_code=404, detail="Fichier non trouv√©")


# ============================================
# ENDPOINTS POUR LA GESTION DES PROJETS
# ============================================

# Mod√®les pour les projets
class ProjectData(BaseModel):
    client: str
    adresse: Optional[str] = ""
    telephone: Optional[str] = ""
    date: Optional[str] = ""
    totalExterieur: Optional[float] = 0.0
    totalInterieur: Optional[float] = 0.0
    formData: Optional[dict] = {}

class ParametersData(BaseModel):
    parameters: dict

# Mod√®les pour la gestion des employ√©s
class NouvelEmploye(BaseModel):
    nom: str
    genre: str
    courriel: str
    telephone: str
    poste: str

class EmployeActif(BaseModel):
    nom: str
    nas: str
    genre: str
    adresse: str
    appartement: Optional[str] = None
    ville: str
    codePostal: str
    telephone: str
    courriel: str
    datePremiere: str
    posteService: str
    tauxHoraire: float

class EmployeModifier(BaseModel):
    nom: str
    nas: str
    genre: str
    adresse: str
    appartement: Optional[str] = None
    ville: str
    codePostal: str
    telephone: str
    courriel: str
    datePremiere: str
    posteService: str
    tauxHoraire: float

class TerminerEmploye(BaseModel):
    motif: str
    dateFinEmploi: Optional[str] = ""
    justificatif: Optional[str] = ""

class CreateUserData(BaseModel):
    username: str
    password: str
    role: str
    department: Optional[str] = None
    email: Optional[str] = None
    monday_api_key: Optional[str] = None
    monday_board_id: Optional[str] = None

# Route pour cr√©er un nouvel utilisateur (admin uniquement)
@app.post("/api/admin/users/create")
async def create_new_user(user_data: CreateUserData):
    """Cr√©e un nouvel utilisateur (accessible aux r√¥les admin/direction)"""
    try:
        success = create_user(
            username=user_data.username,
            password=user_data.password,
            role=user_data.role,
            department=user_data.department,
            email=user_data.email,
            monday_api_key=user_data.monday_api_key,
            monday_board_id=user_data.monday_board_id
        )

        if success:
            return {
                "success": True,
                "message": f"Utilisateur '{user_data.username}' cr√©√© avec succ√®s",
                "user": {
                    "username": user_data.username,
                    "role": user_data.role,
                    "email": user_data.email
                }
            }
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Impossible de cr√©er l'utilisateur '{user_data.username}'. Il existe peut-√™tre d√©j√†."
            )
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] Cr√©ation utilisateur via API: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class AssignCoachData(BaseModel):
    entrepreneur_id: int
    coach_id: Optional[int] = None


@app.post("/api/admin/users/assign-coach")
async def assign_coach_to_entrepreneur(data: AssignCoachData):
    """Assigne ou d√©sassigne un coach √† un entrepreneur"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            # Si on assigne un coach, r√©cup√©rer son username
            coach_username = None
            if data.coach_id:
                cursor.execute("SELECT username FROM users WHERE id = ? AND role = 'coach'", (data.coach_id,))
                coach_row = cursor.fetchone()
                if coach_row:
                    coach_username = coach_row[0]

            # Mettre √† jour BOTH coach_id ET assigned_coach
            cursor.execute("""
                UPDATE users
                SET coach_id = ?, assigned_coach = ?
                WHERE id = ? AND role = 'entrepreneur'
            """, (data.coach_id, coach_username, data.entrepreneur_id))

            conn.commit()

            if cursor.rowcount == 0:
                raise HTTPException(
                    status_code=404,
                    detail="Entrepreneur non trouv√©"
                )

            action = "assign√©" if data.coach_id else "d√©sassign√©"
            return {
                "success": True,
                "message": f"Entrepreneur {action} avec succ√®s"
            }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] Assignation coach: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class UpdateUserData(BaseModel):
    id: int
    username: Optional[str] = None
    email: Optional[str] = None
    role: Optional[str] = None
    password: Optional[str] = None
    prenom: Optional[str] = None
    nom: Optional[str] = None
    telephone: Optional[str] = None
    adresse: Optional[str] = None
    department: Optional[str] = None
    monday_api_key: Optional[str] = None
    monday_board_id: Optional[str] = None


@app.post("/api/admin/users/update")
async def update_user_route(data: UpdateUserData):
    """Met √† jour un utilisateur"""
    try:
        # Validation du r√¥le si fourni
        valid_roles = ["entrepreneur", "coach", "direction", "comptable"]
        if data.role and data.role not in valid_roles:
            raise HTTPException(
                status_code=400,
                detail=f"R√¥le invalide. R√¥les valides: {', '.join(valid_roles)}"
            )

        success = update_user(
            user_id=data.id,
            username=data.username,
            email=data.email,
            role=data.role,
            password=data.password,
            prenom=data.prenom,
            nom=data.nom,
            telephone=data.telephone,
            adresse=data.adresse,
            department=data.department,
            monday_api_key=data.monday_api_key,
            monday_board_id=data.monday_board_id
        )

        if success:
            return {"success": True, "message": "Utilisateur mis √† jour avec succ√®s"}
        else:
            raise HTTPException(
                status_code=400,
                detail="Impossible de mettre √† jour l'utilisateur (peut-√™tre que le username existe d√©j√†)"
            )

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] Mise √† jour utilisateur via API: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class DeleteUserData(BaseModel):
    id: int


@app.post("/api/admin/users/delete")
async def delete_user_route(data: DeleteUserData):
    """Supprime compl√®tement un utilisateur (base de donn√©es + fichiers)"""
    try:
        success = delete_user_completely(user_id=data.id)

        if success:
            return {"success": True, "message": "Utilisateur supprim√© avec succ√®s"}
        else:
            raise HTTPException(status_code=400, detail="Impossible de supprimer l'utilisateur")

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] Suppression utilisateur via API: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class ToggleActiveData(BaseModel):
    id: int
    is_active: bool


@app.post("/api/admin/users/toggle-active")
async def toggle_active_route(data: ToggleActiveData):
    """Active ou d√©sactive un utilisateur"""
    try:
        success = toggle_user_active(user_id=data.id, is_active=data.is_active)

        if success:
            status = "activ√©" if data.is_active else "d√©sactiv√©"
            return {"success": True, "message": f"Utilisateur {status} avec succ√®s"}
        else:
            raise HTTPException(status_code=400, detail="Impossible de modifier le statut de l'utilisateur")

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] Toggle utilisateur via API: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/users/entrepreneurs")
async def get_users_entrepreneurs_api(coach_username: Optional[str] = None):
    """R√©cup√®re la liste de tous les entrepreneurs (ou filtr√©e par coach si sp√©cifi√©) avec le nombre d'employ√©s en attente"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            if coach_username:
                # R√©cup√©rer seulement les entrepreneurs assign√©s √† ce coach via assigned_coach
                cursor.execute("""
                    SELECT username, email, created_at, is_active, prenom, nom
                    FROM users
                    WHERE role = 'entrepreneur' AND assigned_coach = ? AND is_active = 1
                    ORDER BY username
                """, (coach_username,))
            else:
                # R√©cup√©rer tous les entrepreneurs
                cursor.execute("""
                    SELECT username, email, created_at, is_active, prenom, nom
                    FROM users
                    WHERE role = 'entrepreneur'
                    ORDER BY username
                """)

            entrepreneurs = []
            employes_dir = os.path.join(base_cloud, "employes")
            statuts_dir = os.path.join(base_cloud, "facturation_qe_statuts")

            # Charger l'historique pour exclure les paiements d√©j√† dans Rapprochement QBO
            historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")
            paiements_en_rapprochement = set()
            remboursements_en_rapprochement = set()
            if os.path.exists(historique_file):
                try:
                    with open(historique_file, "r", encoding="utf-8") as f:
                        historique = json.load(f)
                        for h in historique:
                            if h.get("statut") == "attente_comptable":
                                if h.get("type") == "remboursement":
                                    # Pour les remboursements: (username, num)
                                    remboursements_en_rapprochement.add((h.get("entrepreneurUsername"), h.get("numeroSoumission")))
                                else:
                                    # Pour les autres paiements: (username, num, type, index)
                                    key = (h.get("entrepreneurUsername"), h.get("numeroSoumission"), h.get("type"), h.get("index"))
                                    paiements_en_rapprochement.add(key)
                except:
                    pass

            for row in cursor.fetchall():
                username = row[0]
                pending_employes_count = 0
                pending_facturations_count = 0
                pending_employes_comptable_count = 0
                pending_facturations_comptable_count = 0
                plaintes_count = 0

                # Calculer le nombre d'employ√©s en attente pour cet entrepreneur (coach ou direction)
                if os.path.exists(employes_dir):
                    user_path = os.path.join(employes_dir, username)
                    if os.path.isdir(user_path):
                        # Compter les nouveaux employ√©s en attente d'activation
                        employes_nouveaux = load_employes(username, "nouveaux")
                        for employe in employes_nouveaux:
                            if employe.get("statut") == "En attente de validation":
                                pending_employes_count += 1
                            elif employe.get("statut") == "En attente comptable":
                                pending_employes_comptable_count += 1

                        # Compter les inactivations en attente de validation coach
                        inactivations = load_inactivations(username)
                        for inact in inactivations:
                            if inact.get("statut") == "Inactivation en attente de validation":
                                pending_employes_count += 1
                            elif inact.get("statut") == "Inactivation en attente comptable":
                                pending_employes_comptable_count += 1

                        # Compter les modifications en attente de validation coach
                        employes_actifs = load_employes(username, "actifs")
                        for employe in employes_actifs:
                            if employe.get("statut") == "Modification en attente de validation":
                                pending_employes_count += 1
                            elif employe.get("statut") == "Modification en attente comptable":
                                pending_employes_comptable_count += 1

                        # Compter les r√©activations en attente de validation coach
                        # IMPORTANT: Chercher dans inactifs ET termines, pas dans reactivations.json
                        # car le statut est mis √† jour dans ces fichiers, pas dans reactivations.json
                        employes_inactifs = load_employes(username, "inactifs")
                        for emp in employes_inactifs:
                            if emp.get("statut") == "R√©activation en attente de validation":
                                pending_employes_count += 1
                            elif emp.get("statut") == "R√©activation en attente comptable":
                                pending_employes_comptable_count += 1

                        employes_termines = load_employes(username, "termines")
                        for emp in employes_termines:
                            if emp.get("statut") == "R√©activation en attente de validation":
                                pending_employes_count += 1
                            elif emp.get("statut") == "R√©activation en attente comptable":
                                pending_employes_comptable_count += 1

                # Calculer le nombre de facturations en traitement pour cet entrepreneur (coach ou direction)
                if os.path.exists(statuts_dir):
                    user_path = os.path.join(statuts_dir, username)
                    if os.path.isdir(user_path):
                        statuts_file = os.path.join(user_path, "statuts_clients.json")
                        if os.path.exists(statuts_file):
                            with open(statuts_file, "r", encoding="utf-8") as f:
                                statuts = json.load(f)

                            for num_soumission, client_statuts in statuts.items():
                                # V√©rifier si le client a un paiement refus√© (urgent)
                                statut_depot = client_statuts.get("statutDepot")
                                statut_paiement_final = client_statuts.get("statutPaiementFinal")
                                autres_paiements = client_statuts.get("autresPaiements", [])

                                depot_refuse = statut_depot == "refuse"
                                paiement_final_refuse = statut_paiement_final == "refuse"
                                autres_refuses = any(p.get("statut") == "refuse" for p in autres_paiements) if isinstance(autres_paiements, list) else False
                                a_paiement_refuse = depot_refuse or paiement_final_refuse or autres_refuses

                                # Si le client a un paiement refus√©, ne pas compter (il est dans Urgent)
                                if a_paiement_refuse:
                                    continue

                                # Compter depot en traitement (coach) ou attente_comptable (comptable)
                                if statut_depot == "traitement":
                                    pending_facturations_count += 1
                                elif statut_depot == "attente_comptable":
                                    # Exclure si d√©j√† dans Rapprochement QBO
                                    if (username, num_soumission, "depot", None) not in paiements_en_rapprochement:
                                        pending_facturations_comptable_count += 1
                                # Compter paiement final en traitement (coach) ou attente_comptable (comptable)
                                if statut_paiement_final == "traitement":
                                    pending_facturations_count += 1
                                elif statut_paiement_final == "attente_comptable":
                                    # Exclure si d√©j√† dans Rapprochement QBO
                                    if (username, num_soumission, "paiement_final", None) not in paiements_en_rapprochement:
                                        pending_facturations_comptable_count += 1
                                # Compter autres paiements en traitement (coach) ou attente_comptable (comptable)
                                if client_statuts.get("statutAutresPaiements") == "traitement":
                                    pending_facturations_count += 1
                                elif client_statuts.get("statutAutresPaiements") == "attente_comptable":
                                    # Compter chaque paiement partiel non encore dans Rapprochement QBO
                                    for idx, ap in enumerate(autres_paiements):
                                        if ap.get("statut") == "attente_comptable":
                                            if (username, num_soumission, "autres_paiements", idx) not in paiements_en_rapprochement:
                                                pending_facturations_comptable_count += 1

                # Compter les remboursements en attente validation coach (coach ou direction)
                remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
                if os.path.exists(remb_file):
                    with open(remb_file, "r", encoding="utf-8") as f:
                        content = f.read().strip()
                        if content:
                            remboursements = json.loads(content)
                            remb_en_attente_coach = sum(1 for r in remboursements if r.get("statut") == "en_attente_coach")
                            pending_facturations_count += remb_en_attente_coach
                            # Pour les remboursements comptable, exclure ceux d√©j√† dans Rapprochement QBO
                            for r in remboursements:
                                if r.get("statut") == "en_attente_comptable":
                                    if (username, r.get("num")) not in remboursements_en_rapprochement:
                                        pending_facturations_comptable_count += 1

                # Compter les plaintes actuelles (non r√©gl√©es) pour cet entrepreneur
                plaintes_file = os.path.join(base_cloud, "plaintes", username, "plaintes.json")
                if os.path.exists(plaintes_file):
                    try:
                        with open(plaintes_file, "r", encoding="utf-8") as f:
                            content = f.read().strip()
                            if content:
                                plaintes = json.loads(content)
                                plaintes_count = sum(1 for p in plaintes if p.get("statut") == "actuelle")
                    except:
                        pass

                # R√©cup√©rer prenom et nom depuis la DB, sinon depuis user_info.json
                prenom = row[4] or ""
                nom = row[5] or ""

                # Si prenom ou nom vide dans DB, lire depuis user_info.json
                if not prenom or not nom:
                    user_info_file = os.path.join(base_cloud, "signatures", username, "user_info.json")
                    if os.path.exists(user_info_file):
                        try:
                            with open(user_info_file, "r", encoding="utf-8") as f:
                                user_info = json.load(f)
                                prenom = prenom or user_info.get("prenom", "")
                                nom = nom or user_info.get("nom", "")
                        except Exception as e:
                            print(f"[API] Erreur lecture user_info pour {username}: {e}")

                entrepreneurs.append({
                    "username": username,
                    "email": row[1],
                    "created_at": row[2],
                    "is_active": bool(row[3]),
                    "prenom": prenom,
                    "nom": nom,
                    "pending_count": pending_employes_count,  # Pour compatibilit√© avec Gestion Employ√©s
                    "pending_employes_count": pending_employes_count,
                    "pending_facturations_count": pending_facturations_count,
                    "pending_employes_comptable_count": pending_employes_comptable_count,
                    "pending_facturations_comptable_count": pending_facturations_comptable_count,
                    "plaintes_count": plaintes_count
                })

            return {
                "success": True,
                "entrepreneurs": entrepreneurs,
                "count": len(entrepreneurs)
            }
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] R√©cup√©ration entrepreneurs: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/users/coaches")
async def get_all_coaches():
    """R√©cup√®re la liste de tous les coachs"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            # R√©cup√©rer tous les coachs avec prenom et nom
            cursor.execute("""
                SELECT username, email, created_at, is_active, prenom, nom
                FROM users
                WHERE role = 'coach'
                ORDER BY username
            """)

            coaches = []
            for row in cursor.fetchall():
                coaches.append({
                    "username": row[0],
                    "email": row[1],
                    "created_at": row[2],
                    "is_active": bool(row[3]),
                    "prenom": row[4] or "",
                    "nom": row[5] or ""
                })

            return {
                "success": True,
                "coaches": coaches,
                "count": len(coaches)
            }
    except Exception as e:
        print(f"[ERREUR] R√©cup√©ration coachs: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/users/direction")
async def get_all_direction():
    """R√©cup√®re la liste de tous les utilisateurs direction"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            # R√©cup√©rer tous les direction avec prenom et nom
            cursor.execute("""
                SELECT username, email, created_at, is_active, prenom, nom
                FROM users
                WHERE role = 'direction'
                ORDER BY username
            """)

            users = []
            for row in cursor.fetchall():
                users.append({
                    "username": row[0],
                    "email": row[1],
                    "created_at": row[2],
                    "is_active": bool(row[3]),
                    "first_name": row[4] or "",  # Garde le nom de cl√© pour compatibilit√© API
                    "last_name": row[5] or ""
                })

            return {
                "success": True,
                "users": users,
                "count": len(users)
            }
    except Exception as e:
        print(f"[ERREUR] R√©cup√©ration direction: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/users/heartbeat")
async def user_heartbeat(request: Request):
    """Enregistre un heartbeat pour marquer l'utilisateur comme en ligne (persist√© en SQLite)"""
    try:
        data = await request.json()
        username = data.get("username")

        if not username:
            return {"success": False, "error": "Username requis"}

        # R√©cup√©rer les infos de l'utilisateur et ins√©rer/mettre √† jour dans online_users
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT prenom, nom, role FROM users WHERE username = ?
            """, (username,))
            row = cursor.fetchone()

            if row:
                # INSERT OR REPLACE pour g√©rer les heartbeats r√©p√©t√©s
                cursor.execute("""
                    INSERT OR REPLACE INTO online_users (username, last_seen, prenom, nom, role)
                    VALUES (?, ?, ?, ?, ?)
                """, (username, time.time(), row[0] or "", row[1] or "", row[2] or "entrepreneur"))
                conn.commit()

        return {"success": True}
    except Exception as e:
        print(f"[ERREUR] Heartbeat: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/users/disconnect")
async def user_disconnect(request: Request):
    """Marque l'utilisateur comme d√©connect√© imm√©diatement (supprime de SQLite)"""
    try:
        data = await request.json()
        username = data.get("username")

        if username:
            with sqlite3.connect(DB_PATH) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM online_users WHERE username = ?", (username,))
                conn.commit()

        return {"success": True}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/users/online")
async def get_online_users():
    """R√©cup√®re la liste des utilisateurs en ligne (heartbeat < 30 secondes) depuis SQLite"""
    try:
        current_time = time.time()
        timeout = 30  # 30 secondes de timeout
        cutoff_time = current_time - timeout

        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            # Nettoyer les utilisateurs inactifs (heartbeat trop vieux)
            cursor.execute("DELETE FROM online_users WHERE last_seen < ?", (cutoff_time,))

            # R√©cup√©rer les utilisateurs actifs
            cursor.execute("""
                SELECT username, prenom, nom, role
                FROM online_users
                WHERE last_seen >= ?
            """, (cutoff_time,))

            rows = cursor.fetchall()
            conn.commit()

            active_users = []
            for row in rows:
                active_users.append({
                    "username": row[0],
                    "prenom": row[1] or "",
                    "nom": row[2] or "",
                    "role": row[3] or "entrepreneur"
                })

        return {
            "success": True,
            "count": len(active_users),
            "users": active_users
        }
    except Exception as e:
        print(f"[ERREUR] Get online users: {e}")
        return {"success": False, "count": 0, "users": []}


@app.get("/api/user-info")
async def get_current_user_info(request: Request):
    """R√©cup√®re les informations de l'utilisateur connect√©"""
    try:
        # R√©cup√©rer le username depuis les cookies
        username = request.cookies.get("username")

        if not username:
            raise HTTPException(status_code=401, detail="Non authentifi√©")

        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT username, prenom, nom, role, email
                FROM users
                WHERE username = ?
            """, (username,))
            result = cursor.fetchone()

            if result:
                return {
                    "success": True,
                    "username": result[0],
                    "first_name": result[1] or "",
                    "last_name": result[2] or "",
                    "role": result[3],
                    "email": result[4]
                }
            else:
                raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR] R√©cup√©ration user info: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/profile/{username}")
async def get_user_profile(username: str):
    """R√©cup√®re le profil d'un utilisateur"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT username, email, prenom, nom, telephone, adresse, photo_url
                FROM users
                WHERE username = ?
            """, (username,))

            row = cursor.fetchone()

            if row:
                return {
                    "success": True,
                    "profile": {
                        "username": row[0],
                        "email": row[1],
                        "prenom": row[2] or "",
                        "nom": row[3] or "",
                        "telephone": row[4] or "",
                        "adresse": row[5] or "",
                        "photo_url": row[6] or ""
                    }
                }
            else:
                raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")
    except Exception as e:
        print(f"[ERREUR] R√©cup√©ration profil: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/profile/update")
async def update_user_profile(request: Request):
    """Met √† jour le profil d'un utilisateur"""
    try:
        data = await request.json()
        username = data.get('username')

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        # Construire dynamiquement la requ√™te SQL avec seulement les champs fournis
        update_fields = []
        update_values = []

        if 'prenom' in data:
            update_fields.append("prenom = ?")
            update_values.append(data.get('prenom', ''))

        if 'nom' in data:
            update_fields.append("nom = ?")
            update_values.append(data.get('nom', ''))

        if 'telephone' in data:
            update_fields.append("telephone = ?")
            update_values.append(data.get('telephone', ''))

        if 'email' in data:
            update_fields.append("email = ?")
            update_values.append(data.get('email', ''))

        if 'adresse' in data:
            update_fields.append("adresse = ?")
            update_values.append(data.get('adresse', ''))

        # Mettre √† jour dans la base de donn√©es SQLite uniquement si des champs sont fournis
        if update_fields:
            with sqlite3.connect(DB_PATH) as conn:
                cursor = conn.cursor()
                update_values.append(username)
                query = f"UPDATE users SET {', '.join(update_fields)} WHERE username = ?"
                cursor.execute(query, update_values)
                conn.commit()

        # Sauvegarder aussi dans le fichier user_info.json pour r√©trocompatibilit√©
        user_folder = f"{base_cloud}/signatures/{username}"
        os.makedirs(user_folder, exist_ok=True)
        user_info_file = os.path.join(user_folder, "user_info.json")

        # Charger les donn√©es existantes ou cr√©er un nouveau dictionnaire
        if os.path.exists(user_info_file):
            with open(user_info_file, "r", encoding="utf-8") as f:
                user_info = json.load(f)
        else:
            user_info = {}

        # Mettre √† jour uniquement les champs fournis dans le JSON
        if 'prenom' in data:
            user_info["prenom"] = data.get('prenom', '')
        if 'nom' in data:
            user_info["nom"] = data.get('nom', '')
        if 'telephone' in data:
            user_info["telephone"] = data.get('telephone', '')
        if 'email' in data:
            user_info["email"] = data.get('email', '')
        if 'adresse' in data:
            user_info["adresse"] = data.get('adresse', '')

        # Sauvegarder
        with open(user_info_file, "w", encoding="utf-8") as f:
            json.dump(user_info, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Profil mis √† jour"}
    except Exception as e:
        print(f"[ERREUR] Mise √† jour profil: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/profile/upload-photo")
async def upload_profile_photo(photo: UploadFile = File(...), username: str = Form(...)):
    """Upload la photo de profil d'un utilisateur"""
    try:
        # Cr√©er le dossier pour les photos de profil s'il n'existe pas
        photos_dir = os.path.join(BASE_DIR, "static", "profile_photos")
        os.makedirs(photos_dir, exist_ok=True)

        # G√©n√©rer un nom de fichier unique
        file_extension = os.path.splitext(photo.filename)[1]
        filename = f"{username}_{int(time.time())}{file_extension}"
        file_path = os.path.join(photos_dir, filename)

        # Sauvegarder le fichier
        with open(file_path, "wb") as buffer:
            content = await photo.read()
            buffer.write(content)

        # Mettre √† jour l'URL dans la base de donn√©es
        photo_url = f"/static/profile_photos/{filename}"

        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE users
                SET photo_url = ?
                WHERE username = ?
            """, (photo_url, username))
            conn.commit()

        return {"success": True, "photo_url": photo_url}
    except Exception as e:
        print(f"[ERREUR] Upload photo: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# R√©cup√©rer tous les projets d'un utilisateur
@app.get("/api/projects/{username}")
async def get_user_projects(username: str):
    """R√©cup√®re tous les projets d'un utilisateur"""
    try:
        projects = load_user_projects(username)
        return {"success": True, "projects": projects}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Cr√©er un nouveau projet
@app.post("/api/projects/{username}")
async def create_new_project(username: str, project_data: ProjectData):
    """Cr√©e un nouveau projet pour un utilisateur"""
    try:
        project = create_project(username, project_data.dict())
        return {"success": True, "project": project}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))




# Mettre √† jour un projet
@app.put("/api/projects/{username}/{project_id}")
async def update_existing_project(username: str, project_id: str, project_data: ProjectData):
    """Met √† jour un projet existant"""
    try:
        project = update_project(username, project_id, project_data.dict())
        if project:
            return {"success": True, "project": project}
        else:
            raise HTTPException(status_code=404, detail="Projet non trouv√©")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Supprimer un projet
@app.delete("/api/projects/{username}/{project_id}")
async def delete_user_project(username: str, project_id: str):
    """Supprime un projet"""
    try:
        success = delete_project(username, project_id)
        if success:
            return {"success": True, "message": "Projet supprim√©"}
        else:
            raise HTTPException(status_code=404, detail="Projet non trouv√©")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# R√©cup√©rer un projet sp√©cifique
@app.get("/api/projects/{username}/{project_id}")
async def get_specific_project(username: str, project_id: str):
    """R√©cup√®re un projet sp√©cifique"""
    try:
        project = get_project(username, project_id)
        if project:
            return {"success": True, "project": project}
        else:
            raise HTTPException(status_code=404, detail="Projet non trouv√©")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# R√©cup√©rer les param√®tres globaux
@app.get("/api/parameters")
async def get_parameters():
    """R√©cup√®re les param√®tres globaux"""
    try:
        params = load_global_parameters()
        return {"success": True, "parameters": params}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Sauvegarder les param√®tres globaux (direction seulement)
@app.post("/api/parameters")
async def save_parameters(params_data: ParametersData, username: str = Query(...)):
    """Sauvegarde les param√®tres globaux (direction seulement)"""
    try:
        # V√©rifier le r√¥le de l'utilisateur depuis la base de donn√©es
        user_info = get_user(username)
        if not user_info:
            raise HTTPException(status_code=401, detail="Utilisateur non trouv√©")
        
        # Ajouter le r√¥le "direction" √† l'admin
        if username == "admin":
            user_role = "direction"
        else:
            user_role = user_info.get("role", "entrepreneur")
        
        if not check_user_permission(username, user_role, "direction"):
            raise HTTPException(status_code=403, detail="Permission refus√©e. R√¥le direction requis.")
        
        save_global_parameters(params_data.parameters, username)
        return {"success": True, "message": "Param√®tres sauvegard√©s"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# R√©cup√©rer les informations d'un utilisateur
@app.get("/api/user/info/{username}")
async def get_user_info(username: str):
    """R√©cup√®re les informations d'un utilisateur (nom, pr√©nom, etc.)"""
    try:
        user_info = get_user(username)
        if not user_info:
            raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")

        return {
            "username": user_info.get("username"),
            "prenom": user_info.get("prenom", ""),
            "nom": user_info.get("nom", ""),
            "email": user_info.get("email", ""),
            "role": user_info.get("role", "")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# V√©rifier les permissions d'un utilisateur
@app.get("/api/user/{username}/permissions")
async def check_permissions(username: str):
    """V√©rifie les permissions d'un utilisateur"""
    try:
        user_info = get_user(username)
        if not user_info:
            raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")

        # Admin a automatiquement le r√¥le direction
        if username == "admin":
            role = "direction"
        else:
            role = user_info.get("role", "entrepreneur")

        return {
            "success": True,
            "username": username,
            "role": role,
            "canEditParameters": check_user_permission(username, role, "direction")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Endpoint de d√©bogage pour voir le contenu d'un projet
@app.get("/api/projects/{username}/{project_id}/debug")
async def debug_project(username: str, project_id: str):
    """Debug: affiche le contenu complet d'un projet"""
    try:
        project = get_project(username, project_id)
        if project:
            # Calculer la taille des donn√©es
            import json
            project_json = json.dumps(project)
            
            return {
                "success": True,
                "project_id": project_id,
                "data_size": len(project_json),
                "has_formData": "formData" in project,
                "formData_keys": list(project.get("formData", {}).keys()) if isinstance(project.get("formData"), dict) else [],
                "formData_size": len(json.dumps(project.get("formData", {}))) if project.get("formData") else 0,
                "project_preview": project
            }
        else:
            raise HTTPException(status_code=404, detail="Projet non trouv√©")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Routes pour la gestion des signatures
@app.post("/api/save-signature")
async def save_signature(
    username: str = Body(...),
    signatureData: str = Body(...)
):
    """Sauvegarde la signature d'un entrepreneur"""
    try:
        # Cr√©er le dossier de signature pour l'utilisateur
        user_signature_dir = f"{base_cloud}/signatures/{username}"
        os.makedirs(user_signature_dir, exist_ok=True)
        
        # D√©coder l'image base64
        header, encoded = signatureData.split(",", 1)
        signature_bytes = base64.b64decode(encoded)
        
        # Sauvegarder l'image blanche originale (√©craser l'ancienne)
        signature_filename = f"signature_{username}.png"
        signature_path = os.path.join(user_signature_dir, signature_filename)
        
        # Supprimer l'ancienne signature si elle existe
        if os.path.exists(signature_path):
            os.remove(signature_path)
        
        with open(signature_path, "wb") as f:
            f.write(signature_bytes)
        
        # Cr√©er la version noire pour le PDF
        from PIL import Image
        import io
        
        # Charger l'image depuis les bytes
        signature_image = Image.open(io.BytesIO(signature_bytes))
        
        # Convertir en RGBA si ce n'est pas d√©j√† le cas
        if signature_image.mode != 'RGBA':
            signature_image = signature_image.convert('RGBA')
        
        # Cr√©er une nouvelle image avec les pixels blancs convertis en noir
        signature_black = signature_image.copy()
        data = signature_black.getdata()
        
        new_data = []
        for item in data:
            # Si le pixel est blanc (ou proche du blanc), le convertir en noir
            # Sinon, le garder transparent
            if item[3] > 0:  # Si le pixel n'est pas transparent
                if item[0] > 200 and item[1] > 200 and item[2] > 200:  # Si c'est blanc/proche du blanc
                    new_data.append((0, 0, 0, item[3]))  # Noir avec m√™me transparence
                else:
                    new_data.append((0, 0, 0, item[3]))  # Convertir tout en noir
            else:
                new_data.append(item)  # Garder transparent
        
        signature_black.putdata(new_data)
        
        # Sauvegarder la version noire
        signature_black_filename = f"signature_{username}_black.png"
        signature_black_path = os.path.join(user_signature_dir, signature_black_filename)
        
        # Supprimer l'ancienne signature noire si elle existe
        if os.path.exists(signature_black_path):
            os.remove(signature_black_path)
        
        signature_black.save(signature_black_path, "PNG")
        
        # Ajouter timestamp pour √©viter le cache
        import time
        timestamp = int(time.time())
        
        return {
            "success": True, 
            "message": "Signature sauvegard√©e avec succ√®s",
            "signatureUrl": f"/cloud/signatures/{username}/{signature_filename}?v={timestamp}"
        }
    except Exception as e:
        print(f"Erreur sauvegarde signature: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/get-user-profile")
async def get_user_profile(request: Request, username: str):
    """R√©cup√®re les informations de profil de l'entrepreneur depuis user_info.json"""
    try:
        # Charger depuis user_info.json si existe
        user_info_path = f"{base_cloud}/signatures/{username}/user_info.json"

        if os.path.exists(user_info_path):
            with open(user_info_path, 'r', encoding='utf-8') as f:
                user_info = json.load(f)
                print(f"[DEBUG] Profil charg√© depuis user_info.json: {user_info}")
                return user_info

        # Sinon retourner vide (sera cr√©√© lors du premier save)
        print(f"[INFO] user_info.json n'existe pas encore pour {username}")
        return {
            "nom": "",
            "prenom": "",
            "telephone": "",
            "courriel": ""
        }
    except Exception as e:
        print(f"Erreur r√©cup√©ration profil utilisateur: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/save-user-info")
async def save_user_info(
    username: str = Body(...),
    nom: str = Body(default=""),
    prenom: str = Body(default=""),
    telephone: str = Body(default=""),
    courriel: str = Body(default=""),
    grade: str = Body(default=None),
    department: str = Body(default="")
):
    """Sauvegarde les informations de l'entrepreneur dans user_info.json"""
    try:
        # Cr√©er le dossier de signature pour l'utilisateur
        user_signature_dir = f"{base_cloud}/signatures/{username}"
        os.makedirs(user_signature_dir, exist_ok=True)

        # Cr√©er le fichier user_info.json
        user_info_path = os.path.join(user_signature_dir, "user_info.json")

        # Charger les donn√©es existantes pour pr√©server onboarding_completed et grade
        existing_info = {}
        if os.path.exists(user_info_path):
            try:
                with open(user_info_path, "r", encoding="utf-8") as f:
                    existing_info = json.load(f)
            except Exception as e:
                print(f"[WARN] Erreur chargement user_info.json existant: {e}")
                existing_info = {}

        # Mettre √† jour avec les nouvelles donn√©es
        user_info = {
            "nom": nom or existing_info.get("nom", ""),
            "prenom": prenom or existing_info.get("prenom", ""),
            "telephone": telephone or existing_info.get("telephone", ""),
            "courriel": courriel or existing_info.get("courriel", "")
        }

        # Ajouter le grade si fourni, sinon pr√©server l'existant
        if grade:
            user_info["grade"] = grade
        elif "grade" in existing_info:
            user_info["grade"] = existing_info["grade"]

        # IMPORTANT: Pr√©server les champs NEQ, TPS, TVQ s'ils existent
        if "neq" in existing_info:
            user_info["neq"] = existing_info["neq"]
        if "tps" in existing_info:
            user_info["tps"] = existing_info["tps"]
        if "tvq" in existing_info:
            user_info["tvq"] = existing_info["tvq"]

        # Ajouter le d√©partement si fourni, sinon pr√©server l'existant
        if department:
            user_info["department"] = department
        elif "department" in existing_info:
            user_info["department"] = existing_info["department"]

        # Pr√©server equipes et niveau_actuel s'ils existent
        if "equipes" in existing_info:
            user_info["equipes"] = existing_info["equipes"]
        if "niveau_actuel" in existing_info:
            user_info["niveau_actuel"] = existing_info["niveau_actuel"]
        if "last_updated" in existing_info:
            user_info["last_updated"] = existing_info["last_updated"]

        # IMPORTANT: Une fois onboarding_completed = true, il ne peut JAMAIS redevenir false
        if existing_info.get("onboarding_completed") == True:
            # D√©j√† compl√©t√©, on garde true peu importe ce qui est envoy√©
            user_info["onboarding_completed"] = True
            user_info["onboarding_date"] = existing_info.get("onboarding_date", "")
        else:
            # Pas encore compl√©t√©, pr√©server la valeur existante si elle existe
            if "onboarding_completed" in existing_info:
                user_info["onboarding_completed"] = existing_info["onboarding_completed"]
            if "onboarding_date" in existing_info:
                user_info["onboarding_date"] = existing_info["onboarding_date"]

        # Pr√©server guide_completed si existe
        if "guide_completed" in existing_info:
            user_info["guide_completed"] = existing_info["guide_completed"]
        if "guide_date" in existing_info:
            user_info["guide_date"] = existing_info["guide_date"]

        with open(user_info_path, "w", encoding="utf-8") as f:
            json.dump(user_info, f, ensure_ascii=False, indent=2)

        print(f"[OK] user_info.json sauvegard√© pour {username}: {user_info}")

        return {
            "success": True,
            "message": "Informations sauvegard√©es avec succ√®s"
        }
    except Exception as e:
        print(f"Erreur sauvegarde user_info: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/get-signature/{username}")
async def get_signature(username: str):
    """R√©cup√®re la signature d'un entrepreneur"""
    try:
        signature_filename = f"signature_{username}.png"
        signature_path = f"{base_cloud}/signatures/{username}/{signature_filename}"
        
        # V√©rifier si la signature existe
        if os.path.exists(signature_path):
            # Ajouter timestamp pour √©viter le cache
            import time
            timestamp = int(time.time())
            
            return {
                "success": True,
                "signatureUrl": f"/cloud/signatures/{username}/{signature_filename}?v={timestamp}"
            }
        else:
            return {
                "success": False,
                "message": "Aucune signature trouv√©e"
            }
    except Exception as e:
        print(f"Erreur r√©cup√©ration signature: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# Routes pour la gestion des photos de profil
@app.post("/api/save-profile-photo")
async def save_profile_photo(
    username: str = Body(...),
    photoData: str = Body(...)
):
    """Sauvegarde la photo de profil d'un utilisateur"""
    try:
        print(f"[DEBUG] [SAVE-PHOTO] D√©but sauvegarde photo pour {username}", flush=True)

        # Cr√©er le dossier de signature pour l'utilisateur (on utilise le m√™me dossier)
        user_signature_dir = os.path.join(base_cloud, "signatures", username)
        os.makedirs(user_signature_dir, exist_ok=True)
        print(f"[DEBUG] [SAVE-PHOTO] Dossier cr√©√©/v√©rifi√©: {user_signature_dir}", flush=True)

        # D√©coder l'image base64
        header, encoded = photoData.split(",", 1)
        photo_bytes = base64.b64decode(encoded)
        print(f"[DEBUG] [SAVE-PHOTO] Image d√©cod√©e, taille: {len(photo_bytes)} bytes", flush=True)

        # Sauvegarder l'image
        photo_filename = f"profile_photo_{username}.png"
        photo_path = os.path.join(user_signature_dir, photo_filename)

        # Supprimer l'ancienne photo si elle existe
        if os.path.exists(photo_path):
            os.remove(photo_path)
            print(f"[DEBUG] [SAVE-PHOTO] Ancienne photo supprim√©e", flush=True)

        with open(photo_path, "wb") as f:
            f.write(photo_bytes)

        print(f"[DEBUG] [SAVE-PHOTO] Photo sauvegard√©e: {photo_path}", flush=True)

        # Ajouter timestamp pour √©viter le cache
        import time
        timestamp = int(time.time())

        photo_url = f"/cloud/signatures/{username}/{photo_filename}?v={timestamp}"

        # Mettre √† jour la base de donn√©es avec la nouvelle photo URL
        try:
            with sqlite3.connect(DB_PATH) as conn:
                cursor = conn.cursor()
                # Stocker l'URL sans le timestamp pour pouvoir ajouter un nouveau timestamp √† chaque chargement
                photo_url_db = f"/cloud/signatures/{username}/{photo_filename}"
                cursor.execute("""
                    UPDATE users
                    SET photo_url = ?
                    WHERE username = ?
                """, (photo_url_db, username))
                conn.commit()
                print(f"[DEBUG] [SAVE-PHOTO] Base de donn√©es mise √† jour avec photo_url: {photo_url_db}", flush=True)
        except Exception as db_error:
            print(f"[WARN] [SAVE-PHOTO] Erreur mise √† jour DB (non bloquant): {db_error}", flush=True)

        print(f"[OK] Photo de profil sauvegard√©e pour {username}: {photo_url}", flush=True)

        return {
            "success": True,
            "message": "Photo de profil sauvegard√©e avec succ√®s",
            "photoUrl": photo_url
        }
    except Exception as e:
        print(f"[ERREUR] Erreur sauvegarde photo de profil: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/facturationqe/save-cheque-photos")
async def save_cheque_photos(
    username: str = Body(...),
    numeroSoumission: str = Body(...),
    typePaiement: str = Body(...),
    photoRecto: str = Body(None),
    photoVerso: str = Body(None)
):
    """Sauvegarde les photos recto/verso d'un ch√®que dans le cloud"""
    try:
        print(f"[DEBUG] [SAVE-CHEQUE] D√©but sauvegarde photos ch√®que pour {username}, soumission {numeroSoumission}, type {typePaiement}", flush=True)

        # Cr√©er le dossier pour les ch√®ques de l'utilisateur
        user_cheques_dir = os.path.join(base_cloud, "cheques", username)
        os.makedirs(user_cheques_dir, exist_ok=True)
        print(f"[DEBUG] [SAVE-CHEQUE] Dossier cr√©√©/v√©rifi√©: {user_cheques_dir}", flush=True)

        result_urls = {}

        # Sauvegarder photo recto si pr√©sente
        if photoRecto and photoRecto.startswith('data:image'):
            try:
                header, encoded = photoRecto.split(",", 1)
                photo_bytes = base64.b64decode(encoded)
                print(f"[DEBUG] [SAVE-CHEQUE] Photo recto d√©cod√©e, taille: {len(photo_bytes)} bytes", flush=True)

                # Format: cheque_<numeroSoumission>_<typePaiement>_recto.png
                photo_filename = f"cheque_{numeroSoumission}_{typePaiement}_recto.png"
                photo_path = os.path.join(user_cheques_dir, photo_filename)

                # Supprimer l'ancienne photo si elle existe
                if os.path.exists(photo_path):
                    os.remove(photo_path)
                    print(f"[DEBUG] [SAVE-CHEQUE] Ancienne photo recto supprim√©e", flush=True)

                with open(photo_path, "wb") as f:
                    f.write(photo_bytes)

                print(f"[DEBUG] [SAVE-CHEQUE] Photo recto sauvegard√©e: {photo_path}", flush=True)

                # Cr√©er l'URL avec timestamp pour √©viter le cache
                import time
                timestamp = int(time.time())
                result_urls['photoRecto'] = f"/cloud/cheques/{username}/{photo_filename}?v={timestamp}"

            except Exception as e:
                print(f"[ERREUR] [SAVE-CHEQUE] Erreur sauvegarde photo recto: {e}", flush=True)

        # Sauvegarder photo verso si pr√©sente
        if photoVerso and photoVerso.startswith('data:image'):
            try:
                header, encoded = photoVerso.split(",", 1)
                photo_bytes = base64.b64decode(encoded)
                print(f"[DEBUG] [SAVE-CHEQUE] Photo verso d√©cod√©e, taille: {len(photo_bytes)} bytes", flush=True)

                # Format: cheque_<numeroSoumission>_<typePaiement>_verso.png
                photo_filename = f"cheque_{numeroSoumission}_{typePaiement}_verso.png"
                photo_path = os.path.join(user_cheques_dir, photo_filename)

                # Supprimer l'ancienne photo si elle existe
                if os.path.exists(photo_path):
                    os.remove(photo_path)
                    print(f"[DEBUG] [SAVE-CHEQUE] Ancienne photo verso supprim√©e", flush=True)

                with open(photo_path, "wb") as f:
                    f.write(photo_bytes)

                print(f"[DEBUG] [SAVE-CHEQUE] Photo verso sauvegard√©e: {photo_path}", flush=True)

                # Cr√©er l'URL avec timestamp pour √©viter le cache
                import time
                timestamp = int(time.time())
                result_urls['photoVerso'] = f"/cloud/cheques/{username}/{photo_filename}?v={timestamp}"

            except Exception as e:
                print(f"[ERREUR] [SAVE-CHEQUE] Erreur sauvegarde photo verso: {e}", flush=True)

        print(f"[OK] Photos de ch√®que sauvegard√©es: {result_urls}", flush=True)

        return {
            "success": True,
            "message": "Photos du ch√®que sauvegard√©es avec succ√®s",
            "urls": result_urls
        }

    except Exception as e:
        print(f"[ERREUR] Erreur sauvegarde photos ch√®que: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/user/update-profile")
async def update_user_profile(request: Request):
    """Met √† jour le profil d'un utilisateur"""
    try:
        data = await request.json()
        username = data.get('username')
        first_name = data.get('first_name')
        last_name = data.get('last_name')

        if not username or not first_name or not last_name:
            raise HTTPException(status_code=400, detail="Missing required fields")

        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE users
                SET prenom = ?, nom = ?
                WHERE username = ?
            """, (first_name, last_name, username))
            conn.commit()

            if cursor.rowcount > 0:
                return {"success": True, "message": "Profile updated successfully"}
            else:
                raise HTTPException(status_code=404, detail="User not found")
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Error updating user profile: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


class ChangePasswordData(BaseModel):
    username: str
    current_password: str
    new_password: str


@app.post("/api/user/change-password")
async def change_user_password(data: ChangePasswordData):
    """Change le mot de passe d'un utilisateur (entrepreneur)"""
    try:
        # V√©rifier que l'utilisateur existe et que le mot de passe actuel est correct
        user_info = authenticate_user(data.username, data.current_password)

        if not user_info:
            raise HTTPException(status_code=401, detail="Mot de passe actuel incorrect")

        # Valider le nouveau mot de passe (minimum 6 caract√®res)
        if len(data.new_password) < 6:
            raise HTTPException(status_code=400, detail="Le nouveau mot de passe doit contenir au moins 6 caract√®res")

        # Mettre √† jour le mot de passe
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()

            # Hasher le nouveau mot de passe
            new_hash = hash_password(data.new_password)

            cursor.execute("""
                UPDATE users
                SET password_hash = ?, password_clear = ?
                WHERE username = ?
            """, (new_hash, data.new_password, data.username))

            conn.commit()

            if cursor.rowcount > 0:
                print(f"[OK] Mot de passe chang√© pour '{data.username}'")
                return {"success": True, "message": "Mot de passe chang√© avec succ√®s"}
            else:
                raise HTTPException(status_code=404, detail="Utilisateur non trouv√©")

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur changement mot de passe: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/get-profile-photo/{username}")
async def get_profile_photo(username: str):
    """R√©cup√®re la photo de profil d'un utilisateur"""
    try:
        # D'abord, chercher dans la base de donn√©es (pour tous les users: entrepreneurs, coaches, direction)
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT photo_url FROM users WHERE username = ?", (username,))
            result = cursor.fetchone()

            if result and result[0]:
                import time
                timestamp = int(time.time())
                photo_url = result[0]
                # Ajouter timestamp pour √©viter le cache
                if '?' in photo_url:
                    photo_url = f"{photo_url}&v={timestamp}"
                else:
                    photo_url = f"{photo_url}?v={timestamp}"

                print(f"[OK] Photo trouv√©e dans DB pour {username}: {photo_url}", flush=True)
                return {
                    "success": True,
                    "photoUrl": photo_url
                }

        # Fallback: chercher dans /cloud/signatures/ (ancien syst√®me)
        photo_filename = f"profile_photo_{username}.png"
        photo_path = os.path.join(base_cloud, "signatures", username, photo_filename)

        if os.path.exists(photo_path):
            import time
            timestamp = int(time.time())
            print(f"[OK] Photo trouv√©e dans signatures pour {username}", flush=True)
            return {
                "success": True,
                "photoUrl": f"/cloud/signatures/{username}/{photo_filename}?v={timestamp}"
            }

        print(f"[INFO] Aucune photo trouv√©e pour {username}", flush=True)
        return {
            "success": False,
            "message": "Aucune photo de profil trouv√©e"
        }
    except Exception as e:
        print(f"[ERREUR] Erreur r√©cup√©ration photo de profil: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/delete-profile-photo")
async def delete_profile_photo(username: str = Body(...)):
    """Supprime la photo de profil d'un utilisateur"""
    try:
        photo_filename = f"profile_photo_{username}.png"
        photo_path = os.path.join(base_cloud, "signatures", username, photo_filename)

        # Supprimer la photo si elle existe
        if os.path.exists(photo_path):
            os.remove(photo_path)
            print(f"[OK] Photo de profil supprim√©e pour {username}", flush=True)
            return {
                "success": True,
                "message": "Photo de profil supprim√©e avec succ√®s"
            }
        else:
            return {
                "success": False,
                "message": "Aucune photo de profil √† supprimer"
            }
    except Exception as e:
        print(f"[ERREUR] Erreur suppression photo de profil: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


# Endpoints pour photo mobile via QR code
@app.get('/mobile-camera')
async def mobile_camera():
    """Servir la page mobile de capture photo"""
    return FileResponse('QE/Frontend/Common/mobile-camera.html')


@app.post('/api/upload-mobile-photo')
async def upload_mobile_photo(
    session: str = Form(...),
    username: str = Form(...),
    photo: UploadFile = File(...)
):
    """Recevoir la photo depuis le mobile"""
    try:
        # Lire la photo et la convertir en base64
        photo_data = await photo.read()
        photo_base64 = f"data:image/jpeg;base64,{base64.b64encode(photo_data).decode()}"

        # Stocker temporairement
        mobile_photo_sessions[session] = {
            'photo': photo_base64,
            'timestamp': datetime.now(),
            'username': username
        }

        print(f"[OK] Photo mobile re√ßue pour session {session}", flush=True)

        # Notifier les clients en attente via SSE
        if session in mobile_photo_waiters:
            mobile_photo_waiters[session].set()

        return {"success": True}
    except Exception as e:
        print(f"[ERREUR] Erreur upload mobile photo: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get('/api/wait-mobile-photo/{session_id}')
async def wait_mobile_photo(session_id: str):
    """Attendre qu'une photo soit upload√©e via SSE"""
    async def event_generator():
        # Cr√©er un √©v√©nement pour ce session_id
        event = asyncio.Event()
        mobile_photo_waiters[session_id] = event

        print(f"[SSE] Client en attente pour session {session_id}", flush=True)

        try:
            # Attendre jusqu'√† 5 minutes ou jusqu'√† ce qu'une photo soit upload√©e
            await asyncio.wait_for(event.wait(), timeout=300)

            # Photo disponible!
            if session_id in mobile_photo_sessions:
                photo_data = mobile_photo_sessions[session_id]['photo']
                del mobile_photo_sessions[session_id]

                print(f"[OK] Photo envoy√©e au client pour session {session_id}", flush=True)
                yield f"data: {json.dumps({'photo': photo_data})}\n\n"

        except asyncio.TimeoutError:
            # Timeout apr√®s 5 minutes
            print(f"[TIMEOUT] Session {session_id} expir√©e", flush=True)
            yield f"data: {json.dumps({'photo': None})}\n\n"
        finally:
            # Nettoyer
            if session_id in mobile_photo_waiters:
                del mobile_photo_waiters[session_id]

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


# Endpoints pour le nouveau workflow des soumissions
@app.get("/soumissions_attente/{username}")
def get_soumissions_attente(username: str):
    """
    R√©cup√®re les soumissions en attente (cr√©√©es mais pas encore sign√©es)
    Ces soumissions sont dans soumissions_completes mais pas dans soumissions_signees NI dans travaux_a_completer
    """
    try:
        # Charger les soumissions completes
        fichier_completes = os.path.join(f"{base_cloud}/soumissions_completes", username, "soumissions.json")
        if not os.path.exists(fichier_completes):
            return []
        
        with open(fichier_completes, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            soumissions_completes = json.loads(content)
        
        # Charger les soumissions sign√©es
        fichier_signees = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
        soumissions_signees = []
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                content_signees = f.read().strip()
                if content_signees:
                    soumissions_signees = json.loads(content_signees)
        
        # Charger les travaux √† compl√©ter (soumissions d√©j√† sign√©es)
        fichier_travaux_ac = os.path.join(f"{base_cloud}/travaux_a_completer", username, "soumissions.json")
        travaux_a_completer = []
        if os.path.exists(fichier_travaux_ac):
            with open(fichier_travaux_ac, "r", encoding="utf-8") as f:
                content_travaux = f.read().strip()
                if content_travaux:
                    travaux_a_completer = json.loads(content_travaux)
        
        # Charger les travaux compl√©t√©s (soumissions termin√©es)
        fichier_travaux_completes = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
        travaux_completes = []
        if os.path.exists(fichier_travaux_completes):
            with open(fichier_travaux_completes, "r", encoding="utf-8") as f:
                content_completes = f.read().strip()
                if content_completes:
                    travaux_completes = json.loads(content_completes)
        
        # Identifier les IDs des soumissions d√©j√† sign√©es (utiliser uniquement l'ID, pas le num)
        ids_signees = {s.get("id", "") for s in soumissions_signees if s.get("id")}
        ids_travaux_ac = {t.get("id", "") for t in travaux_a_completer if t.get("id")}
        ids_travaux_completes = {t.get("id", "") for t in travaux_completes if t.get("id")}
        ids_deja_signees = ids_signees.union(ids_travaux_ac).union(ids_travaux_completes)
        
        print(f"[DEBUG soumissions_attente] {username}:")
        print(f"  - IDs sign√©es: {list(ids_signees)}")
        print(f"  - IDs travaux AC: {list(ids_travaux_ac)}")
        print(f"  - IDs travaux completes: {list(ids_travaux_completes)}")
        print(f"  - Total IDs √† exclure: {list(ids_deja_signees)}")
        
        # Filtrer les soumissions en attente (non sign√©es) - comparer avec les IDs uniquement
        soumissions_attente = []
        ids_completes = []
        for soumission in soumissions_completes:
            # L'ID de r√©f√©rence pour les soumissions completes est leur ID uniquement (UUID)
            soumission_id = soumission.get("id", "")
            ids_completes.append(soumission_id)
            # Exclure si d√©j√† sign√©e OU d√©j√† dans travaux √† compl√©ter (comparer avec l'ID uniquement)
            if soumission_id and soumission_id not in ids_deja_signees:
                print(f"  - ID {soumission_id} GARDE (en attente)")
                soumissions_attente.append({
                    "id": soumission_id,
                    "clientPrenom": soumission.get("prenom", ""),
                    "clientNom": soumission.get("nom", ""),
                    "adresse": soumission.get("adresse", ""),
                    "telephone": soumission.get("telephone", ""),
                    "prix": soumission.get("prix", ""),
                    "courriel": soumission.get("courriel", ""),
                    "pdfUrl": soumission.get("pdf_url", "#")
                })
            else:
                print(f"  - ID {soumission_id} EXCLU (d√©j√† sign√©e/en cours/termin√©e)")
        
        print(f"  - IDs dans soumissions_completes: {ids_completes}")
        print(f"[DEBUG] Comparaison: IDs compl√®tes vs IDs √† exclure")
        
        print(f"[soumissions_attente] {username}: {len(soumissions_attente)} en attente sur {len(soumissions_completes)} completes (exclus: {len(ids_deja_signees)} sign√©es/en cours/termin√©es)")
        return soumissions_attente

    except Exception as e:
        print(f"[ERREUR soumissions_attente] {e}")
        return []


@app.post("/marquer-comme-perdu")
async def marquer_comme_perdu(data: dict = Body(...)):
    """
    Marque un client en attente comme perdu et le d√©place vers clients_perdus
    """
    try:
        username = data.get("username")
        client_id = data.get("id")

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        print(f"[ERROR] Marquage comme perdu pour {username}, ID: {client_id}")

        # Dossiers
        attente_dir = f"{base_cloud}/ventes_attente/{username}"
        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        os.makedirs(perdus_dir, exist_ok=True)

        attente_file = os.path.join(attente_dir, "ventes.json")
        perdus_file = os.path.join(perdus_dir, "clients.json")

        # Charger les ventes en attente
        if not os.path.exists(attente_file):
            raise HTTPException(status_code=404, detail="Aucune vente en attente")

        with open(attente_file, "r", encoding="utf-8") as f:
            ventes_attente = json.load(f)

        # Trouver le client √† marquer comme perdu par ID
        client_trouve = None
        ventes_attente_updated = []

        for vente in ventes_attente:
            if vente.get("id") == client_id:
                client_trouve = vente
            else:
                ventes_attente_updated.append(vente)

        if not client_trouve:
            raise HTTPException(status_code=404, detail="Client introuvable")

        # Sauvegarder la liste mise √† jour (sans le client perdu)
        with open(attente_file, "w", encoding="utf-8") as f:
            json.dump(ventes_attente_updated, f, ensure_ascii=False, indent=2)

        # Ajouter le client dans clients_perdus avec date de marquage
        clients_perdus = []
        if os.path.exists(perdus_file):
            with open(perdus_file, "r", encoding="utf-8") as f:
                clients_perdus = json.load(f)

        client_trouve["date_perdu"] = datetime.now().isoformat()
        client_trouve["statut"] = "perdu"
        clients_perdus.append(client_trouve)

        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus, f, ensure_ascii=False, indent=2)

        # Supprimer le PDF de ventes_attente
        pdf_filename = client_trouve.get("pdf_url", "").split("/")[-1]
        if pdf_filename:
            pdf_path = os.path.join(attente_dir, pdf_filename)
            if os.path.exists(pdf_path):
                os.remove(pdf_path)

        client_nom = f"{client_trouve.get('prenom', '')} {client_trouve.get('nom', '')}".strip()
        print(f"[OK] Client {client_nom} marqu√© comme perdu")

        # Retirer le client de soumissions_signees pour mettre √† jour le RPO
        try:
            soumissions_signees_file = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
            if os.path.exists(soumissions_signees_file):
                with open(soumissions_signees_file, "r", encoding="utf-8") as f:
                    soumissions_signees = json.load(f)

                # Filtrer pour retirer ce client (par num, id, ou nom+prenom+telephone)
                client_num = client_trouve.get('num')
                client_id = client_trouve.get('id')
                client_tel = client_trouve.get('telephone', '')

                signees_filtered = []
                for soum in soumissions_signees:
                    # V√©rifier si c'est le m√™me client - UNIQUEMENT par num ou id (jamais par nom/prenom)
                    is_same = False
                    if client_num and soum.get('num') == client_num:
                        is_same = True
                    elif client_id and soum.get('id') == client_id:
                        is_same = True

                    if not is_same:
                        signees_filtered.append(soum)
                    else:
                        print(f"[SOUM SIGNEES] Client retir√©: {soum.get('prenom')} {soum.get('nom')} ({soum.get('num')})")

                # Sauvegarder la liste filtr√©e
                with open(soumissions_signees_file, "w", encoding="utf-8") as f:
                    json.dump(signees_filtered, f, ensure_ascii=False, indent=2)
                print(f"[OK] Client retir√© de soumissions_signees")
        except Exception as e:
            print(f"[WARNING] Erreur retrait soumissions_signees: {e}")

        # Re-synchroniser le RPO pour mettre √† jour les statistiques
        try:
            from QE.Backend.rpo import sync_ventes_produit_to_rpo, sync_soumissions_to_rpo
            sync_result_produit = sync_ventes_produit_to_rpo(username)
            sync_result_soum = sync_soumissions_to_rpo(username)
            print(f"[RPO SYNC] RPO synchronis√© apr√®s client perdu")
        except Exception as e:
            print(f"[RPO SYNC WARNING] Impossible de synchroniser le RPO: {e}")

        return {"success": True, "message": f"{client_nom} marqu√© comme perdu"}

    except Exception as e:
        print(f"[ERROR] Erreur marquer comme perdu: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/annuler-client-accepte")
async def annuler_client_accepte(data: dict = Body(...)):
    """
    Annule un client accept√© et le d√©place vers clients_perdus
    """
    try:
        username = data.get("username")
        client_id = data.get("id")

        if not username or not client_id:
            raise HTTPException(status_code=400, detail="Username et ID requis")

        print(f"[ANNULATION] Annulation client accept√© pour {username}, ID: {client_id}")

        # Dossiers
        acceptees_dir = f"{base_cloud}/ventes_acceptees/{username}"
        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        os.makedirs(perdus_dir, exist_ok=True)

        acceptees_file = os.path.join(acceptees_dir, "ventes.json")
        perdus_file = os.path.join(perdus_dir, "clients.json")

        if not os.path.exists(acceptees_file):
            raise HTTPException(status_code=404, detail="Aucune vente accept√©e trouv√©e")

        # Charger les ventes accept√©es
        with open(acceptees_file, "r", encoding="utf-8") as f:
            ventes_acceptees = json.load(f)

        # Trouver le client √† annuler
        client_trouve = None
        ventes_acceptees_updated = []
        for vente in ventes_acceptees:
            # Comparer par ID direct (UUID) ou par prenom_nom_telephone
            vente_uuid = vente.get('id', '')
            vente_composite_id = f"{vente.get('prenom', '')}_{vente.get('nom', '')}_{vente.get('telephone', '')}"
            if vente_uuid == client_id or vente_composite_id == client_id:
                client_trouve = vente
            else:
                ventes_acceptees_updated.append(vente)

        if not client_trouve:
            raise HTTPException(status_code=404, detail="Client non trouv√© dans les ventes accept√©es")

        client_nom = f"{client_trouve.get('prenom', '')} {client_trouve.get('nom', '')}"

        # Sauvegarder la liste mise √† jour (sans le client annul√©)
        with open(acceptees_file, "w", encoding="utf-8") as f:
            json.dump(ventes_acceptees_updated, f, ensure_ascii=False, indent=2)

        # Ajouter le client dans clients_perdus avec date d'annulation
        clients_perdus = []
        if os.path.exists(perdus_file):
            with open(perdus_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    clients_perdus = json.loads(content)

        client_trouve["date_perdu"] = datetime.now().isoformat()
        client_trouve["statut"] = "perdu"
        client_trouve["raison"] = "annulation"
        clients_perdus.append(client_trouve)

        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus, f, ensure_ascii=False, indent=2)

        print(f"[OK] Client {client_nom} annul√© et d√©plac√© vers clients perdus")

        # Retirer le client de soumissions_signees pour mettre √† jour le RPO
        try:
            soumissions_signees_file = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
            if os.path.exists(soumissions_signees_file):
                with open(soumissions_signees_file, "r", encoding="utf-8") as f:
                    soumissions_signees = json.load(f)

                client_num = client_trouve.get('num')
                client_id_val = client_trouve.get('id')

                signees_filtered = []
                for soum in soumissions_signees:
                    # UNIQUEMENT par num ou id (jamais par nom/prenom)
                    is_same = False
                    if client_num and soum.get('num') == client_num:
                        is_same = True
                    elif client_id_val and soum.get('id') == client_id_val:
                        is_same = True

                    if not is_same:
                        signees_filtered.append(soum)
                    else:
                        print(f"[SOUM SIGNEES] Client retir√©: {soum.get('prenom')} {soum.get('nom')} ({soum.get('num')})")

                with open(soumissions_signees_file, "w", encoding="utf-8") as f:
                    json.dump(signees_filtered, f, ensure_ascii=False, indent=2)
                print(f"[OK] Client retir√© de soumissions_signees")
        except Exception as e:
            print(f"[WARNING] Erreur retrait soumissions_signees: {e}")

        # Re-synchroniser le RPO pour mettre √† jour les statistiques
        try:
            from QE.Backend.rpo import sync_ventes_produit_to_rpo, sync_soumissions_to_rpo
            sync_result_produit = sync_ventes_produit_to_rpo(username)
            sync_result_soum = sync_soumissions_to_rpo(username)
            print(f"[RPO SYNC] RPO synchronis√© apr√®s client perdu")
        except Exception as e:
            print(f"[RPO SYNC WARNING] Impossible de synchroniser le RPO: {e}")

        return {"success": True, "message": f"{client_nom} annul√© et d√©plac√© vers clients perdus"}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur annuler client accept√©: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/marquer-perdu")
async def marquer_vente_perdue(data: dict = Body(...)):
    """
    Marque un client comme perdu depuis n'importe quelle cat√©gorie (attente, acceptees, produit)
    et le d√©place vers clients_perdus
    """
    try:
        username = data.get("username")
        vente_id = data.get("vente_id")

        if not username or not vente_id:
            raise HTTPException(status_code=400, detail="Username et vente_id requis")

        print(f"[VENTES] Marquage comme perdu pour {username}, ID: {vente_id}")

        # Cr√©er le dossier clients_perdus
        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        os.makedirs(perdus_dir, exist_ok=True)
        perdus_file = os.path.join(perdus_dir, "clients.json")

        # Essayer de trouver le client dans les 3 cat√©gories possibles
        categories = [
            ("attente", "ventes_attente"),
            ("acceptees", "ventes_acceptees"),
            ("produit", "ventes_produit")
        ]

        client_trouve = None
        category_source = None

        for category_name, folder_name in categories:
            category_dir = f"{base_cloud}/{folder_name}/{username}"
            category_file = os.path.join(category_dir, "ventes.json")

            if os.path.exists(category_file):
                with open(category_file, "r", encoding="utf-8") as f:
                    ventes = json.load(f)

                # Chercher le client par ID ou num
                for i, vente in enumerate(ventes):
                    if vente.get("id") == vente_id or vente.get("num") == vente_id:
                        client_trouve = vente
                        category_source = (category_name, folder_name, category_file, ventes, i)
                        break

            if client_trouve:
                break

        if not client_trouve:
            raise HTTPException(status_code=404, detail="Client introuvable dans aucune cat√©gorie")

        # Retirer le client de sa cat√©gorie d'origine
        category_name, folder_name, category_file, ventes, index = category_source
        ventes.pop(index)

        # Sauvegarder la liste mise √† jour
        with open(category_file, "w", encoding="utf-8") as f:
            json.dump(ventes, f, ensure_ascii=False, indent=2)

        # Charger les clients perdus existants
        clients_perdus = []
        if os.path.exists(perdus_file):
            with open(perdus_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    clients_perdus = json.loads(content)

        # Ajouter le client dans clients_perdus avec date de marquage
        client_trouve["date_perdu"] = datetime.now().isoformat()
        client_trouve["statut"] = "perdu"
        client_trouve["category_origine"] = category_name
        clients_perdus.append(client_trouve)

        # Sauvegarder les clients perdus
        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus, f, ensure_ascii=False, indent=2)

        client_nom = f"{client_trouve.get('prenom', client_trouve.get('clientPrenom', ''))} {client_trouve.get('nom', client_trouve.get('clientNom', ''))}".strip()
        print(f"[OK] Client {client_nom} marqu√© comme perdu depuis {category_name}")

        # Retirer le client de soumissions_signees pour mettre √† jour le RPO
        try:
            soumissions_signees_file = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
            if os.path.exists(soumissions_signees_file):
                with open(soumissions_signees_file, "r", encoding="utf-8") as f:
                    soumissions_signees = json.load(f)

                client_num = client_trouve.get('num')
                client_id_val = client_trouve.get('id')

                signees_filtered = []
                for soum in soumissions_signees:
                    # UNIQUEMENT par num ou id (jamais par nom/prenom)
                    is_same = False
                    if client_num and soum.get('num') == client_num:
                        is_same = True
                    elif client_id_val and soum.get('id') == client_id_val:
                        is_same = True

                    if not is_same:
                        signees_filtered.append(soum)
                    else:
                        print(f"[SOUM SIGNEES] Client retir√©: {soum.get('prenom')} {soum.get('nom')} ({soum.get('num')})")

                with open(soumissions_signees_file, "w", encoding="utf-8") as f:
                    json.dump(signees_filtered, f, ensure_ascii=False, indent=2)
                print(f"[OK] Client retir√© de soumissions_signees")
        except Exception as e:
            print(f"[WARNING] Erreur retrait soumissions_signees: {e}")

        # Nettoyer aussi facturation_qe_statuts pour √©viter les notifications orphelines
        try:
            client_num = client_trouve.get('num') or client_trouve.get('numSoumission')
            if client_num:
                statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
                if os.path.exists(statuts_file):
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    if client_num in statuts:
                        del statuts[client_num]
                        with open(statuts_file, "w", encoding="utf-8") as f:
                            json.dump(statuts, f, ensure_ascii=False, indent=2)
                        print(f"[OK] Client {client_num} retir√© de facturation_qe_statuts")
        except Exception as e:
            print(f"[WARNING] Erreur retrait facturation_qe_statuts: {e}")

        # Re-synchroniser le RPO pour mettre √† jour les statistiques
        try:
            from QE.Backend.rpo import sync_ventes_produit_to_rpo, sync_soumissions_to_rpo
            sync_result_produit = sync_ventes_produit_to_rpo(username)
            sync_result_soum = sync_soumissions_to_rpo(username)
            print(f"[RPO SYNC] RPO synchronis√© apr√®s client perdu")
        except Exception as e:
            print(f"[RPO SYNC WARNING] Impossible de synchroniser le RPO: {e}")

        return {"success": True, "message": f"{client_nom} marqu√© comme perdu", "category": category_name}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur marquer comme perdu: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/clients-perdus/{username}")
async def get_clients_perdus(username: str):
    """
    R√©cup√®re la liste de tous les clients marqu√©s comme perdus pour un utilisateur
    """
    try:
        print(f"[BAN] R√©cup√©ration des clients perdus pour {username}")

        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        perdus_file = os.path.join(perdus_dir, "clients.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(perdus_file):
            os.makedirs(perdus_dir, exist_ok=True)
            with open(perdus_file, "w", encoding="utf-8") as f:
                json.dump([], f)
            print(f"[BAN] Dossier clients perdus cr√©√© pour {username}")
            return []

        # Charger et retourner les clients perdus
        with open(perdus_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            clients_perdus = json.loads(content)

        print(f"[OK] {len(clients_perdus)} clients perdus trouv√©s pour {username}")
        return clients_perdus

    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration clients perdus: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/retirer-client-perdu")
async def retirer_client_perdu(data: dict = Body(...)):
    """
    Retire un client de la liste des clients perdus quand il est r√©cup√©r√©
    """
    try:
        username = data.get("username")
        client_id = data.get("clientOriginalId")

        if not username or not client_id:
            raise HTTPException(status_code=400, detail="Username et clientOriginalId requis")

        print(f"[PROCESSING] Retrait client perdu: {client_id} pour {username}")

        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        perdus_file = os.path.join(perdus_dir, "clients.json")

        if not os.path.exists(perdus_file):
            return {"success": True, "message": "Aucun client perdu √† retirer"}

        # Charger les clients perdus
        with open(perdus_file, "r", encoding="utf-8") as f:
            clients_perdus = json.load(f)

        # Trouver et retirer le client (supporter UUID, num, ou format composite prenom_nom_telephone)
        clients_perdus_updated = []
        client_retire = None
        for client in clients_perdus:
            # V√©rifier par UUID
            if client.get('id') == client_id:
                client_retire = client
                continue
            # V√©rifier par num√©ro de soumission
            if client.get('num') == client_id:
                client_retire = client
                continue
            # V√©rifier par format composite
            current_id = f"{client.get('prenom', '')}_{client.get('nom', '')}_{client.get('telephone', '')}"
            if current_id == client_id:
                client_retire = client
                continue
            # Si aucun match, garder le client
            clients_perdus_updated.append(client)

        # Sauvegarder la liste mise √† jour
        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus_updated, f, ensure_ascii=False, indent=2)

        if client_retire:
            print(f"[OK] Client {client_id} retir√© de la liste des perdus")
            return {"success": True, "message": "Client retir√© des perdus", "client": client_retire}
        else:
            print(f"[WARNING] Client {client_id} non trouv√© dans les perdus")
            return {"success": True, "message": "Client non trouv√©"}

    except Exception as e:
        print(f"[ERROR] Erreur retrait client perdu: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/supprimer-client-perdu")
async def supprimer_client_perdu(data: dict = Body(...)):
    """
    Supprime d√©finitivement un client de la liste des clients perdus
    """
    try:
        username = data.get("username")
        prenom = data.get("prenom")
        nom = data.get("nom")
        telephone = data.get("telephone")

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        print(f"[DELETE] Suppression client perdu: {prenom} {nom} pour {username}")

        perdus_dir = f"{base_cloud}/clients_perdus/{username}"
        perdus_file = os.path.join(perdus_dir, "clients.json")

        if not os.path.exists(perdus_file):
            return {"success": True, "message": "Aucun client perdu √† supprimer"}

        # Charger les clients perdus
        with open(perdus_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                clients_perdus = []
            else:
                clients_perdus = json.loads(content)

        # Filtrer pour retirer le client √† supprimer
        clients_perdus_updated = []
        client_supprime = None
        for client in clients_perdus:
            # Comparer par nom, pr√©nom et t√©l√©phone (supporter les deux formats)
            client_prenom = client.get('prenom') or client.get('clientPrenom', '')
            client_nom = client.get('nom') or client.get('clientNom', '')
            client_tel = client.get('telephone', '')

            if not (client_prenom == prenom and
                   client_nom == nom and
                   client_tel == telephone):
                clients_perdus_updated.append(client)
            else:
                client_supprime = client

        # Sauvegarder la liste mise √† jour
        with open(perdus_file, "w", encoding="utf-8") as f:
            json.dump(clients_perdus_updated, f, ensure_ascii=False, indent=2)

        if client_supprime:
            # AUSSI SUPPRIMER DE SOUMISSIONS_COMPLETES si le client y √©tait
            num_soumission = client_supprime.get("num")
            client_id = client_supprime.get("id")

            if num_soumission or client_id:
                soumissions_file = os.path.join(base_cloud, "soumissions_completes", username, "soumissions.json")
                if os.path.exists(soumissions_file):
                    try:
                        with open(soumissions_file, "r", encoding="utf-8") as f:
                            content = f.read().strip()
                            soumissions = json.loads(content) if content else []

                        # Filtrer pour retirer la soumission correspondante
                        soumissions_updated = [
                            s for s in soumissions
                            if not (s.get("num") == num_soumission or s.get("id") == client_id)
                        ]

                        if len(soumissions_updated) < len(soumissions):
                            with open(soumissions_file, "w", encoding="utf-8") as f:
                                json.dump(soumissions_updated, f, ensure_ascii=False, indent=2)
                            print(f"[OK] Soumission {num_soumission or client_id} aussi supprim√©e de soumissions_completes")

                            # Sync RPO pour mettre √† jour estimation_reel
                            try:
                                from QE.Backend.rpo import sync_soumissions_to_rpo
                                sync_soumissions_to_rpo(username)
                                print(f"[OK] RPO synchronis√© apr√®s suppression")
                            except Exception as e:
                                print(f"[WARNING] Erreur sync RPO: {e}")
                    except Exception as e:
                        print(f"[WARNING] Erreur suppression soumission: {e}")

            print(f"[OK] Client {prenom} {nom} supprim√© d√©finitivement de la liste des perdus")
            return {"success": True, "message": "Client supprim√© d√©finitivement"}
        else:
            print(f"[WARNING] Client {prenom} {nom} non trouv√© dans les perdus")
            return {"success": True, "message": "Client non trouv√©"}

    except Exception as e:
        print(f"[ERROR] Erreur suppression client perdu: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/supprimer-prospect")
async def supprimer_prospect_post(data: dict = Body(...)):
    """
    Supprime d√©finitivement un prospect de la liste des prospects
    """
    try:
        username = data.get("username")
        prenom = data.get("prenom")
        nom = data.get("nom")
        telephone = data.get("telephone")

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        print(f"[DELETE] Suppression prospect: {prenom} {nom} pour {username}")

        prospects_dir = f"{base_cloud}/prospects/{username}"
        prospects_file = os.path.join(prospects_dir, "prospects.json")

        if not os.path.exists(prospects_file):
            return {"success": True, "message": "Aucun prospect √† supprimer"}

        # Charger les prospects
        with open(prospects_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                prospects = []
            else:
                prospects = json.loads(content)

        # Filtrer pour retirer le prospect √† supprimer
        prospects_updated = []
        prospect_supprime = None
        for prospect in prospects:
            # Comparer par nom, pr√©nom et t√©l√©phone
            if not (prospect.get('prenom') == prenom and
                   prospect.get('nom') == nom and
                   prospect.get('telephone') == telephone):
                prospects_updated.append(prospect)
            else:
                prospect_supprime = prospect

        # Sauvegarder la liste mise √† jour
        with open(prospects_file, "w", encoding="utf-8") as f:
            json.dump(prospects_updated, f, ensure_ascii=False, indent=2)

        if prospect_supprime:
            print(f"[OK] Prospect {prenom} {nom} supprim√© d√©finitivement")
            return {"success": True, "message": "Prospect supprim√© d√©finitivement"}
        else:
            print(f"[WARNING] Prospect {prenom} {nom} non trouv√©")
            return {"success": True, "message": "Prospect non trouv√©"}

    except Exception as e:
        print(f"[ERROR] Erreur suppression prospect: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def sync_soumissions_signees_to_facturation_qe(username: str):
    """
    Synchronise les soumissions sign√©es vers le dossier facturation QE
    Enrichit avec le num√©ro de soumission original depuis soumissions_completes
    """
    try:
        source_dir = f"{base_cloud}/soumissions_signees/{username}"
        target_dir = f"{base_cloud}/soumission_signee_facturation_qe/{username}"
        completes_dir = f"{base_cloud}/soumissions_completes/{username}"
        
        # Cr√©er le dossier cible s'il n'existe pas
        os.makedirs(target_dir, exist_ok=True)
        
        source_file = os.path.join(source_dir, "soumissions.json")
        target_file = os.path.join(target_dir, "soumissions.json")
        completes_file = os.path.join(completes_dir, "soumissions.json")
        
        if not os.path.exists(source_file):
            # Cr√©er un fichier vide si n√©cessaire
            with open(target_file, "w", encoding="utf-8") as f:
                json.dump([], f)
            print(f"Fichier vide cree: {target_file}")
            return
            
        # Charger les soumissions sign√©es
        with open(source_file, "r", encoding="utf-8") as f:
            soumissions_signees = json.load(f)
        
        # Charger les soumissions compl√®tes pour r√©cup√©rer les num√©ros originaux
        soumissions_completes = {}
        if os.path.exists(completes_file):
            with open(completes_file, "r", encoding="utf-8") as f:
                completes_data = json.load(f)
                # Cr√©er un dictionnaire par ID pour lookup rapide
                for soumission in completes_data:
                    soumissions_completes[soumission.get("id", "")] = soumission
        
        # Enrichir les soumissions sign√©es avec les num√©ros originaux
        soumissions_enrichies = []
        for soumission in soumissions_signees:
            soumission_enrichie = soumission.copy()
            original_id = soumission.get("original_id") or soumission.get("id")
            
            if original_id and original_id in soumissions_completes:
                soumission_complete = soumissions_completes[original_id]
                # Ajouter le num√©ro de soumission original
                soumission_enrichie["numSoumission"] = soumission_complete.get("num", "")
                print(f"Enrichi {original_id} avec numSoumission: {soumission_complete.get('num', '')}")
            else:
                # Fallback: utiliser l'UUID tronqu√© comme num√©ro
                soumission_enrichie["numSoumission"] = (soumission.get("num", ""))[:8]
            
            soumissions_enrichies.append(soumission_enrichie)
        
        # Sauvegarder le fichier enrichi
        with open(target_file, "w", encoding="utf-8") as f:
            json.dump(soumissions_enrichies, f, indent=2, ensure_ascii=False)
            
        print(f"Synchronisation reussie avec enrichissement: {len(soumissions_enrichies)} soumissions")

    except Exception as e:
        print(f"Erreur lors de la synchronisation pour {username}: {e}")

def sync_travaux_complete_to_facturation_qe(username: str):
    """
    Synchronise les travaux complets vers le dossier facturation QE
    Enrichit avec le num√©ro de soumission original depuis soumissions_completes
    """
    try:
        source_dir = f"{base_cloud}/travaux_complete/{username}"
        target_dir = f"{base_cloud}/soumission_signee_facturation_qe/{username}"
        completes_dir = f"{base_cloud}/soumissions_completes/{username}"

        # Cr√©er le dossier cible s'il n'existe pas
        os.makedirs(target_dir, exist_ok=True)

        source_file = os.path.join(source_dir, "soumissions.json")
        target_file = os.path.join(target_dir, "soumissions.json")
        completes_file = os.path.join(completes_dir, "soumissions.json")

        if not os.path.exists(source_file):
            # Cr√©er un fichier vide si n√©cessaire
            with open(target_file, "w", encoding="utf-8") as f:
                json.dump([], f)
            print(f"Fichier vide cree: {target_file}")
            return

        # Charger les travaux complets
        with open(source_file, "r", encoding="utf-8") as f:
            travaux_complets = json.load(f)

        # Charger les soumissions compl√®tes pour r√©cup√©rer les num√©ros originaux
        soumissions_completes = {}
        if os.path.exists(completes_file):
            with open(completes_file, "r", encoding="utf-8") as f:
                completes_data = json.load(f)
                # Cr√©er un dictionnaire par ID pour lookup rapide
                for soumission in completes_data:
                    soumissions_completes[soumission.get("id", "")] = soumission

        # Enrichir les travaux complets avec les num√©ros originaux
        soumissions_enrichies = []
        for soumission in travaux_complets:
            soumission_enrichie = soumission.copy()
            original_id = soumission.get("original_id") or soumission.get("id")

            if original_id and original_id in soumissions_completes:
                soumission_complete = soumissions_completes[original_id]
                # Ajouter le num√©ro de soumission original
                soumission_enrichie["numSoumission"] = soumission_complete.get("num", "")
                print(f"Enrichi {original_id} avec numSoumission: {soumission_complete.get('num', '')}")
            else:
                # Fallback: utiliser l'UUID tronqu√© comme num√©ro
                soumission_enrichie["numSoumission"] = (soumission.get("num", ""))[:8]

            soumissions_enrichies.append(soumission_enrichie)

        # Sauvegarder le fichier enrichi
        with open(target_file, "w", encoding="utf-8") as f:
            json.dump(soumissions_enrichies, f, indent=2, ensure_ascii=False)

        print(f"Synchronisation travaux_complete vers facturation_qe reussie: {len(soumissions_enrichies)} soumissions")

    except Exception as e:
        print(f"Erreur lors de la synchronisation travaux_complete pour {username}: {e}")

@app.get("/soumissions_signees_facturation_qe/{username}")
def get_soumissions_signees_facturation_qe(username: str):
    """
    Endpoint sp√©cifique pour la facturation QE avec gestion des bannissements
    Lit directement depuis soumissions_signees (historique de tous les clients qui ont sign√©)

    Si username est un coach, agr√®ge les soumissions de tous ses entrepreneurs
    """
    try:
        # V√©rifier si c'est un coach
        from QE.Backend.coach_access import get_entrepreneurs_for_coach
        import sqlite3

        is_coach = False
        try:
            db_path = os.path.join(base_cloud, "qwota.db")
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT role FROM users WHERE username = ?", (username,))
            role_row = cursor.fetchone()
            conn.close()

            if role_row and role_row[0] == 'coach':
                is_coach = True
                print(f"[soumissions_signees_facturation_qe] {username} est un COACH")
        except Exception as e:
            print(f"[soumissions_signees_facturation_qe] Erreur v√©rification r√¥le: {e}")

        all_soumissions = []

        # Si c'est un coach, charger les soumissions de tous ses entrepreneurs
        if is_coach:
            entrepreneur_data = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            entrepreneurs = [e["username"] for e in entrepreneur_data]
            print(f"[soumissions_signees_facturation_qe] Coach {username} a {len(entrepreneurs)} entrepreneurs: {entrepreneurs}")

            for entrepreneur in entrepreneurs:
                # 1. Charger les soumissions sign√©es de cet entrepreneur
                fichier_signees = f"{base_cloud}/soumissions_signees/{entrepreneur}/soumissions.json"

                if not os.path.exists(fichier_signees):
                    continue

                with open(fichier_signees, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if not content:
                        continue
                    soumissions = json.loads(content)

                # 2. Charger la blacklist sp√©cifique √† la facturation QE de cet entrepreneur
                blacklist_file = f"{base_cloud}/blacklist/{entrepreneur}_facturation_qe.json"
                blacklisted_clients = []
                if os.path.exists(blacklist_file):
                    with open(blacklist_file, "r", encoding="utf-8") as f:
                        blacklisted_clients = json.load(f)

                # 3. Filtrer les clients bannis
                blacklisted_emails = {client.get("email", "").lower() for client in blacklisted_clients}

                for soumission in soumissions:
                    client_email = soumission.get("email", "").lower()
                    if client_email not in blacklisted_emails:
                        # Ajouter le username de l'entrepreneur pour tra√ßabilit√©
                        soumission['entrepreneur_username'] = entrepreneur
                        all_soumissions.append(soumission)

            print(f"[soumissions_signees_facturation_qe] Coach {username}: {len(all_soumissions)} soumissions au total")
            return all_soumissions

        else:
            # Entrepreneur - comportement normal
            # 1. Charger les soumissions sign√©es (historique permanent)
            fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"

            if not os.path.exists(fichier_signees):
                return []

            with open(fichier_signees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    return []
                soumissions = json.loads(content)

            # 2. Charger la blacklist sp√©cifique √† la facturation QE
            blacklist_file = f"{base_cloud}/blacklist/{username}_facturation_qe.json"
            blacklisted_clients = []
            if os.path.exists(blacklist_file):
                with open(blacklist_file, "r", encoding="utf-8") as f:
                    blacklisted_clients = json.load(f)

            # 3. Filtrer les clients bannis
            blacklisted_emails = {client.get("email", "").lower() for client in blacklisted_clients}

            soumissions_filtrees = []
            for soumission in soumissions:
                client_email = soumission.get("email", "").lower()
                if client_email not in blacklisted_emails:
                    soumissions_filtrees.append(soumission)

            print(f"[BAN] Facturation QE {username}: {len(soumissions)} total, {len(soumissions_filtrees)} apr√®s filtrage")
            return soumissions_filtrees

    except Exception as e:
        print(f"[ERROR] Erreur facturation QE pour {username}: {e}")
        return []

@app.post("/bannir-client-facturation-qe")
def bannir_client_facturation_qe(data: dict = Body(...)):
    """
    Endpoint pour bannir un client sp√©cifiquement dans la facturation QE
    N'affecte PAS le dossier soumissions_signees original
    """
    try:
        username = data.get("username")
        client_email = data.get("client_email")
        client_nom = data.get("client_nom", "")
        client_prenom = data.get("client_prenom", "")
        raison = data.get("raison", "Non sp√©cifi√©e")
        
        if not username or not client_email:
            raise HTTPException(status_code=400, detail="Username et email client requis")
        
        print(f"üö´ Bannissement facturation QE: {client_email} pour {username}")
        
        # Fichier blacklist sp√©cifique facturation QE
        blacklist_dir = f"{base_cloud}/blacklist"
        os.makedirs(blacklist_dir, exist_ok=True)
        blacklist_file = os.path.join(blacklist_dir, f"{username}_facturation_qe.json")
        
        # Charger la blacklist existante
        blacklisted_clients = []
        if os.path.exists(blacklist_file):
            with open(blacklist_file, "r", encoding="utf-8") as f:
                blacklisted_clients = json.load(f)
        
        # V√©rifier si d√©j√† banni
        client_exists = any(
            client.get("email", "").lower() == client_email.lower()
            for client in blacklisted_clients
        )
        
        if client_exists:
            return {"message": f"Le client {client_email} est d√©j√† banni de la facturation QE"}
        
        # Ajouter √† la blacklist
        nouveau_client_banni = {
            "email": client_email,
            "nom": client_nom,
            "prenom": client_prenom,
            "raison": raison,
            "date_bannissement": datetime.now().isoformat(),
            "banni_par": username,
            "type": "facturation_qe"
        }
        
        blacklisted_clients.append(nouveau_client_banni)
        
        # Sauvegarder
        with open(blacklist_file, "w", encoding="utf-8") as f:
            json.dump(blacklisted_clients, f, indent=2, ensure_ascii=False)
        
        print(f"[OK] Client {client_email} banni de la facturation QE pour {username}")
        
        return {
            "message": f"Client {client_email} banni de la facturation QE avec succ√®s [OK]",
            "details": nouveau_client_banni
        }
        
    except Exception as e:
        print(f"[ERROR] Erreur bannissement facturation QE: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du bannissement: {str(e)}"
        )

@app.get("/blacklist-clients-facturation-qe")
def get_blacklist_clients_facturation_qe(username: str):
    """
    R√©cup√®re la blacklist sp√©cifique √† la facturation QE
    """
    try:
        blacklist_file = f"{base_cloud}/blacklist/{username}_facturation_qe.json"
        
        if not os.path.exists(blacklist_file):
            return {"blacklisted_clients": []}
        
        with open(blacklist_file, "r", encoding="utf-8") as f:
            blacklisted_clients = json.load(f)
        
        return {"blacklisted_clients": blacklisted_clients}
        
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration blacklist facturation QE: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration de la blacklist: {str(e)}"
        )

@app.get("/soumissions_signees/{username}")
def get_soumissions_signees(username: str):
    """
    R√©cup√®re les soumissions sign√©es (archive) + ventes accept√©es (en temps r√©el)
    Exclut celles qui sont dans ventes_produit (produits livr√©s)
    """
    try:
        toutes_signees = []
        ids_deja_ajoutes = set()  # Pour √©viter les doublons

        # D'abord, charger les IDs des produits livr√©s pour les exclure
        ids_produits = set()
        fichier_produits = os.path.join(f"{base_cloud}/ventes_produit", username, "ventes.json")
        if os.path.exists(fichier_produits):
            with open(fichier_produits, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    produits = json.loads(content)
                    for p in produits:
                        produit_id = p.get("id", p.get("num", ""))
                        if produit_id:
                            ids_produits.add(produit_id)

        print(f"[DEBUG] IDs dans ventes_produit √† exclure: {list(ids_produits)}")

        # 1. Charger les soumissions sign√©es (ARCHIVE PERMANENTE)
        fichier_signees = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    signees = json.loads(content)
                    for s in signees:
                        submission_id = s.get("id", s.get("num", ""))
                        if submission_id and submission_id not in ids_deja_ajoutes and submission_id not in ids_produits:
                            toutes_signees.append({
                                "id": submission_id,
                                "num": s.get("num", ""),
                                "numero": s.get("num", s.get("numero", submission_id)),
                                "prenom": s.get("prenom", s.get("clientPrenom", "")),
                                "nom": s.get("nom", s.get("clientNom", "")),
                                "adresse": s.get("adresse", ""),
                                "telephone": s.get("telephone", ""),
                                "prix": s.get("prix", ""),
                                "date": s.get("date", ""),
                                "pdfUrl": s.get("pdfUrl") or s.get("pdf_url", "#"),
                                "lien_gqp": s.get("lien_gqp", ""),
                                "statut_paiement": s.get("statut_paiement", "En attente"),
                                "statut": "sign√©e"
                            })
                            ids_deja_ajoutes.add(submission_id)

        # 2. Charger les ventes accept√©es (EN TEMPS R√âEL - pour RPO)
        fichier_acceptees = os.path.join(f"{base_cloud}/ventes_acceptees", username, "ventes.json")
        if os.path.exists(fichier_acceptees):
            with open(fichier_acceptees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    acceptees = json.loads(content)
                    for a in acceptees:
                        submission_id = a.get("id", a.get("num", ""))
                        if submission_id and submission_id not in ids_deja_ajoutes and submission_id not in ids_produits:
                            toutes_signees.append({
                                "id": submission_id,
                                "num": a.get("num", ""),
                                "numero": a.get("num", a.get("numero", submission_id)),
                                "prenom": a.get("prenom", a.get("clientPrenom", "")),
                                "nom": a.get("nom", a.get("clientNom", "")),
                                "adresse": a.get("adresse", ""),
                                "telephone": a.get("telephone", ""),
                                "prix": a.get("prix", ""),
                                "date": a.get("date", ""),
                                "pdfUrl": a.get("pdfUrl", a.get("pdf_url", "#")),
                                "lien_gqp": a.get("lien_gqp", ""),
                                "statut": "en cours"
                            })
                            ids_deja_ajoutes.add(submission_id)

        # Trier par ordre chronologique (plus r√©cent d'abord)
        result = toutes_signees

        print(f"[soumissions_signees] {username}: {len(result)} soumissions sign√©es au total")
        return result

    except Exception as e:
        print(f"[ERREUR soumissions_signees] {e}")
        return []


@app.post("/retour-soumission-signee")
async def retour_soumission_signee(payload: dict = Body(...)):
    """
    Retourne un projet des travaux compl√©t√©s vers les soumissions sign√©es
    En cas d'erreur de l'entrepreneur
    """
    try:
        username = payload.get("username")
        event_id = payload.get("event_id")
        
        if not username or not event_id:
            raise HTTPException(status_code=400, detail="Username et event_id requis")
        
        # Charger les travaux compl√©t√©s
        fichier_completes = os.path.join(f"{base_cloud}/travaux_completes", username, "soumissions.json")
        if not os.path.exists(fichier_completes):
            raise HTTPException(status_code=404, detail="Aucun travaux compl√©t√©s trouv√©s")
        
        with open(fichier_completes, "r", encoding="utf-8") as f:
            travaux_completes = json.load(f)
        
        # Trouver le travail √† retourner
        travail_a_retourner = None
        travaux_restants = []
        
        for travail in travaux_completes:
            travail_id = travail.get("id", travail.get("num", ""))
            if travail_id == event_id:
                travail_a_retourner = travail
            else:
                travaux_restants.append(travail)
        
        if not travail_a_retourner:
            raise HTTPException(status_code=404, detail="Travail non trouv√© dans les compl√©t√©s")
        
        # Supprimer la date de completion
        if "date" in travail_a_retourner:
            del travail_a_retourner["date"]
        
        # Remettre dans travaux √† compl√©ter
        dossier_ac = f"{base_cloud}/travaux_a_completer/{username}"
        os.makedirs(dossier_ac, exist_ok=True)
        fichier_ac = os.path.join(dossier_ac, "soumissions.json")
        
        if os.path.exists(fichier_ac):
            with open(fichier_ac, "r", encoding="utf-8") as f:
                travaux_a_completer = json.load(f)
        else:
            travaux_a_completer = []
        
        # √âviter les duplications - v√©rifier si d√©j√† pr√©sent
        ids_existants = {t.get("id", t.get("num", "")) for t in travaux_a_completer}
        if event_id not in ids_existants:
            travaux_a_completer.append(travail_a_retourner)
            
            # Sauvegarder travaux √† compl√©ter
            with open(fichier_ac, "w", encoding="utf-8") as f:
                json.dump(travaux_a_completer, f, indent=2, ensure_ascii=False)
        
        # Sauvegarder travaux compl√©t√©s (sans l'√©l√©ment retourn√©)
        with open(fichier_completes, "w", encoding="utf-8") as f:
            json.dump(travaux_restants, f, indent=2, ensure_ascii=False)
        
        print(f"[retour-soumission-signee] Projet {event_id} retourn√© aux soumissions sign√©es pour {username}")
        
        return {
            "success": True,
            "message": "Projet retourn√© aux soumissions sign√©es avec succ√®s"
        }
        
    except Exception as e:
        print(f"[ERREUR retour-soumission-signee] {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ===============================================
# ROUTES API POUR LES FACTURATIONS EN TRAITEMENT
# ===============================================

@app.post("/api/envoyer-comptable")
def envoyer_comptable(
    username: str = Body(...),
    clientNom: str = Body(...),
    clientPrenom: str = Body(...),
    numeroSoumission: str = Body(...),
    montantPaiement: str = Body(...),
    typePaiement: str = Body(...),
    pdfUrl: str = Body(...),
    methodePaiement: str = Body(None),  # virement ou cheque
    lienVirement: str = Body(None),
    motDePasseVirement: str = Body(None),
    numeroCheque: str = Body(None),
    photoRectoUrl: str = Body(None),
    photoVersoUrl: str = Body(None)
):
    """
    Enregistre une facturation en traitement quand l'utilisateur clique sur 'Envoy√© au comptable'
    """
    try:
        # Cr√©er le dossier pour les facturations en traitement
        dossier = os.path.join(f"{base_cloud}/facturations_traitement", username)
        os.makedirs(dossier, exist_ok=True)
        fichier = os.path.join(dossier, "facturations.json")
        
        # Pr√©parer les donn√©es de facturation
        facturation_data = {
            "id": str(uuid.uuid4()),
            "clientNom": clientNom,
            "clientPrenom": clientPrenom,
            "numeroSoumission": numeroSoumission,
            "montantPaiement": montantPaiement,
            "typePaiement": typePaiement,
            "pdfUrl": pdfUrl,
            "methodePaiement": methodePaiement,
            "dateEnvoi": datetime.now().isoformat(),
            "statut": "en_traitement"
        }
        
        # Ajouter les champs sp√©cifiques selon la m√©thode de paiement
        if methodePaiement == "virement":
            facturation_data["lienVirement"] = lienVirement
            facturation_data["motDePasseVirement"] = motDePasseVirement
        elif methodePaiement == "cheque":
            facturation_data["numeroCheque"] = numeroCheque
            facturation_data["photoRectoUrl"] = photoRectoUrl
            facturation_data["photoVersoUrl"] = photoVersoUrl
        
        # Charger les facturations existantes
        facturations = []
        if os.path.exists(fichier):
            with open(fichier, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    facturations = json.loads(content)
        
        # Ajouter la nouvelle facturation
        facturations.append(facturation_data)
        
        # Sauvegarder
        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(facturations, f, indent=2, ensure_ascii=False)
        
        print(f"[envoyer-comptable] Facturation enregistr√©e pour {username}: {numeroSoumission}")
        
        return {"message": "Facturation envoy√©e au comptable avec succ√®s"}
        
    except Exception as e:
        print(f"[ERREUR envoyer-comptable] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/facturations_traitement/{username}")
def get_facturations_traitement(username: str):
    """
    R√©cup√®re toutes les facturations en traitement pour un utilisateur
    """
    try:
        fichier = os.path.join(f"{base_cloud}/facturations_traitement", username, "facturations.json")
        if not os.path.exists(fichier):
            return []
        
        with open(fichier, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            
            facturations = json.loads(content)
            
        # Trier par date d'envoi (plus r√©cent d'abord)
        facturations.sort(key=lambda x: x.get("dateEnvoi", ""), reverse=True)
        
        print(f"[facturations_traitement] {username}: {len(facturations)} facturations en traitement")
        return facturations
        
    except Exception as e:
        print(f"[ERREUR facturations_traitement] {e}")
        return []

# ===============================================
# ROUTES API POUR LA GESTION DES FACTURATIONS QE
# ===============================================

@app.get("/facturations_urgentes/{username}")
def get_facturations_urgentes(username: str):
    """
    R√©cup√®re toutes les facturations urgentes pour un utilisateur
    """
    try:
        fichier = os.path.join(f"{base_cloud}/facturations_urgentes", username, "facturations.json")
        if not os.path.exists(fichier):
            return []
        
        with open(fichier, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            facturations = json.loads(content)
            
        facturations.sort(key=lambda x: x.get("dateCreation", ""), reverse=True)
        return facturations
        
    except Exception as e:
        print(f"[ERREUR facturations_urgentes] {e}")
        return []

@app.get("/facturations_en_cours/{username}")
def get_facturations_en_cours(username: str):
    """
    R√©cup√®re toutes les facturations en cours pour un utilisateur
    """
    try:
        fichier = os.path.join(f"{base_cloud}/facturations_en_cours", username, "facturations.json")
        if not os.path.exists(fichier):
            return []
        
        with open(fichier, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            facturations = json.loads(content)
            
        facturations.sort(key=lambda x: x.get("dateCreation", ""), reverse=True)
        return facturations
        
    except Exception as e:
        print(f"[ERREUR facturations_en_cours] {e}")
        return []

@app.get("/facturations_traitees/{username}")
def get_facturations_traitees(username: str):
    """
    R√©cup√®re toutes les facturations trait√©es pour un utilisateur
    """
    try:
        fichier = os.path.join(f"{base_cloud}/facturations_traitees", username, "facturations.json")
        if not os.path.exists(fichier):
            return []
        
        with open(fichier, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            facturations = json.loads(content)
            
        facturations.sort(key=lambda x: x.get("dateTraitement", ""), reverse=True)
        return facturations
        
    except Exception as e:
        print(f"[ERREUR facturations_traitees] {e}")
        return []

@app.get("/facturation/{username}/{numero_facture}")
def get_facturation_details(username: str, numero_facture: str):
    """
    R√©cup√®re les d√©tails d'une facturation sp√©cifique
    """
    try:
        # Chercher dans toutes les cat√©gories
        categories = ["facturations_urgentes", "facturations_en_cours", "facturations_traitement", "facturations_traitees"]
        
        for categorie in categories:
            fichier = os.path.join(f"{base_cloud}", categorie, username, "facturations.json")
            if os.path.exists(fichier):
                with open(fichier, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        facturations = json.loads(content)
                        for facturation in facturations:
                            if facturation.get("numeroSoumission") == numero_facture:
                                return facturation
        
        raise HTTPException(status_code=404, detail="Facturation non trouv√©e")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR get_facturation_details] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/facturation/{username}/{numero_facture}")
async def modifier_facturation(username: str, numero_facture: str, request: Request):
    """
    Modifie une facturation existante
    """
    try:
        data = await request.json()
        
        # Chercher et modifier dans toutes les cat√©gories
        categories = ["facturations_urgentes", "facturations_en_cours", "facturations_traitement"]
        
        for categorie in categories:
            fichier = os.path.join(f"{base_cloud}", categorie, username, "facturations.json")
            if os.path.exists(fichier):
                with open(fichier, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        facturations = json.loads(content)
                        
                        for i, facturation in enumerate(facturations):
                            if facturation.get("numeroSoumission") == numero_facture:
                                # Mettre √† jour les champs modifi√©s
                                facturations[i].update(data)
                                facturations[i]["dateModification"] = datetime.now().isoformat()
                                
                                # Sauvegarder
                                with open(fichier, "w", encoding="utf-8") as fw:
                                    json.dump(facturations, fw, indent=2, ensure_ascii=False)
                                
                                return {"message": "Facturation modifi√©e avec succ√®s", "facturation": facturations[i]}
        
        raise HTTPException(status_code=404, detail="Facturation non trouv√©e")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR modifier_facturation] {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ===============================================
# ROUTES API POUR LA GESTION DES STATUTS FACTURATION QE
# ===============================================

@app.get("/api/facturationqe/clients/{username}")
def api_get_clients_facturation_qe(username: str):
    """
    R√©cup√®re tous les clients avec leurs statuts pour la facturation QE
    """
    try:
        clients = get_clients_facturation_qe(username)
        return {"clients": clients, "total": len(clients)}
    except Exception as e:
        print(f"[ERREUR api_get_clients_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/client/{username}/{numero_soumission}/statuts")
def api_get_statuts_client_facturation_qe(username: str, numero_soumission: str):
    """
    R√©cup√®re les statuts de paiement d'un client sp√©cifique
    """
    try:
        statuts = get_statuts_client_facturation_qe(username, numero_soumission)
        return statuts
    except Exception as e:
        print(f"[ERREUR api_get_statuts_client_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/facturationqe/client/{username}/{numero_soumission}/statut")
async def api_update_statut_client_facturation_qe(username: str, numero_soumission: str, request: Request):
    """
    Met √† jour le statut d'un type de paiement pour un client
    """
    try:
        data = await request.json()
        type_statut = data.get("type_statut")  # depot, paiement_final, autres_paiements
        nouveau_statut = data.get("nouveau_statut")  # non_envoye, envoye, traitement, traite
        
        if not type_statut or not nouveau_statut:
            raise HTTPException(status_code=400, detail="type_statut et nouveau_statut requis")
        
        # Mettre √† jour le statut
        result = update_statut_client_facturation_qe(username, numero_soumission, type_statut, nouveau_statut)
        
        # Ajouter √† l'historique
        ajouter_historique_client_facturation_qe(
            username, numero_soumission, 
            f"Statut {type_statut} mis √† jour",
            {"ancien_statut": data.get("ancien_statut"), "nouveau_statut": nouveau_statut}
        )
        
        return {
            "message": f"Statut {type_statut} mis √† jour avec succ√®s",
            "statuts": result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR api_update_statut_client_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/status-columns/{username}")
def api_get_status_columns_facturation_qe(username: str):
    """
    R√©cup√®re les clients organis√©s par colonnes de statut
    """
    try:
        colonnes = get_status_columns_facturation_qe(username)
        return colonnes
    except Exception as e:
        print(f"[ERREUR api_get_status_columns_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/client/{username}/{numero_soumission}/description")
def api_get_description_statut_client_facturation_qe(username: str, numero_soumission: str):
    """
    G√©n√®re la description du statut pour un client donn√©
    """
    try:
        description = get_description_statut_client_facturation_qe(username, numero_soumission)
        return description
    except Exception as e:
        print(f"[ERREUR api_get_description_statut_client_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/facturationqe/client/{username}/{numero_soumission}/depot/traite")
def api_marquer_depot_traite_facturation_qe(username: str, numero_soumission: str):
    """
    Marque le d√©p√¥t d'un client comme trait√©
    """
    try:
        result = marquer_depot_traite_facturation_qe(username, numero_soumission)
        
        # Ajouter √† l'historique
        ajouter_historique_client_facturation_qe(
            username, numero_soumission,
            "D√©p√¥t marqu√© comme trait√©",
            {"action_type": "marquer_traite", "type_paiement": "depot"}
        )
        
        return result
    except Exception as e:
        print(f"[ERREUR api_marquer_depot_traite_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/facturationqe/client/{username}/{numero_soumission}/envoyer-comptable")
async def api_envoyer_au_comptable_facturation_qe(username: str, numero_soumission: str, request: Request):
    """
    Envoie un paiement au comptable et met √† jour le statut
    """
    try:
        data = await request.json()
        type_paiement = data.get("type_paiement")  # depot, paiement_final, autres_paiements
        details_paiement = data.get("details_paiement")  # D√©tails du paiement avec la date

        if not type_paiement:
            raise HTTPException(status_code=400, detail="type_paiement requis")

        result = envoyer_au_comptable_facturation_qe(username, numero_soumission, type_paiement, details_paiement)
        
        # Ajouter √† l'historique
        ajouter_historique_client_facturation_qe(
            username, numero_soumission,
            f"Envoy√© au comptable - {type_paiement}",
            {"action_type": "envoyer_comptable", "type_paiement": type_paiement}
        )
        
        return result
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR api_envoyer_au_comptable_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/client/{username}/{numero_soumission}/historique")
def api_get_historique_client_facturation_qe(username: str, numero_soumission: str):
    """
    R√©cup√®re l'historique des actions pour un client
    """
    try:
        historique = get_historique_client_facturation_qe(username, numero_soumission)
        return {"historique": historique, "total": len(historique)}
    except Exception as e:
        print(f"[ERREUR api_get_historique_client_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/clients-count/{username}")
def api_get_clients_count_facturation_qe(username: str):
    """
    R√©cup√®re le nombre total de clients pour la facturation QE
    """
    try:
        result = get_clients_count_facturation_qe(username)
        return result
    except Exception as e:
        print(f"[ERREUR api_get_clients_count_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/urgent-count/{username}")
def api_get_urgent_count_facturation_qe(username: str):
    """
    Compte le nombre de paiements urgents (refus√©s) pour un entrepreneur
    """
    try:
        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        urgent_count = 0

        if os.path.exists(statuts_file):
            with open(statuts_file, "r", encoding="utf-8") as f:
                statuts = json.load(f)

            for num_soumission, client_statuts in statuts.items():
                statut_depot = client_statuts.get("statutDepot")
                statut_paiement_final = client_statuts.get("statutPaiementFinal")
                autres_paiements = client_statuts.get("autresPaiements", [])
                depot = client_statuts.get("depot", {})
                paiement_final = client_statuts.get("paiementFinal", {})

                # Compter les d√©p√¥ts refus√©s (seulement si pas encore modifi√© par l'entrepreneur)
                if statut_depot == "refuse" and not depot.get("modificationsApportees"):
                    urgent_count += 1

                # Compter les paiements finaux refus√©s (seulement si pas encore modifi√©)
                if statut_paiement_final == "refuse" and not paiement_final.get("modificationsApportees"):
                    urgent_count += 1

                # Compter les autres paiements refus√©s (seulement si pas encore modifi√©)
                if isinstance(autres_paiements, list):
                    for ap in autres_paiements:
                        if ap.get("statut") == "refuse" and not ap.get("modificationsApportees"):
                            urgent_count += 1

        return {"success": True, "urgent_count": urgent_count}
    except Exception as e:
        print(f"[ERREUR api_get_urgent_count_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/facturationqe/envoyer-comptable/{username}/{numeroSoumission}")
def api_envoyer_comptable_facturation_qe(username: str, numeroSoumission: str, body: dict = Body(...)):
    """
    API endpoint pour envoyer un paiement au comptable
    """
    try:
        type_paiement = body.get("typePaiement", "depot")
        
        # R√©cup√©rer tous les d√©tails du paiement
        details_paiement = {
            "montant": body.get("montantPaiement", "0,00 $"),
            "date": body.get("dateDepot", ""),
            "methode": body.get("methodePaiement", ""),
            "totalTravaux": body.get("totalTravaux", "0,00 $"),
            # Ajouter les champs sp√©cifiques au virement
            "lienVirement": body.get("lienVirement", ""),
            "motDePasseVirement": body.get("motDePasseVirement", ""),
            "numeroCheque": body.get("numeroCheque", ""),
            # Ajouter les photos du ch√®que en base64
            "photoRecto": body.get("photoRecto", ""),
            "photoVerso": body.get("photoVerso", ""),
            # Ajouter le type de paiement autres (un_seul_paiement ou paiement_partiel)
            "typePaiementAutres": body.get("typePaiementAutres", "")
        }
        
        print(f"[DEBUG] [API envoyer-comptable] D√©tails re√ßus: {details_paiement}")
        
        result = envoyer_au_comptable_facturation_qe(username, numeroSoumission, type_paiement, details_paiement)
        
        # Log de l'action
        details = {
            "montant": body.get("paiement", ""),
            "type_paiement": type_paiement,
            "methode": body.get("payePar", ""),
            "date": body.get("dateDepot", "")
        }
        ajouter_historique_client_facturation_qe(username, numeroSoumission, f"Envoy√© au comptable - {type_paiement}", details)
        
        return result
    except Exception as e:
        print(f"[ERREUR api_envoyer_comptable_facturation_qe] {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ===============================================
# ROUTES API POUR LA GESTION DES EMPLOY√âS
# ===============================================

def load_employes(username: str, type_employe: str):
    """Charge les employ√©s d'un type donn√© pour un utilisateur"""
    try:
        fichier_path = os.path.join(f"{base_cloud}/employes", username, f"{type_employe}.json")
        if not os.path.exists(fichier_path):
            return []
        
        with open(fichier_path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            return json.loads(content)
    except Exception as e:
        print(f"Erreur lors du chargement des employ√©s {type_employe}: {e}")
        return []

def save_employes(username: str, type_employe: str, employes: list):
    """Sauvegarde les employ√©s d'un type donn√© pour un utilisateur"""
    try:
        dossier = os.path.join(f"{base_cloud}/employes", username)
        os.makedirs(dossier, exist_ok=True)
        
        fichier_path = os.path.join(dossier, f"{type_employe}.json")
        with open(fichier_path, "w", encoding="utf-8") as f:
            json.dump(employes, f, indent=2, ensure_ascii=False)
        
        return True
    except Exception as e:
        print(f"Erreur lors de la sauvegarde des employ√©s {type_employe}: {e}")
        return False

# R√©cup√©rer les r√©activations en attente d'un entrepreneur (DOIT √™tre avant la route g√©n√©rique)
@app.get("/api/employes/{username}/reactivations")
async def get_reactivations(username: str):
    """R√©cup√®re les r√©activations en attente de validation pour un entrepreneur"""
    try:
        reactivations = load_reactivations(username)
        return {"success": True, "employes": reactivations}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# R√©cup√©rer les inactivations en attente d'un entrepreneur (DOIT √™tre avant la route g√©n√©rique)
@app.get("/api/employes/{username}/inactivations")
async def get_inactivations(username: str):
    """R√©cup√®re les inactivations en attente de validation pour un entrepreneur"""
    try:
        inactivations = load_inactivations(username)
        return {"success": True, "employes": inactivations}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# R√©cup√©rer tous les employ√©s d'un utilisateur
@app.get("/api/employes/{username}/{type_employe}")
async def get_employes(username: str, type_employe: str):
    """R√©cup√®re les employ√©s d'un type sp√©cifique (nouveaux, actifs, termines)"""
    try:
        if type_employe not in ["nouveaux", "actifs", "termines", "inactifs"]:
            raise HTTPException(status_code=400, detail="Type d'employ√© invalide")

        employes = load_employes(username, type_employe)

        # Pour "termines", fusionner avec "inactifs" (processus 3 √©tapes)
        if type_employe == "termines":
            employes_inactifs = load_employes(username, "inactifs")
            # Ajouter les inactifs qui ne sont pas d√©j√† dans termines (par ID)
            ids_existants = {e.get("id") for e in employes}
            for emp in employes_inactifs:
                if emp.get("id") not in ids_existants:
                    employes.append(emp)

        # Assigner le statut par d√©faut uniquement si absent
        if type_employe == "nouveaux":
            for employe in employes:
                if "statut" not in employe or not employe["statut"]:
                    employe["statut"] = "En attente"

        return {"success": True, "employes": employes}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ajouter un nouveau candidat employ√©
@app.post("/api/employes/{username}/nouveaux")
async def ajouter_employe(username: str, employe_data: NouvelEmploye):
    """Ajoute un nouveau candidat employ√©"""
    try:
        employes_nouveaux = load_employes(username, "nouveaux")
        
        # Cr√©er le nouvel employ√© avec un ID unique
        nouvel_employe = {
            "id": str(uuid.uuid4()),
            "nom": employe_data.nom,
            "genre": employe_data.genre,
            "courriel": employe_data.courriel,
            "telephone": employe_data.telephone,
            "poste": employe_data.poste,
            "dateCandidature": datetime.now().strftime("%Y-%m-%d"),
            "statut": "En attente"
        }
        
        employes_nouveaux.append(nouvel_employe)
        
        if save_employes(username, "nouveaux", employes_nouveaux):
            return {"success": True, "message": "Employ√© ajout√©", "employe": nouvel_employe}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Activer un employ√© (met en attente de validation coach)
@app.post("/api/employes/{username}/activer/{employe_id}")
async def activer_employe(
    username: str,
    employe_id: str,
    nom: str = Form(...),
    nas: str = Form(...),
    genre: str = Form(...),
    adresse: str = Form(...),
    appartement: str = Form(""),
    ville: str = Form(...),
    codePostal: str = Form(...),
    telephone: str = Form(...),
    courriel: str = Form(...),
    datePremiere: str = Form(...),
    posteService: str = Form(...),
    tauxHoraire: float = Form(...),
    dateNaissance: str = Form(...),
    specimen: UploadFile = File(None),
    certificat: UploadFile = File(None),
    carte: UploadFile = File(None)
):
    """Met l'employ√© en attente de validation avec toutes ses informations compl√©t√©es et ses documents"""
    try:
        # Charger les employ√©s nouveaux
        employes_nouveaux = load_employes(username, "nouveaux")

        # Trouver l'employ√© √† mettre en attente
        employe_trouve = None
        for employe in employes_nouveaux:
            if employe.get("id") == employe_id:
                employe_trouve = employe
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Mettre √† jour l'employ√© avec toutes les informations ET le statut "En attente de validation"
        employe_trouve.update({
            "nom": nom,
            "nas": nas,
            "genre": genre,
            "adresse": adresse,
            "appartement": appartement or "-",
            "ville": ville,
            "codePostal": codePostal,
            "telephone": telephone,
            "courriel": courriel,
            "datePremiere": datePremiere,
            "posteService": posteService,
            "departement": "0",
            "tauxHoraire": tauxHoraire,
            "dateNaissance": dateNaissance,
            "dateActivation": datetime.now().strftime("%Y-%m-%d"),
            "statut": "En attente de validation"
        })

        # Cr√©er le r√©pertoire pour les documents de l'employ√© s'il n'existe pas
        employe_dir = os.path.join(os.path.dirname(__file__), "data", "employes", username, employe_id)
        os.makedirs(employe_dir, exist_ok=True)

        # Sauvegarder les fichiers si fournis
        if specimen and specimen.filename:
            file_ext = os.path.splitext(specimen.filename)[1]
            file_path = os.path.join(employe_dir, f"specimen{file_ext}")
            with open(file_path, "wb") as f:
                content = await specimen.read()
                f.write(content)
            employe_trouve["specimen"] = f"specimen{file_ext}"
            print(f"[INFO] Sp√©cimen sauvegard√©: {file_path}")

        if certificat and certificat.filename:
            file_ext = os.path.splitext(certificat.filename)[1]
            file_path = os.path.join(employe_dir, f"certificat{file_ext}")
            with open(file_path, "wb") as f:
                content = await certificat.read()
                f.write(content)
            employe_trouve["certificat"] = f"certificat{file_ext}"
            print(f"[INFO] Certificat sauvegard√©: {file_path}")

        if carte and carte.filename:
            file_ext = os.path.splitext(carte.filename)[1]
            file_path = os.path.join(employe_dir, f"carte{file_ext}")
            with open(file_path, "wb") as f:
                content = await carte.read()
                f.write(content)
            employe_trouve["carte"] = f"carte{file_ext}"
            print(f"[INFO] Carte assurance maladie sauvegard√©e: {file_path}")

        # Sauvegarder dans nouveaux.json (l'employ√© reste l√†)
        if save_employes(username, "nouveaux", employes_nouveaux):
            return {"success": True, "message": "Employ√© mis en attente de validation", "employe": employe_trouve}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        print(f"[ERROR] Erreur dans activer_employe: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Valider un employ√© (coach seulement) - change le statut vers "En attente comptable"
@app.post("/api/employes/{username}/valider/{employe_id}")
async def valider_employe_coach(username: str, employe_id: str):
    """Valide un employ√© en attente coach et le passe en attente comptable (action coach)"""
    try:
        # Charger les employ√©s nouveaux
        employes_nouveaux = load_employes(username, "nouveaux")

        # Trouver l'employ√© √† valider
        employe_trouve = False

        for employe in employes_nouveaux:
            if employe.get("id") == employe_id:
                # V√©rifier qu'il est bien en attente de validation (coach)
                if employe.get("statut") != "En attente de validation":
                    raise HTTPException(status_code=400, detail="L'employ√© n'est pas en attente de validation")
                # Changer le statut √† "En attente comptable"
                employe["statut"] = "En attente comptable"
                employe["date_validation_coach"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                employe_trouve = True
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Sauvegarder la liste (l'employ√© reste dans "nouveaux" mais avec un statut diff√©rent)
        if save_employes(username, "nouveaux", employes_nouveaux):
            return {"success": True, "message": "Employ√© valid√© par le coach, en attente de validation comptable"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Valider un employ√© (comptable/admin seulement) - d√©place de nouveaux vers actifs
@app.post("/api/employes/{username}/valider-comptable/{employe_id}")
async def valider_employe_comptable(username: str, employe_id: str):
    """Valide un employ√© en attente comptable et le d√©place vers actifs (action comptable)"""
    try:
        # Charger les employ√©s nouveaux et actifs
        employes_nouveaux = load_employes(username, "nouveaux")
        employes_actifs = load_employes(username, "actifs")

        # Trouver l'employ√© √† valider
        employe_a_valider = None
        employes_nouveaux_restants = []

        for employe in employes_nouveaux:
            if employe.get("id") == employe_id:
                # V√©rifier qu'il est bien en attente comptable
                if employe.get("statut") != "En attente comptable":
                    raise HTTPException(status_code=400, detail="L'employ√© n'est pas en attente de validation comptable")
                employe_a_valider = employe
            else:
                employes_nouveaux_restants.append(employe)

        if not employe_a_valider:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Changer le statut √† "Actif" et d√©placer vers actifs
        employe_a_valider["statut"] = "Actif"
        employe_a_valider["date_validation_comptable"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        # Effacer la conversation de refus si elle existe
        employe_a_valider.pop("conversation_refus", None)
        employe_a_valider.pop("motif_refus_comptable", None)
        employe_a_valider.pop("date_refus_comptable", None)
        employe_a_valider.pop("motif_refus_coach", None)
        employe_a_valider.pop("date_refus_coach", None)
        employes_actifs.append(employe_a_valider)

        # Sauvegarder les deux listes
        if save_employes(username, "nouveaux", employes_nouveaux_restants) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Employ√© valid√© et activ√©", "employe": employe_a_valider}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser un employ√© (coach ou comptable) - remet au statut "Refus√©"
@app.post("/api/employes/{username}/refuser/{employe_id}")
async def refuser_employe(username: str, employe_id: str, request: Request):
    """Refuse un employ√© en attente de validation (action coach ou comptable)"""
    try:
        # R√©cup√©rer la raison du refus
        try:
            body = await request.json()
            motif_refus = body.get("motif_refus", "Aucune raison sp√©cifi√©e")
        except:
            motif_refus = "Aucune raison sp√©cifi√©e"

        # Charger les employ√©s nouveaux
        employes_nouveaux = load_employes(username, "nouveaux")

        # Trouver l'employ√© √† refuser
        employe_trouve = False

        for employe in employes_nouveaux:
            if employe.get("id") == employe_id:
                statut_actuel = employe.get("statut", "")

                # Coach refuse: statut "En attente de validation" -> "Refus√© par coach"
                if statut_actuel == "En attente de validation":
                    employe["statut"] = "Refus√© par coach"
                    employe["date_refus_coach"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    employe["motif_refus_coach"] = motif_refus
                    employe_trouve = True
                # Comptable refuse: statut "En attente comptable" ou "En attente de validation comptable" -> "Refus√© par comptable"
                elif statut_actuel in ["En attente comptable", "En attente de validation comptable"]:
                    employe["statut"] = "Refus√© par comptable"
                    employe["date_refus_comptable"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    employe["motif_refus_comptable"] = motif_refus
                    employe_trouve = True
                else:
                    raise HTTPException(status_code=400, detail=f"L'employ√© n'est pas en attente de validation (statut: {statut_actuel})")
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Sauvegarder la liste
        if save_employes(username, "nouveaux", employes_nouveaux):
            return {"success": True, "message": "Employ√© refus√©"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ========== CONVERSATION DE REFUS EMPLOY√â ==========

# R√©cup√©rer la conversation de refus pour un employ√©
@app.get("/api/employes/{username}/refus-conversation/{employe_id}")
async def get_refus_conversation(username: str, employe_id: str):
    """R√©cup√®re la conversation de refus pour un employ√©"""
    try:
        # Chercher dans nouveaux et actifs
        employes_nouveaux = load_employes(username, "nouveaux")
        employes_actifs = load_employes(username, "actifs")

        employe = None
        for emp in employes_nouveaux + employes_actifs:
            if emp.get("id") == employe_id:
                employe = emp
                break

        if not employe:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # R√©cup√©rer la conversation existante ou cr√©er avec le motif initial
        conversation = employe.get("conversation_refus", [])

        # Si pas de conversation mais un motif de refus existe, cr√©er le premier message
        if not conversation:
            motif = employe.get("motif_refus_coach") or employe.get("motif_refus_comptable") or employe.get("motif_refus_modification") or employe.get("motif_refus_inactivation") or employe.get("motif_refus_reactivation")
            date = employe.get("date_refus_coach") or employe.get("date_refus_comptable") or employe.get("date_refus_modification") or employe.get("date_refus_inactivation") or employe.get("date_refus_reactivation")

            if motif:
                conversation = [{
                    "de": "comptable",
                    "message": motif,
                    "date": date or datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }]

        return {"conversation": conversation, "employeNom": employe.get("nom", "")}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ajouter un message √† la conversation de refus
@app.post("/api/employes/{username}/refus-conversation/{employe_id}/message")
async def add_refus_message(username: str, employe_id: str, request: Request):
    """Ajoute un message √† la conversation de refus"""
    try:
        body = await request.json()
        message = body.get("message", "").strip()
        de = body.get("de", "entrepreneur")

        if not message:
            raise HTTPException(status_code=400, detail="Message vide")

        # Chercher dans nouveaux et actifs
        employes_nouveaux = load_employes(username, "nouveaux")
        employes_actifs = load_employes(username, "actifs")

        employe_trouve = False
        source = None

        # Chercher dans nouveaux
        for i, emp in enumerate(employes_nouveaux):
            if emp.get("id") == employe_id:
                if "conversation_refus" not in employes_nouveaux[i]:
                    # Initialiser avec le motif existant
                    motif = emp.get("motif_refus_coach") or emp.get("motif_refus_comptable")
                    date = emp.get("date_refus_coach") or emp.get("date_refus_comptable")
                    if motif:
                        employes_nouveaux[i]["conversation_refus"] = [{
                            "de": "comptable",
                            "message": motif,
                            "date": date or datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }]
                    else:
                        employes_nouveaux[i]["conversation_refus"] = []

                employes_nouveaux[i]["conversation_refus"].append({
                    "de": de,
                    "message": message,
                    "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "lu": False  # Non lu par d√©faut
                })
                employe_trouve = True
                source = "nouveaux"
                break

        # Si pas trouv√© dans nouveaux, chercher dans actifs
        if not employe_trouve:
            for i, emp in enumerate(employes_actifs):
                if emp.get("id") == employe_id:
                    if "conversation_refus" not in employes_actifs[i]:
                        # Initialiser avec le motif existant
                        motif = emp.get("motif_refus_modification") or emp.get("motif_refus_inactivation") or emp.get("motif_refus_reactivation")
                        date = emp.get("date_refus_modification") or emp.get("date_refus_inactivation") or emp.get("date_refus_reactivation")
                        if motif:
                            employes_actifs[i]["conversation_refus"] = [{
                                "de": "comptable",
                                "message": motif,
                                "date": date or datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            }]
                        else:
                            employes_actifs[i]["conversation_refus"] = []

                    employes_actifs[i]["conversation_refus"].append({
                        "de": de,
                        "message": message,
                        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "lu": False  # Non lu par d√©faut
                    })
                    employe_trouve = True
                    source = "actifs"
                    break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Sauvegarder
        if source == "nouveaux":
            save_employes(username, "nouveaux", employes_nouveaux)
        else:
            save_employes(username, "actifs", employes_actifs)

        return {"success": True, "message": "Message ajout√©"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Compter les messages non lus dans une conversation de refus
@app.get("/api/refus-conversation/unread-counts/{username}")
async def get_refus_unread_counts_unified(username: str):
    """R√©cup√®re le nombre de messages non lus pour chaque employ√© refus√©"""
    try:
        unread_counts = {}  # {employe_id: count}

        # V√©rifier les employ√©s avec statut "Refus√© par coach" ou "Refus√© par comptable"
        employes_nouveaux = load_employes(username, "nouveaux")
        employes_actifs = load_employes(username, "actifs")

        for employe in employes_nouveaux + employes_actifs:
            statut = employe.get("statut", "")
            if statut in ["Refus√© par coach", "Refus√© par comptable"]:
                employe_id = employe.get("id")
                conversation = employe.get("conversation_refus", [])

                # Compter TOUS les messages non lus (peu importe qui les a envoy√©s)
                unread_count = 0
                for msg in conversation:
                    if not msg.get("lu", False):
                        unread_count += 1

                if unread_count > 0:
                    unread_counts[employe_id] = unread_count

        return {"success": True, "unread_counts": unread_counts}
    except Exception as e:
        print(f"Erreur lors du comptage des messages non lus: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Marquer TOUS les messages comme lus dans une conversation
@app.post("/api/refus-conversation/{username}/{employe_id}/mark-all-read")
async def mark_all_refus_messages_read(username: str, employe_id: str):
    """Marque TOUS les messages de la conversation comme lus"""
    try:
        # Chercher dans nouveaux et actifs
        employes_nouveaux = load_employes(username, "nouveaux")
        employes_actifs = load_employes(username, "actifs")

        employe_trouve = False
        source = None

        # Chercher dans nouveaux
        for i, emp in enumerate(employes_nouveaux):
            if emp.get("id") == employe_id:
                conversation = employes_nouveaux[i].get("conversation_refus", [])
                for msg in conversation:
                    msg["lu"] = True
                employe_trouve = True
                source = "nouveaux"
                break

        # Si pas trouv√© dans nouveaux, chercher dans actifs
        if not employe_trouve:
            for i, emp in enumerate(employes_actifs):
                if emp.get("id") == employe_id:
                    conversation = employes_actifs[i].get("conversation_refus", [])
                    for msg in conversation:
                        msg["lu"] = True
                    employe_trouve = True
                    source = "actifs"
                    break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Sauvegarder
        if source == "nouveaux":
            save_employes(username, "nouveaux", employes_nouveaux)
        else:
            save_employes(username, "actifs", employes_actifs)

        return {"success": True, "message": "Messages marqu√©s comme lus"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Compter le total de messages non lus pour tous les entrepreneurs (pour le coach)
@app.get("/api/coach/{coach_username}/refus-unread-total")
async def get_coach_refus_unread_total(coach_username: str):
    """Compte le total de messages non lus dans toutes les conversations de refus pour le coach"""
    try:
        total_unread = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "total": 0}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                employes_nouveaux = load_employes(username, "nouveaux")
                employes_actifs = load_employes(username, "actifs")

                for employe in employes_nouveaux + employes_actifs:
                    statut = employe.get("statut", "")
                    if statut in ["Refus√© par coach", "Refus√© par comptable"]:
                        conversation = employe.get("conversation_refus", [])

                        for msg in conversation:
                            if not msg.get("lu", False):
                                total_unread += 1

        return {"success": True, "total": total_unread}
    except Exception as e:
        print(f"Erreur lors du comptage total des messages non lus: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# R√©cup√©rer tous les messages de refus pour le comptable
@app.get("/api/comptable/messages-refus-employes")
async def get_messages_refus_employes():
    """R√©cup√®re toutes les conversations de refus avec r√©ponses d'entrepreneurs"""
    try:
        messages = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"messages": []}

        # Parcourir tous les entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if not os.path.isdir(user_path):
                continue

            # Chercher dans nouveaux et actifs
            for fichier in ["nouveaux", "actifs"]:
                file_path = os.path.join(user_path, f"{fichier}.json")
                if not os.path.exists(file_path):
                    continue

                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        employes = json.load(f)
                except:
                    continue

                for employe in employes:
                    conversation = employe.get("conversation_refus", [])

                    # Inclure si l'employ√© est refus√© et a une conversation
                    statut = employe.get("statut", "")
                    est_refuse = "refus√©" in statut.lower() or "Refus√©" in statut

                    if est_refuse and conversation:
                        # Trouver s'il y a des r√©ponses de l'entrepreneur
                        messages_entrepreneur = [m for m in conversation if m.get("de") == "entrepreneur"]

                        # Ajouter si conversation existe (m√™me sans r√©ponse entrepreneur)
                        dernier_update = conversation[-1].get("date") if conversation else ""

                        messages.append({
                            "entrepreneur": username,
                            "employeId": employe.get("id"),
                            "employeNom": employe.get("nom", ""),
                            "statut": statut,
                            "conversation": conversation,
                            "dernierUpdate": dernier_update,
                            "nombreReponsesEntrepreneur": len(messages_entrepreneur),
                            # Informations compl√®tes de l'employ√©
                            "employe": {
                                "nom": employe.get("nom", ""),
                                "genre": employe.get("genre", ""),
                                "courriel": employe.get("courriel", ""),
                                "telephone": employe.get("telephone", ""),
                                "poste": employe.get("poste", ""),
                                "nas": employe.get("nas", ""),
                                "adresse": employe.get("adresse", ""),
                                "appartement": employe.get("appartement", ""),
                                "ville": employe.get("ville", ""),
                                "codePostal": employe.get("codePostal", ""),
                                "datePremiere": employe.get("datePremiere", ""),
                                "posteService": employe.get("posteService", ""),
                                "tauxHoraire": employe.get("tauxHoraire", ""),
                                "dateCandidature": employe.get("dateCandidature", ""),
                                "motif_refus_coach": employe.get("motif_refus_coach", ""),
                                "motif_refus_comptable": employe.get("motif_refus_comptable", ""),
                                "date_refus_coach": employe.get("date_refus_coach", ""),
                                "date_refus_comptable": employe.get("date_refus_comptable", "")
                            }
                        })

        # Trier par date de derni√®re mise √† jour (les plus r√©cents d'abord)
        messages.sort(key=lambda x: x.get("dernierUpdate", ""), reverse=True)

        return {"messages": messages}

    except Exception as e:
        print(f"[ERROR] get_messages_refus_employes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Supprimer un employ√© nouveau (annuler apr√®s refus)
@app.delete("/api/employes/{username}/supprimer-nouveau/{employe_id}")
async def supprimer_employe_nouveau(username: str, employe_id: str):
    """Supprime un employ√© de la liste des nouveaux (utilis√© apr√®s un refus)"""
    try:
        employes_nouveaux = load_employes(username, "nouveaux")

        # Trouver et supprimer l'employ√©
        employe_trouve = False
        for i, employe in enumerate(employes_nouveaux):
            if employe.get("id") == employe_id:
                employes_nouveaux.pop(i)
                employe_trouve = True
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Sauvegarder la liste mise √† jour
        if save_employes(username, "nouveaux", employes_nouveaux):
            return {"success": True, "message": "Employ√© supprim√© avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Servir les documents des employ√©s
@app.get("/api/employes/{username}/documents/{employe_id}/{filename}")
async def get_employe_document(username: str, employe_id: str, filename: str):
    """Sert les documents (specimen, certificat, carte) d'un employ√©"""
    try:
        file_path = os.path.join(os.path.dirname(__file__), "data", "employes", username, employe_id, filename)

        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="Document non trouv√©")

        # D√©terminer le type MIME bas√© sur l'extension
        ext = os.path.splitext(filename)[1].lower()
        media_types = {
            '.pdf': 'application/pdf',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif'
        }
        media_type = media_types.get(ext, 'application/octet-stream')

        return FileResponse(file_path, media_type=media_type)
    except Exception as e:
        print(f"[ERROR] Erreur lors de la r√©cup√©ration du document: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Compter les employ√©s en attente de validation pour un coach (activations + inactivations)
@app.get("/api/coach/{coach_username}/employes-en-attente/count")
async def count_employes_en_attente(coach_username: str):
    """Compte le nombre total d'employ√©s en attente de validation pour les entrepreneurs du coach (activations + r√©activations + inactivations + modifications)"""
    try:
        total_activations = 0
        total_reactivations = 0
        total_inactivations = 0
        total_modifications = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0, "activations": 0, "reactivations": 0, "inactivations": 0, "modifications": 0}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Compter les nouveaux employ√©s en attente d'activation
                employes_nouveaux = load_employes(username, "nouveaux")
                for employe in employes_nouveaux:
                    if employe.get("statut") == "En attente de validation":
                        total_activations += 1

                # Compter les r√©activations en attente de validation coach
                # IMPORTANT: Chercher dans inactifs ET termines, pas dans reactivations.json
                # car le statut est mis √† jour dans ces fichiers, pas dans reactivations.json
                employes_inactifs = load_employes(username, "inactifs")
                for emp in employes_inactifs:
                    if emp.get("statut") == "R√©activation en attente de validation":
                        total_reactivations += 1

                employes_termines = load_employes(username, "termines")
                for emp in employes_termines:
                    if emp.get("statut") == "R√©activation en attente de validation":
                        total_reactivations += 1

                # Compter les inactivations en attente de validation coach
                inactivations = load_inactivations(username)
                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente de validation":
                        total_inactivations += 1

                # Compter les modifications en attente de validation coach
                employes_actifs = load_employes(username, "actifs")
                for employe in employes_actifs:
                    if employe.get("statut") == "Modification en attente de validation":
                        total_modifications += 1

        total = total_activations + total_reactivations + total_inactivations + total_modifications
        return {"success": True, "count": total, "activations": total_activations, "reactivations": total_reactivations, "inactivations": total_inactivations, "modifications": total_modifications}
    except Exception as e:
        print(f"Erreur lors du comptage des employ√©s en attente: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Compter les employ√©s refus√©s par coach (en attente de r√©ponse entrepreneur)
@app.get("/api/coach/employes-refuses-coach/count")
async def count_employes_refuses_coach():
    """Compte le nombre total d'employ√©s refus√©s par le coach en attente de r√©ponse de l'entrepreneur"""
    try:
        total_refuses = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Compter les employ√©s avec statut "Refus√© par coach" dans nouveaux
                employes_nouveaux = load_employes(username, "nouveaux")
                for employe in employes_nouveaux:
                    if employe.get("statut") == "Refus√© par coach":
                        total_refuses += 1

                # Compter aussi dans actifs (au cas o√π)
                employes_actifs = load_employes(username, "actifs")
                for employe in employes_actifs:
                    if employe.get("statut") == "Refus√© par coach":
                        total_refuses += 1

        return {"success": True, "count": total_refuses}
    except Exception as e:
        print(f"Erreur lors du comptage des employ√©s refus√©s par coach: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Lister tous les employ√©s en attente de validation pour un coach (activations + inactivations)
@app.get("/api/coach/{coach_username}/employes-en-attente/liste")
async def liste_employes_en_attente(coach_username: str):
    """Liste tous les employ√©s en attente de validation pour les entrepreneurs du coach (activations + inactivations)"""
    try:
        employes_en_attente = []
        inactivations_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "employes": [], "inactivations": []}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Charger les nouveaux employ√©s (activations)
                employes_nouveaux = load_employes(username, "nouveaux")

                # R√©cup√©rer ceux en attente de validation
                for employe in employes_nouveaux:
                    if employe.get("statut") == "En attente de validation":
                        # Ajouter le username de l'entrepreneur
                        employe_avec_info = employe.copy()
                        employe_avec_info["entrepreneur"] = username
                        employe_avec_info["entrepreneurUsername"] = username
                        employe_avec_info["requestType"] = "activation"
                        employes_en_attente.append(employe_avec_info)

                # Charger les inactivations en attente de validation coach
                inactivations = load_inactivations(username)
                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente de validation":
                        inact_avec_info = inact.copy()
                        inact_avec_info["entrepreneur"] = username
                        inact_avec_info["entrepreneurUsername"] = username
                        inact_avec_info["requestType"] = "inactivation"
                        inactivations_en_attente.append(inact_avec_info)

        return {"success": True, "employes": employes_en_attente, "inactivations": inactivations_en_attente}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des employ√©s en attente: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Lister toutes les modifications en attente de validation pour un coach
@app.get("/api/coach/{coach_username}/modifications-en-attente/liste")
async def liste_modifications_en_attente(coach_username: str):
    """Liste toutes les modifications d'employ√©s en attente de validation pour les entrepreneurs du coach"""
    try:
        modifications_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "modifications": []}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Charger les employ√©s actifs avec statut "Modification en attente de validation"
                employes_actifs = load_employes(username, "actifs")
                modifications = load_modifications(username)

                for employe in employes_actifs:
                    if employe.get("statut") == "Modification en attente de validation":
                        # Trouver les donn√©es de modification correspondantes
                        modif_data = None
                        for m in modifications:
                            if m.get("employe_id") == employe.get("id"):
                                modif_data = m
                                break

                        modif_avec_info = employe.copy()
                        modif_avec_info["entrepreneur"] = username
                        modif_avec_info["entrepreneurUsername"] = username
                        modif_avec_info["requestType"] = "modification"

                        # Ajouter les donn√©es anciennes/nouvelles si disponibles
                        if modif_data:
                            modif_avec_info["anciennes_donnees"] = modif_data.get("anciennes_donnees", {})
                            modif_avec_info["nouvelles_donnees"] = modif_data.get("nouvelles_donnees", {})

                        modifications_en_attente.append(modif_avec_info)

        return {"success": True, "modifications": modifications_en_attente}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des modifications en attente: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Compter les facturations en traitement pour un coach
@app.get("/api/coach/{coach_username}/facturation-en-traitement/count")
async def count_facturation_en_traitement(coach_username: str):
    """Compte le nombre total de facturations en traitement pour les entrepreneurs du coach (depot, paiement_final, autres_paiements, remboursements)"""
    try:
        total_count = 0
        details_par_entrepreneur = {}
        statuts_dir = os.path.join(base_cloud, "facturation_qe_statuts")

        if not os.path.exists(statuts_dir):
            return {"success": True, "count": 0, "details": {}}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            entrepreneur_count = 0

            # Compter les paiements en traitement
            user_path = os.path.join(statuts_dir, username)
            if os.path.isdir(user_path):
                statuts_file = os.path.join(user_path, "statuts_clients.json")
                if os.path.exists(statuts_file):
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    for num_soumission, client_statuts in statuts.items():
                        # V√©rifier si le client a un paiement refus√© (urgent)
                        # Si oui, ne pas compter ses paiements "traitement" car il est dans la colonne Urgent
                        statut_depot = client_statuts.get("statutDepot")
                        statut_paiement_final = client_statuts.get("statutPaiementFinal")
                        autres_paiements = client_statuts.get("autresPaiements", [])

                        # V√©rifier si un paiement est refus√©
                        depot_refuse = statut_depot == "refuse"
                        paiement_final_refuse = statut_paiement_final == "refuse"
                        autres_refuses = any(p.get("statut") == "refuse" for p in autres_paiements) if isinstance(autres_paiements, list) else False
                        a_paiement_refuse = depot_refuse or paiement_final_refuse or autres_refuses

                        # Si le client a un paiement refus√©, ne pas compter (il est dans Urgent)
                        if a_paiement_refuse:
                            continue

                        # Compter depot en traitement
                        if statut_depot == "traitement":
                            entrepreneur_count += 1
                            total_count += 1
                        # Compter paiement final en traitement
                        if statut_paiement_final == "traitement":
                            entrepreneur_count += 1
                            total_count += 1
                        # Compter autres paiements en traitement
                        if client_statuts.get("statutAutresPaiements") == "traitement":
                            entrepreneur_count += 1
                            total_count += 1

            # Compter les remboursements en attente validation coach
            remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
            if os.path.exists(remb_file):
                with open(remb_file, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        remboursements = json.loads(content)
                        remb_en_attente = sum(1 for r in remboursements if r.get("statut") == "en_attente_coach")
                        entrepreneur_count += remb_en_attente
                        total_count += remb_en_attente
                        print(f"[COACH NOTIF] {username}: {remb_en_attente} remboursements en attente coach")

            if entrepreneur_count > 0:
                details_par_entrepreneur[username] = entrepreneur_count

        return {"success": True, "count": total_count, "details": details_par_entrepreneur}
    except Exception as e:
        print(f"Erreur lors du comptage des facturations en traitement: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Lister toutes les facturations en traitement pour un coach
@app.get("/api/coach/facturation-en-traitement/liste")
async def liste_facturation_en_traitement():
    """Liste toutes les facturations en traitement avec les infos de l'entrepreneur"""
    try:
        facturations_en_traitement = []
        statuts_dir = os.path.join(base_cloud, "facturation_qe_statuts")

        if not os.path.exists(statuts_dir):
            return {"success": True, "facturations": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(statuts_dir):
            user_path = os.path.join(statuts_dir, username)
            if os.path.isdir(user_path):
                statuts_file = os.path.join(user_path, "statuts_clients.json")
                if os.path.exists(statuts_file):
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    for num_soumission, client_statuts in statuts.items():
                        # Depot en traitement
                        if client_statuts.get("statutDepot") == "traitement":
                            facturations_en_traitement.append({
                                "entrepreneur": username,
                                "numeroSoumission": num_soumission,
                                "type": "depot",
                                "statut": "traitement",
                                "details": client_statuts.get("depot", {}),
                                "dateMiseAJour": client_statuts.get("dateMiseAJour")
                            })
                        # Paiement final en traitement
                        if client_statuts.get("statutPaiementFinal") == "traitement":
                            facturations_en_traitement.append({
                                "entrepreneur": username,
                                "numeroSoumission": num_soumission,
                                "type": "paiement_final",
                                "statut": "traitement",
                                "details": client_statuts.get("paiementFinal", {}),
                                "dateMiseAJour": client_statuts.get("dateMiseAJour")
                            })
                        # Autres paiements en traitement
                        if client_statuts.get("statutAutresPaiements") == "traitement":
                            facturations_en_traitement.append({
                                "entrepreneur": username,
                                "numeroSoumission": num_soumission,
                                "type": "autres_paiements",
                                "statut": "traitement",
                                "details": client_statuts.get("autresPaiements", []),
                                "dateMiseAJour": client_statuts.get("dateMiseAJour")
                            })

        return {"success": True, "facturations": facturations_en_traitement}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des facturations en traitement: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Route Coach pour valider un paiement (passe en attente_comptable)
@app.post("/api/coach/facturation/{username}/{numero_soumission}/valider")
async def valider_facturation_coach(username: str, numero_soumission: str, request: Request):
    """Coach valide un paiement - passe de 'traitement' √† 'attente_comptable'"""
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")

        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # Mettre √† jour le statut vers attente_comptable selon le type
        if type_paiement == "depot":
            statuts[numero_soumission]["statutDepot"] = "attente_comptable"
            if "depot" in statuts[numero_soumission]:
                statuts[numero_soumission]["depot"]["statut"] = "attente_comptable"
        elif type_paiement == "paiement_final":
            statuts[numero_soumission]["statutPaiementFinal"] = "attente_comptable"
            if "paiementFinal" in statuts[numero_soumission]:
                statuts[numero_soumission]["paiementFinal"]["statut"] = "attente_comptable"
        elif type_paiement == "autres_paiements":
            index = data.get("index", 0)
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                statuts[numero_soumission]["autresPaiements"][index]["statut"] = "attente_comptable"
            # V√©rifier si tous les autres paiements sont en attente_comptable
            all_attente = all(ap.get("statut") == "attente_comptable" for ap in statuts[numero_soumission].get("autresPaiements", []))
            if all_attente:
                statuts[numero_soumission]["statutAutresPaiements"] = "attente_comptable"

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Paiement valid√© par le coach - en attente de validation comptable"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la validation coach: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Route Coach pour refuser un paiement
@app.post("/api/coach/facturation/{username}/{numero_soumission}/refuser")
async def refuser_facturation_coach(username: str, numero_soumission: str, request: Request):
    """Coach refuse un paiement - passe de 'traitement' √† 'refuse' avec raison"""
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")
        raison = data.get("raison", "")

        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # R√©cup√©rer le nom de celui qui refuse
        nom_refuseur = data.get("nomRefuseur", "")

        # Cr√©er l'objet de refus avec raison et conversation
        refus_info = {
            "raison": raison,
            "refusePar": "coach",
            "nomRefusePar": nom_refuseur,
            "dateRefus": datetime.now().isoformat(),
            "conversation": [
                {
                    "de": "coach",
                    "nom": nom_refuseur,
                    "message": raison,
                    "date": datetime.now().isoformat()
                }
            ]
        }

        # Stocker le refus au niveau racine pour l'affichage frontend
        statuts[numero_soumission]["refus"] = refus_info

        # Mettre √† jour le statut vers refuse selon le type
        if type_paiement == "depot":
            statuts[numero_soumission]["statutDepot"] = "refuse"
            statuts[numero_soumission]["dateDepot"] = datetime.now().isoformat()
            if "depot" in statuts[numero_soumission]:
                statuts[numero_soumission]["depot"]["statut"] = "refuse"
                statuts[numero_soumission]["depot"]["refus"] = refus_info
        elif type_paiement == "paiement_final":
            statuts[numero_soumission]["statutPaiementFinal"] = "refuse"
            statuts[numero_soumission]["datePaiementFinal"] = datetime.now().isoformat()
            if "paiementFinal" in statuts[numero_soumission]:
                statuts[numero_soumission]["paiementFinal"]["statut"] = "refuse"
                statuts[numero_soumission]["paiementFinal"]["refus"] = refus_info
        elif type_paiement == "autres_paiements":
            index = data.get("index", 0)
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                statuts[numero_soumission]["autresPaiements"][index]["statut"] = "refuse"
                statuts[numero_soumission]["autresPaiements"][index]["refus"] = refus_info
            statuts[numero_soumission]["statutAutresPaiements"] = "refuse"
            statuts[numero_soumission]["dateAutresPaiements"] = datetime.now().isoformat()

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Paiement refus√© par le coach"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors du refus coach: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# ENDPOINTS COACH - GESTION T√ÇCHES RPO
# ============================================

@app.get("/api/coach/tasks")
async def get_coach_tasks(coach_username: str, include_all: bool = False):
    """R√©cup√®re toutes les t√¢ches d'un coach depuis son fichier tasks.json
    Si include_all=True (pour direction), retourne toutes les t√¢ches de tous les utilisateurs"""
    try:
        tasks_dir = os.path.join(base_cloud, "coach_tasks")

        if include_all:
            # Pour les utilisateurs direction, charger toutes les t√¢ches
            all_tasks = []
            if os.path.exists(tasks_dir):
                for filename in os.listdir(tasks_dir):
                    if filename.endswith('_tasks.json'):
                        tasks_file = os.path.join(tasks_dir, filename)
                        try:
                            with open(tasks_file, "r", encoding="utf-8") as f:
                                user_tasks = json.load(f)
                                # √âviter les doublons en v√©rifiant les IDs
                                for task in user_tasks:
                                    if not any(t.get('id') == task.get('id') for t in all_tasks):
                                        all_tasks.append(task)
                        except Exception as e:
                            print(f"Erreur lors de la lecture de {filename}: {e}")
                            continue
            tasks = all_tasks
        else:
            # Pour les coaches, charger seulement leurs t√¢ches
            tasks_file = os.path.join(tasks_dir, f"{coach_username}_tasks.json")
            if not os.path.exists(tasks_file):
                return {"success": True, "tasks": []}

            with open(tasks_file, "r", encoding="utf-8") as f:
                tasks = json.load(f)

        # Enrichir chaque t√¢che avec le nom complet du cr√©ateur
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            for task in tasks:
                creator_username = task.get("created_by")
                if creator_username and not task.get("created_by_username"):
                    cursor.execute("""
                        SELECT prenom, nom
                        FROM users
                        WHERE username = ? AND is_active = 1
                    """, (creator_username,))
                    user = cursor.fetchone()

                    if user:
                        prenom = user[0]
                        nom = user[1]

                        # Construire le nom complet
                        full_name = ""
                        if prenom and nom:
                            full_name = f"{prenom} {nom}"
                        elif prenom:
                            full_name = prenom
                        elif nom:
                            full_name = nom

                        if full_name:
                            # Stocker √† la fois le username et le nom complet
                            task["created_by_username"] = creator_username
                            task["created_by"] = full_name

        return {"success": True, "tasks": tasks}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des t√¢ches: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/coach/tasks")
async def save_coach_task(request: Request):
    """Sauvegarde ou met √† jour une t√¢che pour tous les utilisateurs assign√©s"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        task = data.get("task")

        if not coach_username or not task:
            raise HTTPException(status_code=400, detail="coach_username et task requis")

        tasks_dir = os.path.join(base_cloud, "coach_tasks")
        os.makedirs(tasks_dir, exist_ok=True)

        # G√©n√©rer un ID si n√©cessaire
        if not task.get("id"):
            import uuid
            task["id"] = str(uuid.uuid4())

        # Ajouter le cr√©ateur de la t√¢che seulement s'il n'existe pas d√©j√†
        if not task.get("created_by"):
            task["created_by"] = coach_username

        # R√©cup√©rer la liste des utilisateurs assign√©s
        assigned_users = task.get("assignedUsers", [])

        print(f"[DEBUG] Saving task: id={task.get('id')}, created_by={task.get('created_by')}, assigned_users={len(assigned_users)}", flush=True)

        # Si aucun utilisateur n'est assign√©, assigner seulement au cr√©ateur
        if not assigned_users:
            assigned_users = [{
                "username": coach_username,
                "role": "direction"
            }]
            task["assignedUsers"] = assigned_users

        # Sauvegarder la t√¢che pour CHAQUE utilisateur assign√©
        for user in assigned_users:
            username = user.get("username")
            if not username:
                continue

            tasks_file = os.path.join(tasks_dir, f"{username}_tasks.json")

            # Charger les t√¢ches existantes pour cet utilisateur
            tasks = []
            if os.path.exists(tasks_file):
                with open(tasks_file, "r", encoding="utf-8") as f:
                    loaded_data = json.load(f)
                    # S'assurer que c'est une liste
                    if isinstance(loaded_data, list):
                        tasks = loaded_data
                    elif isinstance(loaded_data, dict):
                        # Si c'est un dict, le convertir en liste (cas d'ancien format)
                        print(f"[WARNING] Converting dict to list for {username}_tasks.json", flush=True)
                        tasks = []
                    else:
                        tasks = []

            # Si task_id existe, mettre √† jour, sinon cr√©er
            task_id = task.get("id")
            task_found = False
            for i, t in enumerate(tasks):
                if t.get("id") == task_id:
                    tasks[i] = task
                    task_found = True
                    break

            if not task_found:
                tasks.append(task)

            # Sauvegarder pour cet utilisateur
            with open(tasks_file, "w", encoding="utf-8") as f:
                json.dump(tasks, f, ensure_ascii=False, indent=2)

        return {"success": True, "task": task}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde de la t√¢che: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/coach/tasks")
async def delete_coach_task(request: Request):
    """Supprime une t√¢che pour tous les utilisateurs assign√©s"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        task_id = data.get("task_id")

        if not coach_username or not task_id:
            raise HTTPException(status_code=400, detail="coach_username et task_id requis")

        tasks_dir = os.path.join(base_cloud, "coach_tasks")
        tasks_file = os.path.join(tasks_dir, f"{coach_username}_tasks.json")

        if not os.path.exists(tasks_file):
            return {"success": True, "message": "Aucune t√¢che √† supprimer"}

        # Charger les t√¢ches du cr√©ateur pour r√©cup√©rer les utilisateurs assign√©s
        with open(tasks_file, "r", encoding="utf-8") as f:
            tasks = json.load(f)

        # Trouver la t√¢che √† supprimer pour r√©cup√©rer les utilisateurs assign√©s
        task_to_delete = None
        for t in tasks:
            if t.get("id") == task_id:
                task_to_delete = t
                break

        # Supprimer la t√¢che pour tous les utilisateurs assign√©s
        if task_to_delete:
            assigned_users = task_to_delete.get("assignedUsers", [])
            for user in assigned_users:
                username = user.get("username")
                if not username:
                    continue

                user_tasks_file = os.path.join(tasks_dir, f"{username}_tasks.json")
                if os.path.exists(user_tasks_file):
                    with open(user_tasks_file, "r", encoding="utf-8") as f:
                        user_tasks = json.load(f)

                    # Filtrer pour supprimer la t√¢che
                    user_tasks = [t for t in user_tasks if t.get("id") != task_id]

                    # Sauvegarder
                    with open(user_tasks_file, "w", encoding="utf-8") as f:
                        json.dump(user_tasks, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "T√¢che supprim√©e pour tous les utilisateurs assign√©s"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la suppression de la t√¢che: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/coach/tasks/complete")
async def complete_coach_task(request: Request):
    """Marque une t√¢che comme compl√©t√©e et la d√©place dans l'historique pour tous les utilisateurs assign√©s"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        task_id = data.get("task_id")

        if not coach_username or not task_id:
            raise HTTPException(status_code=400, detail="coach_username et task_id requis")

        tasks_dir = os.path.join(base_cloud, "coach_tasks")
        os.makedirs(tasks_dir, exist_ok=True)

        tasks_file = os.path.join(tasks_dir, f"{coach_username}_tasks.json")

        # Charger les t√¢ches actuelles
        tasks = []
        if os.path.exists(tasks_file):
            with open(tasks_file, "r", encoding="utf-8") as f:
                tasks = json.load(f)

        # Trouver la t√¢che √† compl√©ter
        task_to_complete = None
        for task in tasks:
            if task.get("id") == task_id:
                task_to_complete = task
                task_to_complete["completed_at"] = datetime.now().isoformat()
                break

        if not task_to_complete:
            raise HTTPException(status_code=404, detail="T√¢che non trouv√©e")

        # R√©cup√©rer les utilisateurs assign√©s
        assigned_users = task_to_complete.get("assignedUsers", [])

        # Marquer comme compl√©t√©e pour tous les utilisateurs assign√©s
        for user in assigned_users:
            username = user.get("username")
            if not username:
                continue

            user_tasks_file = os.path.join(tasks_dir, f"{username}_tasks.json")
            user_history_file = os.path.join(tasks_dir, f"{username}_history.json")

            # Charger les t√¢ches de l'utilisateur
            user_tasks = []
            if os.path.exists(user_tasks_file):
                with open(user_tasks_file, "r", encoding="utf-8") as f:
                    user_tasks = json.load(f)

            # Retirer la t√¢che des t√¢ches actives
            remaining_tasks = [t for t in user_tasks if t.get("id") != task_id]

            # Sauvegarder les t√¢ches restantes
            with open(user_tasks_file, "w", encoding="utf-8") as f:
                json.dump(remaining_tasks, f, ensure_ascii=False, indent=2)

            # Charger l'historique existant
            history = []
            if os.path.exists(user_history_file):
                with open(user_history_file, "r", encoding="utf-8") as f:
                    history = json.load(f)

            # Ajouter la t√¢che √† l'historique (au d√©but de la liste)
            history.insert(0, task_to_complete)

            # Limiter l'historique aux 50 derni√®res t√¢ches
            history = history[:50]

            # Sauvegarder l'historique
            with open(user_history_file, "w", encoding="utf-8") as f:
                json.dump(history, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "T√¢che compl√©t√©e et archiv√©e pour tous les utilisateurs assign√©s"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la compl√©tion de la t√¢che: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/tasks/history")
async def get_coach_tasks_history(coach_username: str, include_all: bool = False):
    """R√©cup√®re l'historique des t√¢ches compl√©t√©es d'un coach
    Si include_all=True (pour direction), retourne l'historique de tous les utilisateurs"""
    try:
        tasks_dir = os.path.join(base_cloud, "coach_tasks")

        if include_all:
            # Pour les utilisateurs direction, charger tout l'historique
            all_history = []
            if os.path.exists(tasks_dir):
                for filename in os.listdir(tasks_dir):
                    if filename.endswith('_history.json'):
                        history_file = os.path.join(tasks_dir, filename)
                        try:
                            with open(history_file, "r", encoding="utf-8") as f:
                                user_history = json.load(f)
                                # √âviter les doublons en v√©rifiant les IDs
                                for task in user_history:
                                    if not any(t.get('id') == task.get('id') for t in all_history):
                                        all_history.append(task)
                        except Exception as e:
                            print(f"Erreur lors de la lecture de {filename}: {e}")
                            continue
            # Trier par date de compl√©tion (plus r√©cent en premier)
            all_history.sort(key=lambda x: x.get('completed_at', ''), reverse=True)
            return all_history[:100]  # Limiter √† 100 t√¢ches
        else:
            # Pour les coaches, charger seulement leur historique
            history_file = os.path.join(tasks_dir, f"{coach_username}_history.json")

            if not os.path.exists(history_file):
                return []

            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)

            return history
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration de l'historique: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# ENDPOINTS COACH - PROBL√àMES HEBDOMADAIRES (RPO)
# ============================================

@app.get("/api/coach/weekly-problem")
async def get_weekly_problem(coach_username: str, week: str):
    """R√©cup√®re le probl√®me hebdomadaire pour un coach et une semaine donn√©e"""
    try:
        problems_dir = os.path.join(base_cloud, "coach_weekly_problems")
        os.makedirs(problems_dir, exist_ok=True)

        problems_file = os.path.join(problems_dir, f"{coach_username}_problems.json")

        if not os.path.exists(problems_file):
            return {"success": True, "problem": None}

        with open(problems_file, "r", encoding="utf-8") as f:
            all_problems = json.load(f)

        # Trouver le probl√®me pour la semaine sp√©cifi√©e
        problem = next((p for p in all_problems if p.get("week") == week), None)

        return {"success": True, "problem": problem}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration du probl√®me hebdomadaire: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/coach/weekly-problem")
async def save_weekly_problem(request: Request):
    """Sauvegarde ou met √† jour le probl√®me hebdomadaire pour un coach"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        week = data.get("week")
        description = data.get("description", "")
        impact = data.get("impact", "")
        solution = data.get("solution", "")

        if not coach_username or not week:
            raise HTTPException(status_code=400, detail="coach_username et week sont requis")

        problems_dir = os.path.join(base_cloud, "coach_weekly_problems")
        os.makedirs(problems_dir, exist_ok=True)

        problems_file = os.path.join(problems_dir, f"{coach_username}_problems.json")

        # Charger les probl√®mes existants ou cr√©er un nouveau fichier
        if os.path.exists(problems_file):
            with open(problems_file, "r", encoding="utf-8") as f:
                all_problems = json.load(f)
        else:
            all_problems = []

        # Chercher si un probl√®me existe d√©j√† pour cette semaine
        existing_index = next((i for i, p in enumerate(all_problems) if p.get("week") == week), None)

        problem_data = {
            "week": week,
            "description": description,
            "impact": impact,
            "solution": solution,
            "updated_at": datetime.now().isoformat()
        }

        if existing_index is not None:
            # Mettre √† jour le probl√®me existant
            all_problems[existing_index] = problem_data
        else:
            # Ajouter un nouveau probl√®me
            problem_data["created_at"] = datetime.now().isoformat()
            all_problems.append(problem_data)

        # Sauvegarder
        with open(problems_file, "w", encoding="utf-8") as f:
            json.dump(all_problems, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Probl√®me hebdomadaire sauvegard√©"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde du probl√®me hebdomadaire: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/coach/macro-micro-problem")
async def save_macro_micro_problem(request: Request):
    """Sauvegarde MACRO, MICRO et Probl√®me pour un coach et une semaine"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        week = data.get("week")
        macro = data.get("macro", "")
        micro = data.get("micro", "")
        problem = data.get("problem", "")

        if not coach_username:
            raise HTTPException(status_code=400, detail="coach_username est requis")
        if not week:
            raise HTTPException(status_code=400, detail="week est requis")

        data_dir = os.path.join(base_cloud, "coach_macro_micro")
        os.makedirs(data_dir, exist_ok=True)

        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        save_data = {
            "coach_username": coach_username,
            "week": week,
            "macro": macro,
            "micro": micro,
            "problem": problem,
            "updated_at": datetime.now().isoformat()
        }

        # Sauvegarder
        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "MACRO/MICRO/Probl√®me sauvegard√©s"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde MACRO/MICRO/Probl√®me: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/macro-micro-problem")
async def get_macro_micro_problem(coach_username: str, week: str):
    """R√©cup√®re MACRO, MICRO et Probl√®me pour un coach et une semaine"""
    try:
        data_dir = os.path.join(base_cloud, "coach_macro_micro")
        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        if not os.path.exists(data_file):
            return {"macro": "", "micro": "", "problem": ""}

        with open(data_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        return data
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration MACRO/MICRO/Probl√®me: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/available-entrepreneurs")
async def get_available_entrepreneurs(coach_username: str, week: str, all: bool = False):
    """Retourne les entrepreneurs du coach (tous si all=true, sinon ceux sans suivi cette semaine)"""
    try:
        # R√©cup√©rer tous les entrepreneurs du coach (retourne maintenant des dicts avec full_name)
        all_entrepreneurs = get_entrepreneurs_for_coach(coach_username)

        if all:
            # Retourner tous les entrepreneurs avec leur full_name
            entrepreneurs_data = all_entrepreneurs
        else:
            # R√©cup√©rer les suivis d√©j√† effectu√©s cette semaine
            data_dir = os.path.join(base_cloud, "coach_weekly_entrepreneur_data")
            data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

            followed_entrepreneurs = set()
            if os.path.exists(data_file):
                with open(data_file, "r", encoding="utf-8") as f:
                    entries = json.load(f)
                    followed_entrepreneurs = {entry.get("entrepreneur_username") for entry in entries if entry.get("entrepreneur_username")}

            # Filtrer pour ne garder que ceux sans suivi
            entrepreneurs_data = [e for e in all_entrepreneurs if e["username"] not in followed_entrepreneurs]

        # Ajouter display_name pour compatibilit√© avec le frontend
        for entrepreneur in entrepreneurs_data:
            entrepreneur["display_name"] = entrepreneur.get("full_name", entrepreneur["username"])

        print(f"[AVAILABLE ENTREPRENEURS] Coach {coach_username}, semaine {week}: {len(entrepreneurs_data)} disponibles")
        return {"entrepreneurs": entrepreneurs_data}

    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des entrepreneurs disponibles: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/weekly-entrepreneur-data")
async def get_weekly_entrepreneur_data(coach_username: str, week: str):
    """R√©cup√®re les donn√©es hebdomadaires des entrepreneurs pour un coach et une semaine"""
    try:
        data_dir = os.path.join(base_cloud, "coach_weekly_entrepreneur_data")
        os.makedirs(data_dir, exist_ok=True)

        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        if not os.path.exists(data_file):
            return {"success": True, "entries": []}

        with open(data_file, "r", encoding="utf-8") as f:
            entries = json.load(f)

        return {"success": True, "entries": entries}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des donn√©es hebdomadaires: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/coach/weekly-entrepreneur-data")
async def save_weekly_entrepreneur_data(request: Request):
    """Sauvegarde ou met √† jour une entr√©e hebdomadaire entrepreneur"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        week = data.get("week")
        entry_id = data.get("id")

        if not coach_username or not week:
            raise HTTPException(status_code=400, detail="coach_username et week sont requis")

        data_dir = os.path.join(base_cloud, "coach_weekly_entrepreneur_data")
        os.makedirs(data_dir, exist_ok=True)

        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        # Charger les entr√©es existantes ou cr√©er un nouveau fichier
        if os.path.exists(data_file):
            with open(data_file, "r", encoding="utf-8") as f:
                entries = json.load(f)
        else:
            entries = []

        # Chercher si une entr√©e existe d√©j√† avec cet ID
        existing_index = next((i for i, e in enumerate(entries) if e.get("id") == entry_id), None)

        entry_data = {
            "id": entry_id,
            "entrepreneur_username": data.get("entrepreneur_username", ""),
            "week_label": data.get("week_label", ""),
            "objectif_hpap": data.get("objectif_hpap", ""),
            "objectif_estims": data.get("objectif_estims", ""),
            "objectif_vendu": data.get("objectif_vendu", ""),
            "probleme_semaine": data.get("probleme_semaine", ""),
            "racine_probleme": data.get("racine_probleme", ""),
            "source_probleme": data.get("source_probleme", ""),
            "type_coaching": data.get("type_coaching", ""),
            "plan_match": data.get("plan_match", ""),
            "updated_at": datetime.now().isoformat()
        }

        if existing_index is not None:
            # Mettre √† jour l'entr√©e existante
            entries[existing_index] = entry_data
        else:
            # Ajouter une nouvelle entr√©e
            entry_data["created_at"] = datetime.now().isoformat()
            entries.append(entry_data)

        # Sauvegarder
        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(entries, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Entr√©e hebdomadaire sauvegard√©e"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde de l'entr√©e hebdomadaire: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/coach/weekly-entrepreneur-data")
async def delete_weekly_entrepreneur_data(request: Request):
    """Supprime une entr√©e hebdomadaire entrepreneur"""
    try:
        data = await request.json()
        coach_username = data.get("coach_username")
        week = data.get("week")
        entry_id = data.get("entry_id")

        if not coach_username or not week or not entry_id:
            raise HTTPException(status_code=400, detail="coach_username, week et entry_id sont requis")

        data_dir = os.path.join(base_cloud, "coach_weekly_entrepreneur_data")
        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        if not os.path.exists(data_file):
            return {"success": True, "message": "Aucune donn√©e √† supprimer"}

        # Charger les entr√©es existantes
        with open(data_file, "r", encoding="utf-8") as f:
            entries = json.load(f)

        # Filtrer pour retirer l'entr√©e √† supprimer
        entries = [e for e in entries if e.get("id") != entry_id]

        # Sauvegarder
        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(entries, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Entr√©e supprim√©e"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la suppression de l'entr√©e: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/entrepreneur-rpo-complet")
async def get_entrepreneur_rpo_complet(entrepreneur_username: str):
    """R√©cup√®re le RPO complet d'un entrepreneur (objectifs + r√©sum√©)"""
    try:
        from QE.Backend.rpo import load_user_rpo_data

        # R√©cup√©rer les donn√©es RPO de l'entrepreneur en utilisant le module RPO
        rpo_data = load_user_rpo_data(entrepreneur_username)

        return {
            "success": True,
            "entrepreneur_username": entrepreneur_username,
            "rpo_data": rpo_data
        }
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration du RPO complet: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/entrepreneur-rpo-data")
async def get_entrepreneur_rpo_data(username: str):
    """R√©cup√®re les donn√©es RPO hebdomadaires d'un entrepreneur pour le modal coach"""
    try:
        from QE.Backend.rpo import load_user_rpo_data

        # R√©cup√©rer les donn√©es RPO de l'entrepreneur en utilisant le module RPO
        rpo_data = load_user_rpo_data(username)

        # Retourner les donn√©es hebdomadaires, mensuelles et annuelles
        return {
            "weekly": rpo_data.get("weekly", {}),
            "monthly": rpo_data.get("monthly", {}),
            "annual": rpo_data.get("annual", {})
        }
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration du RPO: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/entrepreneur/weekly-data")
async def get_entrepreneur_weekly_data_for_week(username: str, week: str):
    """R√©cup√®re les donn√©es RPO hebdomadaires d'un entrepreneur pour une semaine sp√©cifique"""
    try:
        from QE.Backend.coach_access import get_coach_for_entrepreneur

        # Trouver le coach de l'entrepreneur
        coach_username = get_coach_for_entrepreneur(username)

        if not coach_username:
            return {"has_data": False, "data": None}

        # Charger les donn√©es hebdomadaires du coach pour cette semaine
        data_dir = os.path.join(base_cloud, "coach_weekly_entrepreneur_data")
        data_file = os.path.join(data_dir, f"{coach_username}_{week}.json")

        if not os.path.exists(data_file):
            return {"has_data": False, "data": None}

        with open(data_file, "r", encoding="utf-8") as f:
            entries = json.load(f)

        # Filtrer pour l'entrepreneur sp√©cifique
        entrepreneur_data = None
        for entry in entries:
            if entry.get("entrepreneur_username") == username:
                entrepreneur_data = entry
                break

        if entrepreneur_data:
            return {"has_data": True, "data": entrepreneur_data}
        else:
            return {"has_data": False, "data": None}

    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des donn√©es hebdomadaires entrepreneur: {e}")
        return {"has_data": False, "data": None}

@app.get("/api/coach/entrepreneurs")
async def get_coach_entrepreneurs_list(coach_username: str):
    """R√©cup√®re la liste des entrepreneurs assign√©s √† un coach"""
    try:
        from QE.Backend.coach_access import get_entrepreneurs_for_coach
        entrepreneurs = get_entrepreneurs_for_coach(coach_username)
        return {"entrepreneurs": entrepreneurs}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des entrepreneurs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/direction/all-entrepreneurs")
async def get_all_entrepreneurs_list():
    """R√©cup√®re la liste de TOUS les entrepreneurs (pour Direction)"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute("""
                SELECT username, prenom, nom, photo_url
                FROM users
                WHERE role = 'entrepreneur' AND is_active = 1
            """)

            results = cursor.fetchall()
            entrepreneurs = []

            for row in results:
                entrepreneurs.append({
                    "username": row["username"],
                    "prenom": row["prenom"] or "",
                    "nom": row["nom"] or "",
                    "full_name": f"{row['prenom'] or ''} {row['nom'] or ''}".strip() or row["username"],
                    "photo_url": row["photo_url"] or ""
                })

            print(f"[DIRECTION] Total entrepreneurs actifs: {len(entrepreneurs)}")
            return {"entrepreneurs": entrepreneurs}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration de tous les entrepreneurs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/rpo/available-weeks")
def get_available_weeks():
    """
    Retourne toutes les semaines disponibles dans le syst√®me RPO.
    Format: liste de {week_label, start_date, end_date, month_index, week_number}
    IMPORTANT: Cette route doit √™tre d√©finie AVANT /api/rpo/{username} pour √©viter le conflit!
    """
    from datetime import datetime, timezone, timedelta

    # Liste des semaines de janvier √† d√©cembre 2026
    weeks = []

    # D√©finir les semaines manuellement bas√©es sur la structure RPO
    all_weeks = [
        # Mois 0 (Janvier 2026)
        {"month_index": 0, "week_number": 1, "week_label": "5 - 11 janv", "start": "2026-01-05", "end": "2026-01-11"},
        {"month_index": 0, "week_number": 2, "week_label": "12 - 18 janv", "start": "2026-01-12", "end": "2026-01-18"},
        {"month_index": 0, "week_number": 3, "week_label": "19 - 25 janv", "start": "2026-01-19", "end": "2026-01-25"},
        {"month_index": 0, "week_number": 4, "week_label": "26 janv - 1 f√©vr", "start": "2026-01-26", "end": "2026-02-01"},
        # Mois 1 (F√©vrier 2026)
        {"month_index": 1, "week_number": 1, "week_label": "2 - 8 f√©vr", "start": "2026-02-02", "end": "2026-02-08"},
        {"month_index": 1, "week_number": 2, "week_label": "9 - 15 f√©vr", "start": "2026-02-09", "end": "2026-02-15"},
        {"month_index": 1, "week_number": 3, "week_label": "16 - 22 f√©vr", "start": "2026-02-16", "end": "2026-02-22"},
        {"month_index": 1, "week_number": 4, "week_label": "23 f√©vr - 1 mars", "start": "2026-02-23", "end": "2026-03-01"},
        # Mois 2 (Mars 2026)
        {"month_index": 2, "week_number": 1, "week_label": "2 - 8 mars", "start": "2026-03-02", "end": "2026-03-08"},
        {"month_index": 2, "week_number": 2, "week_label": "9 - 15 mars", "start": "2026-03-09", "end": "2026-03-15"},
        {"month_index": 2, "week_number": 3, "week_label": "16 - 22 mars", "start": "2026-03-16", "end": "2026-03-22"},
        {"month_index": 2, "week_number": 4, "week_label": "23 - 29 mars", "start": "2026-03-23", "end": "2026-03-29"},
        {"month_index": 2, "week_number": 5, "week_label": "30 mars - 5 avr", "start": "2026-03-30", "end": "2026-04-05"},
        # Mois 3 (Avril 2026)
        {"month_index": 3, "week_number": 1, "week_label": "6 - 12 avr", "start": "2026-04-06", "end": "2026-04-12"},
        {"month_index": 3, "week_number": 2, "week_label": "13 - 19 avr", "start": "2026-04-13", "end": "2026-04-19"},
        {"month_index": 3, "week_number": 3, "week_label": "20 - 26 avr", "start": "2026-04-20", "end": "2026-04-26"},
        {"month_index": 3, "week_number": 4, "week_label": "27 avr - 3 mai", "start": "2026-04-27", "end": "2026-05-03"},
        # Mois 4 (Mai 2026)
        {"month_index": 4, "week_number": 1, "week_label": "4 - 10 mai", "start": "2026-05-04", "end": "2026-05-10"},
        {"month_index": 4, "week_number": 2, "week_label": "11 - 17 mai", "start": "2026-05-11", "end": "2026-05-17"},
        {"month_index": 4, "week_number": 3, "week_label": "18 - 24 mai", "start": "2026-05-18", "end": "2026-05-24"},
        {"month_index": 4, "week_number": 4, "week_label": "25 - 31 mai", "start": "2026-05-25", "end": "2026-05-31"},
        # Mois 5 (Juin 2026)
        {"month_index": 5, "week_number": 1, "week_label": "1 - 7 juin", "start": "2026-06-01", "end": "2026-06-07"},
        {"month_index": 5, "week_number": 2, "week_label": "8 - 14 juin", "start": "2026-06-08", "end": "2026-06-14"},
        {"month_index": 5, "week_number": 3, "week_label": "15 - 21 juin", "start": "2026-06-15", "end": "2026-06-21"},
        {"month_index": 5, "week_number": 4, "week_label": "22 - 28 juin", "start": "2026-06-22", "end": "2026-06-28"},
        {"month_index": 5, "week_number": 5, "week_label": "29 juin - 5 juil", "start": "2026-06-29", "end": "2026-07-05"},
        # Mois 6 (Juillet 2026)
        {"month_index": 6, "week_number": 1, "week_label": "6 - 12 juil", "start": "2026-07-06", "end": "2026-07-12"},
        {"month_index": 6, "week_number": 2, "week_label": "13 - 19 juil", "start": "2026-07-13", "end": "2026-07-19"},
        {"month_index": 6, "week_number": 3, "week_label": "20 - 26 juil", "start": "2026-07-20", "end": "2026-07-26"},
        {"month_index": 6, "week_number": 4, "week_label": "27 juil - 2 ao√ªt", "start": "2026-07-27", "end": "2026-08-02"},
        # Mois 7 (Ao√ªt 2026)
        {"month_index": 7, "week_number": 1, "week_label": "3 - 9 ao√ªt", "start": "2026-08-03", "end": "2026-08-09"},
        {"month_index": 7, "week_number": 2, "week_label": "10 - 16 ao√ªt", "start": "2026-08-10", "end": "2026-08-16"},
        {"month_index": 7, "week_number": 3, "week_label": "17 - 23 ao√ªt", "start": "2026-08-17", "end": "2026-08-23"},
        {"month_index": 7, "week_number": 4, "week_label": "24 - 30 ao√ªt", "start": "2026-08-24", "end": "2026-08-30"},
        {"month_index": 7, "week_number": 5, "week_label": "31 ao√ªt - 6 sept", "start": "2026-08-31", "end": "2026-09-06"},
        # Mois 8 (Septembre 2026)
        {"month_index": 8, "week_number": 1, "week_label": "7 - 13 sept", "start": "2026-09-07", "end": "2026-09-13"},
        {"month_index": 8, "week_number": 2, "week_label": "14 - 20 sept", "start": "2026-09-14", "end": "2026-09-20"},
        {"month_index": 8, "week_number": 3, "week_label": "21 - 27 sept", "start": "2026-09-21", "end": "2026-09-27"},
        {"month_index": 8, "week_number": 4, "week_label": "28 sept - 4 oct", "start": "2026-09-28", "end": "2026-10-04"},
    ]

    # D√©terminer la semaine actuelle
    now = datetime.now(timezone.utc)
    current_week_index = -1

    for i, w in enumerate(all_weeks):
        start_date = datetime.strptime(w["start"], "%Y-%m-%d").replace(tzinfo=timezone.utc)
        end_date = datetime.strptime(w["end"], "%Y-%m-%d").replace(hour=23, minute=59, second=59, tzinfo=timezone.utc)
        if start_date <= now <= end_date:
            current_week_index = i
            break

    # Marquer la semaine actuelle
    for i, w in enumerate(all_weeks):
        w["is_current"] = (i == current_week_index)

    return {"weeks": all_weeks, "current_week_index": current_week_index}


@app.get("/api/rpo/data/{username}")
async def get_entrepreneur_rpo_data_full(username: str):
    """R√©cup√®re toutes les donn√©es RPO d'un entrepreneur"""
    try:
        from QE.Backend.rpo import load_user_rpo_data

        # Charger les donn√©es RPO en utilisant le module qui g√®re les chemins
        rpo_data = load_user_rpo_data(username)
        return rpo_data
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration du RPO complet: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/rpo/objectifs/{username}")
async def get_entrepreneur_objectifs(username: str):
    """R√©cup√®re les objectifs d'un entrepreneur depuis son fichier RPO"""
    try:
        from QE.Backend.rpo import load_user_rpo_data

        # Charger les donn√©es RPO en utilisant le module qui g√®re les chemins
        rpo_data = load_user_rpo_data(username)
        annual = rpo_data.get("annual", {})

        return {
            "objectif_ca": annual.get("objectif_ca", 0),
            "contrat_moyen": annual.get("cm_prevision", 2500),
            "ratio_mktg": annual.get("ratio_mktg", 85),
            "taux_vente": annual.get("taux_vente", 30),
            "taux_horaire": annual.get("taux_horaire", 43)
        }
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des objectifs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/coach/team-objectifs")
async def get_coach_team_objectifs(coach_username: str):
    """
    R√©cup√®re les pr√©visions d'objectifs pour l'√©quipe d'un coach

    Args:
        coach_username: Nom d'utilisateur du coach

    Returns:
        {
            "success": True,
            "previsions": {"entrepreneur1": 100000, "entrepreneur2": 150000},
            "total": 250000
        }
    """
    try:
        from QE.Backend.coach_previsions import load_coach_previsions, get_team_objectif_total

        previsions = load_coach_previsions(coach_username)
        total = get_team_objectif_total(coach_username)

        return {
            "success": True,
            "previsions": previsions,
            "total": total
        }
    except Exception as e:
        print(f"[COACH API] Erreur GET team-objectifs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class TeamObjectifsRequest(BaseModel):
    coach_username: str
    previsions: dict

@app.post("/api/coach/team-objectifs")
async def save_coach_team_objectifs(request: TeamObjectifsRequest):
    """
    Sauvegarde les pr√©visions d'objectifs pour l'√©quipe d'un coach

    Body:
        {
            "coach_username": "coach1",
            "previsions": {"entrepreneur1": 100000, "entrepreneur2": 150000}
        }

    Returns:
        {"success": True, "total": 250000}
    """
    try:
        from QE.Backend.coach_previsions import save_coach_previsions, get_team_objectif_total

        success = save_coach_previsions(request.coach_username, request.previsions)

        if success:
            total = get_team_objectif_total(request.coach_username)
            return {
                "success": True,
                "total": total
            }
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        print(f"[COACH API] Erreur POST team-objectifs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# ENDPOINTS DIRECTION - TEAM OBJECTIFS
# ============================================

@app.get("/api/direction/team-objectifs")
async def get_direction_team_objectifs(direction_username: str):
    """
    R√©cup√®re les pr√©visions d'objectifs pour les coaches (depuis la direction)

    Args:
        direction_username: Nom d'utilisateur de la direction

    Returns:
        {
            "success": True,
            "previsions": {"coach1": 100000, "coach2": 150000},
            "total": 250000
        }
    """
    try:
        from QE.Backend.direction_previsions import load_direction_previsions, get_direction_team_objectif_total

        previsions = load_direction_previsions(direction_username)
        total = get_direction_team_objectif_total(direction_username)

        return {
            "success": True,
            "previsions": previsions,
            "total": total
        }
    except Exception as e:
        print(f"[DIRECTION API] Erreur GET team-objectifs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class DirectionTeamObjectifsRequest(BaseModel):
    direction_username: str
    previsions: dict

@app.post("/api/direction/team-objectifs")
async def save_direction_team_objectifs(request: DirectionTeamObjectifsRequest):
    """
    Sauvegarde les pr√©visions d'objectifs pour les coaches (depuis la direction)

    Body:
        {
            "direction_username": "direction1",
            "previsions": {"coach1": 100000, "coach2": 150000}
        }

    Returns:
        {"success": True, "total": 250000}
    """
    try:
        from QE.Backend.direction_previsions import save_direction_previsions, get_direction_team_objectif_total

        success = save_direction_previsions(request.direction_username, request.previsions)

        if success:
            total = get_direction_team_objectif_total(request.direction_username)
            return {
                "success": True,
                "total": total
            }
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        print(f"[DIRECTION API] Erreur POST team-objectifs: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========== ENDPOINTS DIRECTION - M√âTRIQUES √âQUIPE (CM, RATIO MARKETING, TAUX DE VENTE) ==========

@app.get("/api/direction/team-metrics")
async def get_direction_team_metrics(direction_username: str):
    """
    R√©cup√®re les m√©triques d'√©quipe de la direction (valeur unique)

    Query params:
        direction_username: Nom d'utilisateur de la direction

    Returns:
        {
            "success": True,
            "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}
        }
    """
    try:
        from QE.Backend.direction_previsions import load_direction_metrics

        metrics = load_direction_metrics(direction_username)

        return {
            "success": True,
            "metrics": metrics
        }

    except Exception as e:
        print(f"[DIRECTION API] Erreur GET team-metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class DirectionTeamMetricsRequest(BaseModel):
    direction_username: str
    metrics: dict  # {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}


@app.post("/api/direction/team-metrics")
async def save_direction_team_metrics(request: DirectionTeamMetricsRequest):
    """
    Sauvegarde les m√©triques d'√©quipe de la direction (valeur unique)

    Body:
        {
            "direction_username": "direction1",
            "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}
        }

    Returns:
        {"success": True, "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}}
    """
    try:
        from QE.Backend.direction_previsions import save_direction_metrics

        success = save_direction_metrics(request.direction_username, request.metrics)

        if success:
            return {
                "success": True,
                "metrics": request.metrics
            }
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        print(f"[DIRECTION API] Erreur POST team-metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ====================================================
# ENDPOINTS DIRECTION - MACRO/MICRO/PROBL√àME
# ====================================================

@app.post("/api/direction/macro-micro-problem")
async def save_direction_macro_micro_problem(request: Request):
    """Sauvegarde MACRO, MICRO et Probl√®me pour la direction et une semaine"""
    try:
        data = await request.json()
        direction_username = data.get("direction_username")
        week = data.get("week")
        macro = data.get("macro", "")
        micro = data.get("micro", "")
        problem = data.get("problem", "")

        if not direction_username:
            raise HTTPException(status_code=400, detail="direction_username est requis")
        if not week:
            raise HTTPException(status_code=400, detail="week est requis")

        data_dir = os.path.join(base_cloud, "direction_macro_micro")
        os.makedirs(data_dir, exist_ok=True)

        data_file = os.path.join(data_dir, f"{direction_username}_{week}.json")

        save_data = {
            "direction_username": direction_username,
            "week": week,
            "macro": macro,
            "micro": micro,
            "problem": problem,
            "updated_at": datetime.now().isoformat()
        }

        # Sauvegarder
        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "MACRO/MICRO/Probl√®me sauvegard√©s"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde MACRO/MICRO/Probl√®me direction: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/direction/macro-micro-problem")
async def get_direction_macro_micro_problem(direction_username: str, week: str):
    """R√©cup√®re MACRO, MICRO et Probl√®me pour la direction et une semaine"""
    try:
        data_dir = os.path.join(base_cloud, "direction_macro_micro")
        data_file = os.path.join(data_dir, f"{direction_username}_{week}.json")

        if not os.path.exists(data_file):
            return {"macro": "", "micro": "", "problem": ""}

        with open(data_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        return data
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration MACRO/MICRO/Probl√®me direction: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ENDPOINTS DIRECTION - SUIVI HEBDOMADAIRE DES COACHES
# ============================================

@app.post("/api/direction/coach-weekly-data")
async def save_direction_coach_weekly_data(request: Request):
    """Sauvegarde les notes hebdomadaires pour un coach depuis la direction"""
    try:
        data = await request.json()
        unique_id = data.get("id")
        coach_username = data.get("coach_username")
        week_label = data.get("week_label")
        notes_hebdo = data.get("notes_hebdo", "")

        if not unique_id or not coach_username or not week_label:
            raise HTTPException(status_code=400, detail="id, coach_username et week_label requis")

        # Cr√©er le r√©pertoire pour les donn√©es direction
        data_dir = os.path.join(base_cloud, "direction_coach_weekly")
        os.makedirs(data_dir, exist_ok=True)

        # Fichier unique par coach + semaine
        data_file = os.path.join(data_dir, f"{unique_id}.json")

        save_data = {
            "id": unique_id,
            "coach_username": coach_username,
            "week_label": week_label,
            "notes_hebdo": notes_hebdo,
            "updated_at": datetime.now().isoformat()
        }

        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Notes hebdomadaires sauvegard√©es"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la sauvegarde des notes hebdomadaires coach (direction): {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/direction/coach-weekly-data")
async def get_direction_coach_weekly_data(id: str):
    """R√©cup√®re les notes hebdomadaires pour un coach depuis la direction"""
    try:
        data_dir = os.path.join(base_cloud, "direction_coach_weekly")
        data_file = os.path.join(data_dir, f"{id}.json")

        if not os.path.exists(data_file):
            return {"success": False, "data": None}

        with open(data_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        return {"success": True, "data": data}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des notes hebdomadaires coach (direction): {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ENDPOINTS COACH - M√âTRIQUES PR√âVISIONNELLES
# ============================================

@app.get("/api/coach/metrics")
async def get_coach_metrics(coach_username: str):
    """
    R√©cup√®re les m√©triques pr√©visionnelles d'un coach (valeur unique)

    Query params:
        coach_username: Nom d'utilisateur du coach

    Returns:
        {
            "success": True,
            "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}
        }
    """
    try:
        from QE.Backend.coach_previsions import load_coach_metrics

        metrics = load_coach_metrics(coach_username)

        return {
            "success": True,
            "metrics": metrics
        }

    except Exception as e:
        print(f"[COACH API] Erreur GET metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class CoachMetricsRequest(BaseModel):
    coach_username: str
    metrics: dict  # {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}


@app.post("/api/coach/metrics")
async def save_coach_metrics(request: CoachMetricsRequest):
    """
    Sauvegarde les m√©triques pr√©visionnelles d'un coach (valeur unique)

    Body:
        {
            "coach_username": "coach1",
            "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}
        }

    Returns:
        {"success": True, "metrics": {"cm": 5000, "ratioMktg": 15.5, "tauxVente": 33.3}}
    """
    try:
        from QE.Backend.coach_previsions import save_coach_metrics

        success = save_coach_metrics(request.coach_username, request.metrics)

        if success:
            return {
                "success": True,
                "metrics": request.metrics
            }
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        print(f"[COACH API] Erreur POST metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))




@app.get("/api/entrepreneur/coach")
async def get_entrepreneur_coach(entrepreneur_username: str):
    """
    R√©cup√®re le coach assign√© √† un entrepreneur

    Query params:
        entrepreneur_username: Nom d'utilisateur de l'entrepreneur

    Returns:
        {
            "success": True,
            "coach_username": "coach3"
        }
    """
    try:
        from QE.Backend.coach_access import get_coach_for_entrepreneur

        coach_username = get_coach_for_entrepreneur(entrepreneur_username)

        if coach_username:
            return {
                "success": True,
                "coach_username": coach_username
            }
        else:
            return {
                "success": False,
                "error": "Aucun coach assign√©"
            }

    except Exception as e:
        print(f"[API] Erreur GET entrepreneur coach: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ENDPOINTS COMPTABLE/DIRECTION - FACTURATION QE
# ============================================

@app.get("/api/comptable/facturation-en-attente/count")
async def count_facturation_en_attente_comptable():
    """Compte le nombre de facturations en attente pour la direction/comptable (statut attente_comptable)"""
    try:
        from QE.Backend.facturationqe import get_facturations_a_traiter_count_direction
        result = get_facturations_a_traiter_count_direction()
        return {"success": True, "count": result.get("count", 0)}
    except Exception as e:
        print(f"Erreur lors du comptage des facturations en attente: {e}")
        return {"success": False, "count": 0, "error": str(e)}

@app.get("/api/comptable/facturation-en-traitement/liste")
async def liste_facturation_en_traitement_comptable():
    """Liste toutes les facturations en traitement pour la direction/comptable avec infos d√©taill√©es"""
    try:
        paiements_en_traitement = []
        statuts_dir = os.path.join(base_cloud, "facturation_qe_statuts")

        if not os.path.exists(statuts_dir):
            return {"success": True, "paiements": []}

        # Charger l'historique pour exclure les paiements d√©j√† valid√©s (seulement ceux qui ne sont pas refus√©s)
        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")
        historique_set = set()
        if os.path.exists(historique_file):
            try:
                with open(historique_file, "r", encoding="utf-8") as f:
                    historique = json.load(f)
                # Cr√©er un set de cl√©s uniques pour les paiements NON REFUS√âS dans l'historique
                # Les paiements refus√©s peuvent revenir en attente_comptable apr√®s correction
                for h in historique:
                    # Ne pas exclure les paiements qui ont √©t√© refus√©s - ils peuvent revenir
                    if h.get("statut") == "refuse":
                        continue
                    if h.get("type") == "autres_paiements":
                        key = (h.get("entrepreneurUsername"), h.get("numeroSoumission"), h.get("type"), h.get("index"))
                    else:
                        key = (h.get("entrepreneurUsername"), h.get("numeroSoumission"), h.get("type"), None)
                    historique_set.add(key)
            except:
                pass

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(statuts_dir):
            user_path = os.path.join(statuts_dir, username)
            if os.path.isdir(user_path):
                statuts_file = os.path.join(user_path, "statuts_clients.json")
                if os.path.exists(statuts_file):
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    # R√©cup√©rer le nom complet et la photo de l'entrepreneur
                    entrepreneur_nom = username
                    entrepreneur_photo = None
                    try:
                        user_info = get_user_info(username)
                        if user_info and user_info.get("success"):
                            data = user_info.get("data", {})
                            prenom = data.get("prenom", "")
                            nom = data.get("nom", "")
                            if prenom or nom:
                                entrepreneur_nom = f"{prenom} {nom}".strip()
                            # R√©cup√©rer la photo de profil
                            files = user_info.get("files", {})
                            entrepreneur_photo = files.get("profile_photo")
                    except:
                        pass

                    # Si pas de photo via get_user_info, chercher manuellement
                    if not entrepreneur_photo:
                        import glob as glob_module
                        user_dir = os.path.join(base_cloud, "signatures", username)
                        pattern = os.path.join(user_dir, "profile_photo*.*")
                        matching_files = glob_module.glob(pattern)
                        if matching_files:
                            filename = os.path.basename(matching_files[0])
                            entrepreneur_photo = f"/api/get-file/{username}/{filename}"

                    # Charger les clients depuis les diff√©rentes sources (soumissions_signees, travaux_a_completer, etc.)
                    clients_data = {}

                    # Source 1: soumissions_signees
                    soumissions_signees_file = os.path.join(base_cloud, "soumissions_signees", username, "soumissions.json")
                    if os.path.exists(soumissions_signees_file):
                        try:
                            with open(soumissions_signees_file, "r", encoding="utf-8") as f:
                                soumissions_list = json.load(f)
                                for soum in soumissions_list:
                                    num = soum.get("num")
                                    if num:
                                        prenom = soum.get("clientPrenom", soum.get("prenom", ""))
                                        nom = soum.get("clientNom", soum.get("nom", ""))
                                        clients_data[num] = f"{prenom} {nom}".strip()
                        except:
                            pass

                    # Source 2: travaux_a_completer
                    travaux_file = os.path.join(base_cloud, "travaux_a_completer", username, "soumissions.json")
                    if os.path.exists(travaux_file):
                        try:
                            with open(travaux_file, "r", encoding="utf-8") as f:
                                travaux_list = json.load(f)
                                for travail in travaux_list:
                                    num = travail.get("num")
                                    if num and num not in clients_data:
                                        prenom = travail.get("clientPrenom", travail.get("prenom", ""))
                                        nom = travail.get("clientNom", travail.get("nom", ""))
                                        clients_data[num] = f"{prenom} {nom}".strip()
                        except:
                            pass

                    for num_soumission, client_statuts in statuts.items():
                        # R√©cup√©rer le nom du client
                        client_nom = clients_data.get(num_soumission, "Client inconnu")

                        # Depot en attente_comptable (valid√© par coach, en attente de direction)
                        if client_statuts.get("statutDepot") == "attente_comptable":
                            # V√©rifier si ce paiement n'est pas d√©j√† dans l'historique (valid√© par direction)
                            if (username, num_soumission, "depot", None) not in historique_set:
                                depot_details = client_statuts.get("depot", {})
                                paiements_en_traitement.append({
                                    "entrepreneur": entrepreneur_nom,
                                    "entrepreneurUsername": username,
                                    "entrepreneurPhoto": entrepreneur_photo,
                                    "client": client_nom,
                                    "numeroSoumission": num_soumission,
                                    "type": "depot",
                                    "montant": depot_details.get("montant", "0,00 $"),
                                    "date": depot_details.get("date", ""),
                                    "methode": depot_details.get("methode", ""),
                                    "lienVirement": depot_details.get("lienVirement", ""),
                                    "dateMiseAJour": client_statuts.get("dateMiseAJour")
                                })

                        # Paiement final en attente_comptable
                        if client_statuts.get("statutPaiementFinal") == "attente_comptable":
                            # V√©rifier si ce paiement n'est pas d√©j√† dans l'historique (valid√© par direction)
                            if (username, num_soumission, "paiement_final", None) not in historique_set:
                                pf_details = client_statuts.get("paiementFinal", {})
                                paiements_en_traitement.append({
                                    "entrepreneur": entrepreneur_nom,
                                    "entrepreneurUsername": username,
                                    "entrepreneurPhoto": entrepreneur_photo,
                                    "client": client_nom,
                                    "numeroSoumission": num_soumission,
                                    "type": "paiement_final",
                                    "montant": pf_details.get("montant", "0,00 $"),
                                    "date": pf_details.get("date", ""),
                                    "methode": pf_details.get("methode", ""),
                                    "lienVirement": pf_details.get("lienVirement", ""),
                                    "dateMiseAJour": client_statuts.get("dateMiseAJour")
                                })

                        # Autres paiements en attente_comptable
                        if client_statuts.get("statutAutresPaiements") == "attente_comptable":
                            autres = client_statuts.get("autresPaiements", [])
                            statut_depot = client_statuts.get("statutDepot", "non_envoye")
                            for idx, ap in enumerate(autres):
                                if ap.get("statut") == "attente_comptable":
                                    # V√©rifier si CE paiement partiel sp√©cifique n'est pas d√©j√† dans l'historique (valid√© par direction)
                                    if (username, num_soumission, "autres_paiements", idx) not in historique_set:
                                        # D√©duire typePaiementAutres si absent
                                        type_paiement = ap.get("typePaiementAutres", "")
                                        if not type_paiement:
                                            type_paiement = "un_seul_paiement" if statut_depot == "non_envoye" else "paiement_partiel"
                                        paiements_en_traitement.append({
                                            "entrepreneur": entrepreneur_nom,
                                            "entrepreneurUsername": username,
                                            "entrepreneurPhoto": entrepreneur_photo,
                                            "client": client_nom,
                                            "numeroSoumission": num_soumission,
                                            "type": "autres_paiements",
                                            "index": idx,
                                            "montant": ap.get("montant", "0,00 $"),
                                            "date": ap.get("date", ""),
                                            "methode": ap.get("methode", ""),
                                            "lienVirement": ap.get("lienVirement", ""),
                                            "typePaiementAutres": type_paiement,
                                            "statutDepot": statut_depot,
                                            "dateMiseAJour": client_statuts.get("dateMiseAJour")
                                        })

        # Charger les remboursements en attente comptable
        remboursements_dir = os.path.join(base_cloud, "remboursements")
        if os.path.exists(remboursements_dir):
            for username in os.listdir(remboursements_dir):
                user_remb_dir = os.path.join(remboursements_dir, username)
                if os.path.isdir(user_remb_dir):
                    remb_file = os.path.join(user_remb_dir, "remboursements.json")
                    if os.path.exists(remb_file):
                        try:
                            with open(remb_file, "r", encoding="utf-8") as f:
                                content = f.read().strip()
                                if content:
                                    remboursements = json.loads(content)

                                    # R√©cup√©rer le nom de l'entrepreneur et sa photo
                                    entrepreneur_nom = username
                                    entrepreneur_photo = None
                                    try:
                                        user_info = get_user_info(username)
                                        if user_info and user_info.get("success"):
                                            data = user_info.get("data", {})
                                            prenom = data.get("prenom", "")
                                            nom = data.get("nom", "")
                                            if prenom or nom:
                                                entrepreneur_nom = f"{prenom} {nom}".strip()
                                            files = user_info.get("files", {})
                                            entrepreneur_photo = files.get("profile_photo")
                                    except:
                                        pass

                                    # Ajouter les remboursements en attente comptable
                                    for remb in remboursements:
                                        if remb.get("statut") == "en_attente_comptable":
                                            # V√©rifier si ce remboursement n'est pas d√©j√† dans l'historique
                                            if (username, remb.get("num"), "remboursement") not in historique_set:
                                                paiements_en_traitement.append({
                                                    "entrepreneur": entrepreneur_nom,
                                                    "entrepreneurUsername": username,
                                                    "entrepreneurPhoto": entrepreneur_photo,
                                                    "client": remb.get("client", "Client inconnu"),
                                                    "numeroSoumission": remb.get("num", ""),
                                                    "type": "remboursement",
                                                    "montant": remb.get("montant", "0,00 $"),
                                                    "date": remb.get("date", ""),
                                                    "courriel": remb.get("courriel", ""),
                                                    "paiement_source": remb.get("paiement_source", ""),
                                                    "date_demande": remb.get("date_demande", ""),
                                                    "date_validation_coach": remb.get("date_validation_coach", ""),
                                                    "remboursementId": remb.get("id", ""),
                                                    "dateMiseAJour": remb.get("date_validation_coach", "")
                                                })
                        except Exception as e:
                            print(f"[REMB] Erreur lecture remboursements pour {username}: {e}")

        return {"success": True, "paiements": paiements_en_traitement}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des facturations comptable: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/comptable/facturation/{username}/{numero_soumission}/valider")
async def valider_facturation_comptable(username: str, numero_soumission: str, request: Request):
    """Direction/Comptable valide un paiement:
    - Reste en 'attente_comptable' (validation direction seulement)
    - Sera marqu√© 'trait√©' seulement quand d√©plac√© dans une p√©riode QBO
    """
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")

        # Traitement sp√©cial pour les remboursements
        if type_paiement == "remboursement":
            remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
            if not os.path.exists(remb_file):
                raise HTTPException(status_code=404, detail="Fichier de remboursements non trouv√©")

            with open(remb_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    raise HTTPException(status_code=404, detail="Aucun remboursement trouv√©")
                remboursements = json.loads(content)

            # Trouver le remboursement
            remb_found = None
            for remb in remboursements:
                if remb.get("num") == numero_soumission:
                    remb_found = remb
                    break

            if not remb_found:
                raise HTTPException(status_code=404, detail="Remboursement non trouv√©")

            # Ajouter √† l'historique (passer un dict vide pour client_statuts car pas applicable)
            await ajouter_historique_facturation(username, numero_soumission, type_paiement, "attente_comptable", {})

            return {"success": True, "message": "Remboursement valid√© - En attente de rapprochement QBO"}

        # Pour les autres types de paiements (depot, paiement_final, autres_paiements)
        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        message = "Paiement valid√© avec succ√®s"
        montant_modifie = data.get("montantModifie")
        montant_original = None

        # Supprimer les infos de refus mais garder le statut attente_comptable
        if type_paiement == "depot":
            # Rester en attente_comptable (ne pas changer √† traite_attente_final)
            # Juste supprimer les infos de refus
            if "depot" in statuts[numero_soumission]:
                if "refus" in statuts[numero_soumission]["depot"]:
                    del statuts[numero_soumission]["depot"]["refus"]
                # Mettre √† jour le montant si modifi√©
                if montant_modifie:
                    montant_original = statuts[numero_soumission]["depot"].get("montant")
                    statuts[numero_soumission]["depot"]["montant"] = montant_modifie
                    print(f"[COMPTABLE] Montant d√©p√¥t modifi√©: {montant_original} -> {montant_modifie}")
            # Supprimer aussi l'objet refus au niveau racine
            if "refus" in statuts[numero_soumission]:
                del statuts[numero_soumission]["refus"]
            message = "D√©p√¥t valid√© - En attente de rapprochement QBO"
        elif type_paiement == "paiement_final":
            # Rester en attente_comptable (ne pas changer √† traite)
            # Juste supprimer les infos de refus
            if "paiementFinal" in statuts[numero_soumission]:
                if "refus" in statuts[numero_soumission]["paiementFinal"]:
                    del statuts[numero_soumission]["paiementFinal"]["refus"]
                # Mettre √† jour le montant si modifi√©
                if montant_modifie:
                    montant_original = statuts[numero_soumission]["paiementFinal"].get("montant")
                    statuts[numero_soumission]["paiementFinal"]["montant"] = montant_modifie
                    print(f"[COMPTABLE] Montant paiement final modifi√©: {montant_original} -> {montant_modifie}")
            # Supprimer aussi l'objet refus au niveau racine
            if "refus" in statuts[numero_soumission]:
                del statuts[numero_soumission]["refus"]
            message = "Paiement final valid√© - En attente de rapprochement QBO"
        elif type_paiement == "autres_paiements":
            index = data.get("index", 0)
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                # Rester en attente_comptable (ne pas changer √† traite)
                # Juste supprimer les infos de refus
                if "refus" in statuts[numero_soumission]["autresPaiements"][index]:
                    del statuts[numero_soumission]["autresPaiements"][index]["refus"]
                # Mettre √† jour le montant si modifi√©
                if montant_modifie:
                    montant_original = statuts[numero_soumission]["autresPaiements"][index].get("montant")
                    statuts[numero_soumission]["autresPaiements"][index]["montant"] = montant_modifie
                    print(f"[COMPTABLE] Montant autre paiement modifi√©: {montant_original} -> {montant_modifie}")
            # Supprimer aussi l'objet refus au niveau racine
            if "refus" in statuts[numero_soumission]:
                del statuts[numero_soumission]["refus"]
            message = "Paiement valid√© - En attente de rapprochement QBO"

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder la notification de modification si le montant a √©t√© modifi√©
        if montant_modifie and montant_original and montant_modifie != montant_original:
            notif_dir = os.path.join(base_cloud, "notifications_comptable", username)
            os.makedirs(notif_dir, exist_ok=True)
            notif_file = os.path.join(notif_dir, "modifications.json")

            notifications = []
            if os.path.exists(notif_file):
                try:
                    with open(notif_file, "r", encoding="utf-8") as f:
                        notifications = json.load(f)
                except:
                    notifications = []

            # R√©cup√©rer le nom du client (essayer plusieurs formats possibles)
            client_nom = statuts[numero_soumission].get("clientNom") or statuts[numero_soumission].get("nom", "")
            client_prenom = statuts[numero_soumission].get("clientPrenom") or statuts[numero_soumission].get("prenom", "")
            nom_complet = f"{client_prenom} {client_nom}".strip() or "Client"

            # Ajouter la nouvelle notification
            notifications.append({
                "id": f"{numero_soumission}_{type_paiement}_{datetime.now().timestamp()}",
                "numero_soumission": numero_soumission,
                "nom_client": nom_complet,
                "type_paiement": type_paiement,
                "montant_original": montant_original,
                "montant_modifie": montant_modifie,
                "date": datetime.now().isoformat(),
                "vu": False
            })

            with open(notif_file, "w", encoding="utf-8") as f:
                json.dump(notifications, f, ensure_ascii=False, indent=2)

            print(f"[COMPTABLE] Notification cr√©√©e pour {username}: {montant_original} -> {montant_modifie}")

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        # Ajouter √† l'historique avec statut "attente_comptable" pour affichage dans Rapprochement QBO
        # Pour les paiements partiels, passer l'index
        paiement_index = data.get("index") if type_paiement == "autres_paiements" else None
        await ajouter_historique_facturation(username, numero_soumission, type_paiement, "attente_comptable", statuts[numero_soumission], paiement_index)

        return {"success": True, "message": message}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la validation: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/comptable/facturation/retourner-general")
async def retourner_paiements_general(request: Request):
    """Retourne des paiements du Rapprochement QBO vers G√©n√©ral (retire de l'historique + remet statut attente_comptable)"""
    try:
        data = await request.json()
        paiements = data.get("paiements", [])

        if not paiements:
            raise HTTPException(status_code=400, detail="Aucun paiement fourni")

        # Charger l'historique
        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")
        if not os.path.exists(historique_file):
            return {"success": True, "message": "Aucun historique trouv√©", "removed": 0}

        with open(historique_file, "r", encoding="utf-8") as f:
            historique = json.load(f)

        # Cr√©er un set des paiements √† retirer
        paiements_a_retirer = set()
        for p in paiements:
            # Cl√© unique: (entrepreneurUsername, numeroSoumission, type, index)
            key = (
                p.get("entrepreneurUsername"),
                p.get("numeroSoumission"),
                p.get("type"),
                p.get("index")
            )
            paiements_a_retirer.add(key)

        # Filtrer l'historique pour retirer les paiements
        historique_original_len = len(historique)
        historique_filtre = []
        for h in historique:
            key = (
                h.get("entrepreneurUsername"),
                h.get("numeroSoumission"),
                h.get("type"),
                h.get("index")
            )
            if key not in paiements_a_retirer:
                historique_filtre.append(h)

        # Sauvegarder l'historique mis √† jour
        with open(historique_file, "w", encoding="utf-8") as f:
            json.dump(historique_filtre, f, ensure_ascii=False, indent=2)

        removed_count = historique_original_len - len(historique_filtre)

        # Remettre le statut √† attente_comptable dans statuts_clients.json pour chaque paiement
        for p in paiements:
            username = p.get("entrepreneurUsername")
            num_soumission = p.get("numeroSoumission")
            type_paiement = p.get("type")
            index = p.get("index")

            if not username or not num_soumission:
                continue

            statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
            if os.path.exists(statuts_file):
                try:
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    if num_soumission in statuts:
                        if type_paiement == "depot":
                            statuts[num_soumission]["statutDepot"] = "attente_comptable"
                            if "depot" in statuts[num_soumission]:
                                statuts[num_soumission]["depot"]["statut"] = "attente_comptable"
                        elif type_paiement == "paiement_final":
                            statuts[num_soumission]["statutPaiementFinal"] = "attente_comptable"
                            if "paiementFinal" in statuts[num_soumission]:
                                statuts[num_soumission]["paiementFinal"]["statut"] = "attente_comptable"
                        elif type_paiement == "autres_paiements" and index is not None:
                            if "autresPaiements" in statuts[num_soumission] and len(statuts[num_soumission]["autresPaiements"]) > index:
                                statuts[num_soumission]["autresPaiements"][index]["statut"] = "attente_comptable"
                            # Mettre aussi statutAutresPaiements si tous les autres sont attente_comptable
                            statuts[num_soumission]["statutAutresPaiements"] = "attente_comptable"

                        with open(statuts_file, "w", encoding="utf-8") as f:
                            json.dump(statuts, f, ensure_ascii=False, indent=2)

                        print(f"[RETOURNER G√âN√âRAL] Statut remis √† attente_comptable: {username}/{num_soumission}/{type_paiement}")
                except Exception as e:
                    print(f"[RETOURNER G√âN√âRAL] Erreur mise √† jour statut {username}/{num_soumission}: {e}")

        print(f"[RETOURNER G√âN√âRAL] {removed_count} paiement(s) retir√©(s) de l'historique")

        return {"success": True, "message": f"{removed_count} paiement(s) retourn√©(s) √† G√©n√©ral", "removed": removed_count}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors du retour √† g√©n√©ral: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/comptable/facturation/remettre-rapprochement")
async def remettre_paiement_rapprochement(request: Request):
    """Remet un paiement dans l'historique (Rapprochement QBO) - utilis√© quand on retire d'une p√©riode"""
    try:
        data = await request.json()
        paiement = data.get("paiement")

        if not paiement:
            raise HTTPException(status_code=400, detail="Paiement non fourni")

        # Charger l'historique
        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")
        historique = []
        if os.path.exists(historique_file):
            with open(historique_file, "r", encoding="utf-8") as f:
                historique = json.load(f)

        # V√©rifier si le paiement n'est pas d√©j√† dans l'historique
        key = (
            paiement.get("entrepreneurUsername"),
            paiement.get("numeroSoumission"),
            paiement.get("type"),
            paiement.get("index")
        )

        already_exists = False
        for h in historique:
            h_key = (
                h.get("entrepreneurUsername"),
                h.get("numeroSoumission"),
                h.get("type"),
                h.get("index")
            )
            if h_key == key:
                already_exists = True
                break

        if not already_exists:
            # Cr√©er l'entr√©e pour l'historique
            entry = {
                "entrepreneur": paiement.get("entrepreneur", ""),
                "entrepreneurUsername": paiement.get("entrepreneurUsername", ""),
                "entrepreneurPhoto": paiement.get("entrepreneurPhoto", ""),
                "client": paiement.get("client", ""),
                "numeroSoumission": paiement.get("numeroSoumission", ""),
                "type": paiement.get("type", ""),
                "montant": paiement.get("montant", "0,00 $"),
                "lienVirement": paiement.get("lienVirement", ""),
                "statut": "attente_comptable",
                "date": paiement.get("date", datetime.now().strftime("%d/%m/%Y %H:%M"))
            }

            # Ajouter l'index pour les paiements partiels
            if paiement.get("type") == "autres_paiements" and paiement.get("index") is not None:
                entry["index"] = paiement.get("index")

            # Ajouter au d√©but de l'historique
            historique.insert(0, entry)

            # Sauvegarder (garder les 500 derni√®res entr√©es)
            historique = historique[:500]
            with open(historique_file, "w", encoding="utf-8") as f:
                json.dump(historique, f, ensure_ascii=False, indent=2)

            print(f"[REMETTRE RAPPROCHEMENT] Paiement ajout√© √† l'historique: {paiement.get('numeroSoumission')}")
            return {"success": True, "message": "Paiement remis dans Rapprochement QBO"}
        else:
            print(f"[REMETTRE RAPPROCHEMENT] Paiement d√©j√† dans l'historique: {paiement.get('numeroSoumission')}")
            return {"success": True, "message": "Paiement d√©j√† dans Rapprochement QBO"}

    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la remise dans rapprochement: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/notifications/modifications/{username}")
async def get_notifications_modifications(username: str):
    """R√©cup√®re les notifications de modifications de montant non vues pour un entrepreneur"""
    try:
        notif_file = os.path.join(base_cloud, "notifications_comptable", username, "modifications.json")

        if not os.path.exists(notif_file):
            return {"success": True, "notifications": []}

        with open(notif_file, "r", encoding="utf-8") as f:
            notifications = json.load(f)

        # Filtrer les notifications non vues
        non_vues = [n for n in notifications if not n.get("vu", False)]

        return {"success": True, "notifications": non_vues}
    except Exception as e:
        print(f"[ERREUR] Get notifications modifications: {e}")
        return {"success": False, "notifications": []}


@app.post("/api/notifications/modifications/{username}/marquer-vues")
async def marquer_notifications_vues(username: str):
    """Marque toutes les notifications de modifications comme vues"""
    try:
        notif_file = os.path.join(base_cloud, "notifications_comptable", username, "modifications.json")

        if not os.path.exists(notif_file):
            return {"success": True}

        with open(notif_file, "r", encoding="utf-8") as f:
            notifications = json.load(f)

        # Marquer toutes comme vues
        for n in notifications:
            n["vu"] = True

        with open(notif_file, "w", encoding="utf-8") as f:
            json.dump(notifications, f, ensure_ascii=False, indent=2)

        return {"success": True}
    except Exception as e:
        print(f"[ERREUR] Marquer notifications vues: {e}")
        return {"success": False}


@app.post("/api/comptable/facturation/{username}/{numero_soumission}/refuser")
async def refuser_facturation_comptable(username: str, numero_soumission: str, request: Request):
    """Refuse un paiement (change le statut de traitement √† refuse) avec raison"""
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")
        raison = data.get("raison", "")

        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # R√©cup√©rer le nom de celui qui refuse
        nom_refuseur = data.get("nomRefuseur", "")

        # Cr√©er l'objet de refus avec raison et conversation
        refus_info = {
            "raison": raison,
            "refusePar": "comptable",
            "nomRefusePar": nom_refuseur,
            "dateRefus": datetime.now().isoformat(),
            "conversation": [
                {
                    "de": "comptable",
                    "nom": nom_refuseur,
                    "message": raison,
                    "date": datetime.now().isoformat()
                }
            ]
        }

        # Stocker le refus au niveau racine pour l'affichage frontend
        statuts[numero_soumission]["refus"] = refus_info

        # Mettre √† jour le statut selon le type
        if type_paiement == "depot":
            statuts[numero_soumission]["statutDepot"] = "refuse"
            statuts[numero_soumission]["dateDepot"] = datetime.now().isoformat()
            if "depot" in statuts[numero_soumission]:
                statuts[numero_soumission]["depot"]["statut"] = "refuse"
                statuts[numero_soumission]["depot"]["refus"] = refus_info
        elif type_paiement == "paiement_final":
            statuts[numero_soumission]["statutPaiementFinal"] = "refuse"
            statuts[numero_soumission]["datePaiementFinal"] = datetime.now().isoformat()
            if "paiementFinal" in statuts[numero_soumission]:
                statuts[numero_soumission]["paiementFinal"]["statut"] = "refuse"
                statuts[numero_soumission]["paiementFinal"]["refus"] = refus_info
        elif type_paiement == "autres_paiements":
            index = data.get("index", 0)
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                statuts[numero_soumission]["autresPaiements"][index]["statut"] = "refuse"
                statuts[numero_soumission]["autresPaiements"][index]["refus"] = refus_info
            # Mettre le statut global √† refuse si au moins un est refus√©
            statuts[numero_soumission]["statutAutresPaiements"] = "refuse"
            statuts[numero_soumission]["dateAutresPaiements"] = datetime.now().isoformat()

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        # Ajouter √† l'historique
        # Pour les paiements partiels, passer l'index
        paiement_index = data.get("index") if type_paiement == "autres_paiements" else None
        await ajouter_historique_facturation(username, numero_soumission, type_paiement, "refuse", statuts[numero_soumission], paiement_index)

        return {"success": True, "message": "Paiement refus√©"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors du refus: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/facturationqe/client/{username}/{numero_soumission}/renvoyer")
async def renvoyer_paiement_en_traitement(username: str, numero_soumission: str, request: Request):
    """Entrepreneur renvoie un paiement refus√© en traitement avec une r√©ponse et modifications"""
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")
        reponse = data.get("reponse", "")
        index = data.get("index", 0)
        modifications = data.get("modifications", {})

        print(f"[RENVOYER] {numero_soumission} - Type: {type_paiement}, Modifications: {list(modifications.keys())}")

        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # Message de l'entrepreneur √† ajouter √† la conversation
        nouveau_message = {
            "de": "entrepreneur",
            "message": reponse,
            "date": datetime.now().isoformat()
        }

        # Ajouter le message √† la conversation au niveau racine si elle existe
        if "refus" in statuts[numero_soumission] and "conversation" in statuts[numero_soumission]["refus"]:
            statuts[numero_soumission]["refus"]["conversation"].append(nouveau_message)

        # Fonction helper pour appliquer les modifications √† un paiement
        def appliquer_modifications(paiement_data, modifs):
            """Applique les modifications au paiement"""
            if not modifs:
                return

            # Lien virement
            if "lienVirement" in modifs:
                paiement_data["lienVirement"] = modifs["lienVirement"]
                print(f"[RENVOYER] Lien virement mis √† jour")

            # Mot de passe virement
            if "motDePasseVirement" in modifs:
                paiement_data["motDePasse"] = modifs["motDePasseVirement"]
                print(f"[RENVOYER] Mot de passe virement mis √† jour")

            # Num√©ro de ch√®que
            if "numeroCheque" in modifs:
                paiement_data["numeroCheque"] = modifs["numeroCheque"]
                print(f"[RENVOYER] Num√©ro de ch√®que mis √† jour")

            # Photo recto (base64)
            if "photoRecto" in modifs:
                paiement_data["photoRecto"] = modifs["photoRecto"]
                print(f"[RENVOYER] Photo recto mise √† jour")

            # Photo verso (base64)
            if "photoVerso" in modifs:
                paiement_data["photoVerso"] = modifs["photoVerso"]
                print(f"[RENVOYER] Photo verso mise √† jour")

            # Marquer que des modifications ont √©t√© faites
            if modifs:
                paiement_data["derniereModification"] = datetime.now().isoformat()
                paiement_data["modificationsApportees"] = True

        # Mettre √† jour le statut selon le type - repasser en traitement pour revalidation par le coach
        if type_paiement == "depot":
            statuts[numero_soumission]["statutDepot"] = "traitement"
            statuts[numero_soumission]["dateDepot"] = datetime.now().isoformat()
            if "depot" in statuts[numero_soumission]:
                statuts[numero_soumission]["depot"]["statut"] = "traitement"
                # Appliquer les modifications
                appliquer_modifications(statuts[numero_soumission]["depot"], modifications)
                # Ajouter la r√©ponse √† la conversation du d√©p√¥t
                if "refus" in statuts[numero_soumission]["depot"] and "conversation" in statuts[numero_soumission]["depot"]["refus"]:
                    statuts[numero_soumission]["depot"]["refus"]["conversation"].append(nouveau_message)
        elif type_paiement == "paiement_final":
            statuts[numero_soumission]["statutPaiementFinal"] = "traitement"
            statuts[numero_soumission]["datePaiementFinal"] = datetime.now().isoformat()
            if "paiementFinal" in statuts[numero_soumission]:
                statuts[numero_soumission]["paiementFinal"]["statut"] = "traitement"
                # Appliquer les modifications
                appliquer_modifications(statuts[numero_soumission]["paiementFinal"], modifications)
                # Ajouter la r√©ponse √† la conversation du paiement final
                if "refus" in statuts[numero_soumission]["paiementFinal"] and "conversation" in statuts[numero_soumission]["paiementFinal"]["refus"]:
                    statuts[numero_soumission]["paiementFinal"]["refus"]["conversation"].append(nouveau_message)
        elif type_paiement == "autres_paiements":
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                statuts[numero_soumission]["autresPaiements"][index]["statut"] = "traitement"
                # Appliquer les modifications
                appliquer_modifications(statuts[numero_soumission]["autresPaiements"][index], modifications)
                # Ajouter la r√©ponse √† la conversation
                if "refus" in statuts[numero_soumission]["autresPaiements"][index] and "conversation" in statuts[numero_soumission]["autresPaiements"][index]["refus"]:
                    statuts[numero_soumission]["autresPaiements"][index]["refus"]["conversation"].append(nouveau_message)
            statuts[numero_soumission]["statutAutresPaiements"] = "traitement"
            statuts[numero_soumission]["dateAutresPaiements"] = datetime.now().isoformat()

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Paiement renvoy√© en traitement pour validation coach"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors du renvoi en traitement: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/facturationqe/client/{username}/{numero_soumission}/message")
async def envoyer_message_conversation(username: str, numero_soumission: str, request: Request):
    """Entrepreneur envoie un message dans la conversation (sans changer le statut)"""
    try:
        data = await request.json()
        type_paiement = data.get("type", "depot")
        message = data.get("message", "")
        index = data.get("index", 0)

        if not message:
            raise HTTPException(status_code=400, detail="Le message ne peut pas √™tre vide")

        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Fichier de statuts non trouv√©")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # Message √† ajouter √† la conversation (peut √™tre de "entrepreneur", "coach", "direction", "comptable")
        expediteur = data.get("de", "entrepreneur")  # Utiliser le param√®tre envoy√© ou "entrepreneur" par d√©faut
        expediteur_nom = data.get("nomExp√©diteur", "")  # Nom complet de l'exp√©diteur
        nouveau_message = {
            "de": expediteur,
            "nom": expediteur_nom,
            "message": message,
            "date": datetime.now().isoformat()
        }

        # Ajouter le message √† la conversation au niveau racine si elle existe
        if "refus" in statuts[numero_soumission] and "conversation" in statuts[numero_soumission]["refus"]:
            statuts[numero_soumission]["refus"]["conversation"].append(nouveau_message)

        # Ajouter aussi dans le sous-objet de paiement correspondant
        if type_paiement == "depot":
            if "depot" in statuts[numero_soumission]:
                if "refus" in statuts[numero_soumission]["depot"] and "conversation" in statuts[numero_soumission]["depot"]["refus"]:
                    statuts[numero_soumission]["depot"]["refus"]["conversation"].append(nouveau_message)
        elif type_paiement == "paiement_final":
            if "paiementFinal" in statuts[numero_soumission]:
                if "refus" in statuts[numero_soumission]["paiementFinal"] and "conversation" in statuts[numero_soumission]["paiementFinal"]["refus"]:
                    statuts[numero_soumission]["paiementFinal"]["refus"]["conversation"].append(nouveau_message)
        elif type_paiement == "autres_paiements":
            if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                if "refus" in statuts[numero_soumission]["autresPaiements"][index] and "conversation" in statuts[numero_soumission]["autresPaiements"][index]["refus"]:
                    statuts[numero_soumission]["autresPaiements"][index]["refus"]["conversation"].append(nouveau_message)

        statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

        # Sauvegarder
        with open(statuts_file, "w", encoding="utf-8") as f:
            json.dump(statuts, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Message envoy√©"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de l'envoi du message: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def ajouter_historique_facturation(username: str, numero_soumission: str, type_paiement: str, statut: str, client_statuts: dict, index: int = None):
    """Ajoute une entr√©e √† l'historique de facturation"""
    try:
        historique_dir = os.path.join(base_cloud, "facturation_qe_historique")
        os.makedirs(historique_dir, exist_ok=True)
        historique_file = os.path.join(historique_dir, "historique.json")

        # Charger l'historique existant
        historique = []
        if os.path.exists(historique_file):
            with open(historique_file, "r", encoding="utf-8") as f:
                content = json.load(f)
                # V√©rifier que c'est bien une liste
                if isinstance(content, list):
                    historique = content
                else:
                    print(f"[HISTORIQUE] Fichier corrompu (dict au lieu de list), r√©initialisation")
                    historique = []

        # R√©cup√©rer le nom et la photo de l'entrepreneur
        entrepreneur_nom = username
        entrepreneur_photo = None
        try:
            user_info = get_user_info(username)
            if user_info and user_info.get("success"):
                data = user_info.get("data", {})
                prenom = data.get("prenom", "")
                nom = data.get("nom", "")
                if prenom or nom:
                    entrepreneur_nom = f"{prenom} {nom}".strip()
                # R√©cup√©rer la photo de profil
                files = user_info.get("files", {})
                entrepreneur_photo = files.get("profile_photo")
        except:
            pass

        # Si pas de photo via get_user_info, chercher manuellement
        if not entrepreneur_photo:
            import glob as glob_module
            user_dir = os.path.join(base_cloud, "signatures", username)
            pattern = os.path.join(user_dir, "profile_photo*.*")
            matching_files = glob_module.glob(pattern)
            if matching_files:
                filename = os.path.basename(matching_files[0])
                entrepreneur_photo = f"/api/get-file/{username}/{filename}"

        # R√©cup√©rer le nom du client depuis les diff√©rentes sources
        client_nom = "Client inconnu"

        # Source 1: soumissions_signees
        soumissions_signees_file = os.path.join(base_cloud, "soumissions_signees", username, "soumissions.json")
        if os.path.exists(soumissions_signees_file):
            try:
                with open(soumissions_signees_file, "r", encoding="utf-8") as f:
                    soumissions_list = json.load(f)
                    for soum in soumissions_list:
                        if soum.get("num") == numero_soumission:
                            prenom = soum.get("clientPrenom", soum.get("prenom", ""))
                            nom = soum.get("clientNom", soum.get("nom", ""))
                            client_nom = f"{prenom} {nom}".strip()
                            break
            except:
                pass

        # Source 2: travaux_a_completer si pas trouv√©
        if client_nom == "Client inconnu":
            travaux_file = os.path.join(base_cloud, "travaux_a_completer", username, "soumissions.json")
            if os.path.exists(travaux_file):
                try:
                    with open(travaux_file, "r", encoding="utf-8") as f:
                        travaux_list = json.load(f)
                        for travail in travaux_list:
                            if travail.get("num") == numero_soumission:
                                prenom = travail.get("clientPrenom", travail.get("prenom", ""))
                                nom = travail.get("clientNom", travail.get("nom", ""))
                                client_nom = f"{prenom} {nom}".strip()
                                break
                except:
                    pass

        # R√©cup√©rer le montant et le lien virement selon le type
        montant = "0,00 $"
        lien_virement = ""
        courriel = ""

        if type_paiement == "depot":
            montant = client_statuts.get("depot", {}).get("montant", "0,00 $")
            lien_virement = client_statuts.get("depot", {}).get("lienVirement", "")
        elif type_paiement == "paiement_final":
            montant = client_statuts.get("paiementFinal", {}).get("montant", "0,00 $")
            lien_virement = client_statuts.get("paiementFinal", {}).get("lienVirement", "")
        elif type_paiement == "autres_paiements":
            autres = client_statuts.get("autresPaiements", [])
            if autres and index is not None and index < len(autres):
                montant = autres[index].get("montant", "0,00 $")
                lien_virement = autres[index].get("lienVirement", "")
            elif autres:
                # Fallback: prendre le dernier si pas d'index
                montant = autres[-1].get("montant", "0,00 $")
                lien_virement = autres[-1].get("lienVirement", "")
        elif type_paiement == "remboursement":
            # Pour les remboursements, r√©cup√©rer les infos depuis remboursements.json
            remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
            if os.path.exists(remb_file):
                try:
                    with open(remb_file, "r", encoding="utf-8") as f:
                        content = f.read().strip()
                        if content:
                            remboursements = json.loads(content)
                            # Trouver le remboursement avec le bon num√©ro de soumission
                            for remb in remboursements:
                                if remb.get("num") == numero_soumission:
                                    montant = remb.get("montant", "0,00 $")
                                    courriel = remb.get("courriel", "")
                                    client_nom = remb.get("client", client_nom)
                                    break
                except Exception as e:
                    print(f"[HISTORIQUE] Erreur lecture remboursement: {e}")

        # Ajouter l'entr√©e
        entry = {
            "entrepreneur": entrepreneur_nom,
            "entrepreneurUsername": username,
            "entrepreneurPhoto": entrepreneur_photo,
            "client": client_nom,
            "numeroSoumission": numero_soumission,
            "type": type_paiement,
            "montant": montant,
            "lienVirement": lien_virement,
            "statut": statut,
            "date": datetime.now().strftime("%d/%m/%Y %H:%M")
        }

        # Ajouter l'index pour les paiements partiels
        if type_paiement == "autres_paiements" and index is not None:
            entry["index"] = index

        # Ajouter le courriel pour les remboursements
        if type_paiement == "remboursement" and courriel:
            entry["courriel"] = courriel

        historique.insert(0, entry)

        # Sauvegarder (garder les 500 derni√®res entr√©es)
        historique = historique[:500]
        with open(historique_file, "w", encoding="utf-8") as f:
            json.dump(historique, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"Erreur lors de l'ajout √† l'historique: {e}")

@app.get("/api/comptable/facturation/historique")
async def get_historique_facturation(limit: int = 100):
    """R√©cup√®re l'historique des facturations valid√©es et trait√©es (sans les refus√©s)"""
    try:
        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")

        if not os.path.exists(historique_file):
            return {"success": True, "historique": []}

        with open(historique_file, "r", encoding="utf-8") as f:
            historique = json.load(f)

        # Filtrer pour exclure les paiements refus√©s (statut "refuse")
        # Inclure les paiements "attente_comptable" (valid√©s par direction) et "valide" (trait√©s)
        historique_valides = [h for h in historique if h.get("statut") != "refuse"]

        return {"success": True, "historique": historique_valides[:limit]}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration de l'historique: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/comptable/facturation/historique/supprimer")
async def supprimer_paiements_historique(request: Request):
    """Supprime des paiements de l'historique (rapprochement QBO)"""
    try:
        data = await request.json()
        paiements_a_supprimer = data.get("paiements", [])

        if not paiements_a_supprimer:
            return {"success": False, "message": "Aucun paiement √† supprimer"}

        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")

        if not os.path.exists(historique_file):
            return {"success": False, "message": "Historique non trouv√©"}

        with open(historique_file, "r", encoding="utf-8") as f:
            historique = json.load(f)

        # Cr√©er un set des paiements √† supprimer pour une recherche rapide
        # Format: (entrepreneurUsername, numeroSoumission, type)
        a_supprimer_set = set()
        for p in paiements_a_supprimer:
            key = (p.get("entrepreneurUsername"), p.get("numeroSoumission"), p.get("type"))
            a_supprimer_set.add(key)

        # Filtrer l'historique
        historique_filtre = []
        supprimes = 0
        for h in historique:
            key = (h.get("entrepreneurUsername"), h.get("numeroSoumission"), h.get("type"))
            if key in a_supprimer_set:
                supprimes += 1
                print(f"[SUPPRIMER HISTORIQUE] Supprim√©: {key}")
            else:
                historique_filtre.append(h)

        # Sauvegarder
        with open(historique_file, "w", encoding="utf-8") as f:
            json.dump(historique_filtre, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": f"{supprimes} paiement(s) supprim√©(s) de l'historique"}
    except Exception as e:
        print(f"Erreur lors de la suppression de l'historique: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/comptable/facturation/supprimer-complet")
async def supprimer_paiement_complet(request: Request):
    """Supprime compl√®tement un paiement: du fichier de statuts ET de l'historique"""
    try:
        data = await request.json()
        username = data.get("entrepreneurUsername")
        numero_soumission = data.get("numeroSoumission")
        type_paiement = data.get("type")
        index = data.get("index")  # Pour autres_paiements

        if not username or not numero_soumission or not type_paiement:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        print(f"[SUPPRIMER COMPLET] username={username}, num={numero_soumission}, type={type_paiement}, index={index}")

        # 1. Supprimer du fichier de statuts
        if type_paiement == "remboursement":
            # Pour les remboursements, supprimer du fichier remboursements.json
            remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
            if os.path.exists(remb_file):
                with open(remb_file, "r", encoding="utf-8") as f:
                    remboursements = json.load(f)

                # Filtrer pour supprimer le remboursement
                remboursements_filtres = [r for r in remboursements if r.get("num") != numero_soumission]

                with open(remb_file, "w", encoding="utf-8") as f:
                    json.dump(remboursements_filtres, f, ensure_ascii=False, indent=2)

                print(f"[SUPPRIMER COMPLET] Remboursement supprim√© de remboursements.json")
        else:
            # Pour les autres types, supprimer du fichier statuts_clients.json
            statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
            if os.path.exists(statuts_file):
                with open(statuts_file, "r", encoding="utf-8") as f:
                    statuts = json.load(f)

                if numero_soumission in statuts:
                    if type_paiement == "depot":
                        # Supprimer les infos du d√©p√¥t
                        if "depot" in statuts[numero_soumission]:
                            del statuts[numero_soumission]["depot"]
                        if "statutDepot" in statuts[numero_soumission]:
                            del statuts[numero_soumission]["statutDepot"]
                        print(f"[SUPPRIMER COMPLET] D√©p√¥t supprim√©")
                    elif type_paiement == "paiement_final":
                        # Supprimer les infos du paiement final
                        if "paiementFinal" in statuts[numero_soumission]:
                            del statuts[numero_soumission]["paiementFinal"]
                        if "statutPaiementFinal" in statuts[numero_soumission]:
                            del statuts[numero_soumission]["statutPaiementFinal"]
                        print(f"[SUPPRIMER COMPLET] Paiement final supprim√©")
                    elif type_paiement == "autres_paiements":
                        # Supprimer le paiement partiel sp√©cifique par index
                        if "autresPaiements" in statuts[numero_soumission] and index is not None:
                            autres = statuts[numero_soumission]["autresPaiements"]
                            if 0 <= index < len(autres):
                                del autres[index]
                                # Si plus aucun paiement partiel, supprimer aussi statutAutresPaiements
                                if len(autres) == 0:
                                    del statuts[numero_soumission]["autresPaiements"]
                                    if "statutAutresPaiements" in statuts[numero_soumission]:
                                        del statuts[numero_soumission]["statutAutresPaiements"]
                                print(f"[SUPPRIMER COMPLET] Paiement partiel index {index} supprim√©")
                        elif "autresPaiements" in statuts[numero_soumission] and index is None:
                            # Si pas d'index, supprimer tous les autres paiements
                            del statuts[numero_soumission]["autresPaiements"]
                            if "statutAutresPaiements" in statuts[numero_soumission]:
                                del statuts[numero_soumission]["statutAutresPaiements"]
                            print(f"[SUPPRIMER COMPLET] Tous les autres paiements supprim√©s")

                    # Si le client n'a plus aucun paiement, supprimer l'entr√©e compl√®te
                    client_data = statuts[numero_soumission]
                    has_depot = "depot" in client_data or "statutDepot" in client_data
                    has_final = "paiementFinal" in client_data or "statutPaiementFinal" in client_data
                    has_autres = "autresPaiements" in client_data and len(client_data.get("autresPaiements", [])) > 0

                    if not has_depot and not has_final and not has_autres:
                        del statuts[numero_soumission]
                        print(f"[SUPPRIMER COMPLET] Client {numero_soumission} supprim√© enti√®rement")

                    with open(statuts_file, "w", encoding="utf-8") as f:
                        json.dump(statuts, f, ensure_ascii=False, indent=2)

        # 2. Supprimer de l'historique
        historique_file = os.path.join(base_cloud, "facturation_qe_historique", "historique.json")
        if os.path.exists(historique_file):
            with open(historique_file, "r", encoding="utf-8") as f:
                historique = json.load(f)

            # Filtrer l'historique
            historique_filtre = []
            for h in historique:
                # V√©rifier si c'est le paiement √† supprimer
                match = (h.get("entrepreneurUsername") == username and
                        h.get("numeroSoumission") == numero_soumission and
                        h.get("type") == type_paiement)
                # Pour autres_paiements, v√©rifier aussi l'index
                if match and type_paiement == "autres_paiements" and index is not None:
                    match = h.get("index") == index

                if not match:
                    historique_filtre.append(h)
                else:
                    print(f"[SUPPRIMER COMPLET] Supprim√© de l'historique")

            with open(historique_file, "w", encoding="utf-8") as f:
                json.dump(historique_filtre, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Paiement supprim√© compl√®tement"}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la suppression compl√®te: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/comptable/facturation/periodes")
async def save_periodes_facturation(data: dict):
    """Sauvegarde les p√©riodes de paiements ET marque les paiements comme 'trait√©'"""
    try:
        periodes_dir = os.path.join(base_cloud, "facturation_qe_periodes")
        os.makedirs(periodes_dir, exist_ok=True)
        periodes_file = os.path.join(periodes_dir, "periodes.json")

        periodes = data.get("periodes", {})

        # Sauvegarder les p√©riodes
        with open(periodes_file, "w", encoding="utf-8") as f:
            json.dump(periodes, f, ensure_ascii=False, indent=2)

        # Marquer tous les paiements dans les p√©riodes comme "trait√©"
        for periode_id, paiements in periodes.items():
            for paiement in paiements:
                username = paiement.get("entrepreneurUsername")
                numero_soumission = paiement.get("numeroSoumission")
                type_paiement = paiement.get("type")

                if not username or not numero_soumission or not type_paiement:
                    continue

                # Traitement sp√©cial pour les remboursements
                if type_paiement == "remboursement":
                    # 1. Charger le fichier de remboursements
                    remb_file = os.path.join(base_cloud, "remboursements", username, "remboursements.json")
                    if not os.path.exists(remb_file):
                        continue

                    with open(remb_file, "r", encoding="utf-8") as f:
                        remboursements = json.load(f)

                    # 2. Trouver le remboursement et v√©rifier s'il n'est pas d√©j√† trait√©
                    remb_found = None
                    for remb in remboursements:
                        if remb.get("num") == numero_soumission or remb.get("numeroSoumission") == numero_soumission:
                            # V√©rifier si d√©j√† trait√© pour √©viter de traiter deux fois
                            if remb.get("statut") == "traite":
                                print(f"[REMBOURSEMENT] {numero_soumission} d√©j√† trait√©, ignor√©")
                                remb_found = None
                                break
                            remb["statut"] = "traite"
                            remb["dateTraitement"] = datetime.now().isoformat()
                            remb_found = remb
                            break

                    if not remb_found:
                        continue

                    # 3. Sauvegarder le fichier de remboursements
                    with open(remb_file, "w", encoding="utf-8") as f:
                        json.dump(remboursements, f, ensure_ascii=False, indent=2)

                    # 4. Calculer le montant sans taxe (taxe Qu√©bec = 14.975%)
                    montant_avec_taxe = remb_found.get("montantNum", 0)
                    montant_sans_taxe = montant_avec_taxe / 1.14975

                    # 5. Charger le fichier de soumissions sign√©es
                    soumissions_file = os.path.join(base_cloud, "soumissions_signees", username, "soumissions.json")
                    if not os.path.exists(soumissions_file):
                        continue

                    with open(soumissions_file, "r", encoding="utf-8") as f:
                        soumissions = json.load(f)

                    # 6. Trouver la soumission correspondante
                    soumission_found = None
                    for soumission in soumissions:
                        if soumission.get("num") == numero_soumission:
                            soumission_found = soumission
                            break

                    if not soumission_found:
                        continue

                    # 7. Parser le prix actuel (format: "1 000,00 $" ou "1000,00 $")
                    prix_str = soumission_found.get("prix", "0,00 $")
                    # Retirer le $ et les espaces, remplacer , par .
                    prix_clean = prix_str.replace("$", "").replace(" ", "").replace(",", ".").strip()
                    try:
                        prix_actuel = float(prix_clean)
                    except ValueError:
                        prix_actuel = 0.0

                    # 8. Soustraire le montant sans taxe
                    nouveau_prix = prix_actuel - montant_sans_taxe

                    # S'assurer que le prix ne devient pas n√©gatif
                    if nouveau_prix < 0:
                        nouveau_prix = 0

                    # 9. Formater le nouveau prix (format: "1 000,00 $")
                    # S√©parer les entiers et les d√©cimales
                    prix_int = int(nouveau_prix)
                    prix_dec = int((nouveau_prix - prix_int) * 100)

                    # Formater avec espaces pour les milliers
                    prix_int_str = f"{prix_int:,}".replace(",", " ")
                    nouveau_prix_format = f"{prix_int_str},{prix_dec:02d} $"

                    # 10. Mettre √† jour le prix
                    soumission_found["prix"] = nouveau_prix_format

                    # 11. Sauvegarder le fichier de soumissions sign√©es
                    with open(soumissions_file, "w", encoding="utf-8") as f:
                        json.dump(soumissions, f, ensure_ascii=False, indent=2)

                    # 12. Aussi mettre √† jour dans ventes_acceptees pour le chiffre d'affaires
                    ventes_acceptees_file = os.path.join(base_cloud, "ventes_acceptees", username, "ventes.json")
                    if os.path.exists(ventes_acceptees_file):
                        with open(ventes_acceptees_file, "r", encoding="utf-8") as f:
                            ventes_acceptees = json.load(f)

                        for vente in ventes_acceptees:
                            if vente.get("num") == numero_soumission:
                                vente["prix"] = nouveau_prix_format
                                break

                        with open(ventes_acceptees_file, "w", encoding="utf-8") as f:
                            json.dump(ventes_acceptees, f, ensure_ascii=False, indent=2)

                    # 13. Aussi mettre √† jour dans ventes_produit si elle y est
                    ventes_produit_file = os.path.join(base_cloud, "ventes_produit", username, "ventes.json")
                    if os.path.exists(ventes_produit_file):
                        with open(ventes_produit_file, "r", encoding="utf-8") as f:
                            ventes_produit = json.load(f)

                        for vente in ventes_produit:
                            if vente.get("num") == numero_soumission:
                                vente["prix"] = nouveau_prix_format
                                break

                        with open(ventes_produit_file, "w", encoding="utf-8") as f:
                            json.dump(ventes_produit, f, ensure_ascii=False, indent=2)

                    print(f"[REMBOURSEMENT] Traite pour {numero_soumission}: {montant_avec_taxe}$ (HT: {montant_sans_taxe:.2f}$) soustrait du prix")
                    continue

                # Charger le fichier de statuts de l'entrepreneur
                statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")
                if not os.path.exists(statuts_file):
                    continue

                with open(statuts_file, "r", encoding="utf-8") as f:
                    statuts = json.load(f)

                if numero_soumission not in statuts:
                    continue

                # Mettre √† jour le statut selon le type
                if type_paiement == "depot":
                    statuts[numero_soumission]["statutDepot"] = "traite_attente_final"
                    if "depot" in statuts[numero_soumission]:
                        statuts[numero_soumission]["depot"]["statut"] = "traite_attente_final"
                elif type_paiement == "paiement_final":
                    statuts[numero_soumission]["statutPaiementFinal"] = "traite"
                    if "paiementFinal" in statuts[numero_soumission]:
                        statuts[numero_soumission]["paiementFinal"]["statut"] = "traite"
                    statuts[numero_soumission]["statutClient"] = "traite"
                    statuts[numero_soumission]["dateTraitement"] = datetime.now().isoformat()
                elif type_paiement == "autres_paiements":
                    index = paiement.get("index", 0)
                    if "autresPaiements" in statuts[numero_soumission] and len(statuts[numero_soumission]["autresPaiements"]) > index:
                        statuts[numero_soumission]["autresPaiements"][index]["statut"] = "traite"

                statuts[numero_soumission]["dateMiseAJour"] = datetime.now().isoformat()

                # Sauvegarder les statuts modifi√©s
                with open(statuts_file, "w", encoding="utf-8") as f:
                    json.dump(statuts, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "P√©riodes sauvegard√©es avec succ√®s"}
    except Exception as e:
        print(f"Erreur lors de la sauvegarde des p√©riodes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/comptable/facturation/periodes")
async def get_periodes_facturation():
    """R√©cup√®re les p√©riodes de paiements sauvegard√©es"""
    try:
        periodes_file = os.path.join(base_cloud, "facturation_qe_periodes", "periodes.json")

        if not os.path.exists(periodes_file):
            return {"success": True, "periodes": {}}

        with open(periodes_file, "r", encoding="utf-8") as f:
            periodes = json.load(f)

        return {"success": True, "periodes": periodes}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des p√©riodes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/comptable/messages-en-attente")
async def get_messages_en_attente():
    """R√©cup√®re tous les messages en attente de r√©ponse de la comptable"""
    try:
        messages = []
        statuts_dir = os.path.join(base_cloud, "facturation_qe_statuts")

        if not os.path.exists(statuts_dir):
            return {"success": True, "messages": []}

        # Parcourir tous les entrepreneurs
        for username in os.listdir(statuts_dir):
            user_path = os.path.join(statuts_dir, username)
            if os.path.isdir(user_path):
                statuts_file = os.path.join(user_path, "statuts_clients.json")

                if os.path.exists(statuts_file):
                    with open(statuts_file, "r", encoding="utf-8") as f:
                        statuts = json.load(f)

                    # R√©cup√©rer les infos de l'entrepreneur (nom complet et photo)
                    entrepreneur_nom_complet = username
                    entrepreneur_photo = None
                    try:
                        user_info = get_user_info(username)
                        if user_info and user_info.get("success"):
                            data = user_info.get("data", {})
                            prenom = data.get("prenom", "")
                            nom = data.get("nom", "")
                            if prenom or nom:
                                entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                            # R√©cup√©rer la photo de profil
                            files = user_info.get("files", {})
                            entrepreneur_photo = files.get("profile_photo")
                        if not entrepreneur_photo:
                            # Chercher manuellement
                            user_dir = os.path.join(base_cloud, "signatures", username)
                            pattern = os.path.join(user_dir, "profile_photo*.*")
                            matching = glob.glob(pattern)
                            if matching:
                                entrepreneur_photo = f"/api/get-file/{username}/{os.path.basename(matching[0])}"
                    except Exception as e:
                        print(f"[WARN] Impossible de r√©cup√©rer infos entrepreneur {username}: {e}")

                    for numero, data in statuts.items():
                        # V√©rifier s'il y a un refus avec conversation
                        refus = data.get("refus") or (data.get("depot", {}).get("refus"))
                        if refus and refus.get("conversation"):
                            conversation = refus["conversation"]
                            # V√©rifier si le dernier message est de l'entrepreneur
                            if conversation and conversation[-1].get("de") == "entrepreneur":
                                # Compter les messages non lus de l'entrepreneur
                                messages_non_lus = 0
                                for msg in reversed(conversation):
                                    if msg.get("de") == "entrepreneur":
                                        messages_non_lus += 1
                                    else:
                                        break

                                # R√©cup√©rer les infos du client depuis ventes_acceptees
                                client_info = {}
                                try:
                                    # D'abord essayer ventes_acceptees
                                    ventes_file = os.path.join(base_cloud, "ventes_acceptees", username, "ventes.json")
                                    if os.path.exists(ventes_file):
                                        with open(ventes_file, "r", encoding="utf-8") as vf:
                                            ventes = json.load(vf)
                                        for vente in ventes:
                                            if vente.get("num") == numero:
                                                client_info = {
                                                    "clientNom": vente.get("clientNom", ""),
                                                    "clientPrenom": vente.get("clientPrenom", ""),
                                                    "adresse": vente.get("adresse", ""),
                                                    "telephone": vente.get("telephone", ""),
                                                    "courriel": vente.get("courriel", ""),
                                                    "prix": vente.get("prix", "")
                                                }
                                                break
                                    # Si pas trouv√©, essayer soumissions_completes
                                    if not client_info.get("clientNom") and not client_info.get("clientPrenom"):
                                        soum_file = os.path.join(base_cloud, "soumissions_completes", username, "soumissions.json")
                                        if os.path.exists(soum_file):
                                            with open(soum_file, "r", encoding="utf-8") as sf:
                                                soumissions = json.load(sf)
                                            for soum in soumissions:
                                                if soum.get("num") == numero:
                                                    client_info = {
                                                        "clientNom": soum.get("nom", ""),
                                                        "clientPrenom": soum.get("prenom", ""),
                                                        "adresse": soum.get("adresse", ""),
                                                        "telephone": soum.get("telephone", ""),
                                                        "courriel": soum.get("courriel", ""),
                                                        "prix": soum.get("prix", "")
                                                    }
                                                    break
                                except Exception as ce:
                                    print(f"[WARN] Erreur r√©cup infos client {numero}: {ce}")

                                # R√©cup√©rer les infos de paiement (depot)
                                paiement_info = data.get("depot", {})

                                messages.append({
                                    "entrepreneur": username,
                                    "entrepreneurNomComplet": entrepreneur_nom_complet,
                                    "entrepreneurPhoto": entrepreneur_photo,
                                    "numeroSoumission": numero,
                                    "dernierMessage": conversation[-1].get("message", "")[:100],
                                    "date": conversation[-1].get("date"),
                                    "nombreMessages": messages_non_lus,
                                    "clientInfo": client_info,
                                    "paiementInfo": paiement_info
                                })

        # Trier par date (plus r√©cent en premier)
        messages.sort(key=lambda x: x.get("date", ""), reverse=True)

        return {"success": True, "messages": messages}
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des messages en attente: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/facturationqe/client/{username}/{numero_soumission}/conversation")
async def get_conversation_refus(username: str, numero_soumission: str):
    """R√©cup√®re la conversation de refus d'un client"""
    try:
        statuts_file = os.path.join(base_cloud, "facturation_qe_statuts", username, "statuts_clients.json")

        if not os.path.exists(statuts_file):
            raise HTTPException(status_code=404, detail="Statuts non trouv√©s")

        with open(statuts_file, "r", encoding="utf-8") as f:
            statuts = json.load(f)

        if numero_soumission not in statuts:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        data = statuts[numero_soumission]
        refus = data.get("refus") or (data.get("depot", {}).get("refus"))

        if not refus:
            return {"success": True, "conversation": []}

        return {"success": True, "conversation": refus.get("conversation", [])}
    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration de la conversation: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Compter les employ√©s en attente comptable
@app.get("/api/comptable/employes-en-attente/count")
async def count_employes_en_attente_comptable():
    """Compte le nombre total d'employ√©s en attente de validation comptable (activations + modifications)"""
    try:
        total_activations = 0
        total_modifications = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0, "activations": 0, "modifications": 0}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Charger les nouveaux employ√©s (activations)
                employes_nouveaux = load_employes(username, "nouveaux")
                for employe in employes_nouveaux:
                    if employe.get("statut") == "En attente comptable":
                        total_activations += 1

                # Charger les employ√©s actifs (modifications en attente comptable)
                employes_actifs = load_employes(username, "actifs")
                for employe in employes_actifs:
                    if employe.get("statut") == "Modification en attente comptable":
                        total_modifications += 1

        total = total_activations + total_modifications
        return {"success": True, "count": total, "activations": total_activations, "modifications": total_modifications}
    except Exception as e:
        print(f"Erreur lors du comptage des employ√©s en attente comptable: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Lister tous les employ√©s en attente comptable
@app.get("/api/comptable/employes-en-attente/liste")
async def liste_employes_en_attente_comptable():
    """Liste tous les employ√©s en attente de validation comptable avec les infos de l'entrepreneur"""
    try:
        employes_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "employes": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Charger les nouveaux employ√©s
                employes_nouveaux = load_employes(username, "nouveaux")

                # R√©cup√©rer ceux en attente comptable
                for employe in employes_nouveaux:
                    if employe.get("statut") == "En attente comptable":
                        # R√©cup√©rer les infos de l'entrepreneur (nom complet et photo)
                        entrepreneur_nom_complet = username
                        photo_profil = None

                        entrepreneur_department = None
                        try:
                            user_info = get_user_info(username)
                            if user_info and user_info.get("success"):
                                # R√©cup√©rer le nom complet depuis data
                                data = user_info.get("data", {})
                                prenom = data.get("prenom", "")
                                nom = data.get("nom", "")
                                if prenom or nom:
                                    entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                                # R√©cup√©rer la photo depuis files
                                files = user_info.get("files", {})
                                photo_profil = files.get("profile_photo")
                                # R√©cup√©rer le d√©partement
                                entrepreneur_department = data.get("department")
                        except:
                            pass

                        # Si pas de photo via get_user_info, chercher manuellement
                        if not photo_profil:
                            import glob as glob_module
                            user_dir = os.path.join(base_cloud, "signatures", username)
                            pattern = os.path.join(user_dir, f"profile_photo*.*")
                            matching_files = glob_module.glob(pattern)
                            if matching_files:
                                filename = os.path.basename(matching_files[0])
                                photo_profil = f"/api/get-file/{username}/{filename}"

                        # Ajouter les infos de l'entrepreneur
                        employe_avec_info = employe.copy()
                        employe_avec_info["entrepreneur"] = entrepreneur_nom_complet
                        employe_avec_info["entrepreneurUsername"] = username
                        employe_avec_info["entrepreneurPhoto"] = photo_profil
                        employe_avec_info["entrepreneurDepartment"] = entrepreneur_department
                        employes_en_attente.append(employe_avec_info)

        return {"success": True, "employes": employes_en_attente}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des employ√©s en attente comptable: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Lister toutes les modifications en attente de validation comptable
@app.get("/api/comptable/modifications-en-attente/liste")
async def liste_modifications_en_attente_comptable():
    """Liste toutes les modifications d'employ√©s en attente de validation comptable"""
    try:
        modifications_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "modifications": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Charger les employ√©s actifs avec statut "Modification en attente comptable"
                employes_actifs = load_employes(username, "actifs")
                modifications = load_modifications(username)

                for employe in employes_actifs:
                    if employe.get("statut") == "Modification en attente comptable":
                        # R√©cup√©rer les infos de l'entrepreneur
                        entrepreneur_nom_complet = username
                        photo_profil = None
                        entrepreneur_department = None

                        try:
                            user_info = get_user_info(username)
                            if user_info and user_info.get("success"):
                                data = user_info.get("data", {})
                                prenom = data.get("prenom", "")
                                nom = data.get("nom", "")
                                if prenom or nom:
                                    entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                                files = user_info.get("files", {})
                                photo_profil = files.get("profile_photo")
                                # R√©cup√©rer le d√©partement
                                entrepreneur_department = data.get("department")
                        except:
                            pass

                        # Si pas de photo via get_user_info, chercher manuellement
                        if not photo_profil:
                            import glob as glob_module
                            user_dir = os.path.join(base_cloud, "signatures", username)
                            pattern = os.path.join(user_dir, f"profile_photo*.*")
                            matching_files = glob_module.glob(pattern)
                            if matching_files:
                                filename = os.path.basename(matching_files[0])
                                photo_profil = f"/api/get-file/{username}/{filename}"

                        # Trouver les donn√©es de modification correspondantes
                        modif_data = None
                        for m in modifications:
                            if m.get("employe_id") == employe.get("id"):
                                modif_data = m
                                break

                        modif_avec_info = employe.copy()
                        modif_avec_info["entrepreneur"] = entrepreneur_nom_complet
                        modif_avec_info["entrepreneurUsername"] = username
                        modif_avec_info["entrepreneurPhoto"] = photo_profil
                        modif_avec_info["entrepreneurDepartment"] = entrepreneur_department
                        modif_avec_info["requestType"] = "modification"

                        # Ajouter les donn√©es anciennes/nouvelles si disponibles
                        if modif_data:
                            modif_avec_info["anciennes_donnees"] = modif_data.get("anciennes_donnees", {})
                            modif_avec_info["nouvelles_donnees"] = modif_data.get("nouvelles_donnees", {})

                        modifications_en_attente.append(modif_avec_info)

        return {"success": True, "modifications": modifications_en_attente}
    except Exception as e:
        print(f"Erreur lors du chargement de la liste des modifications en attente comptable: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Stats globales des employ√©s pour comptable/direction
@app.get("/api/coach/employes/stats")
async def get_employes_stats():
    """Retourne les statistiques globales des employ√©s"""
    try:
        stats = {"total": 0, "pending": 0, "finEmploi": 0}
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return stats

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # Compter les actifs
                employes_actifs = load_employes(username, "actifs")
                stats["total"] += len(employes_actifs)

                # Compter les nouveaux en attente comptable
                employes_nouveaux = load_employes(username, "nouveaux")
                for emp in employes_nouveaux:
                    if emp.get("statut") == "En attente comptable":
                        stats["pending"] += 1

                # Compter les fins d'emploi en attente (√† impl√©menter si n√©cessaire)
                # stats["finEmploi"] += ...

        return stats
    except Exception as e:
        print(f"Erreur stats employ√©s: {e}")
        return {"total": 0, "pending": 0, "finEmploi": 0}

# Derniers employ√©s valid√©s
@app.get("/api/coach/employes/derniers-valides")
async def get_derniers_valides(limit: int = 5):
    """Retourne les derniers employ√©s valid√©s"""
    try:
        derniers_valides = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"employes": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                employes_actifs = load_employes(username, "actifs")
                for emp in employes_actifs:
                    emp_info = {
                        "nom": emp.get("nom", "-"),
                        "dateValidation": emp.get("date_validation_comptable") or emp.get("dateActivation") or "-",
                        "entrepreneur": username
                    }
                    derniers_valides.append(emp_info)

        # Trier par date de validation (plus r√©cent en premier)
        derniers_valides.sort(key=lambda x: x.get("dateValidation", ""), reverse=True)

        return {"employes": derniers_valides[:limit]}
    except Exception as e:
        print(f"Erreur derniers valid√©s: {e}")
        return {"employes": []}

@app.get("/api/coach/employes/historique")
async def get_historique_employes():
    """Retourne l'historique complet des validations/refus d'employ√©s"""
    try:
        historique = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"historique": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer la photo de profil et le nom complet de l'entrepreneur
                photo_profil = None
                entrepreneur_nom_complet = username  # Fallback au username
                user_info = get_user_info(username)
                if user_info and user_info.get("success"):
                    files = user_info.get("files", {})
                    photo_profil = files.get("profile_photo")
                    # R√©cup√©rer le nom complet (prenom + nom)
                    data = user_info.get("data", {})
                    prenom = data.get("prenom", "")
                    nom = data.get("nom", "")
                    if prenom or nom:
                        entrepreneur_nom_complet = f"{prenom} {nom}".strip()

                # Si pas trouv√© via get_user_info, chercher manuellement profile_photo_*
                if not photo_profil:
                    import glob as glob_module
                    user_dir = os.path.join(base_cloud, "signatures", username)
                    pattern = os.path.join(user_dir, f"profile_photo*.*")
                    matching_files = glob_module.glob(pattern)
                    if matching_files:
                        filename = os.path.basename(matching_files[0])
                        photo_profil = f"/api/get-file/{username}/{filename}"

                # Employ√©s actifs (valid√©s comme actif)
                employes_actifs = load_employes(username, "actifs")
                for emp in employes_actifs:
                    # Ne pas inclure ceux en attente d'inactivation
                    if emp.get("statut") and "Inactivation" in emp.get("statut", ""):
                        continue
                    historique.append({
                        "nom": emp.get("nom", "-"),
                        "entrepreneur": entrepreneur_nom_complet,
                        "entrepreneurPhoto": photo_profil,
                        "poste": emp.get("poste") or emp.get("posteService") or "-",
                        "action": "Valid√©",
                        "actionType": "activation",
                        "date": emp.get("date_validation_comptable") or emp.get("dateActivation") or "-",
                        "validePar": emp.get("valide_par") or "Direction",
                        # Donn√©es compl√®tes pour le modal
                        "id": emp.get("id", ""),
                        "genre": emp.get("genre", "-"),
                        "courriel": emp.get("courriel", "-"),
                        "telephone": emp.get("telephone", "-"),
                        "nas": emp.get("nas", "-"),
                        "adresse": emp.get("adresse", "-"),
                        "appartement": emp.get("appartement", "-"),
                        "ville": emp.get("ville", "-"),
                        "codePostal": emp.get("codePostal", "-"),
                        "dateCandidature": emp.get("dateCandidature", "-"),
                        "datePremiere": emp.get("datePremiere", "-"),
                        "posteService": emp.get("posteService", "-"),
                        "tauxHoraire": emp.get("tauxHoraire", "-"),
                        "dateActivation": emp.get("dateActivation", "-"),
                        "statut": emp.get("statut", "Actif")
                    })

                # Employ√©s inactifs (valid√©s comme inactif par comptable)
                employes_inactifs = load_employes(username, "inactifs")
                for emp in employes_inactifs:
                    # Exclure ceux qui ont une r√©activation en cours
                    if emp.get("statut") and "R√©activation" in emp.get("statut", ""):
                        continue
                    historique.append({
                        "nom": emp.get("nom", "-"),
                        "entrepreneur": entrepreneur_nom_complet,
                        "entrepreneurPhoto": photo_profil,
                        "poste": emp.get("poste") or emp.get("posteService") or "-",
                        "action": "Inactif",
                        "actionType": "inactivation",
                        "date": emp.get("date_validation_comptable_inactivation") or emp.get("date_inactivation") or "-",
                        "validePar": emp.get("valide_par_inactivation") or "Direction",
                        # Donn√©es compl√®tes pour le modal
                        "id": emp.get("id", ""),
                        "genre": emp.get("genre", "-"),
                        "courriel": emp.get("courriel", "-"),
                        "telephone": emp.get("telephone", "-"),
                        "nas": emp.get("nas", "-"),
                        "adresse": emp.get("adresse", "-"),
                        "appartement": emp.get("appartement", "-"),
                        "ville": emp.get("ville", "-"),
                        "codePostal": emp.get("codePostal", "-"),
                        "dateCandidature": emp.get("dateCandidature", "-"),
                        "datePremiere": emp.get("datePremiere", "-"),
                        "posteService": emp.get("posteService", "-"),
                        "tauxHoraire": emp.get("tauxHoraire", "-"),
                        "dateActivation": emp.get("dateActivation", "-"),
                        "statut": emp.get("statut", "Inactif"),
                        "motif_inactivation": emp.get("motif_inactivation", "-"),
                        "justificatif_inactivation": emp.get("justificatif_inactivation", "-"),
                        "date_demande_inactivation": emp.get("date_demande_inactivation", "-"),
                        "date_validation_coach_inactivation": emp.get("date_validation_coach_inactivation", "-")
                    })

                # Employ√©s refus√©s (si le fichier existe)
                employes_refuses = load_employes(username, "refuses")
                for emp in employes_refuses:
                    historique.append({
                        "nom": emp.get("nom", "-"),
                        "entrepreneur": entrepreneur_nom_complet,
                        "entrepreneurPhoto": photo_profil,
                        "poste": emp.get("poste") or emp.get("posteService") or "-",
                        "action": "Refus√©",
                        "actionType": "refus",
                        "date": emp.get("date_refus") or emp.get("dateCandidature") or "-",
                        "validePar": emp.get("refuse_par") or "Direction",
                        # Donn√©es compl√®tes pour le modal
                        "id": emp.get("id", ""),
                        "genre": emp.get("genre", "-"),
                        "courriel": emp.get("courriel", "-"),
                        "telephone": emp.get("telephone", "-"),
                        "nas": emp.get("nas", "-"),
                        "adresse": emp.get("adresse", "-"),
                        "appartement": emp.get("appartement", "-"),
                        "ville": emp.get("ville", "-"),
                        "codePostal": emp.get("codePostal", "-"),
                        "dateCandidature": emp.get("dateCandidature", "-"),
                        "datePremiere": emp.get("datePremiere", "-"),
                        "posteService": emp.get("posteService", "-"),
                        "tauxHoraire": emp.get("tauxHoraire", "-"),
                        "dateActivation": emp.get("dateActivation", "-"),
                        "statut": "Refus√©",
                        "motif_refus": emp.get("motif_refus", "-")
                    })

        # Trier par date (plus r√©cent en premier)
        historique.sort(key=lambda x: x.get("date", "") or "", reverse=True)

        return {"historique": historique}
    except Exception as e:
        print(f"Erreur historique employ√©s: {e}")
        return {"historique": []}

# Refuser un candidat employ√©
@app.delete("/api/employes/{username}/nouveaux/{employe_id}")
async def refuser_employe(username: str, employe_id: str):
    """Refuse un candidat employ√© et le supprime"""
    try:
        employes_nouveaux = load_employes(username, "nouveaux")

        # Filtrer pour supprimer l'employ√©
        employes_nouveaux_restants = [e for e in employes_nouveaux if e.get("id") != employe_id]

        if len(employes_nouveaux_restants) == len(employes_nouveaux):
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        if save_employes(username, "nouveaux", employes_nouveaux_restants):
            return {"success": True, "message": "Employ√© refus√©"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/employes/{username}/reactivations/{employe_id}")
async def refuser_reactivation(username: str, employe_id: str):
    """Refuse une r√©activation et la supprime"""
    try:
        reactivations = load_reactivations(username)

        # Filtrer pour supprimer la r√©activation
        reactivations_restantes = [e for e in reactivations if e.get("id") != employe_id]

        if len(reactivations_restantes) == len(reactivations):
            raise HTTPException(status_code=404, detail="R√©activation non trouv√©e")

        if save_reactivations(username, reactivations_restantes):
            return {"success": True, "message": "R√©activation refus√©e"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/employes/{username}/actifs/{employe_id}")
async def refuser_employe_actif(username: str, employe_id: str):
    """Refuse une modification d'employ√© actif et supprime l'employ√©"""
    try:
        employes_actifs = load_employes(username, "actifs")

        # Filtrer pour supprimer l'employ√©
        employes_actifs_restants = [e for e in employes_actifs if e.get("id") != employe_id]

        if len(employes_actifs_restants) == len(employes_actifs):
            raise HTTPException(status_code=404, detail="Employ√© actif non trouv√©")

        if save_employes(username, "actifs", employes_actifs_restants):
            return {"success": True, "message": "Employ√© actif refus√©"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Terminer un employ√© (actif vers termin√©)
@app.post("/api/employes/{username}/terminer/{employe_id}")
async def terminer_employe(username: str, employe_id: str, terminer_data: TerminerEmploye):
    """Termine un employ√© et le d√©place vers la liste des termin√©s"""
    print(f"DEBUG: Terminer employ√© {employe_id} avec motif: {terminer_data.motif}")
    try:
        employes_actifs = load_employes(username, "actifs")
        employes_termines = load_employes(username, "termines")
        
        # Trouver l'employ√© √† terminer
        employe_a_terminer = None
        employes_actifs_restants = []
        
        for employe in employes_actifs:
            if employe.get("id") == employe_id:
                employe_a_terminer = employe
            else:
                employes_actifs_restants.append(employe)
        
        if not employe_a_terminer:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")
        
        # Ajouter la date de fin, le motif, le justificatif et changer le statut
        employe_a_terminer["dateTermine"] = datetime.now().strftime("%Y-%m-%d")
        employe_a_terminer["statut"] = "Termin√©"
        employe_a_terminer["motifTermine"] = terminer_data.motif
        employe_a_terminer["justificatif"] = terminer_data.justificatif
        print(f"DEBUG: Employ√© termin√© avec motif: {employe_a_terminer['motifTermine']} et justificatif: {employe_a_terminer['justificatif']}")
        
        # Ajouter aux employ√©s termin√©s
        employes_termines.append(employe_a_terminer)
        
        # Sauvegarder les deux listes
        if save_employes(username, "actifs", employes_actifs_restants) and save_employes(username, "termines", employes_termines):
            return {"success": True, "message": "Employ√© termin√© avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Modifier un employ√© actif
@app.put("/api/employes/{username}/modifier/{employe_id}")
async def modifier_employe(username: str, employe_id: str, employe_data: EmployeModifier):
    """Modifie les informations d'un employ√© actif"""
    try:
        employes_actifs = load_employes(username, "actifs")
        
        # Trouver l'employ√© √† modifier
        employe_trouve = False
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                # Mettre √† jour les informations en gardant les donn√©es existantes
                employes_actifs[i].update({
                    "nom": employe_data.nom,
                    "nas": employe_data.nas,
                    "genre": employe_data.genre,
                    "adresse": employe_data.adresse,
                    "appartement": employe_data.appartement or "-",
                    "ville": employe_data.ville,
                    "codePostal": employe_data.codePostal,
                    "telephone": employe_data.telephone,
                    "courriel": employe_data.courriel,
                    "datePremiere": employe_data.datePremiere,
                    "posteService": employe_data.posteService,
                    "tauxHoraire": employe_data.tauxHoraire,
                    "dateModification": datetime.now().strftime("%Y-%m-%d")
                })
                employe_trouve = True
                break
        
        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")
        
        if save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Employ√© modifi√© avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Helpers pour les modifications en attente
def load_modifications(username: str):
    """Charge les modifications en attente pour un utilisateur"""
    filepath = os.path.join(base_cloud, "employes", username, "modifications.json")
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_modifications(username: str, modifications: list):
    """Sauvegarde les modifications en attente"""
    filepath = os.path.join(base_cloud, "employes", username, "modifications.json")
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(modifications, f, indent=2, ensure_ascii=False)
    return True

# Demande de modification d'un employ√© (avec validation coach/direction)
@app.post("/api/employes/{username}/demande-modification/{employe_id}")
async def demande_modification_employe(
    username: str,
    employe_id: str,
    nom: str = Form(...),
    nas: str = Form(...),
    genre: str = Form(...),
    adresse: str = Form(...),
    appartement: str = Form(""),
    ville: str = Form(...),
    codePostal: str = Form(...),
    telephone: str = Form(...),
    courriel: str = Form(...),
    datePremiere: str = Form(...),
    posteService: str = Form(...),
    tauxHoraire: str = Form(...),
    dateNaissance: str = Form(...),
    specimenCheque: UploadFile = File(None),
    certificatSecurite: UploadFile = File(None),
    carteAssurance: UploadFile = File(None)
):
    """Demande de modification d'un employ√© - stocke les nouvelles donn√©es en attente, l'employ√© reste actif"""
    try:
        employes_actifs = load_employes(username, "actifs")

        # Trouver l'employ√© √† modifier
        employe_trouve = None
        employe_index = None
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                employe_trouve = employe
                employe_index = i
                break

        if employe_trouve is None:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        # Cr√©er le dossier pour les documents
        employe_folder = os.path.join(base_cloud, "employes", username, employe_id)
        os.makedirs(employe_folder, exist_ok=True)

        # Sauvegarder les nouveaux fichiers s'ils sont fournis
        nouveaux_documents = {}

        if specimenCheque and specimenCheque.filename:
            specimen_path = os.path.join(employe_folder, f"specimen_cheque_{specimenCheque.filename}")
            with open(specimen_path, "wb") as f:
                f.write(await specimenCheque.read())
            nouveaux_documents["specimenCheque"] = f"specimen_cheque_{specimenCheque.filename}"

        if certificatSecurite and certificatSecurite.filename:
            certificat_path = os.path.join(employe_folder, f"certificat_securite_{certificatSecurite.filename}")
            with open(certificat_path, "wb") as f:
                f.write(await certificatSecurite.read())
            nouveaux_documents["certificatSecurite"] = f"certificat_securite_{certificatSecurite.filename}"

        if carteAssurance and carteAssurance.filename:
            carte_path = os.path.join(employe_folder, f"carte_assurance_{carteAssurance.filename}")
            with open(carte_path, "wb") as f:
                f.write(await carteAssurance.read())
            nouveaux_documents["carteAssurance"] = f"carte_assurance_{carteAssurance.filename}"

        # Stocker les anciennes donn√©es (donn√©es actuelles de l'employ√©)
        anciennes_donnees = {
            "nom": employe_trouve.get("nom"),
            "nas": employe_trouve.get("nas"),
            "genre": employe_trouve.get("genre"),
            "adresse": employe_trouve.get("adresse"),
            "appartement": employe_trouve.get("appartement"),
            "ville": employe_trouve.get("ville"),
            "codePostal": employe_trouve.get("codePostal"),
            "telephone": employe_trouve.get("telephone"),
            "courriel": employe_trouve.get("courriel"),
            "datePremiere": employe_trouve.get("datePremiere"),
            "posteService": employe_trouve.get("posteService"),
            "departement": employe_trouve.get("departement"),
            "tauxHoraire": employe_trouve.get("tauxHoraire"),
            "dateNaissance": employe_trouve.get("dateNaissance"),
            "specimenCheque": employe_trouve.get("specimenCheque"),
            "certificatSecurite": employe_trouve.get("certificatSecurite"),
            "carteAssurance": employe_trouve.get("carteAssurance")
        }

        # Stocker les nouvelles donn√©es demand√©es
        nouvelles_donnees = {
            "nom": nom,
            "nas": nas,
            "genre": genre,
            "adresse": adresse,
            "appartement": appartement or "-",
            "ville": ville,
            "codePostal": codePostal,
            "telephone": telephone,
            "courriel": courriel,
            "datePremiere": datePremiere,
            "posteService": posteService,
            "departement": employe_trouve.get("departement", "0"),
            "tauxHoraire": tauxHoraire,
            "dateNaissance": dateNaissance,
            "specimenCheque": nouveaux_documents.get("specimenCheque") or employe_trouve.get("specimenCheque"),
            "certificatSecurite": nouveaux_documents.get("certificatSecurite") or employe_trouve.get("certificatSecurite"),
            "carteAssurance": nouveaux_documents.get("carteAssurance") or employe_trouve.get("carteAssurance")
        }

        # Cr√©er l'objet de modification en attente
        modification = {
            "id": employe_id,
            "employe_id": employe_id,
            "anciennes_donnees": anciennes_donnees,
            "nouvelles_donnees": nouvelles_donnees,
            "statut": "Modification en attente de validation",
            "date_demande": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        # Charger les modifications existantes et ajouter la nouvelle
        modifications = load_modifications(username)
        # Supprimer toute modification existante pour cet employ√©
        modifications = [m for m in modifications if m.get("employe_id") != employe_id]
        modifications.append(modification)

        # Mettre √† jour le statut de l'employ√© dans actifs (mais garder ses donn√©es actuelles)
        employes_actifs[employe_index]["statut"] = "Modification en attente de validation"
        employes_actifs[employe_index]["anciennes_donnees"] = anciennes_donnees
        employes_actifs[employe_index]["nouvelles_donnees"] = nouvelles_donnees
        employes_actifs[employe_index]["date_demande_modification"] = modification["date_demande"]

        if save_modifications(username, modifications) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Demande de modification envoy√©e pour validation"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Valider une modification d'employ√© (coach) - passe en attente comptable
@app.post("/api/employes/{username}/valider-modification/{employe_id}")
async def valider_modification_employe(username: str, employe_id: str):
    """Valide la modification par le coach - passe en attente comptable"""
    try:
        employes_actifs = load_employes(username, "actifs")
        modifications = load_modifications(username)

        # Trouver l'employ√©
        employe_trouve = False
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                # Passer au statut "en attente comptable"
                employes_actifs[i]["statut"] = "Modification en attente comptable"
                employes_actifs[i]["date_validation_coach_modification"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                employe_trouve = True
                break

        # Mettre √† jour aussi dans le fichier modifications
        for i, modif in enumerate(modifications):
            if modif.get("employe_id") == employe_id:
                modifications[i]["statut"] = "Modification en attente comptable"
                modifications[i]["date_validation_coach"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        if save_employes(username, "actifs", employes_actifs) and save_modifications(username, modifications):
            return {"success": True, "message": "Modification valid√©e par le coach, en attente comptable"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Valider une modification d'employ√© (comptable) - applique les modifications
@app.post("/api/employes/{username}/valider-modification-comptable/{employe_id}")
async def valider_modification_comptable(username: str, employe_id: str):
    """Valide la modification par le comptable - applique les nouvelles donn√©es"""
    try:
        employes_actifs = load_employes(username, "actifs")
        modifications = load_modifications(username)

        # Trouver l'employ√© et appliquer les nouvelles donn√©es
        employe_trouve = False
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                nouvelles = employe.get("nouvelles_donnees", {})
                if nouvelles:
                    # Appliquer les nouvelles donn√©es (incluant les documents)
                    employes_actifs[i].update({
                        "nom": nouvelles.get("nom", employe.get("nom")),
                        "nas": nouvelles.get("nas", employe.get("nas")),
                        "genre": nouvelles.get("genre", employe.get("genre")),
                        "adresse": nouvelles.get("adresse", employe.get("adresse")),
                        "appartement": nouvelles.get("appartement", employe.get("appartement")),
                        "ville": nouvelles.get("ville", employe.get("ville")),
                        "codePostal": nouvelles.get("codePostal", employe.get("codePostal")),
                        "telephone": nouvelles.get("telephone", employe.get("telephone")),
                        "courriel": nouvelles.get("courriel", employe.get("courriel")),
                        "datePremiere": nouvelles.get("datePremiere", employe.get("datePremiere")),
                        "posteService": nouvelles.get("posteService", employe.get("posteService")),
                        "tauxHoraire": nouvelles.get("tauxHoraire", employe.get("tauxHoraire")),
                        "specimenCheque": nouvelles.get("specimenCheque", employe.get("specimenCheque")),
                        "certificatSecurite": nouvelles.get("certificatSecurite", employe.get("certificatSecurite")),
                        "carteAssurance": nouvelles.get("carteAssurance", employe.get("carteAssurance"))
                    })

                # Nettoyer et remettre en statut Actif
                employes_actifs[i]["statut"] = "Actif"
                employes_actifs[i].pop("anciennes_donnees", None)
                employes_actifs[i].pop("nouvelles_donnees", None)
                employes_actifs[i].pop("date_demande_modification", None)
                employes_actifs[i].pop("date_validation_coach_modification", None)
                # Effacer la conversation de refus si elle existe
                employes_actifs[i].pop("conversation_refus", None)
                employes_actifs[i].pop("motif_refus_comptable", None)
                employes_actifs[i].pop("date_refus_comptable", None)
                employes_actifs[i]["date_modification"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                employe_trouve = True
                break

        # Supprimer la modification du fichier modifications
        modifications = [m for m in modifications if m.get("employe_id") != employe_id]

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        if save_employes(username, "actifs", employes_actifs) and save_modifications(username, modifications):
            return {"success": True, "message": "Modification valid√©e et appliqu√©e avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser une modification d'employ√© (coach ou comptable)
@app.post("/api/employes/{username}/refuser-modification/{employe_id}")
async def refuser_modification_employe(username: str, employe_id: str, request: Request):
    """Refuse la modification - l'employ√© reste avec ses donn√©es actuelles"""
    try:
        # R√©cup√©rer la raison du refus
        try:
            body = await request.json()
            motif_refus = body.get("motif_refus", "Aucune raison sp√©cifi√©e")
        except:
            motif_refus = "Aucune raison sp√©cifi√©e"

        employes_actifs = load_employes(username, "actifs")
        modifications = load_modifications(username)

        # Trouver l'employ√© et nettoyer les donn√©es de modification
        employe_trouve = False
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                # Nettoyer les donn√©es de modification et remettre en statut Refus√©
                employes_actifs[i]["statut"] = "Modification refus√©e"
                employes_actifs[i]["motif_refus_modification"] = motif_refus
                employes_actifs[i]["date_refus_modification"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                employes_actifs[i].pop("anciennes_donnees", None)
                employes_actifs[i].pop("nouvelles_donnees", None)
                employes_actifs[i].pop("date_demande_modification", None)
                employes_actifs[i].pop("date_validation_coach_modification", None)
                employe_trouve = True
                break

        # Supprimer la modification du fichier modifications
        modifications = [m for m in modifications if m.get("employe_id") != employe_id]

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")

        if save_employes(username, "actifs", employes_actifs) and save_modifications(username, modifications):
            return {"success": True, "message": "Modification refus√©e"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# R√©activer un employ√© termin√©
@app.post("/api/employes/{username}/reactiver/{employe_id}")
async def reactiver_employe(username: str, employe_id: str):
    """R√©active un employ√© termin√© et le remet dans les actifs"""
    try:
        employes_termines = load_employes(username, "termines")
        employes_actifs = load_employes(username, "actifs")
        
        # Trouver l'employ√© √† r√©activer
        employe_a_reactiver = None
        employes_termines_restants = []
        
        for employe in employes_termines:
            if employe.get("id") == employe_id:
                employe_a_reactiver = employe
            else:
                employes_termines_restants.append(employe)
        
        if not employe_a_reactiver:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√©")
        
        # Mettre √† jour le statut et ajouter la date de r√©activation
        employe_a_reactiver["statut"] = "Actif"
        employe_a_reactiver["dateReactivation"] = datetime.now().strftime("%Y-%m-%d")
        # Supprimer la date de fin
        if "dateTermine" in employe_a_reactiver:
            del employe_a_reactiver["dateTermine"]
        
        # Ajouter aux employ√©s actifs
        employes_actifs.append(employe_a_reactiver)
        
        # Sauvegarder les deux listes
        if save_employes(username, "termines", employes_termines_restants) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Employ√© r√©activ√© avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# =============================================
# PROCESSUS D'INACTIVATION (Entrepreneur ‚Üí Coach ‚Üí Comptable)
# =============================================

# Charger/Sauvegarder les demandes d'inactivation
def load_inactivations(username):
    """Charge les demandes d'inactivation pour un entrepreneur"""
    filepath = os.path.join(base_cloud, "employes", username, "inactivations.json")
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_inactivations(username, inactivations):
    """Sauvegarde les demandes d'inactivation pour un entrepreneur"""
    filepath = os.path.join(base_cloud, "employes", username, "inactivations.json")
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(inactivations, f, ensure_ascii=False, indent=2)
    return True

# Demander l'inactivation d'un employ√© (entrepreneur)
@app.post("/api/employes/{username}/demander-inactivation/{employe_id}")
async def demander_inactivation(username: str, employe_id: str, data: TerminerEmploye):
    """L'entrepreneur demande l'inactivation d'un employ√© actif"""
    try:
        employes_actifs = load_employes(username, "actifs")
        inactivations = load_inactivations(username)

        # V√©rifier que l'employ√© n'est pas d√©j√† en demande d'inactivation
        for inact in inactivations:
            if inact.get("id") == employe_id:
                raise HTTPException(status_code=400, detail="Une demande d'inactivation existe d√©j√† pour cet employ√©")

        # Trouver l'employ√© dans les actifs
        employe_trouve = None
        for employe in employes_actifs:
            if employe.get("id") == employe_id:
                employe_trouve = employe.copy()
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√© dans les actifs")

        # Cr√©er la demande d'inactivation avec motif, date de fin et justificatif
        employe_trouve["statut"] = "Inactivation en attente de validation"
        employe_trouve["date_demande_inactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        employe_trouve["motif_inactivation"] = data.motif
        employe_trouve["dateFinEmploi"] = data.dateFinEmploi
        employe_trouve["justificatif_inactivation"] = data.justificatif

        inactivations.append(employe_trouve)

        # Mettre √† jour le statut dans actifs.json aussi pour afficher le spinner
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                employes_actifs[i]["statut"] = "Inactivation en attente de validation"
                employes_actifs[i]["date_demande_inactivation"] = employe_trouve["date_demande_inactivation"]
                employes_actifs[i]["motif_inactivation"] = data.motif
                employes_actifs[i]["dateFinEmploi"] = data.dateFinEmploi
                employes_actifs[i]["justificatif_inactivation"] = data.justificatif
                break

        if save_inactivations(username, inactivations) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Demande d'inactivation envoy√©e pour validation"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Annuler une demande d'inactivation (entrepreneur)
@app.delete("/api/employes/{username}/annuler-inactivation/{employe_id}")
async def annuler_inactivation(username: str, employe_id: str):
    """L'entrepreneur annule une demande d'inactivation en attente"""
    try:
        inactivations = load_inactivations(username)
        employes_actifs = load_employes(username, "actifs")

        # Trouver et supprimer la demande
        inactivations_restantes = []
        trouve = False

        for inact in inactivations:
            if inact.get("id") == employe_id:
                # V√©rifier que la demande est encore au stade entrepreneur
                if inact.get("statut") != "Inactivation en attente de validation":
                    raise HTTPException(status_code=400, detail="La demande a d√©j√† √©t√© valid√©e par le coach, impossible d'annuler")
                trouve = True
            else:
                inactivations_restantes.append(inact)

        if not trouve:
            raise HTTPException(status_code=404, detail="Demande d'inactivation non trouv√©e")

        # Remettre le statut de l'employ√© √† "Actif" dans actifs.json
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                employes_actifs[i]["statut"] = "Actif"
                employes_actifs[i].pop("date_demande_inactivation", None)
                break

        if save_inactivations(username, inactivations_restantes) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Demande d'inactivation annul√©e"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Valider une inactivation (coach) - passe de "en attente de validation" √† "en attente comptable"
@app.post("/api/employes/{username}/valider-inactivation/{employe_id}")
async def valider_inactivation_coach(username: str, employe_id: str):
    """Le coach valide une demande d'inactivation et la passe en attente comptable"""
    try:
        inactivations = load_inactivations(username)
        employes_actifs = load_employes(username, "actifs")

        # Trouver la demande d'inactivation
        employe_trouve = False
        date_validation = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        for inact in inactivations:
            if inact.get("id") == employe_id:
                # V√©rifier qu'elle est bien en attente de validation (coach)
                if inact.get("statut") != "Inactivation en attente de validation":
                    raise HTTPException(status_code=400, detail="La demande n'est pas en attente de validation")
                # Changer le statut √† "en attente comptable"
                inact["statut"] = "Inactivation en attente comptable"
                inact["date_validation_coach_inactivation"] = date_validation
                employe_trouve = True
                break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Demande d'inactivation non trouv√©e")

        # Mettre √† jour le statut dans actifs.json aussi pour afficher le bon spinner
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                employes_actifs[i]["statut"] = "Inactivation en attente comptable"
                employes_actifs[i]["date_validation_coach_inactivation"] = date_validation
                break

        if save_inactivations(username, inactivations) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Inactivation valid√©e par le coach, en attente de validation comptable"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser une inactivation (coach ou comptable)
@app.post("/api/employes/{username}/refuser-inactivation/{employe_id}")
async def refuser_inactivation(username: str, employe_id: str, request: Request):
    """Refuse une demande d'inactivation et la supprime"""
    try:
        print(f"[DEBUG] Refuser inactivation: username={username}, employe_id={employe_id}")
        # R√©cup√©rer la raison du refus
        try:
            body = await request.json()
            motif_refus = body.get("motif_refus", "Aucune raison sp√©cifi√©e")
            print(f"[DEBUG] Motif refus re√ßu: {motif_refus}")
        except Exception as e:
            print(f"[DEBUG] Erreur parsing JSON: {e}")
            motif_refus = "Aucune raison sp√©cifi√©e"

        inactivations = load_inactivations(username)
        employes_actifs = load_employes(username, "actifs")
        print(f"[DEBUG] Inactivations trouv√©es: {len(inactivations)}, Actifs: {len(employes_actifs)}")

        # Trouver et supprimer la demande
        inactivations_restantes = []
        trouve = False

        for inact in inactivations:
            if inact.get("id") == employe_id:
                trouve = True
                print(f"[DEBUG] Inactivation trouv√©e pour {employe_id}")
            else:
                inactivations_restantes.append(inact)

        if not trouve:
            print(f"[DEBUG] Inactivation NON trouv√©e pour {employe_id}")
            raise HTTPException(status_code=404, detail="Demande d'inactivation non trouv√©e")

        # Remettre le statut de l'employ√© avec info de refus dans actifs.json
        employe_trouve = False
        for i, employe in enumerate(employes_actifs):
            if employe.get("id") == employe_id:
                employes_actifs[i]["statut"] = "Actif"  # Remettre en Actif, pas "Fin d'emploi refus√©e"
                employes_actifs[i]["motif_refus_inactivation"] = motif_refus
                employes_actifs[i]["date_refus_inactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                # Supprimer les champs de date d'inactivation si pr√©sents
                employes_actifs[i].pop("date_demande_inactivation", None)
                employes_actifs[i].pop("date_validation_coach_inactivation", None)
                employe_trouve = True
                print(f"[DEBUG] Employ√© trouv√© et mis √† jour: {employe_id}")
                break

        if not employe_trouve:
            print(f"[DEBUG] Employ√© NON trouv√© dans actifs pour {employe_id}")

        if save_inactivations(username, inactivations_restantes) and save_employes(username, "actifs", employes_actifs):
            print(f"[DEBUG] Sauvegarde r√©ussie")
            return {"success": True, "message": "Demande d'inactivation refus√©e"}
        else:
            print(f"[DEBUG] Erreur sauvegarde")
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Exception: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Valider une inactivation (comptable/direction) - d√©place de actifs vers inactifs
@app.post("/api/employes/{username}/valider-inactivation-comptable/{employe_id}")
async def valider_inactivation_comptable(username: str, employe_id: str):
    """Le comptable/direction valide l'inactivation finale"""
    try:
        inactivations = load_inactivations(username)
        employes_actifs = load_employes(username, "actifs")
        employes_inactifs = load_employes(username, "inactifs")

        # Trouver la demande d'inactivation
        demande_inactivation = None
        inactivations_restantes = []

        for inact in inactivations:
            if inact.get("id") == employe_id:
                # V√©rifier qu'elle est bien en attente comptable
                if inact.get("statut") != "Inactivation en attente comptable":
                    raise HTTPException(status_code=400, detail="La demande n'est pas en attente de validation comptable")
                demande_inactivation = inact
            else:
                inactivations_restantes.append(inact)

        if not demande_inactivation:
            raise HTTPException(status_code=404, detail="Demande d'inactivation non trouv√©e")

        # Retirer l'employ√© des actifs
        employes_actifs_restants = []
        employe_a_inactiver = None

        for employe in employes_actifs:
            if employe.get("id") == employe_id:
                employe_a_inactiver = employe
            else:
                employes_actifs_restants.append(employe)

        if not employe_a_inactiver:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√© dans les actifs")

        # Mettre √† jour le statut et ajouter aux inactifs
        employe_a_inactiver["statut"] = "Inactif"
        employe_a_inactiver["date_inactivation"] = datetime.now().strftime("%Y-%m-%d")
        employe_a_inactiver["date_validation_comptable_inactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        employes_inactifs.append(employe_a_inactiver)

        # Sauvegarder les trois listes
        if (save_inactivations(username, inactivations_restantes) and
            save_employes(username, "actifs", employes_actifs_restants) and
            save_employes(username, "inactifs", employes_inactifs)):
            return {"success": True, "message": "Employ√© inactiv√© avec succ√®s", "employe": employe_a_inactiver}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ===== ROUTES POUR VALIDATION DE R√âACTIVATION =====

# R√©cup√©rer les donn√©es de r√©activation d'un employ√©
@app.get("/api/employes/{username}/reactivation/{employe_id}")
async def get_reactivation_data(username: str, employe_id: str):
    """R√©cup√®re les donn√©es de r√©activation d'un employ√© depuis reactivations.json"""
    try:
        reactivations = load_reactivations(username)

        for react in reactivations:
            if react.get("id") == employe_id:
                # Normaliser les noms de fichiers (g√©rer les alias)
                if not react.get("specimenCheque") and react.get("specimen"):
                    react["specimenCheque"] = react["specimen"]
                if not react.get("certificatSecurite") and react.get("certificat"):
                    react["certificatSecurite"] = react["certificat"]
                if not react.get("carteAssurance") and react.get("carte"):
                    react["carteAssurance"] = react["carte"]

                return {"success": True, "data": react}

        raise HTTPException(status_code=404, detail="R√©activation non trouv√©e")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Valider une r√©activation (coach) - passe de "en attente de validation" √† "en attente comptable"
@app.post("/api/employes/{username}/valider-reactivation/{employe_id}")
async def valider_reactivation_coach(username: str, employe_id: str):
    """Le coach valide une demande de r√©activation et la passe en attente comptable"""
    try:
        date_validation = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        employe_trouve = False
        source_file = None

        # R√©cup√©rer les donn√©es de r√©activation avec les fichiers
        reactivations = load_reactivations(username)
        reactivation_data = None
        for react in reactivations:
            if react.get("id") == employe_id:
                reactivation_data = react
                break

        if not reactivation_data:
            raise HTTPException(status_code=404, detail="Demande de r√©activation non trouv√©e")

        # Chercher dans inactifs d'abord
        inactifs = load_employes(username, "inactifs")
        for i, employe in enumerate(inactifs):
            if employe.get("id") == employe_id:
                if employe.get("statut") != "R√©activation en attente de validation":
                    raise HTTPException(status_code=400, detail="L'employ√© n'est pas en attente de validation de r√©activation")

                # Copier TOUTES les donn√©es de r√©activation (incluant les fichiers)
                inactifs[i] = reactivation_data.copy()
                inactifs[i]["statut"] = "R√©activation en attente comptable"
                inactifs[i]["date_validation_coach_reactivation"] = date_validation
                employe_trouve = True
                source_file = "inactifs"
                break

        # Si pas trouv√©, chercher dans termines
        if not employe_trouve:
            termines = load_employes(username, "termines")
            for i, employe in enumerate(termines):
                if employe.get("id") == employe_id:
                    if employe.get("statut") != "R√©activation en attente de validation":
                        raise HTTPException(status_code=400, detail="L'employ√© n'est pas en attente de validation de r√©activation")

                    # Copier TOUTES les donn√©es de r√©activation (incluant les fichiers)
                    termines[i] = reactivation_data.copy()
                    termines[i]["statut"] = "R√©activation en attente comptable"
                    termines[i]["date_validation_coach_reactivation"] = date_validation
                    employe_trouve = True
                    source_file = "termines"
                    break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√© dans les inactifs ou termin√©s")

        # Sauvegarder dans le bon fichier
        if source_file == "inactifs":
            if save_employes(username, "inactifs", inactifs):
                return {"success": True, "message": "R√©activation valid√©e par le coach, en attente de validation comptable"}
            else:
                raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
        else:
            if save_employes(username, "termines", termines):
                return {"success": True, "message": "R√©activation valid√©e par le coach, en attente de validation comptable"}
            else:
                raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser une r√©activation (coach)
@app.post("/api/employes/{username}/refuser-reactivation/{employe_id}")
async def refuser_reactivation_coach(username: str, employe_id: str):
    """Le coach refuse une demande de r√©activation"""
    try:
        employe_trouve = False
        source_file = None

        # Chercher dans inactifs d'abord
        inactifs = load_employes(username, "inactifs")
        for employe in inactifs:
            if employe.get("id") == employe_id:
                if employe.get("statut") not in ["R√©activation en attente de validation", "R√©activation en attente comptable"]:
                    raise HTTPException(status_code=400, detail="L'employ√© n'a pas de demande de r√©activation en cours")
                employe["statut"] = "Inactif"
                employe.pop("date_demande_reactivation", None)
                employe.pop("date_validation_coach_reactivation", None)
                employe_trouve = True
                source_file = "inactifs"
                break

        # Si pas trouv√©, chercher dans termines
        if not employe_trouve:
            termines = load_employes(username, "termines")
            for employe in termines:
                if employe.get("id") == employe_id:
                    if employe.get("statut") not in ["R√©activation en attente de validation", "R√©activation en attente comptable"]:
                        raise HTTPException(status_code=400, detail="L'employ√© n'a pas de demande de r√©activation en cours")
                    # Remettre le statut √† "Termin√© par comptable"
                    employe["statut"] = "Termin√© par comptable"
                    employe.pop("date_demande_reactivation", None)
                    employe.pop("date_validation_coach_reactivation", None)
                    employe_trouve = True
                    source_file = "termines"
                    break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√© dans les inactifs ou termin√©s")

        # Sauvegarder dans le bon fichier
        if source_file == "inactifs":
            if save_employes(username, "inactifs", inactifs):
                return {"success": True, "message": "Demande de r√©activation refus√©e"}
            else:
                raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
        else:
            if save_employes(username, "termines", termines):
                return {"success": True, "message": "Demande de r√©activation refus√©e"}
            else:
                raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Compter les inactivations en attente de validation pour un coach
@app.get("/api/coach/inactivations-en-attente/count")
async def count_inactivations_en_attente_coach():
    """Compte le nombre total d'inactivations en attente de validation pour tous les entrepreneurs"""
    try:
        total_en_attente = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                inactivations = load_inactivations(username)

                # Compter celles en attente de validation (coach)
                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente de validation":
                        total_en_attente += 1

        return {"success": True, "count": total_en_attente}
    except Exception as e:
        print(f"Erreur compteur inactivations coach: {e}")
        return {"success": False, "count": 0, "error": str(e)}


# Compter les inactivations en attente comptable pour la Direction
@app.get("/api/comptable/inactivations-en-attente/count")
async def count_inactivations_en_attente_comptable():
    """Compte le nombre total d'inactivations en attente comptable pour tous les entrepreneurs"""
    try:
        total_en_attente = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                inactivations = load_inactivations(username)

                # Compter celles en attente comptable
                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente comptable":
                        total_en_attente += 1

        return {"success": True, "count": total_en_attente}
    except Exception as e:
        print(f"Erreur compteur inactivations comptable: {e}")
        return {"success": False, "count": 0, "error": str(e)}

# Liste des inactivations en attente pour le coach
@app.get("/api/coach/inactivations-en-attente/liste")
async def get_inactivations_en_attente_coach():
    """Retourne la liste des inactivations en attente de validation pour le coach"""
    try:
        inactivations_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"inactivations": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer la photo de profil et le nom complet de l'entrepreneur
                photo_profil = None
                entrepreneur_nom_complet = username
                entrepreneur_department = None
                try:
                    user_info = get_user_info(username)
                    if user_info and user_info.get("success"):
                        data = user_info.get("data", {})
                        prenom = data.get("prenom", "")
                        nom = data.get("nom", "")
                        if prenom or nom:
                            entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                        files = user_info.get("files", {})
                        photo_profil = files.get("profile_photo")
                        # R√©cup√©rer le d√©partement
                        entrepreneur_department = data.get("department")
                except:
                    pass

                inactivations = load_inactivations(username)

                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente de validation":
                        inact_info = inact.copy()
                        inact_info["entrepreneur"] = entrepreneur_nom_complet
                        inact_info["entrepreneurUsername"] = username
                        inact_info["entrepreneurPhoto"] = photo_profil
                        inact_info["entrepreneurDepartment"] = entrepreneur_department
                        inactivations_en_attente.append(inact_info)

        return {"inactivations": inactivations_en_attente}
    except Exception as e:
        print(f"Erreur liste inactivations coach: {e}")
        return {"inactivations": [], "error": str(e)}

# Liste des inactivations en attente pour le comptable/direction
@app.get("/api/comptable/inactivations-en-attente/liste")
async def get_inactivations_en_attente_comptable():
    """Retourne la liste des inactivations en attente comptable pour la Direction"""
    try:
        inactivations_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"inactivations": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer la photo de profil et le nom complet (comme dans historique)
                photo_profil = None
                entrepreneur_nom_complet = username
                entrepreneur_department = None

                user_info = get_user_info(username)
                if user_info and user_info.get("success"):
                    files = user_info.get("files", {})
                    photo_profil = files.get("profile_photo")
                    # R√©cup√©rer le nom complet (prenom + nom)
                    data = user_info.get("data", {})
                    prenom = data.get("prenom", "")
                    nom = data.get("nom", "")
                    if prenom or nom:
                        entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                    # R√©cup√©rer le d√©partement
                    entrepreneur_department = data.get("department")

                # Si pas trouv√© via get_user_info, chercher manuellement profile_photo_*
                if not photo_profil:
                    import glob as glob_module
                    user_dir = os.path.join(base_cloud, "signatures", username)
                    pattern = os.path.join(user_dir, f"profile_photo*.*")
                    matching_files = glob_module.glob(pattern)
                    if matching_files:
                        filename = os.path.basename(matching_files[0])
                        photo_profil = f"/api/get-file/{username}/{filename}"

                inactivations = load_inactivations(username)

                for inact in inactivations:
                    if inact.get("statut") == "Inactivation en attente comptable":
                        inact_info = inact.copy()
                        inact_info["entrepreneur"] = entrepreneur_nom_complet
                        inact_info["entrepreneurUsername"] = username
                        inact_info["entrepreneurPhoto"] = photo_profil
                        inact_info["entrepreneurDepartment"] = entrepreneur_department
                        inactivations_en_attente.append(inact_info)

        return {"inactivations": inactivations_en_attente}
    except Exception as e:
        print(f"Erreur liste inactivations comptable: {e}")
        return {"inactivations": [], "error": str(e)}

# Historique des inactivations
@app.get("/api/coach/inactivations/historique")
async def get_historique_inactivations():
    """Retourne l'historique complet des inactivations d'employ√©s"""
    try:
        historique = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"historique": []}

        # Parcourir tous les dossiers d'entrepreneurs
        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer la photo de profil et le nom complet de l'entrepreneur
                photo_profil = None
                entrepreneur_nom_complet = username
                try:
                    user_info = get_user_info(username)
                    if user_info and user_info.get("success"):
                        data = user_info.get("data", {})
                        prenom = data.get("prenom", "")
                        nom = data.get("nom", "")
                        if prenom or nom:
                            entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                        files = user_info.get("files", {})
                        photo_profil = files.get("profile_photo")
                except:
                    pass

                # Employ√©s inactifs (inactiv√©s)
                employes_inactifs = load_employes(username, "inactifs")
                for emp in employes_inactifs:
                    # Exclure ceux qui ont une r√©activation en cours
                    if emp.get("statut") and "R√©activation" in emp.get("statut", ""):
                        continue
                    emp_info = emp.copy()
                    emp_info["entrepreneur"] = entrepreneur_nom_complet
                    emp_info["entrepreneurPhoto"] = photo_profil
                    emp_info["action"] = "Inactiv√©"
                    emp_info["date"] = emp.get("date_inactivation") or emp.get("date_validation_comptable_inactivation") or "-"
                    historique.append(emp_info)

        # Trier par date (plus r√©cent en premier)
        historique.sort(key=lambda x: x.get("date", ""), reverse=True)

        return {"historique": historique}
    except Exception as e:
        print(f"Erreur historique inactivations: {e}")
        return {"historique": []}

# ========================================
# R√âACTIVATIONS - Processus en 3 √©tapes
# ========================================

# Fonctions utilitaires pour les r√©activations
def load_reactivations(username):
    """Charge les demandes de r√©activation d'un entrepreneur"""
    filepath = os.path.join(base_cloud, "employes", username, "reactivations.json")
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_reactivations(username, reactivations):
    """Sauvegarde les demandes de r√©activation"""
    filepath = os.path.join(base_cloud, "employes", username, "reactivations.json")
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(reactivations, f, ensure_ascii=False, indent=2)
    return True

# Mod√®le Pydantic pour la demande de r√©activation
# Demander la r√©activation d'un employ√© (entrepreneur)
@app.post("/api/employes/{username}/demande-reactivation/{employe_id}")
async def demander_reactivation(
    username: str,
    employe_id: str,
    nom: str = Form(...),
    genre: str = Form(...),
    nas: str = Form(...),
    courriel: str = Form(...),
    telephone: str = Form(...),
    poste: str = Form(...),
    tauxHoraire: str = Form(...),
    datePremiere: str = Form(...),
    adresse: str = Form(...),
    ville: str = Form(...),
    codePostal: str = Form(...),
    dateNaissance: str = Form(...),
    specimenCheque: UploadFile = File(None),
    certificatSecurite: UploadFile = File(None),
    carteAssurance: UploadFile = File(None)
):
    """L'entrepreneur demande la r√©activation d'un employ√© inactif avec nouveaux documents"""
    try:
        employes_inactifs = load_employes(username, "inactifs")
        employes_termines = load_employes(username, "termines")
        reactivations = load_reactivations(username)

        # V√©rifier que l'employ√© n'est pas d√©j√† en demande de r√©activation
        for react in reactivations:
            if react.get("id") == employe_id:
                raise HTTPException(status_code=400, detail="Une demande de r√©activation existe d√©j√† pour cet employ√©")

        # Chercher l'employ√© dans inactifs ou termines
        employe_trouve = None
        source = None
        for employe in employes_inactifs:
            if employe.get("id") == employe_id:
                employe_trouve = employe.copy()
                source = "inactifs"
                break

        if not employe_trouve:
            for employe in employes_termines:
                if employe.get("id") == employe_id:
                    employe_trouve = employe.copy()
                    source = "termines"
                    break

        if not employe_trouve:
            raise HTTPException(status_code=404, detail="Employ√© non trouv√© dans les inactifs ou termin√©s")

        # Cr√©er le r√©pertoire pour les documents de l'employ√© s'il n'existe pas
        employe_dir = os.path.join(os.path.dirname(__file__), "data", "employes", username, employe_id)
        os.makedirs(employe_dir, exist_ok=True)

        # Normaliser les noms de fichiers (g√©rer les alias specimen/specimenCheque, etc.)
        if not employe_trouve.get("specimenCheque") and employe_trouve.get("specimen"):
            employe_trouve["specimenCheque"] = employe_trouve["specimen"]
        if not employe_trouve.get("certificatSecurite") and employe_trouve.get("certificat"):
            employe_trouve["certificatSecurite"] = employe_trouve["certificat"]
        if not employe_trouve.get("carteAssurance") and employe_trouve.get("carte"):
            employe_trouve["carteAssurance"] = employe_trouve["carte"]

        # Log des fichiers existants
        print(f"[INFO] Fichiers existants dans employe_trouve: specimenCheque={employe_trouve.get('specimenCheque')}, certificatSecurite={employe_trouve.get('certificatSecurite')}, carteAssurance={employe_trouve.get('carteAssurance')}")

        # Sauvegarder les nouveaux fichiers (si fournis, ils √©crasent les anciens)
        if specimenCheque and specimenCheque.filename:
            file_ext = os.path.splitext(specimenCheque.filename)[1]
            file_path = os.path.join(employe_dir, f"specimen{file_ext}")
            with open(file_path, "wb") as f:
                content = await specimenCheque.read()
                f.write(content)
            employe_trouve["specimenCheque"] = f"specimen{file_ext}"
            print(f"[INFO] Sp√©cimen ch√®que r√©activation sauvegard√©: {file_path}")

        if certificatSecurite and certificatSecurite.filename:
            file_ext = os.path.splitext(certificatSecurite.filename)[1]
            file_path = os.path.join(employe_dir, f"certificat{file_ext}")
            with open(file_path, "wb") as f:
                content = await certificatSecurite.read()
                f.write(content)
            employe_trouve["certificatSecurite"] = f"certificat{file_ext}"
            print(f"[INFO] Certificat s√©curit√© r√©activation sauvegard√©: {file_path}")

        if carteAssurance and carteAssurance.filename:
            file_ext = os.path.splitext(carteAssurance.filename)[1]
            file_path = os.path.join(employe_dir, f"carte{file_ext}")
            with open(file_path, "wb") as f:
                content = await carteAssurance.read()
                f.write(content)
            employe_trouve["carteAssurance"] = f"carte{file_ext}"
            print(f"[INFO] Carte assurance r√©activation sauvegard√©e: {file_path}")

        # Mettre √† jour les donn√©es de l'employ√© avec les nouvelles valeurs
        employe_trouve["nom"] = nom
        employe_trouve["genre"] = genre
        employe_trouve["nas"] = nas
        employe_trouve["courriel"] = courriel
        employe_trouve["telephone"] = telephone
        employe_trouve["poste"] = poste
        employe_trouve["departement"] = employe_trouve.get("departement", "0")
        employe_trouve["tauxHoraire"] = tauxHoraire
        employe_trouve["datePremiere"] = datePremiere
        employe_trouve["adresse"] = adresse
        employe_trouve["ville"] = ville
        employe_trouve["codePostal"] = codePostal
        employe_trouve["dateNaissance"] = dateNaissance

        # Cr√©er la demande de r√©activation
        employe_trouve["statut"] = "R√©activation en attente de validation"
        employe_trouve["date_demande_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        employe_trouve["source_reactivation"] = source

        reactivations.append(employe_trouve)

        # Mettre √† jour le statut dans le fichier source pour afficher le spinner
        if source == "inactifs":
            for i, employe in enumerate(employes_inactifs):
                if employe.get("id") == employe_id:
                    employes_inactifs[i]["statut"] = "R√©activation en attente de validation"
                    employes_inactifs[i]["date_demande_reactivation"] = employe_trouve["date_demande_reactivation"]
                    break
            save_employes(username, "inactifs", employes_inactifs)
        else:
            for i, employe in enumerate(employes_termines):
                if employe.get("id") == employe_id:
                    employes_termines[i]["statut"] = "R√©activation en attente de validation"
                    employes_termines[i]["date_demande_reactivation"] = employe_trouve["date_demande_reactivation"]
                    break
            save_employes(username, "termines", employes_termines)

        if save_reactivations(username, reactivations):
            return {"success": True, "message": "Demande de r√©activation envoy√©e pour validation"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Compter les r√©activations en attente de validation coach
@app.get("/api/coach/{coach_username}/reactivations-en-attente/count")
async def count_reactivations_en_attente_coach(coach_username: str):
    """Compte le nombre total de r√©activations en attente de validation pour les entrepreneurs du coach"""
    try:
        total_en_attente = 0
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                reactivations = load_reactivations(username)

                # Compter celles en attente de validation (coach)
                for react in reactivations:
                    if react.get("statut") == "R√©activation en attente de validation":
                        total_en_attente += 1

        return {"success": True, "count": total_en_attente}
    except Exception as e:
        print(f"Erreur compteur reactivations coach: {e}")
        return {"success": True, "count": 0}

# Liste des r√©activations en attente pour le coach
@app.get("/api/coach/{coach_username}/reactivations-en-attente/liste")
async def get_reactivations_en_attente_coach(coach_username: str):
    """Retourne la liste des r√©activations en attente de validation pour les entrepreneurs du coach"""
    try:
        reactivations_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"reactivations": []}

        # R√©cup√©rer les entrepreneurs assign√©s √† ce coach
        entrepreneurs_list = get_entrepreneurs_for_coach(coach_username)
        coach_entrepreneur_usernames = [e["username"] for e in entrepreneurs_list]

        # Parcourir uniquement les entrepreneurs du coach
        for username in coach_entrepreneur_usernames:
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer les infos de l'entrepreneur via get_user_info
                entrepreneur_nom_complet = username
                try:
                    user_info = get_user_info(username)
                    if user_info and user_info.get("success"):
                        data = user_info.get("data", {})
                        prenom = data.get("prenom", "")
                        nom = data.get("nom", "")
                        if prenom or nom:
                            entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                except:
                    pass

                # Utiliser l'URL de l'API pour la photo de profil
                photo_profil = f"/api/get-file/{username}/profile_photo_{username}.png"

                reactivations = load_reactivations(username)
                for react in reactivations:
                    if react.get("statut") == "R√©activation en attente de validation":
                        react_info = react.copy()
                        react_info["entrepreneur"] = entrepreneur_nom_complet
                        react_info["entrepreneurUsername"] = username
                        react_info["entrepreneurPhoto"] = photo_profil
                        reactivations_en_attente.append(react_info)

        return {"reactivations": reactivations_en_attente}
    except Exception as e:
        print(f"Erreur liste reactivations coach: {e}")
        return {"reactivations": [], "error": str(e)}

# Valider une r√©activation par le coach
@app.post("/api/coach/reactivations/valider/{username}/{employe_id}")
async def valider_reactivation_coach(username: str, employe_id: str):
    """Le coach valide une demande de r√©activation"""
    try:
        reactivations = load_reactivations(username)

        # Trouver et mettre √† jour la r√©activation
        for react in reactivations:
            if react.get("id") == employe_id and react.get("statut") == "R√©activation en attente de validation":
                react["statut"] = "R√©activation en attente comptable"
                react["date_validation_coach_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                break
        else:
            raise HTTPException(status_code=404, detail="Demande de r√©activation non trouv√©e")

        # Mettre √† jour aussi dans le fichier source (inactifs ou termines)
        source = None
        for react in reactivations:
            if react.get("id") == employe_id:
                source = react.get("source_reactivation", "inactifs")
                break

        if source == "inactifs":
            employes_inactifs = load_employes(username, "inactifs")
            for i, employe in enumerate(employes_inactifs):
                if employe.get("id") == employe_id:
                    employes_inactifs[i]["statut"] = "R√©activation en attente comptable"
                    employes_inactifs[i]["date_validation_coach_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    break
            save_employes(username, "inactifs", employes_inactifs)
        else:
            employes_termines = load_employes(username, "termines")
            for i, employe in enumerate(employes_termines):
                if employe.get("id") == employe_id:
                    employes_termines[i]["statut"] = "R√©activation en attente comptable"
                    employes_termines[i]["date_validation_coach_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    break
            save_employes(username, "termines", employes_termines)

        if save_reactivations(username, reactivations):
            return {"success": True, "message": "R√©activation valid√©e, en attente de la direction"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser une r√©activation par le coach
@app.post("/api/coach/reactivations/refuser/{username}/{employe_id}")
async def refuser_reactivation_coach(username: str, employe_id: str):
    """Le coach refuse une demande de r√©activation"""
    try:
        reactivations = load_reactivations(username)
        source = None

        # Trouver et supprimer la r√©activation
        reactivations_restantes = []
        for react in reactivations:
            if react.get("id") == employe_id:
                source = react.get("source_reactivation", "inactifs")
            else:
                reactivations_restantes.append(react)

        if len(reactivations_restantes) == len(reactivations):
            raise HTTPException(status_code=404, detail="Demande de r√©activation non trouv√©e")

        # Remettre le statut normal dans le fichier source
        if source == "inactifs":
            employes_inactifs = load_employes(username, "inactifs")
            for i, employe in enumerate(employes_inactifs):
                if employe.get("id") == employe_id:
                    employes_inactifs[i]["statut"] = "Inactif"
                    employes_inactifs[i].pop("date_demande_reactivation", None)
                    break
            save_employes(username, "inactifs", employes_inactifs)
        else:
            employes_termines = load_employes(username, "termines")
            for i, employe in enumerate(employes_termines):
                if employe.get("id") == employe_id:
                    employes_termines[i]["statut"] = "Termin√©"
                    employes_termines[i].pop("date_demande_reactivation", None)
                    break
            save_employes(username, "termines", employes_termines)

        if save_reactivations(username, reactivations_restantes):
            return {"success": True, "message": "Demande de r√©activation refus√©e"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Compter les r√©activations en attente comptable pour la Direction
@app.get("/api/comptable/reactivations-en-attente/count")
async def count_reactivations_en_attente_comptable():
    """Compte le nombre total de r√©activations en attente comptable pour tous les entrepreneurs"""
    try:
        count = 0
        employes_dir = os.path.join(base_cloud, "employes")
        ids_comptes = set()

        if not os.path.exists(employes_dir):
            return {"success": True, "count": 0}

        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # D'abord compter dans reactivations.json
                reactivations = load_reactivations(username)
                for react in reactivations:
                    if react.get("statut") == "R√©activation en attente comptable":
                        count += 1
                        ids_comptes.add(react.get("id"))

                # Fallback: compter aussi dans inactifs.json et termines.json
                for source in ["inactifs", "termines"]:
                    employes_source = load_employes(username, source)
                    for emp in employes_source:
                        if emp.get("statut") == "R√©activation en attente comptable" and emp.get("id") not in ids_comptes:
                            count += 1
                            ids_comptes.add(emp.get("id"))

        return {"success": True, "count": count}
    except Exception as e:
        print(f"Erreur compteur reactivations comptable: {e}")
        return {"success": True, "count": 0}

# Liste des r√©activations en attente pour le comptable/direction
@app.get("/api/comptable/reactivations-en-attente/liste")
async def get_reactivations_en_attente_comptable():
    """Retourne la liste des r√©activations en attente comptable pour la Direction"""
    try:
        reactivations_en_attente = []
        employes_dir = os.path.join(base_cloud, "employes")
        ids_deja_ajoutes = set()

        if not os.path.exists(employes_dir):
            return {"reactivations": []}

        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer les infos de l'entrepreneur
                entrepreneur_nom_complet = username
                try:
                    user_info = get_user_info(username)
                    if user_info and user_info.get("success"):
                        data = user_info.get("data", {})
                        prenom = data.get("prenom", "")
                        nom = data.get("nom", "")
                        if prenom or nom:
                            entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                except:
                    pass

                # Utiliser l'URL de l'API pour la photo de profil
                photo_profil = f"/api/get-file/{username}/profile_photo_{username}.png"

                # D'abord v√©rifier dans reactivations.json
                reactivations = load_reactivations(username)
                for react in reactivations:
                    if react.get("statut") == "R√©activation en attente comptable":
                        react_info = react.copy()
                        react_info["entrepreneur"] = entrepreneur_nom_complet
                        react_info["entrepreneurUsername"] = username
                        react_info["entrepreneurPhoto"] = photo_profil
                        reactivations_en_attente.append(react_info)
                        ids_deja_ajoutes.add(react.get("id"))
                        # Debug: afficher les documents
                        print(f"[DEBUG REACTIVATION] {react.get('nom')}: specimen={react.get('specimenCheque')}, certificat={react.get('certificatSecurite')}, carte={react.get('carteAssurance')}")

                # Fallback: v√©rifier aussi dans inactifs.json et termines.json
                # en cas de d√©synchronisation des fichiers
                for source in ["inactifs", "termines"]:
                    employes_source = load_employes(username, source)
                    for emp in employes_source:
                        if emp.get("statut") == "R√©activation en attente comptable" and emp.get("id") not in ids_deja_ajoutes:
                            emp_info = emp.copy()
                            emp_info["entrepreneur"] = entrepreneur_nom_complet
                            emp_info["entrepreneurUsername"] = username
                            emp_info["entrepreneurPhoto"] = photo_profil
                            emp_info["source_reactivation"] = source

                            # R√©cup√©rer les documents depuis reactivations.json car ils n'existent pas dans inactifs/termines
                            for react in reactivations:
                                if react.get("id") == emp.get("id"):
                                    if react.get("specimenCheque"):
                                        emp_info["specimenCheque"] = react.get("specimenCheque")
                                    if react.get("certificatSecurite"):
                                        emp_info["certificatSecurite"] = react.get("certificatSecurite")
                                    if react.get("carteAssurance"):
                                        emp_info["carteAssurance"] = react.get("carteAssurance")
                                    # R√©cup√©rer aussi les nouvelles donn√©es modifi√©es
                                    if react.get("tauxHoraire"):
                                        emp_info["tauxHoraire"] = react.get("tauxHoraire")
                                    if react.get("datePremiere"):
                                        emp_info["datePremiere"] = react.get("datePremiere")
                                    print(f"[DEBUG] Documents r√©cup√©r√©s depuis reactivations.json pour {emp.get('nom')}: specimen={react.get('specimenCheque')}")
                                    break

                            reactivations_en_attente.append(emp_info)
                            ids_deja_ajoutes.add(emp.get("id"))

        return {"reactivations": reactivations_en_attente}
    except Exception as e:
        print(f"Erreur liste reactivations comptable: {e}")
        return {"reactivations": [], "error": str(e)}

# R√©cup√©rer tous les employ√©s actifs et termin√©s de tous les entrepreneurs (pour la Direction)
@app.get("/api/direction/tous-employes")
async def get_tous_employes_direction():
    """Retourne tous les employ√©s actifs et termin√©s de tous les entrepreneurs"""
    try:
        tous_actifs = []
        tous_termines = []
        employes_dir = os.path.join(base_cloud, "employes")

        if not os.path.exists(employes_dir):
            return {"actifs": [], "termines": []}

        for username in os.listdir(employes_dir):
            user_path = os.path.join(employes_dir, username)
            if os.path.isdir(user_path):
                # R√©cup√©rer les infos de l'entrepreneur
                entrepreneur_nom_complet = username
                entrepreneur_department = None
                try:
                    user_info = get_user_info(username)
                    if user_info and user_info.get("success"):
                        data = user_info.get("data", {})
                        prenom = data.get("prenom", "")
                        nom = data.get("nom", "")
                        if prenom or nom:
                            entrepreneur_nom_complet = f"{prenom} {nom}".strip()
                        # R√©cup√©rer le d√©partement
                        entrepreneur_department = data.get("department")
                except:
                    pass

                photo_profil = f"/api/get-file/{username}/profile_photo_{username}.png"

                # Charger les actifs (tous ceux dans actifs.json sont consid√©r√©s actifs)
                actifs = load_employes(username, "actifs")
                for emp in actifs:
                    emp_info = emp.copy()
                    emp_info["entrepreneur"] = entrepreneur_nom_complet
                    emp_info["entrepreneurUsername"] = username
                    emp_info["entrepreneurPhoto"] = photo_profil
                    emp_info["entrepreneurDepartment"] = entrepreneur_department
                    tous_actifs.append(emp_info)

                # Charger les termin√©s/inactifs
                termines = load_employes(username, "termines")
                for emp in termines:
                    emp_info = emp.copy()
                    emp_info["entrepreneur"] = entrepreneur_nom_complet
                    emp_info["entrepreneurUsername"] = username
                    emp_info["entrepreneurPhoto"] = photo_profil
                    emp_info["entrepreneurDepartment"] = entrepreneur_department
                    tous_termines.append(emp_info)

                # Aussi les inactifs (qui sont vraiment inactifs, pas en attente)
                inactifs = load_employes(username, "inactifs")
                for emp in inactifs:
                    statut = emp.get("statut", "").lower()
                    if "attente" not in statut and emp.get("id") not in [t.get("id") for t in tous_termines]:
                        emp_info = emp.copy()
                        emp_info["entrepreneur"] = entrepreneur_nom_complet
                        emp_info["entrepreneurUsername"] = username
                        emp_info["entrepreneurPhoto"] = photo_profil
                        emp_info["entrepreneurDepartment"] = entrepreneur_department
                        tous_termines.append(emp_info)

        return {"actifs": tous_actifs, "termines": tous_termines}
    except Exception as e:
        print(f"Erreur get tous employes direction: {e}")
        return {"actifs": [], "termines": [], "error": str(e)}

# Mettre fin √† l'emploi de plusieurs employ√©s (comptable/direction)
@app.post("/api/comptable/fin-emploi-multiple")
async def fin_emploi_multiple(request: Request):
    """Mettre fin √† l'emploi de plusieurs employ√©s avec un message commun"""
    try:
        body = await request.json()
        employes_list = body.get("employes", [])
        motif = body.get("motif", "Non sp√©cifi√©")
        justificatif = body.get("justificatif", "")

        if not employes_list:
            raise HTTPException(status_code=400, detail="Aucun employ√© s√©lectionn√©")

        count_succes = 0
        errors = []

        for emp_data in employes_list:
            try:
                emp_id = emp_data.get("id")
                entrepreneur_username = emp_data.get("entrepreneurUsername")

                if not emp_id or not entrepreneur_username:
                    errors.append(f"Donn√©es manquantes pour un employ√©")
                    continue

                # Charger les employ√©s actifs de cet entrepreneur
                actifs = load_employes(entrepreneur_username, "actifs")
                termines = load_employes(entrepreneur_username, "termines")

                # Trouver l'employ√©
                employe_a_terminer = None
                actifs_restants = []

                for emp in actifs:
                    if emp.get("id") == emp_id:
                        employe_a_terminer = emp.copy()
                    else:
                        actifs_restants.append(emp)

                if not employe_a_terminer:
                    errors.append(f"Employ√© {emp_data.get('nom', emp_id)} non trouv√© dans les actifs")
                    continue

                # Mettre √† jour les infos de l'employ√©
                employe_a_terminer["statut"] = "Termin√© par comptable"
                employe_a_terminer["motif_inactivation"] = motif
                employe_a_terminer["justificatif_inactivation"] = justificatif if justificatif else "Fin d'emploi par la comptabilit√©"
                employe_a_terminer["date_fin_emploi"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                employe_a_terminer["date_inactivation"] = datetime.now().strftime("%Y-%m-%d")

                # Ajouter aux termin√©s
                termines.append(employe_a_terminer)

                # Sauvegarder
                save_employes(entrepreneur_username, "actifs", actifs_restants)
                save_employes(entrepreneur_username, "termines", termines)

                count_succes += 1

            except Exception as emp_error:
                errors.append(f"Erreur pour {emp_data.get('nom', 'inconnu')}: {str(emp_error)}")

        if count_succes == 0:
            raise HTTPException(status_code=500, detail=f"Aucun employ√© n'a pu √™tre termin√©. Erreurs: {', '.join(errors)}")

        return {
            "success": True,
            "count": count_succes,
            "message": f"{count_succes} employ√©(s) mis en fin d'emploi",
            "errors": errors if errors else None
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"Erreur fin emploi multiple: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# Valider une r√©activation par le comptable/direction (remet dans actifs)
@app.post("/api/comptable/reactivations/valider/{username}/{employe_id}")
async def valider_reactivation_comptable(username: str, employe_id: str):
    """Le comptable/direction valide une r√©activation et remet l'employ√© dans les actifs"""
    try:
        reactivations = load_reactivations(username)
        employes_actifs = load_employes(username, "actifs")

        # Trouver la r√©activation
        employe_a_reactiver = None
        reactivations_restantes = []
        source = None

        # Chercher d'abord dans reactivations.json
        for react in reactivations:
            if react.get("id") == employe_id and react.get("statut") == "R√©activation en attente comptable":
                employe_a_reactiver = react.copy()
                source = react.get("source_reactivation", "inactifs")
            else:
                reactivations_restantes.append(react)

        # Si pas trouv√© dans reactivations.json, chercher dans inactifs et termines
        if not employe_a_reactiver:
            for source_name in ["inactifs", "termines"]:
                employes_source = load_employes(username, source_name)
                for emp in employes_source:
                    if emp.get("id") == employe_id and emp.get("statut") == "R√©activation en attente comptable":
                        employe_a_reactiver = emp.copy()
                        source = source_name
                        # R√©cup√©rer les documents depuis reactivations.json si disponibles
                        for react in reactivations:
                            if react.get("id") == employe_id:
                                if react.get("specimenCheque"):
                                    employe_a_reactiver["specimenCheque"] = react.get("specimenCheque")
                                if react.get("certificatSecurite"):
                                    employe_a_reactiver["certificatSecurite"] = react.get("certificatSecurite")
                                if react.get("carteAssurance"):
                                    employe_a_reactiver["carteAssurance"] = react.get("carteAssurance")
                                break
                        break
                if employe_a_reactiver:
                    break

        if not employe_a_reactiver:
            raise HTTPException(status_code=404, detail="Demande de r√©activation non trouv√©e")

        # Pr√©parer l'employ√© pour les actifs
        employe_a_reactiver["statut"] = "Actif"
        employe_a_reactiver["date_reactivation"] = datetime.now().strftime("%Y-%m-%d")
        employe_a_reactiver["date_validation_comptable_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        # Effacer la conversation de refus si elle existe
        employe_a_reactiver.pop("conversation_refus", None)
        employe_a_reactiver.pop("motif_refus_comptable", None)
        employe_a_reactiver.pop("date_refus_comptable", None)

        # Ajouter aux actifs
        employes_actifs.append(employe_a_reactiver)

        # Retirer du fichier source (inactifs ou termines)
        if source == "inactifs":
            employes_inactifs = load_employes(username, "inactifs")
            employes_inactifs = [e for e in employes_inactifs if e.get("id") != employe_id]
            save_employes(username, "inactifs", employes_inactifs)
        else:
            employes_termines = load_employes(username, "termines")
            employes_termines = [e for e in employes_termines if e.get("id") != employe_id]
            save_employes(username, "termines", employes_termines)

        if save_reactivations(username, reactivations_restantes) and save_employes(username, "actifs", employes_actifs):
            return {"success": True, "message": "Employ√© r√©activ√© avec succ√®s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Refuser une r√©activation par le comptable/direction
@app.post("/api/comptable/reactivations/refuser/{username}/{employe_id}")
async def refuser_reactivation_comptable(username: str, employe_id: str, request: Request):
    """Le comptable/direction refuse une r√©activation"""
    try:
        # R√©cup√©rer la raison du refus
        try:
            body = await request.json()
            motif_refus = body.get("motif_refus", "Aucune raison sp√©cifi√©e")
        except:
            motif_refus = "Aucune raison sp√©cifi√©e"

        reactivations = load_reactivations(username)
        source = None

        # Trouver et supprimer la r√©activation
        reactivations_restantes = []
        for react in reactivations:
            if react.get("id") == employe_id:
                source = react.get("source_reactivation", "inactifs")
            else:
                reactivations_restantes.append(react)

        if len(reactivations_restantes) == len(reactivations):
            raise HTTPException(status_code=404, detail="Demande de r√©activation non trouv√©e")

        # Remettre le statut avec info de refus dans le fichier source
        if source == "inactifs":
            employes_inactifs = load_employes(username, "inactifs")
            for i, employe in enumerate(employes_inactifs):
                if employe.get("id") == employe_id:
                    employes_inactifs[i]["statut"] = "R√©activation refus√©e"
                    employes_inactifs[i]["motif_refus_reactivation"] = motif_refus
                    employes_inactifs[i]["date_refus_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    employes_inactifs[i].pop("date_demande_reactivation", None)
                    employes_inactifs[i].pop("date_validation_coach_reactivation", None)
                    break
            save_employes(username, "inactifs", employes_inactifs)
        else:
            employes_termines = load_employes(username, "termines")
            for i, employe in enumerate(employes_termines):
                if employe.get("id") == employe_id:
                    employes_termines[i]["statut"] = "R√©activation refus√©e"
                    employes_termines[i]["motif_refus_reactivation"] = motif_refus
                    employes_termines[i]["date_refus_reactivation"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    employes_termines[i].pop("date_demande_reactivation", None)
                    employes_termines[i].pop("date_validation_coach_reactivation", None)
                    break
            save_employes(username, "termines", employes_termines)

        if save_reactivations(username, reactivations_restantes):
            return {"success": True, "message": "Demande de r√©activation refus√©e"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Endpoint sp√©cifique pour r√©cup√©rer les employ√©s actifs pour les √©quipes
@app.get("/get-employees-actifs/{username}")
async def get_employees_actifs_for_teams(username: str):
    """R√©cup√®re les employ√©s actifs avec seulement les infos n√©cessaires pour les √©quipes"""
    try:
        employes_actifs = load_employes(username, "actifs")
        
        # Formatter les donn√©es pour les √©quipes (nom, pr√©nom, courriel)
        employees_for_teams = []
        for employe in employes_actifs:
            # S√©parer le nom complet en pr√©nom et nom si possible
            nom_complet = employe.get("nom", "")
            nom_parts = nom_complet.split(" ", 1)
            prenom = nom_parts[0] if len(nom_parts) > 0 else ""
            nom = nom_parts[1] if len(nom_parts) > 1 else ""
            
            employees_for_teams.append({
                "prenom": prenom,
                "nom": nom,
                "courriel": employe.get("courriel", "")
            })
        
        return {"employees": employees_for_teams}
        
    except Exception as e:
        print(f"Erreur lors du chargement des employ√©s actifs: {e}")
        return {"employees": []}


# [USER] User Info Management Endpoints
@app.post("/api/save-info")
async def save_user_info(
    username: str = Form(...),
    data: str = Form(...),
    specimen: UploadFile = File(None),
    betonel: UploadFile = File(None),
    integration: UploadFile = File(None),
    profile_photo: UploadFile = File(None)
):
    """Sauvegarder les informations utilisateur (NEQ, TPS, TVQ) et fichiers"""
    try:
        # Parse les donn√©es JSON
        import json
        user_data = json.loads(data)
        print(f"[DEBUG] [BACKEND] Donn√©es re√ßues pour {username}:", user_data)

        # Cr√©er le dossier utilisateur (utiliser base_cloud pour compatibilit√© Windows)
        user_dir = os.path.join(base_cloud, "signatures", username)
        os.makedirs(user_dir, exist_ok=True)
        
        # Fichier pour les informations utilisateur
        info_file = os.path.join(user_dir, "user_info.json")
        
        # Charger les infos existantes ou cr√©er un nouveau dictionnaire
        if os.path.exists(info_file):
            with open(info_file, "r", encoding="utf-8") as f:
                existing_info = json.load(f)
        else:
            existing_info = {}
        
        # Mettre √† jour avec les nouvelles donn√©es
        # Pour nom/pr√©nom/tel/courriel: pr√©server les valeurs existantes si les nouvelles sont vides
        # Pour NEQ/TPS/TVQ: permettre l'effacement (utiliser directement les nouvelles valeurs)
        def get_value_preserve(key, default=""):
            """Retourne la nouvelle valeur ou l'existante si la nouvelle est vide (champs obligatoires)"""
            new_val = user_data.get(key, "")
            if new_val and str(new_val).strip():
                return new_val
            return existing_info.get(key, default)

        updated_data = {
            "nom": get_value_preserve("nom"),
            "prenom": get_value_preserve("prenom"),
            "telephone": get_value_preserve("telephone"),
            "courriel": get_value_preserve("courriel"),
            "neq": user_data.get("neq", ""),  # Permettre l'effacement
            "tps": user_data.get("tps", ""),  # Permettre l'effacement
            "tvq": user_data.get("tvq", ""),  # Permettre l'effacement
            "grade": user_data.get("grade", existing_info.get("grade", "recrue")),  # Grade depuis onboarding ou existant
            "equipes": user_data.get("equipes") if user_data.get("equipes") else existing_info.get("equipes", []),
            "niveau_actuel": user_data.get("niveau_actuel", existing_info.get("niveau_actuel", 1)),
            "last_updated": datetime.now().isoformat()
        }

        # Une fois onboarding_completed = true, il ne peut JAMAIS redevenir false
        if existing_info.get("onboarding_completed") == True:
            # D√©j√† compl√©t√©, on garde true peu importe ce qui est envoy√©
            updated_data["onboarding_completed"] = True
            updated_data["onboarding_date"] = existing_info.get("onboarding_date", "")
        else:
            # Pas encore compl√©t√©, on met √† jour selon les donn√©es re√ßues
            if "onboarding_completed" in user_data:
                updated_data["onboarding_completed"] = user_data["onboarding_completed"]
            if "onboarding_date" in user_data:
                updated_data["onboarding_date"] = user_data["onboarding_date"]

        # Une fois guide_completed = true, il ne peut JAMAIS redevenir false
        if existing_info.get("guide_completed") == True:
            updated_data["guide_completed"] = True
            updated_data["guide_date"] = existing_info.get("guide_date", "")
        else:
            # Pas encore compl√©t√©, on met √† jour selon les donn√©es re√ßues
            if "guide_completed" in user_data:
                updated_data["guide_completed"] = user_data["guide_completed"]
            if "guide_date" in user_data:
                updated_data["guide_date"] = user_data["guide_date"]

        existing_info.update(updated_data)

        print(f"[DEBUG] [BACKEND] Donn√©es mises √† jour:", existing_info)
        
        # Gestion des fichiers
        file_mapping = {
            "specimen": specimen,
            "betonel": betonel,
            "integration": integration,
            "profile_photo": profile_photo
        }
        
        for file_key, uploaded_file in file_mapping.items():
            delete_flag = user_data.get(f"{file_key}_delete", False)
            
            if delete_flag:
                # Supprimer tous les fichiers avec ce nom (peu importe l'extension)
                import glob
                pattern = os.path.join(user_dir, f"{file_key}.*")
                for file_path in glob.glob(pattern):
                    os.remove(file_path)
                    print(f"[DELETE] Fichier {file_key} supprim√©: {file_path}")
            elif uploaded_file and uploaded_file.size > 0:
                # D√©tecter l'extension du fichier original
                original_filename = uploaded_file.filename or ""
                file_extension = ""
                if "." in original_filename:
                    file_extension = original_filename.split(".")[-1].lower()
                else:
                    # Fallback bas√© sur le content type
                    content_type = uploaded_file.content_type or ""
                    if "pdf" in content_type:
                        file_extension = "pdf"
                    elif "image" in content_type:
                        if "png" in content_type:
                            file_extension = "png"
                        elif "jpeg" in content_type or "jpg" in content_type:
                            file_extension = "jpg"
                        else:
                            file_extension = "png"  # fallback par d√©faut
                    else:
                        file_extension = "bin"  # fallback g√©n√©rique
                
                # Supprimer les anciens fichiers avec le m√™me nom
                import glob
                pattern = os.path.join(user_dir, f"{file_key}.*")
                for old_file in glob.glob(pattern):
                    os.remove(old_file)
                
                # Sauvegarder le nouveau fichier avec la bonne extension
                file_content = await uploaded_file.read()
                file_path = os.path.join(user_dir, f"{file_key}.{file_extension}")
                with open(file_path, "wb") as f:
                    f.write(file_content)
                print(f"[FILE] Fichier {file_key}.{file_extension} sauvegard√© pour {username}")
        
        # Sauvegarder les informations mises √† jour
        with open(info_file, "w", encoding="utf-8") as f:
            json.dump(existing_info, f, ensure_ascii=False, indent=2)
        
        print(f"[OK] Informations sauvegard√©es pour {username}")
        return {"success": True, "message": "Informations sauvegard√©es avec succ√®s"}
        
    except Exception as e:
        print(f"[ERROR] Erreur sauvegarde info utilisateur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur sauvegarde: {e}")


@app.get("/api/check-profile-complete/{username}")
def check_profile_complete(username: str):
    """V√©rifier si le profil utilisateur est complet (infos obligatoires)"""
    try:
        user_dir = os.path.join(base_cloud, "signatures", username)
        info_file = os.path.join(user_dir, "user_info.json")

        # Charger les informations
        user_data = {}
        if os.path.exists(info_file):
            with open(info_file, "r", encoding="utf-8") as f:
                user_data = json.load(f)

        # V√©rifier les champs obligatoires
        missing = []
        valid = []

        if not user_data.get("nom", "").strip():
            missing.append("Nom")
        else:
            valid.append("Nom")

        if not user_data.get("prenom", "").strip():
            missing.append("Pr√©nom")
        else:
            valid.append("Pr√©nom")

        if not user_data.get("telephone", "").strip():
            missing.append("T√©l√©phone")
        else:
            valid.append("T√©l√©phone")

        if not user_data.get("courriel", "").strip():
            missing.append("Courriel")
        else:
            valid.append("Courriel")

        # V√©rifier la signature
        signature_path = os.path.join(user_dir, f"signature_{username}_black.png")
        if not os.path.exists(signature_path):
            missing.append("Signature")
        else:
            valid.append("Signature")

        # V√©rifier Gmail connect√©
        gmail_path = os.path.join(base_cloud, "emails", f"{username}.json")
        if not os.path.exists(gmail_path):
            missing.append("Gmail connect√©")
        else:
            valid.append("Gmail connect√©")

        is_complete = len(missing) == 0

        print(f"[DEBUG] [CHECK-PROFILE] {username} - Complet: {is_complete}, Manquant: {missing}, Valide: {valid}")

        return {
            "success": True,
            "is_complete": is_complete,
            "missing": missing,
            "valid": valid
        }

    except Exception as e:
        print(f"[ERROR] Erreur v√©rification profil: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur v√©rification: {e}")


@app.get("/api/get-info/{username}")
def get_user_info(username: str):
    """R√©cup√©rer les informations utilisateur (NEQ, TPS, TVQ) et status des fichiers"""
    try:
        user_dir = os.path.join(base_cloud, "signatures", username)
        info_file = os.path.join(user_dir, "user_info.json")

        # Charger les informations si elles existent
        user_data = {}
        if os.path.exists(info_file):
            with open(info_file, "r", encoding="utf-8") as f:
                user_data = json.load(f)
            print(f"[DEBUG] [GET-INFO] Donn√©es lues pour {username}:", user_data)
        else:
            print(f"[DEBUG] [GET-INFO] Aucun fichier info trouv√© pour {username}")

        # R√©cup√©rer le d√©partement depuis la base de donn√©es
        department = None
        try:
            user_db = get_user(username)
            if user_db:
                department = user_db.get("department")
        except:
            pass

        # V√©rifier l'existence des fichiers (n'importe quelle extension)
        file_status = {}
        for file_key in ["specimen", "betonel", "integration", "profile_photo"]:
            import glob
            # Pattern plus g√©n√©rique pour matcher profile_photo.*, profile_photo_*, etc.
            pattern = os.path.join(user_dir, f"{file_key}*.*")
            matching_files = glob.glob(pattern)
            file_status[f"{file_key}_exists"] = len(matching_files) > 0
            if matching_files:
                # Stocker aussi le nom du fichier trouv√© pour le frontend
                file_status[f"{file_key}_filename"] = os.path.basename(matching_files[0])

        # Construire les URLs des fichiers
        files = {}
        for file_key in ["specimen", "betonel", "integration", "profile_photo"]:
            if file_status.get(f"{file_key}_exists"):
                filename = file_status.get(f"{file_key}_filename")
                if filename:
                    files[file_key] = f"/api/get-file/{username}/{filename}"

        return {
            "success": True,
            "data": {
                "nom": user_data.get("nom", ""),
                "prenom": user_data.get("prenom", ""),
                "telephone": user_data.get("telephone", ""),
                "courriel": user_data.get("courriel", ""),
                "neq": user_data.get("neq", ""),
                "tps": user_data.get("tps", ""),
                "tvq": user_data.get("tvq", ""),
                "grade": user_data.get("grade", ""),
                "department": department,
                "equipes": user_data.get("equipes", []),
                "niveau_actuel": user_data.get("niveau_actuel", 1),
                "onboarding_completed": user_data.get("onboarding_completed", False),
                "onboarding_date": user_data.get("onboarding_date", ""),
                "guide_completed": user_data.get("guide_completed", False),
                "guide_date": user_data.get("guide_date", ""),
                **file_status
            },
            "files": files
        }
        
    except Exception as e:
        print(f"[ERROR] Erreur chargement info utilisateur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur chargement: {e}")


@app.post("/api/update-info/{username}")
async def update_user_info(username: str, request: Request):
    """Mettre √† jour les informations utilisateur (grade, etc.)"""
    try:
        user_dir = os.path.join(base_cloud, "signatures", username)
        info_file = os.path.join(user_dir, "user_info.json")

        # Cr√©er le dossier s'il n'existe pas
        os.makedirs(user_dir, exist_ok=True)

        # Charger les informations existantes
        user_data = {}
        if os.path.exists(info_file):
            with open(info_file, "r", encoding="utf-8") as f:
                user_data = json.load(f)

        # R√©cup√©rer les donn√©es de la requ√™te
        body = await request.json()

        # Mettre √† jour les champs fournis
        if "grade" in body:
            user_data["grade"] = body["grade"]
            print(f"[DEBUG] [UPDATE-INFO] Grade mis √† jour pour {username}: {body['grade']}")

        # Debug: afficher toutes les donn√©es re√ßues
        print(f"[DEBUG] [UPDATE-INFO] Body re√ßu: {body}")
        print(f"[DEBUG] [UPDATE-INFO] Donn√©es avant sauvegarde: {user_data}")

        # Ajouter la date de derni√®re mise √† jour
        from datetime import datetime
        user_data["last_updated"] = datetime.now().isoformat()

        # Sauvegarder les informations
        with open(info_file, "w", encoding="utf-8") as f:
            json.dump(user_data, f, indent=2, ensure_ascii=False)

        print(f"[DEBUG] [UPDATE-INFO] Informations sauvegard√©es dans {info_file}")
        print(f"[DEBUG] [UPDATE-INFO] Contenu sauvegard√©: {user_data}")

        return {
            "success": True,
            "message": "Informations mises √† jour avec succ√®s",
            "data": user_data
        }

    except Exception as e:
        print(f"[ERROR] Erreur mise √† jour info utilisateur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur mise √† jour: {e}")


@app.get("/api/get-file/{username}/{filename}")
def get_user_file(username: str, filename: str):
    """Servir les fichiers utilisateur (specimen, betonel, integration, profile_photo)"""
    try:
        user_dir = os.path.join(base_cloud, "signatures", username)
        file_path = os.path.join(user_dir, filename)
        
        # V√©rifier que le fichier existe et est dans le bon dossier (s√©curit√©)
        if not os.path.exists(file_path) or not os.path.commonpath([user_dir, file_path]) == user_dir:
            raise HTTPException(status_code=404, detail="Fichier non trouv√©")
        
        # D√©terminer le content type bas√© sur l'extension
        file_extension = filename.split(".")[-1].lower()
        content_type_mapping = {
            "pdf": "application/pdf",
            "png": "image/png",
            "jpg": "image/jpeg",
            "jpeg": "image/jpeg",
            "gif": "image/gif",
            "webp": "image/webp",
            "bmp": "image/bmp",
            "tiff": "image/tiff"
        }
        
        content_type = content_type_mapping.get(file_extension, "application/octet-stream")
        
        return FileResponse(
            file_path,
            media_type=content_type,
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur r√©cup√©ration fichier: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur fichier: {e}")


# [TARGET] GQP Management Endpoints
@app.post("/save-gqp-to-queue")
async def save_gqp_to_queue(
    username: str = Form(...),
    client_name: str = Form(...),
    numero_soumission: str = Form(...),
    gqp_data: str = Form(...),
    pdf_url: str = Form(...),
    images: List[UploadFile] = File(default=[])
):
    """Sauvegarder un GQP dans la file d'attente '√† envoyer'"""
    try:
        dossier_user = f"{base_cloud}/gqp/{username}"
        os.makedirs(dossier_user, exist_ok=True)
        
        # File pour les GQP √† envoyer
        queue_file = os.path.join(dossier_user, "gqp_a_envoyer.json")
        
        if os.path.exists(queue_file):
            with open(queue_file, "r", encoding="utf-8") as f:
                queue = json.load(f)
        else:
            queue = []
        
        # Cr√©er un ID unique pour ce GQP
        gqp_id = str(uuid.uuid4())
        
        # Cr√©er le dossier pour les images de ce GQP
        images_dir = f"{base_cloud}/gqp_images/{username}/{gqp_id}"
        os.makedirs(images_dir, exist_ok=True)
        
        # Sauvegarder les images
        image_paths = []
        for i, image in enumerate(images):
            if image.filename:
                # Cr√©er un nom de fichier s√ªr
                safe_filename = f"image_{i}_{image.filename}"
                image_path = os.path.join(images_dir, safe_filename)
                
                # Sauvegarder l'image
                with open(image_path, "wb") as f:
                    content = await image.read()
                    f.write(content)
                
                image_paths.append({
                    "filename": safe_filename,
                    "original_name": image.filename,
                    "path": image_path,
                    "size": len(content)
                })
        
        # Parser les donn√©es GQP
        gqp_data_dict = json.loads(gqp_data)
        
        # Cr√©er l'entr√©e
        gqp_entry = {
            "id": gqp_id,
            "client_name": client_name,
            "numero_soumission": numero_soumission,
            "pdf_url": pdf_url,
            "gqp_data": gqp_data_dict,
            "images": image_paths,
            "date_creation": datetime.now().isoformat(),
            "status": "pending"
        }
        
        queue.append(gqp_entry)
        
        # Sauvegarder
        with open(queue_file, "w", encoding="utf-8") as f:
            json.dump(queue, f, ensure_ascii=False, indent=2)
        
        return {"success": True, "gqp_id": gqp_entry["id"]}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur sauvegarde GQP: {e}")


@app.post("/delete-gqp-from-queue")
def delete_gqp_from_queue(
    username: str = Body(...),
    gqp_id: str = Body(...)
):
    """Supprimer un GQP de la file d'attente"""
    try:
        queue_file = f"{base_cloud}/gqp/{username}/gqp_a_envoyer.json"

        if not os.path.exists(queue_file):
            return {"success": True, "message": "Queue vide"}

        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)

        # Trouver et supprimer le GQP
        original_length = len(queue)
        queue = [gqp for gqp in queue if str(gqp.get('id', '')) != str(gqp_id)]

        if len(queue) < original_length:
            # Sauvegarder la queue mise √† jour
            with open(queue_file, "w", encoding="utf-8") as f:
                json.dump(queue, f, ensure_ascii=False, indent=2)

            print(f"[OK] GQP {gqp_id} supprim√© de la queue pour {username}")
            return {"success": True, "message": "GQP supprim√©"}
        else:
            return {"success": True, "message": "GQP non trouv√© dans la queue"}

    except Exception as e:
        print(f"[ERROR] Erreur suppression GQP de queue: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur suppression GQP: {e}")


@app.get("/get-gqp-images/{username}/{gqp_id}/{filename}")
def get_gqp_image(username: str, gqp_id: str, filename: str):
    """R√©cup√©rer une image stock√©e pour un GQP"""
    try:
        image_path = f"{base_cloud}/gqp_images/{username}/{gqp_id}/{filename}"

        if not os.path.exists(image_path):
            raise HTTPException(status_code=404, detail="Image non trouv√©e")

        return FileResponse(image_path)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration image: {e}")


@app.get("/gqp-view/{username}/{gqp_id}")
def view_gqp_html(username: str, gqp_id: str):
    """Afficher le GQP HTML (avec support vid√©os)"""
    try:
        # Chemin vers le fichier HTML
        html_path = f"{base_cloud}/gqp/{username}/gqp_{gqp_id}/index.html"

        if not os.path.exists(html_path):
            # Fallback: peut-√™tre un ancien GQP PDF
            raise HTTPException(status_code=404, detail="GQP non trouv√©")

        # Lire le HTML
        with open(html_path, "r", encoding="utf-8") as f:
            html_content = f.read()

        # Injecter les styles de scrollbar discret si pas d√©j√† pr√©sent
        scrollbar_styles = """
        <style id="qwota-scrollbar-override">
            /* Scrollbar personnalis√©e discr√®te - inject√©e dynamiquement */
            ::-webkit-scrollbar {
                width: 6px !important;
                height: 6px !important;
            }
            ::-webkit-scrollbar-track {
                background: transparent !important;
            }
            ::-webkit-scrollbar-thumb {
                background: rgba(100, 116, 139, 0.4) !important;
                border-radius: 3px !important;
            }
            ::-webkit-scrollbar-thumb:hover {
                background: rgba(100, 116, 139, 0.6) !important;
            }
            html, body {
                scrollbar-width: thin;
                scrollbar-color: rgba(100, 116, 139, 0.4) transparent;
            }
            /* Lightbox nav en avant-plan */
            .lightbox-nav {
                z-index: 10010 !important;
            }
            .lightbox-content {
                max-width: 60vw !important;
                z-index: 1 !important;
            }
            .lightbox-content img, .lightbox-content video {
                max-width: 60vw !important;
            }
        </style>
        """

        # Injecter avant </head> si pas d√©j√† pr√©sent
        if "qwota-scrollbar-override" not in html_content:
            html_content = html_content.replace("</head>", scrollbar_styles + "\n</head>")

        return HTMLResponse(content=html_content, status_code=200)

    except HTTPException:
        raise
    except Exception as e:
        print(f"[GQP-VIEW] Erreur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur affichage GQP: {e}")


@app.get("/get-gqp-queue/{username}")
def get_gqp_queue(username: str):
    """R√©cup√©rer la liste des GQP √† envoyer"""
    try:
        queue_file = f"{base_cloud}/gqp/{username}/gqp_a_envoyer.json"
        
        if not os.path.exists(queue_file):
            return {"gqps": []}
        
        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)
        
        return {"gqps": queue}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur chargement queue GQP: {e}")


@app.post("/assign-gqp-to-team")
def assign_gqp_to_team(
    username: str = Body(...),
    gqp_id: str = Body(...),
    team_data: dict = Body(...)
):
    """Assigner un GQP √† une √©quipe et l'envoyer par email"""
    try:
        print(f"[START] [ASSIGN-GQP] ===== D√âBUT ASSIGNATION GQP =====")
        print(f"üë§ [ASSIGN-GQP] Utilisateur: {username}")
        print(f"üÜî [ASSIGN-GQP] GQP ID: {gqp_id}")
        print(f"üë• [ASSIGN-GQP] √âquipe: {team_data.get('nom', 'N/A')}")

        queue_file = f"{base_cloud}/gqp/{username}/gqp_a_envoyer.json"
        print(f"[FILE] [ASSIGN-GQP] Fichier queue: {queue_file}")

        if not os.path.exists(queue_file):
            print(f"[ERROR] [ASSIGN-GQP] ERREUR: File d'attente GQP non trouv√©e")
            raise HTTPException(status_code=404, detail="File d'attente GQP non trouv√©e")

        # Charger la queue
        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)

        print(f"[BAN] [ASSIGN-GQP] Nombre de GQP dans la queue: {len(queue)}")

        # Trouver le GQP
        gqp_to_assign = None
        for i, gqp in enumerate(queue):
            print(f"[DEBUG] [ASSIGN-GQP] GQP {i+1}: ID={gqp.get('id', 'N/A')}, Client={gqp.get('client_name', 'N/A')}")
            if gqp["id"] == gqp_id:
                gqp_to_assign = gqp
                print(f"[OK] [ASSIGN-GQP] GQP trouv√© ! Client: {gqp.get('client_name', 'N/A')}, Num√©ro: {gqp.get('numero_soumission', 'N/A')}")
                break

        if not gqp_to_assign:
            print(f"[ERROR] [ASSIGN-GQP] ERREUR: GQP {gqp_id} non trouv√© dans la queue")
            raise HTTPException(status_code=404, detail="GQP non trouv√©")
        
        # TODO: Envoyer l'email √† l'√©quipe
        team_emails = [p["courriel"] for p in team_data.get("peintres", [])]
        
        if team_emails:
            # Ici on pourrait utiliser l'endpoint existant envoyer-gqp-email-simple
            gqp_data = gqp_to_assign["gqp_data"]
            
            # Construction simple du corps email
            html = (
                f'<div style="font-family: Arial, sans-serif; font-size: 16px; color: #000;">'
                f'<p>Bonjour √©quipe {team_data["nom"]},</p>'
                f'<p>Voici le GQP de travaux pour {gqp_data.get("nom", "")} {gqp_data.get("prenom", "")}.</p>'
                f'<p>Client: {gqp_to_assign["client_name"]}</p>'
                f'<p>N¬∞ Soumission: {gqp_to_assign["numero_soumission"]}</p><br>'
                f'<p>Vous pouvez consulter le document en cliquant sur le lien ci-dessous :</p>'
                f'<p><a href="{gqp_to_assign["pdf_url"]}" target="_blank" '
                f'style="background-color: #000000; color: #ffffff; padding: 6px 12px; '
                f'border-radius: 20px; text-decoration: none; display: inline-block; '
                f'font-weight: bold; font-size: 14px;">Voir le GQP</a></p>'
                f'<p>Bonne journ√©e!</p></div>'
            )
            
            # Envoyer l'email (utiliser la logique existante d'envoi d'email)
            # Pour l'instant, on simule l'envoi r√©ussi
        
        # Supprimer les images stock√©es pour ce GQP
        images_dir = f"{base_cloud}/gqp_images/{username}/{gqp_id}"
        if os.path.exists(images_dir):
            try:
                shutil.rmtree(images_dir)
                print(f"[DELETE] Images supprim√©es pour GQP {gqp_id}: {images_dir}")
            except Exception as e:
                print(f"[WARNING] Erreur suppression images GQP {gqp_id}: {e}")
        
        # NOUVEAU: Lier le GQP au client dans les donn√©es permanentes
        def lier_gqp_au_client(client_name, numero_soumission, pdf_url):
            print(f"üîó [ASSIGN-GQP] D√©but liaison GQP pour client: '{client_name}', num√©ro: '{numero_soumission}', URL: {pdf_url}")
            liaison_reussie = False
            fichiers_modifies = []

            # Chercher dans soumissions_signees
            fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
            print(f"[FILE] [ASSIGN-GQP] V√©rification fichier: {fichier_signees}")

            if os.path.exists(fichier_signees):
                try:
                    with open(fichier_signees, "r", encoding="utf-8") as f:
                        signees = json.load(f)

                    print(f"[DATA] [ASSIGN-GQP] Nombre de clients dans soumissions_signees: {len(signees)}")

                    modified = False
                    for i, client in enumerate(signees):
                        client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
                        print(f"[DEBUG] [ASSIGN-GQP] Client {i+1}: '{client_nom}' | Num: {client.get('num', 'N/A')} | Numero: {client.get('numero', 'N/A')} | ID: {client.get('id', 'N/A')}")
                        print(f"[DEBUG] [ASSIGN-GQP] A d√©j√† GQP? {bool(client.get('lien_gqp'))} | URL actuelle: {client.get('lien_gqp', 'AUCUNE')}")

                        # Comparaison par nom OU num√©ro OU ID
                        match_nom = client_nom.lower() == client_name.lower()
                        match_num = client.get('num') == numero_soumission
                        match_numero = client.get('numero') == numero_soumission

                        print(f"[DEBUG] [ASSIGN-GQP] Correspondances - Nom: {match_nom}, Num: {match_num}, Numero: {match_numero}")

                        if match_nom or match_num or match_numero:
                            client['lien_gqp'] = pdf_url
                            modified = True
                            liaison_reussie = True
                            print(f"[OK] [ASSIGN-GQP] GQP li√© au client dans soumissions_signees: '{client_nom}' !")
                            print(f"[OK] [ASSIGN-GQP] URL GQP ajout√©e: {pdf_url}")
                            break

                    if modified:
                        with open(fichier_signees, "w", encoding="utf-8") as f:
                            json.dump(signees, f, ensure_ascii=False, indent=2)
                        fichiers_modifies.append("soumissions_signees")
                        print(f"[SAVE] [ASSIGN-GQP] Fichier soumissions_signees sauvegard√© avec succ√®s!")
                    else:
                        print(f"[WARNING] [ASSIGN-GQP] AUCUN CLIENT TROUV√â dans soumissions_signees pour '{client_name}'")

                except Exception as e:
                    print(f"[ERROR] [ASSIGN-GQP] ERREUR liaison GQP soumissions_signees: {e}")
            else:
                print(f"[ERROR] [ASSIGN-GQP] FICHIER INEXISTANT: {fichier_signees}")

            # Chercher dans travaux_completes
            fichier_completes = f"{base_cloud}/travaux_completes/{username}/soumissions.json"
            print(f"[FILE] [ASSIGN-GQP] V√©rification fichier: {fichier_completes}")

            if os.path.exists(fichier_completes):
                try:
                    with open(fichier_completes, "r", encoding="utf-8") as f:
                        completes = json.load(f)

                    print(f"[DATA] [ASSIGN-GQP] Nombre de clients dans travaux_completes: {len(completes)}")

                    modified = False
                    for i, client in enumerate(completes):
                        client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
                        print(f"[DEBUG] [ASSIGN-GQP] Client produits {i+1}: '{client_nom}' | A d√©j√† GQP? {bool(client.get('lien_gqp'))}")

                        # Comparaison par nom OU num√©ro OU ID
                        if (client_nom.lower() == client_name.lower() or
                            client.get('num') == numero_soumission or
                            client.get('numero') == numero_soumission):
                            client['lien_gqp'] = pdf_url
                            modified = True
                            liaison_reussie = True
                            fichiers_modifies.append("travaux_completes")
                            print(f"[OK] [ASSIGN-GQP] GQP li√© au client dans travaux_completes: '{client_nom}' !")

                    if modified:
                        with open(fichier_completes, "w", encoding="utf-8") as f:
                            json.dump(completes, f, ensure_ascii=False, indent=2)
                        print(f"[SAVE] [ASSIGN-GQP] Fichier travaux_completes sauvegard√© avec succ√®s!")
                    else:
                        print(f"[WARNING] [ASSIGN-GQP] AUCUN CLIENT TROUV√â dans travaux_completes pour '{client_name}'")
                except Exception as e:
                    print(f"[ERROR] [ASSIGN-GQP] ERREUR liaison GQP travaux_completes: {e}")
            else:
                print(f"[ERROR] [ASSIGN-GQP] FICHIER INEXISTANT: {fichier_completes}")

            # Aussi chercher dans travaux_a_completer
            fichier_travaux_ac = f"{base_cloud}/travaux_a_completer/{username}/soumissions.json"
            print(f"[FILE] [ASSIGN-GQP] V√©rification fichier: {fichier_travaux_ac}")

            if os.path.exists(fichier_travaux_ac):
                try:
                    with open(fichier_travaux_ac, "r", encoding="utf-8") as f:
                        travaux_ac = json.load(f)

                    print(f"[DATA] [ASSIGN-GQP] Nombre de clients dans travaux_a_completer: {len(travaux_ac)}")

                    modified = False
                    for i, client in enumerate(travaux_ac):
                        client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
                        print(f"[DEBUG] [ASSIGN-GQP] Client travaux AC {i+1}: '{client_nom}' | A d√©j√† GQP? {bool(client.get('lien_gqp'))}")

                        if (client_nom.lower() == client_name.lower() or
                            client.get('num') == numero_soumission or
                            client.get('numero') == numero_soumission):
                            client['lien_gqp'] = pdf_url
                            modified = True
                            liaison_reussie = True
                            fichiers_modifies.append("travaux_a_completer")
                            print(f"[OK] [ASSIGN-GQP] GQP li√© au client dans travaux_a_completer: '{client_nom}' !")

                    if modified:
                        with open(fichier_travaux_ac, "w", encoding="utf-8") as f:
                            json.dump(travaux_ac, f, ensure_ascii=False, indent=2)
                        print(f"[SAVE] [ASSIGN-GQP] Fichier travaux_a_completer sauvegard√© avec succ√®s!")
                    else:
                        print(f"[WARNING] [ASSIGN-GQP] AUCUN CLIENT TROUV√â dans travaux_a_completer pour '{client_name}'")
                except Exception as e:
                    print(f"[ERROR] [ASSIGN-GQP] ERREUR liaison GQP travaux_a_completer: {e}")
            else:
                print(f"[ERROR] [ASSIGN-GQP] FICHIER INEXISTANT: {fichier_travaux_ac}")

            # Rapport final
            if liaison_reussie:
                print(f"[SUCCESS] [ASSIGN-GQP] LIAISON R√âUSSIE ! GQP li√© dans: {', '.join(fichiers_modifies)}")
                return True
            else:
                print(f"üí• [ASSIGN-GQP] √âCHEC TOTAL ! Aucune liaison effectu√©e pour '{client_name}'")
                return False

        # Lier le GQP au client
        print(f"üîó [ASSIGN-GQP] ===== D√âBUT LIAISON AU CLIENT =====")
        liaison_success = lier_gqp_au_client(gqp_to_assign["client_name"], gqp_to_assign["numero_soumission"], gqp_to_assign["pdf_url"])

        # FALLBACK: Si pas trouv√© par client_name/numero, essayer par nom du GQP
        if not liaison_success and "gqp_data" in gqp_to_assign:
            print(f"[PROCESSING] [ASSIGN-GQP] ===== TENTATIVE FALLBACK =====")
            gqp_data = gqp_to_assign["gqp_data"]
            client_name_from_gqp = f"{gqp_data.get('prenom', '')} {gqp_data.get('nom', '')}".strip()
            if client_name_from_gqp:
                print(f"[PROCESSING] [ASSIGN-GQP] Tentative fallback avec nom du GQP: '{client_name_from_gqp}'")
                liaison_success = lier_gqp_au_client(client_name_from_gqp, "", gqp_to_assign["pdf_url"])

        # Retirer le GQP de la queue
        print(f"[DELETE] [ASSIGN-GQP] Suppression du GQP de la queue...")
        queue_before = len(queue)
        queue = [gqp for gqp in queue if gqp["id"] != gqp_id]
        queue_after = len(queue)
        print(f"[DELETE] [ASSIGN-GQP] Queue: {queue_before} -> {queue_after} GQP(s)")

        # Sauvegarder la queue mise √† jour
        with open(queue_file, "w", encoding="utf-8") as f:
            json.dump(queue, f, ensure_ascii=False, indent=2)
        print(f"[SAVE] [ASSIGN-GQP] Queue sauvegard√©e avec succ√®s!")

        # Message final selon le succ√®s de la liaison
        if liaison_success:
            final_message = f"GQP assign√© √† l'√©quipe {team_data['nom']} et li√© au client avec succ√®s [OK]"
            print(f"[SUCCESS] [ASSIGN-GQP] ===== SUCC√àS TOTAL =====")
        else:
            final_message = f"GQP assign√© √† l'√©quipe {team_data['nom']} mais √âCHEC de liaison au client [ERROR]"
            print(f"[WARNING] [ASSIGN-GQP] ===== SUCC√àS PARTIEL =====")

        print(f"üèÅ [ASSIGN-GQP] ===== FIN ASSIGNATION GQP =====")
        return {"success": True, "message": final_message, "liaison_success": liaison_success}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur assignation GQP: {e}")


@app.get("/clients-avec-gqp/{username}")
def get_clients_avec_gqp(username: str):
    """R√©cup√©rer la liste des clients qui ont d√©j√† un GQP assign√©"""
    clients_avec_gqp = []

    try:
        # V√©rifier dans soumissions_signees
        fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                signees = json.load(f)

            for client in signees:
                if client.get('lien_gqp'):
                    client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
                    clients_avec_gqp.append({
                        "nom": client_nom,
                        "numero_soumission": client.get('num', ''),
                        "id": client.get('id', ''),
                        "source": "soumissions_signees"
                    })

        # V√©rifier dans travaux_completes
        fichier_completes = f"{base_cloud}/travaux_completes/{username}/soumissions.json"
        if os.path.exists(fichier_completes):
            with open(fichier_completes, "r", encoding="utf-8") as f:
                completes = json.load(f)

            for client in completes:
                if client.get('lien_gqp'):
                    client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
                    # √âviter les doublons
                    if not any(c["nom"].lower() == client_nom.lower() for c in clients_avec_gqp):
                        clients_avec_gqp.append({
                            "nom": client_nom,
                            "numero_soumission": client.get('num', ''),
                            "id": client.get('id', ''),
                            "source": "travaux_completes"
                        })

        return {"clients": clients_avec_gqp}

    except Exception as e:
        print(f"[WARNING] Erreur r√©cup√©ration clients avec GQP: {e}")
        return {"clients": []}


@app.get("/soumissions-disponibles-gqp/{username}")
def get_soumissions_disponibles_gqp(username: str):
    """R√©cup√©rer les soumissions disponibles pour cr√©er un GQP (sans celles qui ont d√©j√† un GQP)"""
    soumissions_disponibles = []

    try:
        # R√©cup√©rer toutes les soumissions sign√©es et travaux compl√©t√©s
        toutes_soumissions = []

        # Charger soumissions_signees
        fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                signees = json.load(f)
                toutes_soumissions.extend(signees)

        # Charger travaux_completes
        fichier_completes = f"{base_cloud}/travaux_completes/{username}/soumissions.json"
        if os.path.exists(fichier_completes):
            with open(fichier_completes, "r", encoding="utf-8") as f:
                completes = json.load(f)
                toutes_soumissions.extend(completes)

        # Filtrer celles qui n'ont PAS de GQP
        for soumission in toutes_soumissions:
            if not soumission.get('lien_gqp'):  # Pas de GQP assign√©
                soumissions_disponibles.append({
                    "id": soumission.get("id", ""),
                    "num": soumission.get("num", ""),
                    "numero": soumission.get("num", soumission.get("numero", "")),
                    "prenom": soumission.get("prenom", soumission.get("clientPrenom", "")),
                    "nom": soumission.get("nom", soumission.get("clientNom", "")),
                    "adresse": soumission.get("adresse", ""),
                    "telephone": soumission.get("telephone", ""),
                    "prix": soumission.get("prix", ""),
                    "date": soumission.get("date", "")
                })

        return soumissions_disponibles

    except Exception as e:
        print(f"[WARNING] Erreur r√©cup√©ration soumissions disponibles GQP: {e}")
        return []


@app.post("/lier-gqp-manuel")
def lier_gqp_manuel(
    username: str = Body(...),
    client_name: str = Body(...),
    numero_soumission: str = Body(default=""),
    pdf_url: str = Body(...)
):
    """Lier manuellement un GQP √† un client"""
    try:
        print(f"üîó Liaison manuelle GQP pour client: '{client_name}', num√©ro: '{numero_soumission}'")

        modified_any = False

        # Chercher dans soumissions_signees
        fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
        if os.path.exists(fichier_signees):
            try:
                with open(fichier_signees, "r", encoding="utf-8") as f:
                    signees = json.load(f)

                modified = False
                for client in signees:
                    client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                    if (client_nom.lower() == client_name.lower() or
                        client.get('num') == numero_soumission or
                        client.get('numero') == numero_soumission):
                        client['lien_gqp'] = pdf_url
                        modified = True
                        modified_any = True
                        print(f"[OK] GQP li√© manuellement au client dans soumissions_signees: {client_nom}")

                if modified:
                    with open(fichier_signees, "w", encoding="utf-8") as f:
                        json.dump(signees, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"[WARNING] Erreur liaison manuelle GQP soumissions_signees: {e}")

        # Chercher dans travaux_completes
        fichier_completes = f"{base_cloud}/travaux_completes/{username}/soumissions.json"
        if os.path.exists(fichier_completes):
            try:
                with open(fichier_completes, "r", encoding="utf-8") as f:
                    completes = json.load(f)

                modified = False
                for client in completes:
                    client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                    if (client_nom.lower() == client_name.lower() or
                        client.get('num') == numero_soumission or
                        client.get('numero') == numero_soumission):
                        client['lien_gqp'] = pdf_url
                        modified = True
                        modified_any = True
                        print(f"[OK] GQP li√© manuellement au client dans travaux_completes: {client_nom}")

                if modified:
                    with open(fichier_completes, "w", encoding="utf-8") as f:
                        json.dump(completes, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"[WARNING] Erreur liaison manuelle GQP travaux_completes: {e}")

        # Chercher dans travaux_a_completer
        fichier_travaux_ac = f"{base_cloud}/travaux_a_completer/{username}/soumissions.json"
        if os.path.exists(fichier_travaux_ac):
            try:
                with open(fichier_travaux_ac, "r", encoding="utf-8") as f:
                    travaux_ac = json.load(f)

                modified = False
                for client in travaux_ac:
                    client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                    if (client_nom.lower() == client_name.lower() or
                        client.get('num') == numero_soumission or
                        client.get('numero') == numero_soumission):
                        client['lien_gqp'] = pdf_url
                        modified = True
                        modified_any = True
                        print(f"[OK] GQP li√© manuellement au client dans travaux_a_completer: {client_nom}")

                if modified:
                    with open(fichier_travaux_ac, "w", encoding="utf-8") as f:
                        json.dump(travaux_ac, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"[WARNING] Erreur liaison manuelle GQP travaux_a_completer: {e}")

        if modified_any:
            return {"success": True, "message": f"GQP li√© avec succ√®s au client '{client_name}'"}
        else:
            return {"success": False, "message": f"Client '{client_name}' non trouv√©"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur liaison manuelle GQP: {e}")


@app.post("/lier-gqp-existant")
def lier_gqp_existant(
    username: str = Body(...),
    gqp_url: str = Body(...),
    numero_soumission: str = Body(default="")
):
    """Lier un GQP existant √† un client par num√©ro de soumission ou par nom trouv√© dans gqp_list.json"""
    try:
        # D'abord chercher dans gqp_list.json pour trouver les infos du client
        gqp_list_file = f"{base_cloud}/gqp/{username}/gqp_list.json"
        client_info = None

        if os.path.exists(gqp_list_file):
            with open(gqp_list_file, "r", encoding="utf-8") as f:
                gqp_list = json.load(f)

            # Trouver le GQP correspondant √† l'URL
            for gqp in gqp_list:
                if gqp.get("lien_pdf") == gqp_url:
                    client_info = gqp
                    break

        if not client_info:
            return {"success": False, "message": "GQP non trouv√© dans la liste"}

        # Construire le nom du client
        client_name = f"{client_info.get('prenom', '')} {client_info.get('nom', '')}".strip()

        # Si pas de num√©ro fourni, essayer de trouver par nom
        if not numero_soumission:
            numero_soumission = client_info.get('numero_soumission', '')

        print(f"üîó Liaison GQP existant pour: '{client_name}', num√©ro: '{numero_soumission}', URL: {gqp_url}")

        modified_any = False

        # Chercher et lier dans toutes les collections
        collections = [
            ("soumissions_signees", f"{base_cloud}/soumissions_signees/{username}/soumissions.json"),
            ("travaux_completes", f"{base_cloud}/travaux_completes/{username}/soumissions.json"),
            ("travaux_a_completer", f"{base_cloud}/travaux_a_completer/{username}/soumissions.json")
        ]

        for collection_name, fichier in collections:
            if os.path.exists(fichier):
                try:
                    with open(fichier, "r", encoding="utf-8") as f:
                        data = json.load(f)

                    modified = False
                    for client in data:
                        client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                        # Comparer par nom ET/OU num√©ro
                        match_by_name = client_nom.lower() == client_name.lower()
                        match_by_number = (numero_soumission and
                                         (client.get('num') == numero_soumission or
                                          client.get('numero') == numero_soumission))

                        if match_by_name or match_by_number:
                            client['lien_gqp'] = gqp_url
                            modified = True
                            modified_any = True
                            print(f"[OK] GQP li√© dans {collection_name}: {client_nom}")

                    if modified:
                        with open(fichier, "w", encoding="utf-8") as f:
                            json.dump(data, f, ensure_ascii=False, indent=2)

                except Exception as e:
                    print(f"[WARNING] Erreur liaison {collection_name}: {e}")

        if modified_any:
            return {"success": True, "message": f"GQP li√© avec succ√®s au client '{client_name}'"}
        else:
            return {"success": False, "message": f"Client '{client_name}' non trouv√© dans les soumissions"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur liaison GQP existant: {e}")


@app.post("/lier-gqp-depuis-liste")
def lier_gqp_depuis_liste(username: str = Body(...)):
    """Lier automatiquement tous les GQP de gqp_list.json aux clients correspondants"""
    try:
        gqp_list_file = f"{base_cloud}/gqp/{username}/gqp_list.json"

        if not os.path.exists(gqp_list_file):
            return {"success": False, "message": "Aucun GQP trouv√©"}

        with open(gqp_list_file, "r", encoding="utf-8") as f:
            gqp_list = json.load(f)

        linked_count = 0
        for gqp in gqp_list:
            client_name = f"{gqp.get('prenom', '')} {gqp.get('nom', '')}".strip()
            pdf_url = gqp.get('lien_pdf', '')
            numero_soumission = gqp.get('numero_soumission', '')

            if client_name and pdf_url:
                print(f"üîó Liaison GQP pour: '{client_name}', URL: {pdf_url}")

                # Chercher et lier dans soumissions_signees
                fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"
                if os.path.exists(fichier_signees):
                    try:
                        with open(fichier_signees, "r", encoding="utf-8") as f:
                            signees = json.load(f)

                        modified = False
                        for client in signees:
                            client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()

                            # Comparer par nom exact (case insensitive)
                            if client_nom.lower() == client_name.lower():
                                # V√©rifier si pas d√©j√† li√©
                                if not client.get('lien_gqp'):
                                    client['lien_gqp'] = pdf_url
                                    modified = True
                                    linked_count += 1
                                    print(f"[OK] GQP li√© √† {client_nom}")
                                else:
                                    print(f"[INFO] {client_nom} a d√©j√† un GQP")

                        if modified:
                            with open(fichier_signees, "w", encoding="utf-8") as f:
                                json.dump(signees, f, ensure_ascii=False, indent=2)

                    except Exception as e:
                        print(f"[WARNING] Erreur liaison {client_name}: {e}")

        return {"success": True, "message": f"{linked_count} GQP(s) li√©(s) avec succ√®s"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur liaison GQP depuis liste: {e}")


@app.post("/test-liaison-gqp")
def test_liaison_gqp(username: str = Body(...)):
    """Test direct pour lier le GQP de Mathis Labelle"""
    try:
        print(f"[FIX] Test liaison GQP pour {username}")

        # Lier directement le GQP de Mathis
        fichier_signees = f"{base_cloud}/soumissions_signees/{username}/soumissions.json"

        if not os.path.exists(fichier_signees):
            return {"success": False, "message": "Fichier soumissions_signees non trouv√©"}

        with open(fichier_signees, "r", encoding="utf-8") as f:
            signees = json.load(f)

        print(f"[BAN] Trouv√© {len(signees)} soumissions sign√©es")

        modified = False
        for client in signees:
            client_nom = f"{client.get('prenom', client.get('clientPrenom', ''))} {client.get('nom', client.get('clientNom', ''))}".strip()
            print(f"[DEBUG] Client trouv√©: '{client_nom}'")

            # Chercher Mathis Labelle sp√©cifiquement
            if client_nom.lower() == "mathis labelle":
                if not client.get('lien_gqp'):
                    client['lien_gqp'] = f"{BASE_URL}/cloud/gqp/mathis/GQP_20250920_175947.pdf"
                    modified = True
                    print(f"[OK] GQP ajout√© √† {client_nom}")
                else:
                    print(f"[INFO] {client_nom} a d√©j√† un GQP: {client.get('lien_gqp')}")

        if modified:
            with open(fichier_signees, "w", encoding="utf-8") as f:
                json.dump(signees, f, ensure_ascii=False, indent=2)
            return {"success": True, "message": "GQP li√© avec succ√®s √† Mathis Labelle"}
        else:
            return {"success": False, "message": "Mathis Labelle non trouv√© ou GQP d√©j√† pr√©sent"}

    except Exception as e:
        print(f"[ERROR] Erreur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur test liaison: {e}")


@app.delete("/remove-gqp-from-queue")
def remove_gqp_from_queue(
    username: str = Body(...),
    gqp_id: str = Body(...)
):
    """Supprimer un GQP de la file d'attente"""
    try:
        queue_file = f"{base_cloud}/gqp/{username}/gqp_a_envoyer.json"
        
        if not os.path.exists(queue_file):
            return {"success": True}
        
        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)
        
        # Supprimer les images stock√©es pour ce GQP
        images_dir = f"{base_cloud}/gqp_images/{username}/{gqp_id}"
        if os.path.exists(images_dir):
            try:
                shutil.rmtree(images_dir)
                print(f"[DELETE] Images supprim√©es pour GQP {gqp_id}: {images_dir}")
            except Exception as e:
                print(f"[WARNING] Erreur suppression images GQP {gqp_id}: {e}")
        
        # Retirer le GQP
        queue = [gqp for gqp in queue if gqp["id"] != gqp_id]
        
        with open(queue_file, "w", encoding="utf-8") as f:
            json.dump(queue, f, ensure_ascii=False, indent=2)
        
        return {"success": True}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur suppression GQP: {e}")


@app.post("/lier-gqp-simple")
def lier_gqp_simple(
    username: str = Body(...),
    client_name: str = Body(...),
    numero_soumission: str = Body(...),
    gqp_url: str = Body(...)
):
    """Lier simplement un GQP √† un client - utilis√© apr√®s envoi email"""
    try:
        print(f"üîó [LIAISON-SIMPLE] D√©but liaison pour '{client_name}', num√©ro: '{numero_soumission}', URL: {gqp_url}")

        modified_any = False
        fichiers_modifies = []

        # Normaliser le nom client
        client_name_normalized = client_name.strip().lower()

        fichiers_a_modifier = [
            f"{base_cloud}/soumissions_signees/{username}/soumissions.json",
            f"{base_cloud}/travaux_a_completer/{username}/soumissions.json",
            f"{base_cloud}/travaux_completes/{username}/soumissions.json"
        ]

        for fichier in fichiers_a_modifier:
            if os.path.exists(fichier):
                try:
                    with open(fichier, "r", encoding="utf-8") as f:
                        data = json.load(f)

                    modified = False
                    for client in data:
                        # Essayer plusieurs combinaisons de noms
                        noms_possibles = [
                            f"{client.get('prenom', '')} {client.get('nom', '')}".strip(),
                            f"{client.get('clientPrenom', '')} {client.get('clientNom', '')}".strip()
                        ]

                        for nom_possible in noms_possibles:
                            if (nom_possible.lower() == client_name_normalized or
                                client.get('num') == numero_soumission or
                                client.get('numero') == numero_soumission):
                                client['lien_gqp'] = gqp_url
                                modified = True
                                modified_any = True
                                print(f"[OK] [LIAISON-SIMPLE] GQP li√© dans {fichier}: '{nom_possible}'")
                                break

                    if modified:
                        with open(fichier, "w", encoding="utf-8") as f:
                            json.dump(data, f, ensure_ascii=False, indent=2)
                        fichiers_modifies.append(fichier.split('/')[-2])  # Juste le nom du dossier

                except Exception as e:
                    print(f"[ERROR] [LIAISON-SIMPLE] Erreur modification {fichier}: {e}")

        if modified_any:
            print(f"[SUCCESS] [LIAISON-SIMPLE] SUCC√àS ! GQP li√© dans: {', '.join(fichiers_modifies)}")
            return {
                "success": True,
                "message": f"GQP li√© avec succ√®s √† '{client_name}'",
                "fichiers_modifies": fichiers_modifies
            }
        else:
            print(f"[WARNING] [LIAISON-SIMPLE] √âCHEC ! Client '{client_name}' non trouv√©")
            return {
                "success": False,
                "message": f"Client '{client_name}' non trouv√© dans les donn√©es"
            }

    except Exception as e:
        print(f"[ERROR] [LIAISON-SIMPLE] ERREUR: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur liaison: {e}")


# [TARGET] Soumissions Management Endpoints
@app.post("/save-soumission-to-queue")
async def save_soumission_to_queue(data: dict = Body(...)):
    """Sauvegarder une soumission dans la file d'attente '√† envoyer'"""
    try:
        username = data.get("username")
        dossier_user = f"{base_cloud}/soumissions/{username}"
        os.makedirs(dossier_user, exist_ok=True)

        # File pour les soumissions √† envoyer
        queue_file = os.path.join(dossier_user, "soumissions_a_envoyer.json")

        if os.path.exists(queue_file):
            with open(queue_file, "r", encoding="utf-8") as f:
                queue = json.load(f)
        else:
            queue = []

        # V√©rifier si c'est une mise √† jour d'une soumission existante
        existing_id = data.get("soumission_id")
        is_update = False

        if existing_id:
            # Mode mise √† jour: chercher et mettre √† jour la soumission existante
            for i, soum in enumerate(queue):
                if soum.get("id") == existing_id:
                    # Mettre √† jour les donn√©es
                    queue[i] = {
                        "id": existing_id,  # Garder le m√™me ID
                        "num": data.get("num"),
                        "nom": data.get("nom"),
                        "prenom": data.get("prenom"),
                        "telephone": data.get("telephone"),
                        "courriel": data.get("courriel"),
                        "date": data.get("date"),
                        "temps": data.get("temps"),
                        "date2": data.get("date2"),
                        "prix": data.get("prix"),
                        "adresse": data.get("adresse"),
                        "endroit": data.get("endroit"),
                        "item": data.get("item"),
                        "produit": data.get("produit"),
                        "part": data.get("part"),
                        "payer_par": data.get("payer_par"),
                        "date_creation": soum.get("date_creation", datetime.now().isoformat()),  # Garder date originale
                        "date_modification": datetime.now().isoformat(),
                        "status": "pending"
                    }
                    is_update = True
                    print(f"[UPDATE] Soumission mise √† jour: {existing_id}")
                    break

        if not is_update:
            # Cr√©er un ID unique pour cette nouvelle soumission
            soumission_id = str(uuid.uuid4())

            # Cr√©er l'entr√©e
            soumission_entry = {
                "id": soumission_id,
                "num": data.get("num"),
                "nom": data.get("nom"),
                "prenom": data.get("prenom"),
                "telephone": data.get("telephone"),
                "courriel": data.get("courriel"),
                "date": data.get("date"),
                "temps": data.get("temps"),
                "date2": data.get("date2"),
                "prix": data.get("prix"),
                "adresse": data.get("adresse"),
                "endroit": data.get("endroit"),
                "item": data.get("item"),
                "produit": data.get("produit"),
                "part": data.get("part"),
                "payer_par": data.get("payer_par"),
                "date_creation": datetime.now().isoformat(),
                "status": "pending"
            }

            queue.append(soumission_entry)
            existing_id = soumission_id
            print(f"[OK] Nouvelle soumission sauvegard√©e en queue: {soumission_id}")

        # Sauvegarder
        with open(queue_file, "w", encoding="utf-8") as f:
            json.dump(queue, f, ensure_ascii=False, indent=2)

        return {"success": True, "soumission_id": existing_id, "updated": is_update}

    except Exception as e:
        print(f"[ERROR] Erreur sauvegarde soumission: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur sauvegarde soumission: {e}")


@app.get("/get-soumissions-queue/{username}")
def get_soumissions_queue(username: str):
    """R√©cup√©rer la liste des soumissions √† envoyer"""
    try:
        queue_file = f"{base_cloud}/soumissions/{username}/soumissions_a_envoyer.json"

        if not os.path.exists(queue_file):
            return {"soumissions": []}

        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)

        return {"soumissions": queue}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur chargement queue soumissions: {e}")


@app.post("/send-soumission-from-queue")
async def send_soumission_from_queue(data: dict = Body(...)):
    """Envoyer une soumission depuis la file d'attente"""
    try:
        username = data.get("username")
        soumission_id = data.get("soumission_id")

        print(f"[EMAIL] [SEND-SOUMISSION] D√©but envoi soumission ID: {soumission_id}")

        queue_file = f"{base_cloud}/soumissions/{username}/soumissions_a_envoyer.json"

        if not os.path.exists(queue_file):
            raise HTTPException(status_code=404, detail="File d'attente non trouv√©e")

        # Charger la queue
        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)

        # Trouver la soumission
        soumission_to_send = None
        for soumission in queue:
            if soumission["id"] == soumission_id:
                soumission_to_send = soumission
                break

        if not soumission_to_send:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # G√©n√©rer le PDF
        pdf_data = {
            "username": username,
            "num": soumission_to_send["num"],
            "nom": soumission_to_send["nom"],
            "prenom": soumission_to_send["prenom"],
            "telephone": soumission_to_send["telephone"],
            "courriel": soumission_to_send["courriel"],
            "date": soumission_to_send["date"],
            "temps": soumission_to_send["temps"],
            "date2": soumission_to_send["date2"],
            "prix": soumission_to_send["prix"],
            "adresse": soumission_to_send["adresse"],
            "endroit": soumission_to_send["endroit"],
            "item": soumission_to_send["item"],
            "produit": soumission_to_send["produit"],
            "part": soumission_to_send["part"],
            "payer_par": soumission_to_send["payer_par"]
        }

        # NOTE: R√©utiliser la logique de g√©n√©ration PDF existante
        # Cette partie d√©pend de votre endpoint /creer-pdf

        print(f"[OK] [SEND-SOUMISSION] Soumission envoy√©e avec succ√®s")
        return {"success": True, "message": "Soumission envoy√©e"}

    except Exception as e:
        print(f"[ERROR] [SEND-SOUMISSION] Erreur: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur envoi soumission: {e}")


@app.delete("/remove-soumission-from-queue")
def remove_soumission_from_queue(data: dict = Body(...)):
    """Supprimer une soumission de la file d'attente"""
    try:
        username = data.get("username")
        soumission_id = data.get("soumission_id")

        queue_file = f"{base_cloud}/soumissions/{username}/soumissions_a_envoyer.json"

        if not os.path.exists(queue_file):
            raise HTTPException(status_code=404, detail="File d'attente non trouv√©e")

        with open(queue_file, "r", encoding="utf-8") as f:
            queue = json.load(f)

        # Filtrer pour retirer la soumission
        new_queue = [s for s in queue if s["id"] != soumission_id]

        with open(queue_file, "w", encoding="utf-8") as f:
            json.dump(new_queue, f, ensure_ascii=False, indent=2)

        print(f"[DELETE] Soumission {soumission_id} supprim√©e de la queue")
        return {"success": True, "message": "Soumission supprim√©e"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur suppression soumission: {e}")


# [DATA] Route pour enregistrer une soumission envoy√©e (statistiques)
@app.post("/api/record-soumission/{username}")
def record_soumission_sent(username: str):
    """Enregistrer qu'une soumission a √©t√© envoy√©e avec succ√®s (pour statistiques)"""
    try:
        from datetime import datetime

        # Dossier pour les statistiques
        stats_dir = f"{base_cloud}/stats/{username}"
        os.makedirs(stats_dir, exist_ok=True)

        # Fichier des soumissions envoy√©es
        stats_file = os.path.join(stats_dir, "soumissions_sent.json")

        # Charger les stats existantes
        stats = []
        if os.path.exists(stats_file):
            with open(stats_file, "r", encoding="utf-8") as f:
                stats = json.load(f)

        # Ajouter la nouvelle soumission avec la date du jour
        today = datetime.now().strftime("%Y-%m-%d")
        stats.append({
            "date": today,
            "timestamp": datetime.now().isoformat()
        })

        # Sauvegarder
        with open(stats_file, "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

        print(f"[DATA] [Stats] Soumission enregistr√©e pour {username} le {today}")

        # Sync RPO apr√®s l'envoi de la soumission
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo
            sync_soumissions_to_rpo(username)
            print(f"[DATA] [Stats] RPO synchronis√© pour {username}")
        except Exception as sync_error:
            print(f"[WARNING] [Stats] Erreur sync RPO: {sync_error}")

        return {"success": True, "message": "Soumission enregistr√©e"}

    except Exception as e:
        print(f"[ERROR] [Stats] Erreur enregistrement soumission {username}: {e}")
        return {"success": False, "message": str(e)}

# [DATA] Route pour calculer le taux de satisfaction
@app.get("/api/taux-satisfaction/{username}")
def get_taux_satisfaction(username: str):
    """Calculer le taux de satisfaction client bas√© sur les avis"""
    try:
        # Charger tous les avis pour cet utilisateur
        path_reviews = os.path.join(f"{base_cloud}", "reviews", username, "reviews.json")
        print(f"[Debug Taux] Chemin fichier avis: {path_reviews}")
        print(f"[Debug Taux] Fichier existe: {os.path.exists(path_reviews)}")

        reviews = []
        if os.path.exists(path_reviews):
            with open(path_reviews, "r", encoding="utf-8") as f:
                reviews = json.load(f)
            print(f"[Debug Taux] Contenu fichier avis: {reviews}")
        else:
            print(f"[Debug Taux] Fichier avis non trouv√© pour {username}")

        if not reviews:
            print(f"[Debug Taux] Aucun avis trouv√©, retour 0")
            return {"taux_satisfaction": 0, "moyenne_etoiles": 0.0, "nombre_avis": 0}

        # Calculer le taux de satisfaction (moyenne des notes / 5 * 100)
        print(f"[Debug Taux] Calcul avec {len(reviews)} avis")
        for i, review in enumerate(reviews):
            print(f"[Debug Taux] Avis {i+1}: {review}")

        total_notes = sum(float(review.get("rating", 0)) for review in reviews)
        nb_avis = len(reviews)
        moyenne_etoiles = total_notes / nb_avis if nb_avis > 0 else 0
        taux_satisfaction = (moyenne_etoiles / 5) * 100

        print(f"[Taux Satisfaction] {username}: {nb_avis} avis, total={total_notes}, moyenne={moyenne_etoiles:.1f}, taux={taux_satisfaction:.1f}%")

        return {
            "taux_satisfaction": round(taux_satisfaction, 1),
            "moyenne_etoiles": round(moyenne_etoiles, 1),
            "nombre_avis": nb_avis
        }

    except Exception as e:
        print(f"[Erreur Taux Satisfaction] {username}: {e}")
        import traceback
        print(f"[Erreur Taux Satisfaction] Stacktrace: {traceback.format_exc()}")
        return {"taux_satisfaction": 0, "moyenne_etoiles": 0.0, "nombre_avis": 0}

# [DATA] Routes RPO (R√©sultats, Pr√©visions, Objectifs)
from QE.Backend.rpo import (
    load_user_rpo_data, save_user_rpo_data,
    update_annual_data, update_monthly_data, update_weekly_data,
    get_annual_data, get_monthly_data, get_all_monthly_data,
    get_weekly_data, get_all_weekly_data_for_month,
    sync_soumissions_to_rpo,
    update_etats_resultats_budget, get_etats_resultats_budget,
    update_etats_resultats_cible_percent, get_etats_resultats_actuel
)

@app.get("/api/rpo/{username}")
async def get_rpo_data(username: str, team: bool = Query(False), all_teams: bool = Query(False)):
    """
    R√©cup√®re toutes les donn√©es RPO d'un utilisateur
    Si team=true, agr√®ge les donn√©es de tous les membres de l'√©quipe du coach
    Si all_teams=true, agr√®ge les donn√©es de TOUS les entrepreneurs
    """
    try:
        # Si all_teams=true, r√©cup√©rer tous les entrepreneurs
        if all_teams:
            usernames_to_process = get_all_entrepreneurs()
        # Sinon, si team=true, r√©cup√©rer les membres de l'√©quipe
        elif team:
            team_members = get_entrepreneurs_for_coach(username)
            # Extraire les usernames des dictionnaires retourn√©s
            usernames_to_process = [e["username"] for e in team_members] if team_members else [username]
        else:
            usernames_to_process = [username]

        # Si un seul utilisateur, retourner ses donn√©es directement
        # NOTE: Le sync se fait maintenant sur les endpoints d'action (signer-soumission, production-terminee)
        # et non plus ici, pour √©viter le double sync
        if len(usernames_to_process) == 1:
            user = usernames_to_process[0]
            data = load_user_rpo_data(user)
            return data

        # Si plusieurs utilisateurs (√©quipe), agr√©ger les donn√©es
        print(f"[RPO API] Agr√©gation des donn√©es pour l'√©quipe: {usernames_to_process}", flush=True)
        aggregated_data = None

        for user in usernames_to_process:
            user_data = load_user_rpo_data(user)

            if aggregated_data is None:
                aggregated_data = user_data
            else:
                # Agr√©ger les donn√©es (addition simple pour les valeurs num√©riques)
                if isinstance(user_data, dict):
                    for key, value in user_data.items():
                        if isinstance(value, (int, float)) and key in aggregated_data:
                            aggregated_data[key] += value
                        elif isinstance(value, dict) and key in aggregated_data and isinstance(aggregated_data[key], dict):
                            # Agr√©ger les dictionnaires imbriqu√©s
                            for subkey, subvalue in value.items():
                                if isinstance(subvalue, (int, float)) and subkey in aggregated_data[key]:
                                    aggregated_data[key][subkey] += subvalue

        return aggregated_data
    except Exception as e:
        print(f"[Erreur RPO] Chargement donn√©es {username}: {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/{username}/force-sync")
async def force_sync_rpo(username: str):
    """Route de debug pour forcer la synchronisation"""
    try:
        print(f"[DEBUG] Force sync pour {username}", flush=True)
        result = sync_soumissions_to_rpo(username)

        # Recharger les donn√©es apr√®s sync
        data = load_user_rpo_data(username)

        return {
            "success": result,
            "message": "Synchronisation forc√©e termin√©e",
            "octobre_semaine_2": data.get('weekly', {}).get('-2', {}).get('2', {})
        }
    except Exception as e:
        print(f"[ERROR Force Sync] {e}", flush=True)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/{username}/annual")
async def save_annual_data(username: str, data: dict):
    """Sauvegarde les donn√©es annuelles"""
    try:
        success = update_annual_data(username, data)
        if success:
            # Synchroniser le RPO du coach si l'utilisateur est un entrepreneur
            try:
                from QE.Backend.coach_access import get_coach_for_entrepreneur
                from QE.Backend.rpo import sync_coach_rpo
                coach_username = get_coach_for_entrepreneur(username)
                if coach_username:
                    print(f"[SAVE ANNUAL] Synchronisation RPO coach: {coach_username}")
                    sync_coach_rpo(coach_username)
            except Exception as sync_error:
                print(f"[SAVE ANNUAL] [WARN] Erreur sync coach RPO: {sync_error}")

            return {"status": "success", "message": "Donn√©es annuelles sauvegard√©es"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
    except Exception as e:
        print(f"[Erreur RPO] Sauvegarde annual {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/{username}/monthly/{month}")
async def save_monthly_data(username: str, month: str, data: dict):
    """Sauvegarde les donn√©es d'un mois sp√©cifique"""
    try:
        success = update_monthly_data(username, month, data)
        if success:
            return {"status": "success", "message": f"Donn√©es {month} sauvegard√©es"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
    except Exception as e:
        print(f"[Erreur RPO] Sauvegarde monthly {username}/{month}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/{username}/monthly/{month}")
async def get_month_data(username: str, month: str):
    """R√©cup√®re les donn√©es d'un mois sp√©cifique"""
    try:
        data = get_monthly_data(username, month)
        return data
    except Exception as e:
        print(f"[Erreur RPO] Chargement monthly {username}/{month}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/{username}/monthly")
async def get_all_months_data(username: str):
    """R√©cup√®re toutes les donn√©es mensuelles"""
    try:
        data = get_all_monthly_data(username)
        return data
    except Exception as e:
        print(f"[Erreur RPO] Chargement all monthly {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/{username}/weekly/{month_index}/{week_number}")
async def save_week_data(username: str, month_index: int, week_number: int, data: dict):
    """Sauvegarde les donn√©es d'une semaine sp√©cifique"""
    print(f"[API] üì® Requ√™te re√ßue: {username}, mois {month_index}, semaine {week_number}", flush=True)
    print(f"[API] üì¶ Data re√ßue: {data}", flush=True)
    if 'prod_horaire' in data:
        print(f"[API] üí∞ PROD_HORAIRE trouv√©: {data['prod_horaire']}", flush=True)
    else:
        print(f"[API] ‚ö†Ô∏è PROD_HORAIRE absent!", flush=True)
    try:
        success = update_weekly_data(username, month_index, week_number, data)
        if success:
            return {"status": "success", "message": f"Donn√©es semaine {week_number} sauvegard√©es"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
    except Exception as e:
        print(f"[Erreur RPO] Sauvegarde weekly {username}/{month_index}/{week_number}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/{username}/weekly/{month_index}/{week_number}")
async def get_week_data_route(username: str, month_index: int, week_number: int):
    """R√©cup√®re les donn√©es d'une semaine sp√©cifique"""
    try:
        data = get_weekly_data(username, month_index, week_number)
        return data
    except Exception as e:
        print(f"[Erreur RPO] Chargement weekly {username}/{month_index}/{week_number}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/{username}/weekly/{month_index}")
async def get_month_weeks_data(username: str, month_index: int):
    """R√©cup√®re toutes les donn√©es hebdomadaires d'un mois"""
    try:
        data = get_all_weekly_data_for_month(username, month_index)
        return data
    except Exception as e:
        print(f"[Erreur RPO] Chargement weekly month {username}/{month_index}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/rpo/why/{username}")
async def get_rpo_why(username: str):
    """R√©cup√®re le WHY (motivation) de l'entrepreneur depuis son JSON RPO"""
    try:
        from QE.Backend.rpo import load_user_rpo_data

        rpo_data = load_user_rpo_data(username)
        why_text = rpo_data.get("why", "")

        print(f"[WHY] ‚úÖ Charg√© pour {username} depuis RPO JSON")
        return {
            "success": True,
            "why": why_text,
            "last_updated": rpo_data.get("last_updated", "")
        }

    except Exception as e:
        print(f"[WHY] ‚ùå Erreur chargement pour {username}: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/rpo/why/{username}")
async def save_rpo_why(username: str, request: Request):
    """Sauvegarde le WHY (motivation) dans le JSON RPO de l'entrepreneur"""
    try:
        from QE.Backend.rpo import load_user_rpo_data, save_user_rpo_data

        data = await request.json()
        why_text = data.get("why", "")

        # Charger les donn√©es RPO existantes
        rpo_data = load_user_rpo_data(username)

        # Mettre √† jour le WHY
        rpo_data["why"] = why_text

        # Sauvegarder
        save_user_rpo_data(username, rpo_data)

        print(f"[WHY] ‚úÖ Sauvegard√© pour {username} dans RPO JSON: {len(why_text)} caract√®res")
        return {
            "success": True,
            "message": "WHY sauvegard√© avec succ√®s"
        }

    except Exception as e:
        print(f"[WHY] ‚ùå Erreur sauvegarde pour {username}: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


@app.post("/api/rpo/save-weekly-targets")
async def save_weekly_targets(data: dict):
    """Sauvegarde les objectifs "Vis√©" hebdomadaires calcul√©s depuis le plan d'affaires"""
    try:
        username = data.get('username')
        weekly_targets = data.get('weekly_targets', {})

        if not username:
            raise HTTPException(status_code=400, detail="Username manquant")

        print(f"[SAVE TARGETS] Sauvegarde des objectifs hebdomadaires pour {username}")

        # Charger les donn√©es RPO en utilisant le module qui g√®re les chemins
        from QE.Backend.rpo import load_user_rpo_data, save_user_rpo_data, get_week_number_from_date
        from datetime import datetime

        rpo_data = load_user_rpo_data(username)

        # D√©terminer la semaine actuelle pour ne r√©initialiser que les semaines futures
        today = datetime.now().strftime('%Y-%m-%d')
        current_month_index, current_week_num = get_week_number_from_date(today)
        print(f"[SAVE TARGETS] Semaine actuelle: mois {current_month_index}, semaine {current_week_num}")

        # Mettre √† jour les donn√©es hebdomadaires avec les valeurs "Vis√©"
        if "weekly" not in rpo_data:
            rpo_data["weekly"] = {}

        for month_index, weeks in weekly_targets.items():
            month_key = str(month_index)

            if month_key not in rpo_data["weekly"]:
                rpo_data["weekly"][month_key] = {}

            for week_num, week_data in weeks.items():
                week_key = str(week_num)

                # Si la semaine n'existe pas, la cr√©er
                if week_key not in rpo_data["weekly"][month_key]:
                    rpo_data["weekly"][month_key][week_key] = {}

                # Mettre √† jour les champs "Vis√©" du plan d'affaires
                rpo_data["weekly"][month_key][week_key]["week_label"] = week_data.get("week_label", "")
                rpo_data["weekly"][month_key][week_key]["h_marketing_vise"] = week_data.get("h_marketing_vise", 0)
                rpo_data["weekly"][month_key][week_key]["estimation_vise"] = week_data.get("estimation_vise", 0)
                rpo_data["weekly"][month_key][week_key]["contract_vise"] = week_data.get("contract_vise", 0)
                rpo_data["weekly"][month_key][week_key]["dollar_vise"] = week_data.get("dollar_vise", 0)

                # IMPORTANT: NE PAS r√©initialiser les *_obj_modifier!
                # On met √† jour seulement les *_vise (valeurs du plan) et on garde les modifications manuelles
                # Si les champs *_obj_modifier n'existent pas encore, les cr√©er √† 0 (utiliser valeur du plan)
                # Note: modifier = 0 signifie "utiliser la valeur du plan", modifier > 0 = override manuel
                if "h_marketing_obj_modifier" not in rpo_data["weekly"][month_key][week_key]:
                    rpo_data["weekly"][month_key][week_key]["h_marketing_obj_modifier"] = 0
                if "estimation_obj_modifier" not in rpo_data["weekly"][month_key][week_key]:
                    rpo_data["weekly"][month_key][week_key]["estimation_obj_modifier"] = 0
                if "contract_obj_modifier" not in rpo_data["weekly"][month_key][week_key]:
                    rpo_data["weekly"][month_key][week_key]["contract_obj_modifier"] = 0
                if "dollar_obj_modifier" not in rpo_data["weekly"][month_key][week_key]:
                    rpo_data["weekly"][month_key][week_key]["dollar_obj_modifier"] = 0

                print(f"[SAVE TARGETS] Mise √† jour *_vise pour mois {month_key} semaine {week_key} (garde overrides existants)")

        # Sauvegarder les donn√©es RPO en utilisant le module qui g√®re les chemins
        save_user_rpo_data(username, rpo_data)

        # Synchroniser le RPO du coach si l'utilisateur est un entrepreneur
        try:
            from QE.Backend.coach_access import get_coach_for_entrepreneur
            from QE.Backend.rpo import sync_coach_rpo
            coach_username = get_coach_for_entrepreneur(username)
            if coach_username:
                print(f"[SAVE TARGETS] Synchronisation RPO coach: {coach_username}")
                sync_coach_rpo(coach_username)
        except Exception as sync_error:
            print(f"[SAVE TARGETS] [WARN] Erreur sync coach RPO: {sync_error}")

        print(f"[SAVE TARGETS] [OK] Objectifs hebdomadaires sauvegardes avec succes pour {username}")
        return {"status": "success", "message": "Objectifs hebdomadaires sauvegard√©s"}

    except Exception as e:
        print(f"[SAVE TARGETS] [ERREUR] Erreur: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/sync-ventes-produit/{username}")
async def sync_ventes_produit(username: str):
    """
    Synchronise automatiquement les ventes produit dans le RPO
    Lit ventes_produit/{username}/ventes.json et met √† jour les semaines du RPO
    """
    try:
        from QE.Backend.rpo import sync_ventes_produit_to_rpo

        result = sync_ventes_produit_to_rpo(username)
        print(f"[SYNC VENTES] {username}: {result}")

        return result
    except Exception as e:
        print(f"[SYNC VENTES ERROR] {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/sync-coach/{coach_username}")
async def force_sync_coach_rpo(coach_username: str):
    """
    Force la synchronisation du RPO du coach
    Agr√®ge les donn√©es de tous ses entrepreneurs et met √† jour team_previsions et team_metrics
    """
    try:
        from QE.Backend.rpo import sync_coach_rpo

        result = sync_coach_rpo(coach_username)
        if result:
            return {"status": "success", "message": f"RPO coach {coach_username} synchronis√©"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la synchronisation")
    except Exception as e:
        print(f"[SYNC COACH ERROR] {coach_username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/rpo/sync-all-coaches")
async def sync_all_coaches_rpo():
    """
    Synchronise le RPO de TOUS les coaches du syst√®me
    Utile pour migration ou mise √† jour globale
    """
    try:
        from QE.Backend.rpo import sync_coach_rpo
        from QE.Backend.user_management import get_all_users

        # R√©cup√©rer tous les utilisateurs
        all_users = get_all_users()

        # Filtrer les coaches
        coaches = [user['username'] for user in all_users if user.get('role') == 'coach']

        print(f"[SYNC ALL COACHES] Found {len(coaches)} coaches to sync")

        success_count = 0
        failed_coaches = []

        for coach_username in coaches:
            try:
                print(f"[SYNC ALL COACHES] Syncing {coach_username}...")
                result = sync_coach_rpo(coach_username)
                if result:
                    success_count += 1
                    print(f"[SYNC ALL COACHES] ‚úÖ {coach_username} synchronized")
                else:
                    failed_coaches.append(coach_username)
                    print(f"[SYNC ALL COACHES] ‚ùå {coach_username} failed")
            except Exception as e:
                failed_coaches.append(coach_username)
                print(f"[SYNC ALL COACHES] ‚ùå Error syncing {coach_username}: {e}")

        return {
            "status": "success",
            "total_coaches": len(coaches),
            "synchronized": success_count,
            "failed": len(failed_coaches),
            "failed_coaches": failed_coaches,
            "message": f"{success_count}/{len(coaches)} coaches synchronis√©s"
        }
    except Exception as e:
        print(f"[SYNC ALL COACHES ERROR] {e}")
        raise HTTPException(status_code=500, detail=str(e))


# [STATS] Routes √âtats des R√©sultats

@app.post("/api/etats-resultats/budget/{username}")
async def save_budget_data(username: str, data: dict):
    """Sauvegarde les pourcentages Budget des √âtats des R√©sultats"""
    try:
        budget_percent_data = data.get('budget_percent_data', {})
        success = update_etats_resultats_budget(username, budget_percent_data)
        if success:
            return {"status": "success", "message": "Budget % sauvegard√©"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
    except Exception as e:
        print(f"[Erreur √âtats R√©sultats] Sauvegarde budget {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/etats-resultats/budget/{username}")
async def get_budget_data(username: str):
    """R√©cup√®re les pourcentages Budget des √âtats des R√©sultats"""
    try:
        data = get_etats_resultats_budget(username)
        return {"budget_percent_data": data}
    except Exception as e:
        print(f"[Erreur √âtats R√©sultats] Chargement budget {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/etats-resultats/actuel/{username}")
async def save_actuel_data(username: str, request: Request):
    """Sauvegarde uniquement les % cibl√©s des √âtats des R√©sultats
    Les $ cibl√©s sont calcul√©s dynamiquement: CA √ó % cible
    """
    try:
        data = await request.json()
        cible_percent = data.get('cible_percent', {})

        success = update_etats_resultats_cible_percent(username, cible_percent)

        if success:
            return {"status": "success", "message": "% cibl√©s sauvegard√©s"}
        else:
            raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde")
    except Exception as e:
        print(f"[Erreur √âtats R√©sultats] Sauvegarde {username}: {e}", flush=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/etats-resultats/actuel/{username}")
async def get_actuel_data(username: str):
    """R√©cup√®re les % cibl√©s des √âtats des R√©sultats
    Les $ cibl√©s sont calcul√©s dynamiquement: CA √ó % cible
    """
    try:
        data = get_etats_resultats_actuel(username)
        return {
            "budget_percent": data.get('budget_percent', {})
        }
    except Exception as e:
        print(f"[Erreur √âtats R√©sultats] Chargement cible_percent {username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# [BAN] Routes Templates Particularit√©s des travaux
class TemplateCreate(BaseModel):
    username: str
    name: str
    content: str

def get_templates_file(username: str) -> str:
    """Retourne le chemin du fichier templates pour un utilisateur"""
    if sys.platform == 'win32':
        templates_dir = os.path.join(os.path.dirname(__file__), 'data', 'templates')
    else:
        templates_dir = f"{base_cloud}/templates"
    os.makedirs(templates_dir, exist_ok=True)
    return os.path.join(templates_dir, f"{username}_part_travaux.json")

@app.get("/api/templates/part-travaux/{username}")
async def get_user_templates(username: str):
    """R√©cup√®re tous les templates d'un utilisateur"""
    try:
        filepath = get_templates_file(username)
        if not os.path.exists(filepath):
            return []

        with open(filepath, 'r', encoding='utf-8') as f:
            templates = json.load(f)
        return templates
    except Exception as e:
        print(f"[Erreur Templates] Chargement templates {username}: {e}")
        return []

@app.post("/api/templates/part-travaux")
async def save_user_template(template: TemplateCreate):
    """Sauvegarde un nouveau template"""
    try:
        filepath = get_templates_file(template.username)

        # Charger les templates existants
        templates = []
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                templates = json.load(f)

        # Ajouter le nouveau template
        templates.append({
            "name": template.name,
            "content": template.content,
            "created_at": datetime.now().isoformat()
        })

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(templates, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Template sauvegard√©"}
    except Exception as e:
        print(f"[Erreur Templates] Sauvegarde template {template.username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/templates/part-travaux/{username}/{template_name}")
async def delete_user_template(username: str, template_name: str):
    """Supprime un template"""
    try:
        filepath = get_templates_file(username)

        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail="Aucun template trouv√©")

        # Charger les templates
        with open(filepath, 'r', encoding='utf-8') as f:
            templates = json.load(f)

        # Filtrer pour retirer le template √† supprimer
        templates = [t for t in templates if t['name'] != template_name]

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(templates, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Template supprim√©"}
    except Exception as e:
        print(f"[Erreur Templates] Suppression template {username}/{template_name}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# [BAN] Routes Templates √âtapes GQP
def get_etapes_templates_file(username: str) -> str:
    """Retourne le chemin du fichier templates √©tapes pour un utilisateur"""
    if sys.platform == 'win32':
        templates_dir = os.path.join(os.path.dirname(__file__), 'data', 'templates')
    else:
        templates_dir = f"{base_cloud}/templates"
    os.makedirs(templates_dir, exist_ok=True)
    return os.path.join(templates_dir, f"{username}_etapes.json")

@app.get("/api/templates/etapes/{username}")
async def get_user_etapes_templates(username: str):
    """R√©cup√®re tous les templates d'√©tapes d'un utilisateur"""
    try:
        filepath = get_etapes_templates_file(username)
        if not os.path.exists(filepath):
            return []

        with open(filepath, 'r', encoding='utf-8') as f:
            templates = json.load(f)
        return templates
    except Exception as e:
        print(f"[Erreur Templates √âtapes] Chargement templates {username}: {e}")
        return []

@app.post("/api/templates/etapes")
async def save_user_etapes_template(template: TemplateCreate):
    """Sauvegarde un nouveau template d'√©tapes"""
    try:
        filepath = get_etapes_templates_file(template.username)

        # Charger les templates existants
        templates = []
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                templates = json.load(f)

        # Ajouter le nouveau template
        templates.append({
            "name": template.name,
            "content": template.content,
            "created_at": datetime.now().isoformat()
        })

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(templates, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Template √©tapes sauvegard√©"}
    except Exception as e:
        print(f"[Erreur Templates √âtapes] Sauvegarde template {template.username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/templates/etapes/{username}/{template_name}")
async def delete_user_etapes_template(username: str, template_name: str):
    """Supprime un template d'√©tapes"""
    try:
        filepath = get_etapes_templates_file(username)

        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail="Aucun template trouv√©")

        # Charger les templates
        with open(filepath, 'r', encoding='utf-8') as f:
            templates = json.load(f)

        # Filtrer pour retirer le template √† supprimer
        templates = [t for t in templates if t['name'] != template_name]

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(templates, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Template √©tapes supprim√©"}
    except Exception as e:
        print(f"[Erreur Templates √âtapes] Suppression template {username}/{template_name}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# [BAN] Routes Gestion des Projets Calcul
class ProjetCreate(BaseModel):
    username: str
    projet: dict

def get_projets_file(username: str) -> str:
    """Retourne le chemin du fichier projets pour un utilisateur"""
    if sys.platform == 'win32':
        projets_dir = os.path.join(os.path.dirname(__file__), 'data', 'projets')
    else:
        projets_dir = f"{base_cloud}/projets"
    os.makedirs(projets_dir, exist_ok=True)
    return os.path.join(projets_dir, f"{username}_projets.json")

@app.get("/api/projets/{username}")
async def get_user_projets(username: str):
    """R√©cup√®re tous les projets d'un utilisateur"""
    try:
        filepath = get_projets_file(username)
        if not os.path.exists(filepath):
            return []

        with open(filepath, 'r', encoding='utf-8') as f:
            projets = json.load(f)
        return projets
    except Exception as e:
        print(f"[Erreur Projets] Chargement projets {username}: {e}")
        return []

@app.post("/api/projets")
async def save_user_projet(data: ProjetCreate):
    """Sauvegarde ou met √† jour un projet"""
    try:
        filepath = get_projets_file(data.username)

        # Charger les projets existants
        projets = []
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                projets = json.load(f)

        # V√©rifier si le projet existe d√©j√† (m√™me ID)
        projet_id = data.projet.get('id')
        existing_index = -1

        if projet_id:
            for i, p in enumerate(projets):
                if p.get('id') == projet_id:
                    existing_index = i
                    break

        if existing_index >= 0:
            # Mettre √† jour le projet existant
            projets[existing_index] = data.projet
        else:
            # Ajouter un nouveau projet
            projets.append(data.projet)

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(projets, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Projet sauvegard√©"}
    except Exception as e:
        print(f"[Erreur Projets] Sauvegarde projet {data.username}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/projets/{username}/{projet_id}")
async def delete_user_projet(username: str, projet_id: str):
    """Supprime un projet"""
    try:
        filepath = get_projets_file(username)

        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail="Aucun projet trouv√©")

        # Charger les projets
        with open(filepath, 'r', encoding='utf-8') as f:
            projets = json.load(f)

        # Filtrer pour retirer le projet √† supprimer
        projets = [p for p in projets if p.get('id') != projet_id]

        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(projets, f, indent=2, ensure_ascii=False)

        return {"success": True, "message": "Projet supprim√©"}
    except Exception as e:
        print(f"[Erreur Projets] Suppression projet {username}/{projet_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# üì± Routes PWA
@app.get("/manifest.webmanifest")
def get_manifest():
    with open("static/manifest.webmanifest", "r", encoding="utf-8") as f:
        manifest_content = f.read()
    return Response(content=manifest_content, media_type="application/manifest+json")

@app.get("/sw.js")
def get_service_worker():
    # Service worker auto-destructeur - se d√©sinstalle automatiquement
    sw_content = """
// Service Worker auto-destructeur
// Se d√©sinstalle automatiquement pour √©viter les probl√®mes de cache
self.addEventListener('install', function(e) {
    self.skipWaiting();
});

self.addEventListener('activate', function(e) {
    self.registration.unregister()
        .then(function() {
            return self.clients.matchAll();
        })
        .then(function(clients) {
            clients.forEach(client => client.navigate(client.url));
        });
});
"""
    return Response(
        content=sw_content,
        media_type="application/javascript",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )


# ============================================
# ROUTES GESTION VENTES (travaux.html)
# ============================================

@app.get("/ventes/attente/{username}")
def get_ventes_attente(username: str):
    """
    R√©cup√®re les soumissions en attente de signature (ventes_attente/)
    """
    try:
        ventes_dir = os.path.join(f"{base_cloud}/ventes_attente", username)
        fichier_attente = os.path.join(ventes_dir, "ventes.json")

        print(f"[INFO] GET ventes/attente/{username} - Fichier: {fichier_attente}")
        print(f"[INFO] Fichier existe? {os.path.exists(fichier_attente)}")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(fichier_attente):
            os.makedirs(ventes_dir, exist_ok=True)
            with open(fichier_attente, "w", encoding="utf-8") as f:
                json.dump([], f)
            print(f"[NOTE] Fichier cr√©√© vide")
            return []

        with open(fichier_attente, "r", encoding="utf-8") as f:
            content = f.read().strip()
            print(f"[FILE] Contenu lu ({len(content)} chars): {content[:100]}...")
            if not content:
                print(f"[WARNING] Contenu vide!")
                return []
            ventes = json.loads(content)

            # Initialiser les champs d'√©tiquettes s'ils n'existent pas
            for vente in ventes:
                if "statut_vente" not in vente:
                    vente["statut_vente"] = ""
                if "provenance" not in vente:
                    vente["provenance"] = ""
                if "type_travaux" not in vente:
                    vente["type_travaux"] = ""
                if "notes" not in vente:
                    vente["notes"] = ""

            print(f"[OK] {len(ventes)} ventes charg√©es")
            return ventes
    except Exception as e:
        print(f"[ERREUR ventes_attente] {e}")
        import traceback
        traceback.print_exc()
        return []


@app.post("/ventes/creer-soumission")
async def creer_soumission_vente(data: dict = Body(...)):
    """
    Cr√©e une soumission et la place dans ventes_attente/ + soumissions_completes/ (historique)
    """
    try:
        username = data.get("username")
        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        # R√©cup√©rer la langue de l'utilisateur
        user_language = 'fr'  # Par d√©faut fran√ßais
        try:
            account_file = os.path.join(base_cloud, "accounts", f"{username}.json")
            if os.path.exists(account_file):
                with open(account_file, 'r', encoding='utf-8') as f:
                    account_data = json.load(f)
                    user_language = account_data.get('language_preference', 'fr')
                    print(f"[SOUMISSION] Langue utilisateur {username}: {user_language}")
        except Exception as e:
            print(f"[SOUMISSION] Erreur r√©cup√©ration langue utilisateur: {e}")

        # G√©n√©rer PDF de soumission avec la langue appropri√©e
        pdf_buffer = generate_pdf(data, language=user_language)

        # Cr√©er ID unique
        soumission_id = str(uuid.uuid4())
        num_soumission = data.get("num", datetime.now().strftime("%Y%m%d%H%M%S"))

        # Sauvegarder PDF dans ventes_attente
        pdf_dir = os.path.join(f"{base_cloud}/ventes_attente", username)
        os.makedirs(pdf_dir, exist_ok=True)
        pdf_filename = f"soumission_{num_soumission}.pdf"
        pdf_path = os.path.join(pdf_dir, pdf_filename)

        with open(pdf_path, "wb") as f:
            f.write(pdf_buffer.read())

        pdf_url = f"{BASE_URL}/cloud/ventes_attente/{username}/{pdf_filename}"

        # Cr√©er objet soumission
        soumission = {
            "id": soumission_id,
            "num": num_soumission,
            "prenom": data.get("prenom", ""),
            "nom": data.get("nom", ""),
            "telephone": data.get("telephone", ""),
            "adresse": data.get("adresse", ""),
            "courriel": data.get("courriel", ""),
            "prix": data.get("prix", ""),
            "date": data.get("date", datetime.now().strftime("%Y-%m-%d")),
            "date2": data.get("date2", ""),
            "item": data.get("item", ""),
            "temps": data.get("temps", ""),
            "endroit": data.get("endroit", ""),
            "produit": data.get("produit", ""),
            "part": data.get("part", ""),
            "payer_par": data.get("payer_par", ""),
            "pdf_url": pdf_url,
            "lien_calcul": data.get("lien_calcul", None),
            "language": user_language,  # NOUVEAU: Stocker la langue de la soumission
            "created_at": datetime.now().isoformat()
        }

        # 1. Sauvegarder dans ventes_attente/
        fichier_ventes = os.path.join(pdf_dir, "ventes.json")
        ventes = []
        if os.path.exists(fichier_ventes):
            with open(fichier_ventes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    ventes = json.loads(content)

        ventes.append(soumission)

        with open(fichier_ventes, "w", encoding="utf-8") as f:
            json.dump(ventes, f, ensure_ascii=False, indent=2)

        # 2. AJOUTER (ne jamais supprimer) dans soumissions_completes/ (historique permanent)
        dir_completes = os.path.join(f"{base_cloud}/soumissions_completes", username)
        os.makedirs(dir_completes, exist_ok=True)

        fichier_completes = os.path.join(dir_completes, "soumissions.json")
        soumissions_completes = []
        if os.path.exists(fichier_completes):
            with open(fichier_completes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    soumissions_completes = json.loads(content)

        soumissions_completes.append(soumission)

        with open(fichier_completes, "w", encoding="utf-8") as f:
            json.dump(soumissions_completes, f, ensure_ascii=False, indent=2)

        # Copier PDF dans soumissions_completes aussi
        pdf_complete_path = os.path.join(dir_completes, pdf_filename)
        shutil.copy2(pdf_path, pdf_complete_path)

        return {"success": True, "pdf_url": pdf_url, "id": soumission_id}

    except Exception as e:
        print(f"[ERREUR creer_soumission_vente] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/signer-soumission")
async def signer_soumission_vente(data: dict = Body(...)):
    """
    D√©place ventes_attente/ -> ventes_acceptees/ + AJOUTE dans soumissions_signees/ (historique)
    """
    try:
        username = data.get("username")
        soumission_id = data.get("id")

        if not username or not soumission_id:
            raise HTTPException(status_code=400, detail="Username et ID requis")

        # Charger ventes en attente
        fichier_attente = os.path.join(f"{base_cloud}/ventes_attente", username, "ventes.json")
        if not os.path.exists(fichier_attente):
            raise HTTPException(status_code=404, detail="Aucune vente en attente")

        with open(fichier_attente, "r", encoding="utf-8") as f:
            ventes_attente = json.loads(f.read())

        # Trouver la soumission
        soumission = None
        ventes_attente_updated = []
        for v in ventes_attente:
            if v.get("id") == soumission_id:
                soumission = v.copy()
                soumission["date_signature"] = datetime.now().isoformat()

                # Pr√©server les champs d'√©tiquettes (s'ils n'existent pas, initialiser √† "")
                if "statut_vente" not in soumission:
                    soumission["statut_vente"] = ""
                if "provenance" not in soumission:
                    soumission["provenance"] = ""
                if "type_travaux" not in soumission:
                    soumission["type_travaux"] = ""
                if "notes" not in soumission:
                    soumission["notes"] = ""
            else:
                ventes_attente_updated.append(v)

        if not soumission:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # 1. Sauvegarder dans ventes_acceptees
        dir_acceptees = os.path.join(f"{base_cloud}/ventes_acceptees", username)
        os.makedirs(dir_acceptees, exist_ok=True)

        fichier_acceptees = os.path.join(dir_acceptees, "ventes.json")
        ventes_acceptees = []
        if os.path.exists(fichier_acceptees):
            with open(fichier_acceptees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    ventes_acceptees = json.loads(content)

        ventes_acceptees.append(soumission)

        with open(fichier_acceptees, "w", encoding="utf-8") as f:
            json.dump(ventes_acceptees, f, ensure_ascii=False, indent=2)

        # 2. AJOUTER (ne jamais supprimer) dans soumissions_signees/ (historique permanent)
        dir_signees = os.path.join(f"{base_cloud}/soumissions_signees", username)
        os.makedirs(dir_signees, exist_ok=True)

        fichier_signees = os.path.join(dir_signees, "soumissions.json")
        soumissions_signees = []
        if os.path.exists(fichier_signees):
            with open(fichier_signees, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    soumissions_signees = json.loads(content)

        soumissions_signees.append(soumission)

        with open(fichier_signees, "w", encoding="utf-8") as f:
            json.dump(soumissions_signees, f, ensure_ascii=False, indent=2)

        # 3. Retirer de ventes_attente
        with open(fichier_attente, "w", encoding="utf-8") as f:
            json.dump(ventes_attente_updated, f, ensure_ascii=False, indent=2)

        # 3b. Retirer le client des prospects s'il y √©tait
        try:
            print(f"[PROSPECTS] V√©rification et suppression du prospect: {soumission.get('prenom')} {soumission.get('nom')}")
            prospects_file = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
            if os.path.exists(prospects_file):
                with open(prospects_file, "r", encoding="utf-8") as f:
                    prospects = json.load(f)

                # Filtrer les prospects qui ne correspondent pas √† ce client
                prospects_filtered = [
                    p for p in prospects
                    if not (
                        p.get("prenom", "").strip().lower() == soumission.get('prenom', '').strip().lower() and
                        p.get("nom", "").strip().lower() == soumission.get('nom', '').strip().lower() and
                        p.get("adresse", "").strip().lower() == soumission.get('adresse', '').strip().lower()
                    )
                ]

                if len(prospects_filtered) < len(prospects):
                    with open(prospects_file, "w", encoding="utf-8") as f:
                        json.dump(prospects_filtered, f, ensure_ascii=False, indent=2)
                    print(f"[OK] Prospect {soumission.get('prenom')} {soumission.get('nom')} retir√© de la liste des prospects")
                else:
                    print(f"[INFO] Client n'√©tait pas dans les prospects")
        except Exception as e:
            print(f"[WARNING] Erreur lors de la suppression du prospect: {e}")

        # Copier/d√©placer le PDF
        pdf_filename = soumission.get("pdf_url", "").split("/")[-1]
        if pdf_filename:
            src_pdf = os.path.join(f"{base_cloud}/ventes_attente", username, pdf_filename)
            dst_pdf_acceptees = os.path.join(dir_acceptees, pdf_filename)
            dst_pdf_signees = os.path.join(dir_signees, pdf_filename)

            if os.path.exists(src_pdf):
                shutil.copy2(src_pdf, dst_pdf_acceptees)
                shutil.copy2(src_pdf, dst_pdf_signees)
                os.remove(src_pdf)

        # 4. Synchroniser avec Monday.com EN ARRI√àRE-PLAN (automatique si configur√©)
        print(f"[MONDAY] Tentative de synchronisation pour {username}")

        def sync_monday_background():
            sync_success = sync_vente_to_monday(username, soumission)
            if sync_success:
                print(f"[MONDAY] ‚úì Synchronisation Monday.com r√©ussie")
            else:
                print(f"[MONDAY] ‚úó Synchronisation Monday.com √©chou√©e (non bloquant)")

        threading.Thread(target=sync_monday_background, daemon=True).start()
        print(f"[MONDAY] üöÄ Synchronisation Monday.com lanc√©e en arri√®re-plan")

        # --- SYNCHRONISATION RPO (entrepreneur -> coach -> direction) ---
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo
            sync_soumissions_to_rpo(username)
            print(f"[RPO SYNC] RPO synchronis√© apr√®s signature pour {username}")
        except Exception as e:
            print(f"[RPO SYNC WARNING] Erreur synchronisation RPO: {e}")

        return {"success": True, "message": "Soumission accept√©e"}

    except Exception as e:
        print(f"[ERREUR signer_soumission_vente] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/ventes/acceptees/{username}")
def get_ventes_acceptees(username: str):
    """
    R√©cup√®re les soumissions accept√©es (ventes_acceptees/)
    + Synchronisation automatique des nouvelles ventes vers Monday.com
    """
    try:
        ventes_dir = os.path.join(f"{base_cloud}/ventes_acceptees", username)
        fichier_acceptees = os.path.join(ventes_dir, "ventes.json")
        fichier_synced = os.path.join(ventes_dir, ".monday_synced.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(fichier_acceptees):
            os.makedirs(ventes_dir, exist_ok=True)
            with open(fichier_acceptees, "w", encoding="utf-8") as f:
                json.dump([], f)
            return []

        with open(fichier_acceptees, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            ventes = json.loads(content)

        # Initialiser les champs d'√©tiquettes s'ils n'existent pas
        for vente in ventes:
            if "statut_vente" not in vente:
                vente["statut_vente"] = ""
            if "provenance" not in vente:
                vente["provenance"] = ""
            if "type_travaux" not in vente:
                vente["type_travaux"] = ""
            if "notes" not in vente:
                vente["notes"] = ""

        # Charger la liste des ventes d√©j√† synchronis√©es
        synced_ids = set()
        if os.path.exists(fichier_synced):
            with open(fichier_synced, "r", encoding="utf-8") as f:
                synced_content = f.read().strip()
                if synced_content:
                    synced_ids = set(json.loads(synced_content))

        # V√©rifier s'il y a de nouvelles ventes √† synchroniser
        nouvelles_ventes = []
        for vente in ventes:
            vente_id = f"{vente.get('id', '')}_{vente.get('num', '')}".replace(" ", "_")
            if vente_id not in synced_ids:
                nouvelles_ventes.append((vente_id, vente))

        # Synchroniser les nouvelles ventes vers Monday.com EN ARRI√àRE-PLAN
        if nouvelles_ventes:
            def sync_ventes_background():
                for vente_id, vente in nouvelles_ventes:
                    sync_success = sync_vente_to_monday(username, vente)
                    if sync_success:
                        synced_ids.add(vente_id)

                # Sauvegarder la liste mise √† jour des ventes synchronis√©es
                with open(fichier_synced, "w", encoding="utf-8") as f:
                    json.dump(list(synced_ids), f, ensure_ascii=False, indent=2)

            threading.Thread(target=sync_ventes_background, daemon=True).start()
            print(f"[MONDAY] üöÄ Synchronisation de {len(nouvelles_ventes)} vente(s) lanc√©e en arri√®re-plan")

        return ventes
    except Exception:
        # Erreur de lecture du fichier - retourner tableau vide
        return []


@app.post("/ventes/production-terminee")
async def production_terminee_vente(data: dict = Body(...)):
    """
    D√©place ventes_acceptees/ -> ventes_produit/ (remplace travaux_completes/)
    """
    try:
        username = data.get("username")
        soumission_id = data.get("id")

        if not username or not soumission_id:
            raise HTTPException(status_code=400, detail="Username et ID requis")

        # Charger ventes accept√©es
        fichier_acceptees = os.path.join(f"{base_cloud}/ventes_acceptees", username, "ventes.json")
        if not os.path.exists(fichier_acceptees):
            raise HTTPException(status_code=404, detail="Aucune vente accept√©e")

        with open(fichier_acceptees, "r", encoding="utf-8") as f:
            ventes_acceptees = json.loads(f.read())

        # Trouver la soumission
        soumission = None
        ventes_acceptees_updated = []
        for v in ventes_acceptees:
            if v.get("id") == soumission_id:
                soumission = v.copy()
                soumission["date_completion"] = datetime.now().isoformat()

                # Pr√©server les champs d'√©tiquettes
                if "statut_vente" not in soumission:
                    soumission["statut_vente"] = ""
                if "provenance" not in soumission:
                    soumission["provenance"] = ""
                if "type_travaux" not in soumission:
                    soumission["type_travaux"] = ""
                if "notes" not in soumission:
                    soumission["notes"] = ""
            else:
                ventes_acceptees_updated.append(v)

        if not soumission:
            raise HTTPException(status_code=404, detail="Soumission non trouv√©e")

        # Sauvegarder dans ventes_produit (remplace travaux_completes)
        dir_produit = os.path.join(f"{base_cloud}/ventes_produit", username)
        os.makedirs(dir_produit, exist_ok=True)

        fichier_produit = os.path.join(dir_produit, "ventes.json")
        ventes_produit = []
        if os.path.exists(fichier_produit):
            with open(fichier_produit, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    ventes_produit = json.loads(content)

        ventes_produit.append(soumission)

        with open(fichier_produit, "w", encoding="utf-8") as f:
            json.dump(ventes_produit, f, ensure_ascii=False, indent=2)

        # Retirer de ventes_acceptees
        with open(fichier_acceptees, "w", encoding="utf-8") as f:
            json.dump(ventes_acceptees_updated, f, ensure_ascii=False, indent=2)

        # Copier/d√©placer le PDF
        pdf_filename = soumission.get("pdf_url", "").split("/")[-1]
        if pdf_filename:
            src_pdf = os.path.join(f"{base_cloud}/ventes_acceptees", username, pdf_filename)
            dst_pdf = os.path.join(dir_produit, pdf_filename)
            if os.path.exists(src_pdf):
                shutil.copy2(src_pdf, dst_pdf)
                os.remove(src_pdf)

        # Copier GQP si pr√©sent (reste dans /mnt/cloud/gqp, pas de d√©placement)
        gqp_url = soumission.get("lien_gqp", "")
        if gqp_url:
            gqp_filename = gqp_url.split("/")[-1]
            src_gqp = os.path.join(f"{base_cloud}/gqp", username, gqp_filename)
            dst_gqp = os.path.join(dir_produit, gqp_filename)
            if os.path.exists(src_gqp):
                shutil.copy2(src_gqp, dst_gqp)

        # --- ENVOI EMAIL DEMANDE DE SATISFACTION ---
        try:
            url_avis = (
                f"{BASE_URL}/avisclient?"
                f"username={username}&"
                f"travail_id={soumission.get('id')}&"
                f"nom={urllib.parse.quote(soumission.get('clientNom',''))}&"
                f"prenom={urllib.parse.quote(soumission.get('clientPrenom',''))}"
            )
            envoyer_email_demande_satisfaction(username, soumission, url_avis)
        except Exception as e:
            print(f"[ERREUR] envoi email satisfaction: {e}")

        # --- SYNCHRONISATION RPO (entrepreneur -> coach -> direction) ---
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo
            sync_soumissions_to_rpo(username)
            print(f"[RPO SYNC] RPO synchronis√© apr√®s production termin√©e pour {username}")
        except Exception as e:
            print(f"[RPO SYNC WARNING] Erreur synchronisation RPO: {e}")

        return {"success": True, "message": "Production termin√©e"}

    except Exception as e:
        print(f"[ERREUR production_terminee_vente] {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ROUTES API PLAINTES
# ============================================

@app.get("/api/soumissions/{username}/signed")
def get_soumissions_signees(username: str):
    """
    R√©cup√®re toutes les soumissions sign√©es (ventes accept√©es) d'un entrepreneur
    Retourne les donn√©es n√©cessaires pour le dropdown de s√©lection client
    """
    try:
        ventes_dir = os.path.join(f"{base_cloud}/ventes_acceptees", username)
        fichier_acceptees = os.path.join(ventes_dir, "ventes.json")

        # Si le fichier n'existe pas, retourner une liste vide
        if not os.path.exists(fichier_acceptees):
            return {"success": True, "soumissions": []}

        with open(fichier_acceptees, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return {"success": True, "soumissions": []}
            ventes = json.loads(content)

        # Formater les donn√©es pour le dropdown
        soumissions = []
        for vente in ventes:
            soumissions.append({
                "id": vente.get("id", ""),
                "prenom": vente.get("prenom", ""),
                "nom": vente.get("nom", ""),
                "num": vente.get("num", ""),
                "telephone": vente.get("telephone", ""),
                "courriel": vente.get("courriel", "")
            })

        return {"success": True, "soumissions": soumissions}

    except Exception as e:
        print(f"[ERREUR get_soumissions_signees] {e}")
        return {"success": False, "message": str(e)}


@app.post("/api/plaintes")
async def ajouter_plainte(data: dict = Body(...)):
    """
    Ajoute une nouvelle plainte
    """
    try:
        entrepreneur_username = data.get("entrepreneur_username")
        client_prenom = data.get("client_prenom")
        client_nom = data.get("client_nom")
        client_telephone = data.get("client_telephone", "")
        client_courriel = data.get("client_courriel", "")
        soumission_num = data.get("soumission_num")
        description = data.get("description")
        statut = data.get("statut", "actuelle")  # actuelle ou reglee

        if not all([entrepreneur_username, client_prenom, client_nom, soumission_num, description]):
            raise HTTPException(status_code=400, detail="Tous les champs sont requis")

        # Charger ou cr√©er le fichier de plaintes
        plaintes_dir = os.path.join(f"{base_cloud}/plaintes", entrepreneur_username)
        os.makedirs(plaintes_dir, exist_ok=True)
        fichier_plaintes = os.path.join(plaintes_dir, "plaintes.json")

        plaintes = []
        if os.path.exists(fichier_plaintes):
            with open(fichier_plaintes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    plaintes = json.loads(content)

        # Cr√©er la nouvelle plainte
        nouvelle_plainte = {
            "id": str(uuid.uuid4()),
            "client_prenom": client_prenom,
            "client_nom": client_nom,
            "client_telephone": client_telephone,
            "client_courriel": client_courriel,
            "soumission_num": soumission_num,
            "description": description,
            "statut": statut,
            "date_creation": datetime.now().isoformat(),
            "date_reglee": None
        }

        plaintes.append(nouvelle_plainte)

        # Sauvegarder
        with open(fichier_plaintes, "w", encoding="utf-8") as f:
            json.dump(plaintes, f, ensure_ascii=False, indent=2)

        return {"success": True, "message": "Plainte ajout√©e avec succ√®s", "plainte": nouvelle_plainte}

    except Exception as e:
        print(f"[ERREUR ajouter_plainte] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/plaintes/{username}")
def get_plaintes(username: str):
    """
    R√©cup√®re toutes les plaintes d'un entrepreneur
    """
    try:
        plaintes_dir = os.path.join(f"{base_cloud}/plaintes", username)
        fichier_plaintes = os.path.join(plaintes_dir, "plaintes.json")

        # Si le fichier n'existe pas, retourner des listes vides
        if not os.path.exists(fichier_plaintes):
            return {
                "success": True,
                "plaintes_actuelles": [],
                "plaintes_reglees": []
            }

        with open(fichier_plaintes, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return {
                    "success": True,
                    "plaintes_actuelles": [],
                    "plaintes_reglees": []
                }
            plaintes = json.loads(content)

        # S√©parer les plaintes actuelles et r√©gl√©es
        plaintes_actuelles = [p for p in plaintes if p.get("statut") == "actuelle"]
        plaintes_reglees = [p for p in plaintes if p.get("statut") == "reglee"]

        return {
            "success": True,
            "plaintes_actuelles": plaintes_actuelles,
            "plaintes_reglees": plaintes_reglees
        }

    except Exception as e:
        print(f"[ERREUR get_plaintes] {e}")
        return {"success": False, "message": str(e)}


@app.post("/api/submit-plainte")
async def submit_plainte_public(request: Request):
    """
    Endpoint public pour soumettre une plainte depuis le formulaire client
    G√®re les fichiers upload√©s
    """
    try:
        form = await request.form()

        # R√©cup√©rer les donn√©es du formulaire
        status = form.get("status", "")
        entrepreneur = form.get("entrepreneur", "")
        nature = form.get("nature", "")
        elaboration = form.get("elaboration", "")
        contrat = form.get("contrat", "")
        availability_json = form.get("availability", "[]")
        attentes = form.get("attentes", "")
        nom = form.get("nom", "")
        telephone = form.get("telephone", "")
        courriel = form.get("courriel", "")

        # Parser les disponibilit√©s
        try:
            availability = json.loads(availability_json)
        except:
            availability = []

        if not entrepreneur:
            raise HTTPException(status_code=400, detail="Entrepreneur requis")

        # Cr√©er le dossier pour les plaintes de cet entrepreneur
        plaintes_dir = os.path.join(base_cloud, "plaintes", entrepreneur)
        os.makedirs(plaintes_dir, exist_ok=True)

        # G√©n√©rer un ID unique pour cette plainte
        plainte_id = str(uuid.uuid4())

        # Cr√©er un dossier pour les fichiers de cette plainte
        fichiers_dir = os.path.join(plaintes_dir, "fichiers", plainte_id)
        os.makedirs(fichiers_dir, exist_ok=True)

        # Sauvegarder les fichiers upload√©s
        fichiers_sauvegardes = []
        for key in form.keys():
            if key.startswith("file_"):
                file = form[key]
                if hasattr(file, 'filename') and file.filename:
                    # S√©curiser le nom du fichier
                    safe_filename = file.filename.replace("/", "_").replace("\\", "_")
                    file_path = os.path.join(fichiers_dir, safe_filename)

                    # Sauvegarder le fichier
                    content = await file.read()
                    with open(file_path, "wb") as f:
                        f.write(content)

                    fichiers_sauvegardes.append({
                        "nom": safe_filename,
                        "chemin": file_path
                    })

        # Charger les plaintes existantes
        fichier_plaintes = os.path.join(plaintes_dir, "plaintes.json")
        plaintes = []
        if os.path.exists(fichier_plaintes):
            with open(fichier_plaintes, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    plaintes = json.loads(content)

        # Mapper les valeurs pour l'affichage
        status_labels = {
            "non_client": "Non client - a communiqu√© avec l'entrepreneur",
            "travaux_non_faits": "Client - travaux non faits",
            "travaux_en_cours": "Client - travaux en cours",
            "travaux_termines": "Client - travaux termin√©s"
        }

        nature_labels = {
            "qualite_travaux": "Qualit√© des travaux",
            "qualite_communication": "Qualit√© de la communication",
            "non_respect_horaire": "Non-respect de l'horaire des travaux",
            "comportement_employes": "Comportement des employ√©s"
        }

        # Cr√©er la nouvelle plainte
        nouvelle_plainte = {
            "id": plainte_id,
            "source": "formulaire_public",
            "client_statut": status,
            "client_statut_label": status_labels.get(status, status),
            "nature": nature,
            "nature_label": nature_labels.get(nature, nature),
            "description": elaboration,
            "numero_contrat": contrat,
            "disponibilites": availability,
            "attentes": attentes,
            "client_nom": nom,
            "client_telephone": telephone,
            "client_courriel": courriel,
            "fichiers": fichiers_sauvegardes,
            "statut": "actuelle",
            "date_creation": datetime.now().isoformat(),
            "date_reglee": None
        }

        plaintes.append(nouvelle_plainte)

        # Sauvegarder
        with open(fichier_plaintes, "w", encoding="utf-8") as f:
            json.dump(plaintes, f, ensure_ascii=False, indent=2)

        print(f"[PLAINTE] Nouvelle plainte soumise pour {entrepreneur}: {plainte_id}")

        return {"success": True, "message": "Plainte soumise avec succ√®s", "plainte_id": plainte_id}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR submit_plainte_public] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/plaintes/count/coach/{coach_username}")
def get_coach_plaintes_count(coach_username: str):
    """
    Compte toutes les plaintes non r√©gl√©es pour les entrepreneurs d'un coach
    """
    try:
        # Charger la liste des entrepreneurs du coach
        entrepreneurs_file = os.path.join(base_cloud, "entrepreneurs", f"{coach_username}.json")

        if not os.path.exists(entrepreneurs_file):
            return {"success": True, "count": 0}

        with open(entrepreneurs_file, "r", encoding="utf-8") as f:
            entrepreneurs_data = json.load(f)

        entrepreneurs = entrepreneurs_data.get("entrepreneurs", [])
        total_count = 0

        for entrepreneur in entrepreneurs:
            entrepreneur_username = entrepreneur.get("username", "")
            if not entrepreneur_username:
                continue

            fichier_plaintes = os.path.join(base_cloud, "plaintes", entrepreneur_username, "plaintes.json")

            if os.path.exists(fichier_plaintes):
                try:
                    with open(fichier_plaintes, "r", encoding="utf-8") as f:
                        content = f.read().strip()
                        if content:
                            plaintes = json.loads(content)
                            total_count += sum(1 for p in plaintes if p.get("statut") == "actuelle")
                except:
                    continue

        return {"success": True, "count": total_count}

    except Exception as e:
        print(f"[ERREUR get_coach_plaintes_count] {e}")
        return {"success": False, "count": 0}


@app.get("/api/plaintes/count/all")
def get_all_plaintes_count():
    """
    Compte toutes les plaintes non r√©gl√©es pour tous les entrepreneurs (pour direction)
    """
    try:
        plaintes_base = os.path.join(f"{base_cloud}/plaintes")
        total_count = 0

        if not os.path.exists(plaintes_base):
            return {"success": True, "count": 0}

        for entrepreneur_folder in os.listdir(plaintes_base):
            fichier_plaintes = os.path.join(plaintes_base, entrepreneur_folder, "plaintes.json")

            if os.path.exists(fichier_plaintes):
                try:
                    with open(fichier_plaintes, "r", encoding="utf-8") as f:
                        content = f.read().strip()
                        if content:
                            plaintes = json.loads(content)
                            # Compter seulement les plaintes actuelles (non r√©gl√©es)
                            total_count += sum(1 for p in plaintes if p.get("statut") == "actuelle")
                except:
                    continue

        return {"success": True, "count": total_count}

    except Exception as e:
        print(f"[ERREUR get_all_plaintes_count] {e}")
        return {"success": False, "count": 0}


@app.put("/api/plaintes/{plainte_id}/resoudre")
async def resoudre_plainte(plainte_id: str):
    """
    Marque une plainte comme r√©gl√©e
    """
    try:
        # Chercher dans tous les dossiers d'entrepreneurs
        plaintes_base = os.path.join(f"{base_cloud}/plaintes")

        for entrepreneur_folder in os.listdir(plaintes_base):
            fichier_plaintes = os.path.join(plaintes_base, entrepreneur_folder, "plaintes.json")

            if os.path.exists(fichier_plaintes):
                with open(fichier_plaintes, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if not content:
                        continue
                    plaintes = json.loads(content)

                # Chercher la plainte par ID
                plainte_found = False
                for plainte in plaintes:
                    if plainte.get("id") == plainte_id:
                        plainte["statut"] = "reglee"
                        plainte["date_reglee"] = datetime.now().isoformat()
                        plainte_found = True
                        break

                if plainte_found:
                    # Sauvegarder
                    with open(fichier_plaintes, "w", encoding="utf-8") as f:
                        json.dump(plaintes, f, ensure_ascii=False, indent=2)

                    return {"success": True, "message": "Plainte marqu√©e comme r√©gl√©e"}

        return {"success": False, "message": "Plainte non trouv√©e"}

    except Exception as e:
        print(f"[ERREUR resoudre_plainte] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-statut-paiement")
async def update_statut_paiement_vente(data: dict = Body(...)):
    """
    Met √† jour le statut de paiement d'une vente dans n'importe quelle cat√©gorie
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouveau_statut = data.get("statut")
        category = data.get("category")  # attente, acceptees, produit

        if not username or not vente_id or not nouveau_statut or not category:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # D√©terminer le fichier selon la cat√©gorie
        fichier_ventes = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier_ventes):
            raise HTTPException(status_code=404, detail=f"Fichier ventes_{category} non trouv√©")

        # Charger les ventes
        with open(fichier_ventes, "r", encoding="utf-8") as f:
            ventes = json.load(f)

        # Trouver et mettre √† jour la vente
        vente_trouvee = False
        for vente in ventes:
            if vente.get("id") == vente_id or vente.get("num") == vente_id:
                vente["statut_paiement"] = nouveau_statut
                vente_trouvee = True
                break

        if not vente_trouvee:
            raise HTTPException(status_code=404, detail="Vente non trouv√©e")

        # Sauvegarder les modifications
        with open(fichier_ventes, "w", encoding="utf-8") as f:
            json.dump(ventes, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] Statut paiement mis √† jour pour {username}/{vente_id}: {nouveau_statut}")
        return {"success": True, "message": "Statut de paiement mis √† jour"}

    except Exception as e:
        print(f"[ERREUR update_statut_paiement_vente] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-statut-vente")
async def update_statut_vente(data: dict = Body(...)):
    """
    Met √† jour le statut de vente (√Ä traiter, En cours, Termin√©)
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouveau_statut = data.get("statut")
        category = data.get("category")

        if not username or not vente_id or nouveau_statut is None or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False
        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["statut_vente"] = nouveau_statut
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] Statut vente mis √† jour pour {username}/{vente_id}: {nouveau_statut}")
        return {"success": True, "message": "Statut de vente mis √† jour"}

    except Exception as e:
        print(f"[ERREUR update_statut_vente] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-provenance")
async def update_provenance(data: dict = Body(...)):
    """
    Met √† jour la provenance d'une vente
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouvelle_provenance = data.get("provenance")
        category = data.get("category")

        if not username or not vente_id or nouvelle_provenance is None or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False
        soumission_num = None
        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["provenance"] = nouvelle_provenance
                soumission_num = item.get("num")  # Capturer le num√©ro de soumission pour Monday
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] Provenance mise √† jour pour {username}/{vente_id}: {nouvelle_provenance}")

        # Synchroniser avec Monday.com si la cat√©gorie est acceptees ou produit (client sign√©)
        if category in ["acceptees", "produit"] and soumission_num:
            try:
                # R√©cup√©rer les credentials Monday
                api_key, board_id = get_monday_credentials(username)

                if api_key and board_id:
                    # Trouver l'item Monday correspondant en utilisant le num√©ro de soumission
                    monday_item_id = find_monday_item_by_soumission(username, soumission_num)

                    if monday_item_id:
                        # Mapper l'√©tiquette au bon index Monday en cherchant par NOM
                        if nouvelle_provenance and nouvelle_provenance.strip():
                            # R√©cup√©rer le mapping des labels Monday
                            from QE.Backend.monday_sync import get_monday_column_labels, add_label_to_monday_column

                            label_map = get_monday_column_labels(api_key, board_id, "dup__of_couleurs_mkm0awjt")

                            # Chercher l'index Monday correspondant au nom de l'√©tiquette
                            monday_index = None

                            # Essayer avec le nom exact
                            if nouvelle_provenance in label_map:
                                monday_index = label_map[nouvelle_provenance]
                            # Essayer avec le nom normalis√© (minuscules)
                            elif nouvelle_provenance.lower() in label_map:
                                monday_index = label_map[nouvelle_provenance.lower()]

                            # Si l'√©tiquette n'existe pas dans Monday, essayer de la cr√©er
                            if monday_index is None:
                                print(f"[MONDAY] √âtiquette '{nouvelle_provenance}' non trouv√©e dans Monday")

                                # Essayer de cr√©er l'√©tiquette automatiquement
                                # R√©cup√©rer la couleur de l'√©tiquette dans Qwota
                                etiquette_color = "#3b82f6"  # Couleur par d√©faut (bleu)
                                try:
                                    fichier_etiquettes = os.path.join(f"{base_cloud}/ventes_etiquettes", username, "etiquettes.json")
                                    if os.path.exists(fichier_etiquettes):
                                        with open(fichier_etiquettes, "r", encoding="utf-8") as f:
                                            etiquettes = json.load(f)
                                        provenances = etiquettes.get("provenances", [])
                                        for prov in provenances:
                                            if isinstance(prov, dict) and prov.get("label") == nouvelle_provenance:
                                                etiquette_color = prov.get("color", etiquette_color)
                                                break
                                except Exception as e:
                                    print(f"[MONDAY] Impossible de r√©cup√©rer la couleur: {e}")

                                print(f"[MONDAY] Tentative de cr√©ation de l'√©tiquette '{nouvelle_provenance}'...")
                                monday_index = add_label_to_monday_column(
                                    api_key,
                                    board_id,
                                    "dup__of_couleurs_mkm0awjt",
                                    nouvelle_provenance,
                                    etiquette_color
                                )

                                # Si la cr√©ation √©choue, essayer une correspondance partielle
                                if monday_index is None:
                                    print(f"[MONDAY] Recherche de correspondance partielle...")
                                    nouvelle_prov_lower = nouvelle_provenance.lower()
                                    for label_name, idx in label_map.items():
                                        if label_name and nouvelle_prov_lower in label_name.lower() or label_name.lower() in nouvelle_prov_lower:
                                            monday_index = idx
                                            print(f"[MONDAY] Correspondance partielle trouv√©e: '{nouvelle_provenance}' -> '{label_name}' (index {monday_index})")
                                            break

                            if monday_index is not None:
                                value_json = json.dumps({"index": monday_index})
                                success = update_monday_column(
                                    api_key,
                                    board_id,
                                    monday_item_id,
                                    "dup__of_couleurs_mkm0awjt",  # ID colonne Provenance Monday
                                    value_json
                                )
                                if success:
                                    print(f"[MONDAY] Provenance synchronis√©e: {nouvelle_provenance} -> index {monday_index}")
                                else:
                                    print(f"[MONDAY ERROR] √âchec synchronisation provenance")
                            else:
                                print(f"[MONDAY WARN] ‚ö†Ô∏è √âtiquette '{nouvelle_provenance}' absente dans Monday.com")
                                print(f"[MONDAY WARN] üí° Ajoutez manuellement l'√©tiquette dans la colonne 'Provenance' de votre board Monday")
                                print(f"[MONDAY WARN] Labels disponibles: {', '.join([k for k in label_map.keys() if k and k[0].isupper()])}")
                        else:
                            # Vide - effacer la valeur
                            value_json = json.dumps({"index": None})
                            update_monday_column(api_key, board_id, monday_item_id, "dup__of_couleurs_mkm0awjt", value_json)
                    else:
                        print(f"[MONDAY] Item non trouv√© dans Monday pour {vente_id}")
            except Exception as e:
                print(f"[MONDAY ERROR] Erreur sync provenance: {e}")

        return {"success": True, "message": "Provenance mise √† jour"}

    except Exception as e:
        print(f"[ERREUR update_provenance] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-type-travaux")
async def update_type_travaux(data: dict = Body(...)):
    """
    Met √† jour le type de travaux d'une vente
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouveau_type = data.get("type_travaux")
        category = data.get("category")

        if not username or not vente_id or nouveau_type is None or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False
        soumission_num = None
        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["type_travaux"] = nouveau_type
                soumission_num = item.get("num")  # Capturer le num√©ro de soumission pour Monday
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] Type travaux mis √† jour pour {username}/{vente_id}: {nouveau_type}")

        # Synchroniser avec Monday.com si la cat√©gorie est acceptees ou produit (client sign√©)
        if category in ["acceptees", "produit"] and soumission_num:
            try:
                # R√©cup√©rer les credentials Monday
                api_key, board_id = get_monday_credentials(username)

                if api_key and board_id:
                    # Trouver l'item Monday correspondant en utilisant le num√©ro de soumission
                    monday_item_id = find_monday_item_by_soumission(username, soumission_num)

                    if monday_item_id:
                        # Mapper l'√©tiquette au bon index Monday en cherchant par NOM
                        if nouveau_type and nouveau_type.strip():
                            # R√©cup√©rer le mapping des labels Monday
                            from QE.Backend.monday_sync import get_monday_column_labels, add_label_to_monday_column

                            label_map = get_monday_column_labels(api_key, board_id, "status_1")

                            # Chercher l'index Monday correspondant au nom de l'√©tiquette
                            monday_index = None

                            # Essayer avec le nom exact
                            if nouveau_type in label_map:
                                monday_index = label_map[nouveau_type]
                            # Essayer avec le nom normalis√© (minuscules)
                            elif nouveau_type.lower() in label_map:
                                monday_index = label_map[nouveau_type.lower()]

                            # Si l'√©tiquette n'existe pas dans Monday, essayer de la cr√©er
                            if monday_index is None:
                                print(f"[MONDAY] √âtiquette '{nouveau_type}' non trouv√©e dans Monday")

                                # Essayer de cr√©er l'√©tiquette automatiquement
                                # R√©cup√©rer la couleur de l'√©tiquette dans Qwota
                                etiquette_color = "#3b82f6"  # Couleur par d√©faut (bleu)
                                try:
                                    fichier_etiquettes = os.path.join(f"{base_cloud}/ventes_etiquettes", username, "etiquettes.json")
                                    if os.path.exists(fichier_etiquettes):
                                        with open(fichier_etiquettes, "r", encoding="utf-8") as f:
                                            etiquettes = json.load(f)
                                        types_travaux = etiquettes.get("types_travaux", [])
                                        for type_item in types_travaux:
                                            if isinstance(type_item, dict) and type_item.get("label") == nouveau_type:
                                                etiquette_color = type_item.get("color", etiquette_color)
                                                break
                                except Exception as e:
                                    print(f"[MONDAY] Impossible de r√©cup√©rer la couleur: {e}")

                                print(f"[MONDAY] Tentative de cr√©ation de l'√©tiquette '{nouveau_type}'...")
                                monday_index = add_label_to_monday_column(
                                    api_key,
                                    board_id,
                                    "status_1",
                                    nouveau_type,
                                    etiquette_color
                                )

                                # Si la cr√©ation √©choue, essayer une correspondance partielle
                                if monday_index is None:
                                    print(f"[MONDAY] Recherche de correspondance partielle...")
                                    nouveau_type_lower = nouveau_type.lower()
                                    for label_name, idx in label_map.items():
                                        if label_name and nouveau_type_lower in label_name.lower() or label_name.lower() in nouveau_type_lower:
                                            monday_index = idx
                                            print(f"[MONDAY] Correspondance partielle trouv√©e: '{nouveau_type}' -> '{label_name}' (index {monday_index})")
                                            break

                            if monday_index is not None:
                                value_json = json.dumps({"index": monday_index})
                                success = update_monday_column(
                                    api_key,
                                    board_id,
                                    monday_item_id,
                                    "status_1",  # ID colonne Type de travaux Monday
                                    value_json
                                )
                                if success:
                                    print(f"[MONDAY] Type travaux synchronis√©: {nouveau_type} -> index {monday_index}")
                                else:
                                    print(f"[MONDAY ERROR] √âchec synchronisation type travaux")
                            else:
                                print(f"[MONDAY WARN] ‚ö†Ô∏è √âtiquette '{nouveau_type}' absente dans Monday.com")
                                print(f"[MONDAY WARN] üí° Ajoutez manuellement l'√©tiquette dans la colonne 'Type de travaux' de votre board Monday")
                                print(f"[MONDAY WARN] Labels disponibles: {', '.join([k for k in label_map.keys() if k and k[0].isupper()])}")
                        else:
                            # Vide - effacer la valeur
                            value_json = json.dumps({"index": None})
                            update_monday_column(api_key, board_id, monday_item_id, "status_1", value_json)
                    else:
                        print(f"[MONDAY] Item non trouv√© dans Monday pour {vente_id}")
            except Exception as e:
                print(f"[MONDAY ERROR] Erreur sync type travaux: {e}")

        return {"success": True, "message": "Type de travaux mis √† jour"}

    except Exception as e:
        print(f"[ERREUR update_type_travaux] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-paiement")
async def update_paiement(data: dict = Body(...)):
    """
    Met √† jour le paiement d'une vente (SANS synchronisation Monday)
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouveau_paiement = data.get("paiement")
        category = data.get("category")

        if not username or not vente_id or nouveau_paiement is None or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False
        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["paiement"] = nouveau_paiement
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] Paiement mis √† jour pour {username}/{vente_id}: {nouveau_paiement}")

        return {"success": True, "message": "Paiement mis √† jour"}

    except Exception as e:
        print(f"[ERREUR update_paiement] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-notes")
async def update_notes(data: dict = Body(...)):
    """
    Met √† jour les notes d'une vente et synchronise avec Monday.com
    """
    try:
        username = data.get("username")
        vente_id = data.get("id")
        nouvelles_notes = data.get("notes")
        category = data.get("category")

        if not username or not vente_id or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False
        soumission_num = None
        prenom = None
        nom = None

        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["notes"] = nouvelles_notes
                soumission_num = item.get("num")
                prenom = item.get("prenom")
                nom = item.get("nom")
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        notes_preview = nouvelles_notes[:50] + "..." if nouvelles_notes and len(nouvelles_notes) > 50 else nouvelles_notes
        print(f"[VENTES] Notes mises √† jour pour {username}/{vente_id}: {notes_preview}")

        # Synchroniser avec Monday.com
        try:
            api_key, board_id = get_monday_credentials(username)

            if api_key and board_id and soumission_num:
                # Trouver l'item Monday
                monday_item_id = find_monday_item_by_soumission(username, soumission_num)

                if monday_item_id:
                    # Mettre √† jour la colonne "Infos sup" (ID: "text")
                    update_monday_text_column(
                        api_key=api_key,
                        board_id=board_id,
                        item_id=monday_item_id,
                        column_id="text",
                        value=nouvelles_notes or ""
                    )
                    print(f"[MONDAY] Notes synchronis√©es pour l'item {monday_item_id}")
                else:
                    print(f"[MONDAY] Item non trouv√© dans Monday pour {soumission_num}")
            else:
                print(f"[MONDAY] Pas de configuration Monday pour {username}")
        except Exception as monday_err:
            print(f"[MONDAY ERROR] Erreur synchronisation notes: {monday_err}")
            # Ne pas faire √©chouer la requ√™te si Monday sync √©choue

        return {"success": True, "message": "Notes mises √† jour"}

    except Exception as e:
        print(f"[ERREUR update_notes] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/update-etiquette")
async def update_etiquette(data: dict = Body(...)):
    """
    Met √† jour l'√©tiquette (status) d'une vente
    """
    try:
        username = data.get("username")
        vente_id = data.get("vente_id")
        nouvelle_etiquette = data.get("value", "")
        category = data.get("category")

        if not username or not vente_id or category is None:
            raise HTTPException(status_code=400, detail="Param√®tres manquants")

        # G√©rer les prospects
        if category == "prospects":
            fichier = os.path.join(f"{base_cloud}/prospects", username, "prospects.json")
        else:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")

        if not os.path.exists(fichier):
            raise HTTPException(status_code=404, detail=f"Fichier non trouv√©")

        with open(fichier, "r", encoding="utf-8") as f:
            items = json.load(f)

        item_trouve = False

        for item in items:
            if item.get("id") == vente_id or item.get("num") == vente_id:
                item["etiquette"] = nouvelle_etiquette
                item_trouve = True
                break

        if not item_trouve:
            raise HTTPException(status_code=404, detail="Item non trouv√©")

        with open(fichier, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] √âtiquette mise √† jour pour {username}/{vente_id}: {nouvelle_etiquette}")

        return {"success": True, "message": "√âtiquette mise √† jour"}

    except Exception as e:
        print(f"[ERREUR update_etiquette] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/monday/columns/{username}")
async def get_monday_columns(username: str):
    """
    R√©cup√®re toutes les colonnes du board Monday d'un entrepreneur
    Endpoint temporaire pour trouver les IDs de colonnes
    """
    try:
        # R√©cup√©rer les credentials Monday
        api_key, board_id = get_monday_credentials(username)

        if not api_key or not board_id:
            return {"error": "Pas de configuration Monday.com pour cet entrepreneur"}

        # Query pour r√©cup√©rer toutes les colonnes
        url = "https://api.monday.com/v2"
        headers = {
            "Authorization": api_key,
            "Content-Type": "application/json"
        }

        query = f"""
        query {{
          boards(ids: {board_id}) {{
            columns {{
              id
              title
              type
            }}
          }}
        }}
        """

        response = requests.post(url, headers=headers, json={"query": query})

        if response.status_code == 200:
            data = response.json()
            if "data" in data and data["data"]["boards"]:
                columns = data["data"]["boards"][0]["columns"]
                return {
                    "username": username,
                    "board_id": board_id,
                    "columns": columns
                }
            else:
                return {"error": "Aucune colonne trouv√©e"}
        else:
            return {"error": f"HTTP {response.status_code}", "details": response.text}

    except Exception as e:
        print(f"[MONDAY COLUMNS ERROR] {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


@app.post("/api/monday/force-sync/{username}/{vente_id}")
async def force_sync_monday(username: str, vente_id: str):
    """
    Endpoint temporaire pour forcer la synchronisation d'un client vers Monday
    """
    try:
        # Charger la vente depuis acceptees ou produit
        vente = None
        for category in ["acceptees", "produit"]:
            fichier = os.path.join(f"{base_cloud}/ventes_{category}", username, "ventes.json")
            if os.path.exists(fichier):
                with open(fichier, "r", encoding="utf-8") as f:
                    ventes = json.load(f)
                for v in ventes:
                    if v.get("id") == vente_id or v.get("num") == vente_id:
                        vente = v
                        break
            if vente:
                break

        if not vente:
            return {"error": "Vente non trouv√©e"}

        # Forcer la synchronisation
        success = sync_vente_to_monday(username, vente)

        if success:
            return {"success": True, "message": "Client synchronis√© avec Monday.com"}
        else:
            return {"success": False, "message": "Erreur lors de la synchronisation"}

    except Exception as e:
        print(f"[FORCE SYNC ERROR] {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


@app.post("/api/monday/webhook")
async def monday_webhook(request: Request):
    """
    Webhook pour recevoir les changements de Monday.com
    Synchronise les colonnes provenance et type vers Qwota
    """
    try:
        payload = await request.json()
        print(f"[MONDAY WEBHOOK] Received: {json.dumps(payload, indent=2)}")

        # Monday envoie un challenge lors de la configuration du webhook
        if "challenge" in payload:
            return {"challenge": payload["challenge"]}

        # Extraire les donn√©es du webhook
        event = payload.get("event", {})
        pulse_id = event.get("pulseId")  # ID de l'item Monday
        column_id = event.get("columnId")  # ID de la colonne modifi√©e
        value = event.get("value")  # Nouvelle valeur
        board_id = event.get("boardId")

        if not pulse_id or not column_id:
            print("[MONDAY WEBHOOK] Donn√©es manquantes")
            return {"status": "ignored"}

        # V√©rifier si c'est une colonne qui nous int√©resse (provenance ou type)
        if column_id not in ["dup__of_couleurs_mkm0awjt", "status_1"]:
            print(f"[MONDAY WEBHOOK] Colonne {column_id} ignor√©e")
            return {"status": "ignored"}

        # Trouver l'entrepreneur correspondant au board_id
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT username FROM users WHERE monday_board_id = ?
            """, (str(board_id),))
            result = cursor.fetchone()

            if not result:
                print(f"[MONDAY WEBHOOK] Aucun entrepreneur trouv√© pour board_id {board_id}")
                return {"status": "error", "message": "Entrepreneur non trouv√©"}

            username = result[0]

        # Parser la valeur Monday (format: {"index": X})
        try:
            value_data = json.loads(value) if isinstance(value, str) else value
            monday_index = value_data.get("index") if value_data else None
        except:
            monday_index = None

        # R√©cup√©rer les credentials Monday pour mapper l'index au nom
        api_key, board_id_local = get_monday_credentials(username)
        if not api_key or not board_id_local:
            print(f"[MONDAY WEBHOOK] Pas de config Monday pour {username}")
            return {"status": "error", "message": "Config Monday manquante"}

        # R√©cup√©rer le mapping Monday (nom -> index) et inverser pour (index -> nom)
        from QE.Backend.monday_sync import get_monday_column_labels
        label_map = get_monday_column_labels(api_key, board_id_local, column_id)

        # Inverser le mapping pour trouver le nom √† partir de l'index
        index_to_name = {idx: name for name, idx in label_map.items()}

        # Trouver le nom du label correspondant √† l'index Monday
        nouvelle_valeur = ""
        if monday_index is not None and monday_index in index_to_name:
            # Prendre le nom original (pas la version normalis√©e)
            for name, idx in label_map.items():
                if idx == monday_index and name[0].isupper():  # Prendre la version avec majuscules
                    nouvelle_valeur = name
                    break
            if not nouvelle_valeur:  # Fallback
                nouvelle_valeur = index_to_name[monday_index]

        print(f"[MONDAY WEBHOOK] Mise √† jour: colonne={column_id}, valeur={nouvelle_valeur}")

        # TODO: Trouver la vente correspondante dans Qwota et la mettre √† jour
        # Pour l'instant, on retourne un succ√®s
        print(f"[MONDAY WEBHOOK] Synchronisation Monday‚ÜíQwota r√©ussie")

        return {"status": "success", "username": username, "value": nouvelle_valeur}

    except Exception as e:
        print(f"[MONDAY WEBHOOK ERROR] {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": str(e)}


@app.get("/api/ventes/etiquettes/monday-status/{username}")
async def get_etiquettes_monday_status(username: str):
    """
    V√©rifie quelles √©tiquettes Qwota ont une correspondance dans Monday.com
    """
    try:
        from QE.Backend.monday_sync import get_monday_column_labels, get_monday_credentials

        # R√©cup√©rer les credentials Monday
        api_key, board_id = get_monday_credentials(username)

        if not api_key or not board_id:
            return {
                "has_monday": False,
                "provenances": {},
                "types_travaux": {}
            }

        # Charger les √©tiquettes de l'entrepreneur
        fichier_etiquettes = os.path.join(f"{base_cloud}/ventes_etiquettes", username, "etiquettes.json")

        etiquettes_defaut = {
            "provenances": [
                {"label": "P√ÄP", "color": "#ff8c42"},
                {"label": "Qualit√© √âtudiants", "color": "#e2445c"},
                {"label": "Facebook", "color": "#3b82f6"}
            ],
            "types_travaux": [
                {"label": "Balcons et Cl√¥tures", "color": "#6bcf7f"},
                {"label": "Rev√™tement", "color": "#ff8c42"},
                {"label": "Int√©rieur", "color": "#a25ddc"},
                {"label": "Fer forg√©", "color": "#64748b"}
            ]
        }

        if os.path.exists(fichier_etiquettes):
            with open(fichier_etiquettes, "r", encoding="utf-8") as f:
                etiquettes = json.load(f)
        else:
            etiquettes = etiquettes_defaut

        # R√©cup√©rer les labels Monday pour Provenance
        monday_provenances = get_monday_column_labels(api_key, board_id, "dup__of_couleurs_mkm0awjt")

        # R√©cup√©rer les labels Monday pour Type de travaux
        monday_types = get_monday_column_labels(api_key, board_id, "status_1")

        # V√©rifier les correspondances pour Provenances
        provenances_status = {}
        for prov in etiquettes.get("provenances", []):
            label = prov.get("label") if isinstance(prov, dict) else prov
            if label:
                # V√©rifier correspondance exacte
                has_match = (
                    label in monday_provenances or
                    label.lower() in monday_provenances
                )
                provenances_status[label] = has_match

        # V√©rifier les correspondances pour Types de travaux
        types_status = {}
        for type_item in etiquettes.get("types_travaux", []):
            label = type_item.get("label") if isinstance(type_item, dict) else type_item
            if label:
                # V√©rifier correspondance exacte
                has_match = (
                    label in monday_types or
                    label.lower() in monday_types
                )
                types_status[label] = has_match

        return {
            "has_monday": True,
            "provenances": provenances_status,
            "types_travaux": types_status
        }

    except Exception as e:
        print(f"[ERROR get_etiquettes_monday_status] {e}")
        import traceback
        traceback.print_exc()
        return {
            "has_monday": False,
            "provenances": {},
            "types_travaux": {}
        }


@app.get("/api/ventes/etiquettes/{username}")
def get_etiquettes_entrepreneur(username: str):
    """
    R√©cup√®re les √©tiquettes personnalis√©es d'un entrepreneur
    """
    try:
        fichier_etiquettes = os.path.join(f"{base_cloud}/ventes_etiquettes", username, "etiquettes.json")

        # √âtiquettes par d√©faut
        etiquettes_defaut = {
            "statuts": [],
            "provenances": [
                {"label": "P√ÄP", "color": "#ff8c42"},
                {"label": "Qualit√© √âtudiants", "color": "#e2445c"},
                {"label": "Facebook", "color": "#3b82f6"}
            ],
            "types_travaux": [
                {"label": "Balcons et Cl√¥tures", "color": "#6bcf7f"},
                {"label": "Rev√™tement", "color": "#ff8c42"},
                {"label": "Int√©rieur", "color": "#a25ddc"},
                {"label": "Fer forg√©", "color": "#64748b"}
            ],
            "paiements": [
                {"label": "En attente", "color": "#e2445c"},
                {"label": "D√©p√¥t re√ßu", "color": "#fdab3d"},
                {"label": "Paiement final re√ßu", "color": "#00c875"}
            ],
            "etiquettes": [
                {"label": "√Ä confirmer", "color": "#ef4444"},
                {"label": "Confirm√©", "color": "#22c55e"},
                {"label": "√Ä rappeler", "color": "#f59e0b"}
            ]
        }

        if not os.path.exists(fichier_etiquettes):
            # Cr√©er le fichier avec des listes vides
            os.makedirs(os.path.dirname(fichier_etiquettes), exist_ok=True)
            with open(fichier_etiquettes, "w", encoding="utf-8") as f:
                json.dump(etiquettes_defaut, f, ensure_ascii=False, indent=2)
            return etiquettes_defaut

        with open(fichier_etiquettes, "r", encoding="utf-8") as f:
            etiquettes = json.load(f)

        # Fusionner avec les valeurs par d√©faut pour s'assurer que tous les champs existent
        for key in etiquettes_defaut:
            if key not in etiquettes:
                etiquettes[key] = etiquettes_defaut[key]

        return etiquettes

    except Exception as e:
        print(f"[ERREUR get_etiquettes_entrepreneur] {e}")
        # Retourner les √©tiquettes par d√©faut en cas d'erreur
        return {
            "statuts": [],
            "provenances": [
                {"label": "P√ÄP", "color": "#ff8c42"},
                {"label": "Qualit√© √âtudiants", "color": "#e2445c"},
                {"label": "Facebook", "color": "#3b82f6"}
            ],
            "types_travaux": [
                {"label": "Balcons et Cl√¥tures", "color": "#6bcf7f"},
                {"label": "Rev√™tement", "color": "#ff8c42"},
                {"label": "Int√©rieur", "color": "#a25ddc"},
                {"label": "Fer forg√©", "color": "#64748b"}
            ],
            "paiements": [
                {"label": "En attente", "color": "#e2445c"},
                {"label": "D√©p√¥t re√ßu", "color": "#fdab3d"},
                {"label": "Paiement final re√ßu", "color": "#00c875"}
            ]
        }


@app.post("/api/ventes/etiquettes")
async def save_etiquettes_entrepreneur(data: dict = Body(...)):
    """
    Sauvegarde les √©tiquettes personnalis√©es d'un entrepreneur
    """
    try:
        username = data.get("username")
        statuts = data.get("statuts", [])
        provenances = data.get("provenances", [])
        types_travaux = data.get("types_travaux", [])
        paiements = data.get("paiements", [])
        etiquettes_status = data.get("etiquettes", [])

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        fichier_etiquettes = os.path.join(f"{base_cloud}/ventes_etiquettes", username, "etiquettes.json")
        os.makedirs(os.path.dirname(fichier_etiquettes), exist_ok=True)

        etiquettes = {
            "statuts": statuts,
            "provenances": provenances,
            "types_travaux": types_travaux,
            "paiements": paiements,
            "etiquettes": etiquettes_status
        }

        with open(fichier_etiquettes, "w", encoding="utf-8") as f:
            json.dump(etiquettes, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] √âtiquettes sauvegard√©es pour {username}")
        return {"success": True, "message": "√âtiquettes sauvegard√©es"}

    except Exception as e:
        print(f"[ERREUR save_etiquettes_entrepreneur] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/ventes/marquer-perdu")
async def marquer_vente_perdue(data: dict = Body(...)):
    """
    D√©place une vente de ventes_attente vers clients_perdus
    """
    try:
        username = data.get("username")
        vente_id = data.get("vente_id")

        if not username or not vente_id:
            raise HTTPException(status_code=400, detail="Username et vente_id requis")

        # Fichiers source et destination
        fichier_attente = os.path.join(f"{base_cloud}/ventes_attente", username, "ventes.json")
        fichier_perdus = os.path.join(f"{base_cloud}/clients_perdus", username, "clients.json")

        if not os.path.exists(fichier_attente):
            raise HTTPException(status_code=404, detail="Fichier ventes_attente non trouv√©")

        # Charger les ventes en attente
        with open(fichier_attente, "r", encoding="utf-8") as f:
            ventes_attente = json.load(f)

        # Trouver la vente √† d√©placer
        vente_a_deplacer = None
        nouvelles_ventes_attente = []
        for vente in ventes_attente:
            if vente.get("id") == vente_id or vente.get("num") == vente_id:
                vente_a_deplacer = vente
            else:
                nouvelles_ventes_attente.append(vente)

        if not vente_a_deplacer:
            raise HTTPException(status_code=404, detail="Vente non trouv√©e dans ventes_attente")

        # Sauvegarder les ventes en attente mises √† jour
        with open(fichier_attente, "w", encoding="utf-8") as f:
            json.dump(nouvelles_ventes_attente, f, ensure_ascii=False, indent=2)

        # Charger ou cr√©er le fichier clients perdus
        clients_perdus_dir = os.path.dirname(fichier_perdus)
        os.makedirs(clients_perdus_dir, exist_ok=True)

        if os.path.exists(fichier_perdus):
            with open(fichier_perdus, "r", encoding="utf-8") as f:
                content = f.read().strip()
                clients_perdus = json.loads(content) if content else []
        else:
            clients_perdus = []

        # Ajouter la vente aux clients perdus
        clients_perdus.append(vente_a_deplacer)

        # Sauvegarder les clients perdus
        with open(fichier_perdus, "w", encoding="utf-8") as f:
            json.dump(clients_perdus, f, ensure_ascii=False, indent=2)

        print(f"[VENTES] ‚úÖ Vente {vente_id} d√©plac√©e vers clients perdus pour {username}")
        return {"success": True, "message": "Vente marqu√©e comme perdue"}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERREUR marquer_vente_perdue] {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/clients-perdus/{username}")
def get_clients_perdus(username: str):
    """
    R√©cup√®re les clients perdus d'un utilisateur
    """
    try:
        clients_perdus_dir = os.path.join(f"{base_cloud}/clients_perdus", username)
        fichier_perdus = os.path.join(clients_perdus_dir, "clients.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(fichier_perdus):
            os.makedirs(clients_perdus_dir, exist_ok=True)
            with open(fichier_perdus, "w", encoding="utf-8") as f:
                json.dump([], f)
            return []

        with open(fichier_perdus, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            return json.loads(content)
    except Exception as e:
        print(f"[ERREUR clients_perdus] {e}")
        return []


@app.post("/clients-perdus/supprimer")
async def supprimer_client_perdu(data: dict = Body(...)):
    """
    Supprime d√©finitivement un client perdu de TOUS les fichiers du syst√®me:
    - clients_perdus
    - soumissions_completes
    - soumissions_signees
    - ventes_acceptees
    - ventes_produit
    - travaux_a_completer
    - facturation_qe_historique
    - facturation_qe_statuts
    Puis sync le RPO
    """
    try:
        username = data.get("username")
        client_id = data.get("client_id")  # Peut √™tre UUID ou num

        if not username or not client_id:
            raise HTTPException(status_code=400, detail="Username et client_id requis")

        client_id_str = str(client_id)
        supprime_de = []

        # D'abord, r√©cup√©rer le client perdu pour obtenir TOUTES ses identifiants (id ET num)
        fichier_perdus = os.path.join(f"{base_cloud}/clients_perdus", username, "clients.json")
        identifiants_a_matcher = {client_id_str}  # Set pour √©viter les doublons

        if os.path.exists(fichier_perdus):
            try:
                with open(fichier_perdus, "r", encoding="utf-8") as f:
                    clients_perdus = json.load(f)

                # Trouver le client perdu et r√©cup√©rer tous ses identifiants
                for client in clients_perdus:
                    if str(client.get('id', '')) == client_id_str or str(client.get('num', '')) == client_id_str:
                        # Ajouter tous les identifiants possibles
                        if client.get('id'):
                            identifiants_a_matcher.add(str(client.get('id')))
                        if client.get('num'):
                            identifiants_a_matcher.add(str(client.get('num')))
                        print(f"[DELETE] Client trouv√© - ID: {client.get('id')}, Num: {client.get('num')}")
                        break
            except Exception as e:
                print(f"[WARN] Erreur lecture clients_perdus: {e}")

        print(f"[DELETE] Identifiants √† matcher: {identifiants_a_matcher}")

        # Helper pour supprimer d'un fichier JSON (liste) - utilise TOUS les identifiants
        def supprimer_de_fichier_liste(fichier_path, match_keys=['id', 'num']):
            if not os.path.exists(fichier_path):
                return False
            try:
                with open(fichier_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    data_list = json.loads(content) if content else []

                original_len = len(data_list)
                # Filtrer pour retirer les entr√©es qui matchent N'IMPORTE QUEL identifiant
                data_list = [item for item in data_list
                            if not any(str(item.get(key, '')) in identifiants_a_matcher for key in match_keys)]

                if len(data_list) < original_len:
                    with open(fichier_path, "w", encoding="utf-8") as f:
                        json.dump(data_list, f, indent=2, ensure_ascii=False)
                    print(f"[DELETE] Supprim√© de {fichier_path}: {original_len - len(data_list)} entr√©e(s)")
                    return True
                return False
            except Exception as e:
                print(f"[WARN] Erreur suppression de {fichier_path}: {e}")
                return False

        # 1. clients_perdus
        if supprimer_de_fichier_liste(fichier_perdus):
            supprime_de.append("clients_perdus")

        # 2. soumissions_completes
        fichier_completes = os.path.join(f"{base_cloud}/soumissions_completes", username, "soumissions.json")
        if supprimer_de_fichier_liste(fichier_completes):
            supprime_de.append("soumissions_completes")

        # 3. soumissions_signees
        fichier_signees = os.path.join(f"{base_cloud}/soumissions_signees", username, "soumissions.json")
        if supprimer_de_fichier_liste(fichier_signees):
            supprime_de.append("soumissions_signees")

        # 4. ventes_acceptees
        fichier_ventes_acc = os.path.join(f"{base_cloud}/ventes_acceptees", username, "ventes.json")
        if supprimer_de_fichier_liste(fichier_ventes_acc):
            supprime_de.append("ventes_acceptees")

        # 5. ventes_produit
        fichier_ventes_prod = os.path.join(f"{base_cloud}/ventes_produit", username, "ventes.json")
        if supprimer_de_fichier_liste(fichier_ventes_prod):
            supprime_de.append("ventes_produit")

        # 6. travaux_a_completer
        fichier_travaux = os.path.join(f"{base_cloud}/travaux_a_completer", username, "soumissions.json")
        if supprimer_de_fichier_liste(fichier_travaux):
            supprime_de.append("travaux_a_completer")

        # 6b. ventes_attente
        fichier_ventes_attente = os.path.join(f"{base_cloud}/ventes_attente", username, "ventes.json")
        if supprimer_de_fichier_liste(fichier_ventes_attente):
            supprime_de.append("ventes_attente")

        # 7. facturation_qe_historique (global, pas par user)
        fichier_historique = os.path.join(f"{base_cloud}/facturation_qe_historique", "historique.json")
        if os.path.exists(fichier_historique):
            try:
                with open(fichier_historique, "r", encoding="utf-8") as f:
                    historique = json.load(f)
                original_len = len(historique)
                # Utiliser tous les identifiants pour matcher
                historique = [h for h in historique
                             if not (h.get('numeroSoumission') in identifiants_a_matcher and h.get('entrepreneurUsername') == username)]
                if len(historique) < original_len:
                    with open(fichier_historique, "w", encoding="utf-8") as f:
                        json.dump(historique, f, indent=2, ensure_ascii=False)
                    supprime_de.append("facturation_qe_historique")
                    print(f"[DELETE] Supprim√© de facturation_qe_historique: {original_len - len(historique)} entr√©e(s)")
            except Exception as e:
                print(f"[WARN] Erreur suppression de historique: {e}")

        # 8. facturation_qe_statuts (supprimer l'entr√©e pour ce num_soumission)
        fichier_statuts = os.path.join(f"{base_cloud}/facturation_qe_statuts", username, "statuts_clients.json")
        if os.path.exists(fichier_statuts):
            try:
                with open(fichier_statuts, "r", encoding="utf-8") as f:
                    statuts = json.load(f)
                # Supprimer toutes les entr√©es qui matchent n'importe quel identifiant
                keys_to_delete = [key for key in statuts.keys() if key in identifiants_a_matcher]
                if keys_to_delete:
                    for key in keys_to_delete:
                        del statuts[key]
                    with open(fichier_statuts, "w", encoding="utf-8") as f:
                        json.dump(statuts, f, indent=2, ensure_ascii=False)
                    supprime_de.append("facturation_qe_statuts")
                    print(f"[DELETE] Supprim√© de facturation_qe_statuts: {len(keys_to_delete)} entr√©e(s)")
            except Exception as e:
                print(f"[WARN] Erreur suppression de statuts: {e}")

        # 9. Sync RPO pour mettre √† jour les compteurs
        try:
            from QE.Backend.rpo import sync_soumissions_to_rpo, sync_ventes_produit_to_rpo
            sync_soumissions_to_rpo(username)
            sync_ventes_produit_to_rpo(username)
            print(f"[OK] RPO synchronis√© (soumissions + produits) pour {username}")
        except Exception as e:
            print(f"[WARN] Erreur sync RPO: {e}")

        print(f"[OK] Client perdu {identifiants_a_matcher} supprim√© de: {', '.join(supprime_de) if supprime_de else 'aucun fichier'} pour {username}")
        return JSONResponse({
            "success": True,
            "message": f"Client supprim√© de {len(supprime_de)} source(s)",
            "supprime_de": supprime_de
        })

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur lors de la suppression du client perdu: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/prospects/{username}")
def get_prospects(username: str):
    """
    R√©cup√®re les prospects d'un utilisateur
    """
    try:
        prospects_dir = os.path.join(f"{base_cloud}/prospects", username)
        fichier_prospects = os.path.join(prospects_dir, "prospects.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(fichier_prospects):
            os.makedirs(prospects_dir, exist_ok=True)
            with open(fichier_prospects, "w", encoding="utf-8") as f:
                json.dump([], f)
            return []

        with open(fichier_prospects, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            return json.loads(content)
    except Exception as e:
        print(f"[ERREUR prospects] {e}")
        return []


@app.get("/ventes/produit/{username}")
def get_ventes_produit(username: str):
    """
    R√©cup√®re les ventes avec production termin√©e (ventes_produit/)
    """
    try:
        ventes_dir = os.path.join(f"{base_cloud}/ventes_produit", username)
        fichier_produit = os.path.join(ventes_dir, "ventes.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(fichier_produit):
            os.makedirs(ventes_dir, exist_ok=True)
            with open(fichier_produit, "w", encoding="utf-8") as f:
                json.dump([], f)
            return []

        with open(fichier_produit, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            ventes = json.loads(content)

            # Initialiser les champs d'√©tiquettes s'ils n'existent pas
            for vente in ventes:
                if "statut_vente" not in vente:
                    vente["statut_vente"] = ""
                if "provenance" not in vente:
                    vente["provenance"] = ""
                if "type_travaux" not in vente:
                    vente["type_travaux"] = ""
                if "notes" not in vente:
                    vente["notes"] = ""

            return ventes
    except Exception as e:
        print(f"[ERREUR ventes_produit] {e}")
        return []

@app.get("/api/ventes_produit/{username}")
def api_get_ventes_produit(username: str):
    """
    R√©cup√®re les ventes avec production termin√©e (ventes_produit/) - endpoint API
    """
    return get_ventes_produit(username)


# ========================================
# ENDPOINTS REMBOURSEMENTS
# ========================================

@app.get("/api/remboursements/{username}")
async def get_remboursements(username: str):
    """
    R√©cup√®re la liste de tous les remboursements pour un utilisateur
    """
    try:
        print(f"[BAN] R√©cup√©ration des remboursements pour {username}")

        remb_dir = f"{base_cloud}/remboursements/{username}"
        remb_file = os.path.join(remb_dir, "remboursements.json")

        # Cr√©er le dossier et le fichier s'ils n'existent pas
        if not os.path.exists(remb_file):
            os.makedirs(remb_dir, exist_ok=True)
            with open(remb_file, "w", encoding="utf-8") as f:
                json.dump([], f)
            print(f"[BAN] Dossier remboursements cr√©√© pour {username}")
            return []

        # Charger et retourner les remboursements
        with open(remb_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []
            remboursements = json.loads(content)

        print(f"[OK] {len(remboursements)} remboursements trouv√©s pour {username}")
        return remboursements

    except Exception as e:
        print(f"[ERROR] ERREUR get_remboursements: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration remboursements: {e}")


@app.post("/api/remboursements/{username}")
async def add_remboursement(username: str, remboursement: dict = Body(...)):
    """
    Ajoute un nouveau remboursement
    """
    try:
        print(f"[MONEY] Ajout d'un remboursement pour {username}")

        remb_dir = f"{base_cloud}/remboursements/{username}"
        remb_file = os.path.join(remb_dir, "remboursements.json")

        # Cr√©er le dossier s'il n'existe pas
        os.makedirs(remb_dir, exist_ok=True)

        # Charger les remboursements existants
        remboursements = []
        if os.path.exists(remb_file):
            with open(remb_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    remboursements = json.loads(content)

        # Ajouter le nouveau remboursement
        remboursements.append(remboursement)

        # Sauvegarder
        with open(remb_file, "w", encoding="utf-8") as f:
            json.dump(remboursements, f, indent=2, ensure_ascii=False)

        print(f"[OK] Remboursement ajout√© pour {username}")
        return {"status": "success", "message": "Remboursement ajout√©"}

    except Exception as e:
        print(f"[ERROR] ERREUR add_remboursement: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur ajout remboursement: {e}")


@app.delete("/api/remboursements/{username}/{num_soumission}")
async def delete_remboursement(username: str, num_soumission: str):
    """
    Supprime un remboursement par num√©ro de soumission
    """
    try:
        print(f"[DELETE] Suppression du remboursement {num_soumission} pour {username}")

        remb_file = f"{base_cloud}/remboursements/{username}/remboursements.json"

        if not os.path.exists(remb_file):
            raise HTTPException(status_code=404, detail="Aucun remboursement trouv√©")

        # Charger les remboursements
        with open(remb_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                raise HTTPException(status_code=404, detail="Aucun remboursement trouv√©")
            remboursements = json.loads(content)

        # Filtrer pour supprimer le remboursement
        remboursements_filtres = [r for r in remboursements if r.get('num') != num_soumission]

        if len(remboursements_filtres) == len(remboursements):
            raise HTTPException(status_code=404, detail="Remboursement non trouv√©")

        # Sauvegarder
        with open(remb_file, "w", encoding="utf-8") as f:
            json.dump(remboursements_filtres, f, indent=2, ensure_ascii=False)

        print(f"[OK] Remboursement {num_soumission} supprim√© pour {username}")
        return {"status": "success", "message": "Remboursement supprim√©"}

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ERREUR delete_remboursement: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur suppression remboursement: {e}")


@app.put("/api/remboursements/{username}/update")
async def update_remboursements(username: str, remboursements: list = Body(...)):
    """
    Met √† jour tous les remboursements pour un utilisateur (utilis√© pour la validation coach)
    """
    try:
        print(f"[UPDATE] Mise √† jour des remboursements pour {username}")

        remb_dir = f"{base_cloud}/remboursements/{username}"
        remb_file = os.path.join(remb_dir, "remboursements.json")

        # Cr√©er le dossier s'il n'existe pas
        os.makedirs(remb_dir, exist_ok=True)

        # Sauvegarder les remboursements mis √† jour
        with open(remb_file, "w", encoding="utf-8") as f:
            json.dump(remboursements, f, indent=2, ensure_ascii=False)

        print(f"[OK] Remboursements mis √† jour pour {username}")
        return {"status": "success", "message": "Remboursements mis √† jour"}

    except Exception as e:
        print(f"[ERROR] ERREUR update_remboursements: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur mise √† jour remboursements: {e}")


# ============================================================================
# ROUTES GAMIFICATION
# ============================================================================

@app.get("/api/gamification/profile/{username}")
def get_gamification_profile(username: str):
    """R√©cup√®re le profil de gamification d'un utilisateur"""
    try:
        profile = gamification.get_user_progress(username)
        return {"status": "success", "profile": profile}
    except Exception as e:
        print(f"[ERROR] Erreur get_gamification_profile: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/gamification/award-xp")
def award_xp_endpoint(data: dict = Body(...)):
    """
    Attribue des XP √† un utilisateur
    Body: {username, xp_amount, action_type, action_description}
    """
    try:
        username = data.get("username")
        xp_amount = data.get("xp_amount", 0)
        action_type = data.get("action_type", "")
        action_description = data.get("action_description", "")

        if not username:
            raise HTTPException(status_code=400, detail="Username requis")

        result = gamification.award_xp(username, xp_amount, action_type, action_description)
        return {"status": "success", "result": result}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur award_xp: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/history/{username}")
def get_xp_history_endpoint(username: str, limit: int = 50):
    """R√©cup√®re l'historique des XP d'un utilisateur"""
    try:
        history = gamification.get_xp_history(username, limit)
        return {"status": "success", "history": history}
    except Exception as e:
        print(f"[ERROR] Erreur get_xp_history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/gamification/check-quest-rewards/{username}")
def check_quest_rewards_endpoint(username: str):
    """V√©rifie et r√©compense les side quests compl√©t√©es"""
    try:
        newly_rewarded = gamification.check_and_reward_completed_quests(username)
        return {
            "status": "success",
            "newly_rewarded": newly_rewarded,
            "message": f"{newly_rewarded} nouvelle(s) quest(s) r√©compens√©e(s)"
        }
    except Exception as e:
        print(f"[ERROR] Erreur check_quest_rewards: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/leaderboard")
def get_leaderboard_endpoint(limit: int = 100):
    """R√©cup√®re le classement des utilisateurs"""
    try:
        leaderboard = gamification.get_leaderboard(limit)
        return {"status": "success", "leaderboard": leaderboard}
    except Exception as e:
        print(f"[ERROR] Erreur get_leaderboard: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/levels")
def get_all_levels():
    """Retourne la configuration de tous les niveaux"""
    try:
        return {"status": "success", "levels": gamification.LEVELS_CONFIG}
    except Exception as e:
        print(f"[ERROR] Erreur get_all_levels: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/level/{level}")
def get_level_info_endpoint(level: int):
    """Retourne les informations d'un niveau sp√©cifique"""
    try:
        level_info = gamification.get_level_info(level)
        if not level_info:
            raise HTTPException(status_code=404, detail="Niveau non trouv√©")
        return {"status": "success", "level_info": level_info}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur get_level_info: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/xp-rewards")
def get_xp_rewards():
    """Retourne la configuration des r√©compenses XP pour chaque action"""
    try:
        return {"status": "success", "xp_rewards": gamification.XP_REWARDS}
    except Exception as e:
        print(f"[ERROR] Erreur get_xp_rewards: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ROUTES BADGES
# ============================================================================

@app.post("/api/gamification/badges/unlock")
def unlock_badge_endpoint(data: dict = Body(...)):
    """
    D√©bloque un badge pour un utilisateur (endpoint admin)
    Body: {username, badge_id, reason}
    """
    try:
        username = data.get("username")
        badge_id = data.get("badge_id")
        reason = data.get("reason", "")

        if not username or not badge_id:
            raise HTTPException(status_code=400, detail="Username et badge_id requis")

        result = gamification.unlock_badge(username, badge_id, reason)

        if not result.get("success"):
            if result.get("already_unlocked"):
                raise HTTPException(status_code=400, detail="Badge d√©j√† d√©bloqu√©")
            raise HTTPException(status_code=404, detail=result.get("error", "Erreur inconnue"))

        return {"status": "success", "result": result}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur unlock_badge: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/gamification/badges/remove")
def remove_badge_endpoint(data: dict = Body(...)):
    """
    Retire un badge d'un utilisateur (endpoint admin)
    Body: {username, badge_id}
    """
    try:
        username = data.get("username")
        badge_id = data.get("badge_id")

        if not username or not badge_id:
            raise HTTPException(status_code=400, detail="Username et badge_id requis")

        result = gamification.remove_badge(username, badge_id)

        if not result.get("success"):
            raise HTTPException(status_code=404, detail=result.get("error", "Erreur inconnue"))

        return {"status": "success", "result": result}
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] Erreur remove_badge: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/gamification/recalculate-xp")
def recalculate_xp_endpoint():
    """
    Recalcule l'XP de tous les utilisateurs bas√© sur leurs badges actifs uniquement
    Endpoint admin pour migration/correction des donn√©es
    """
    try:
        result = gamification.recalculate_all_user_xp()
        return {"status": "success", "result": result}
    except Exception as e:
        print(f"[ERROR] Erreur recalculate_xp: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/coaches/list")
def get_coaches_list():
    """Retourne la liste de tous les coaches actifs"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute("""
                SELECT username, prenom, nom, email, photo_url
                FROM users
                WHERE role = 'coach' AND is_active = 1
                ORDER BY prenom, nom
            """)
            coaches = [dict(row) for row in cursor.fetchall()]
            return coaches
    except Exception as e:
        print(f"[ERROR] Erreur get_coaches_list: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/user-info/{username}")
def get_user_info_endpoint(username: str):
    """R√©cup√®re les informations utilisateur depuis user_info.json"""
    try:
        import json
        # Utiliser base_cloud pour compatibilit√© Render
        user_info_path = os.path.join(base_cloud, "signatures", username, "user_info.json")

        print(f"[DEBUG] [GET-INFO] Chemin user_info: {user_info_path}")
        print(f"[DEBUG] [GET-INFO] Fichier existe: {os.path.exists(user_info_path)}")

        if not os.path.exists(user_info_path):
            raise HTTPException(status_code=404, detail=f"User info not found for {username}")

        with open(user_info_path, 'r', encoding='utf-8') as f:
            user_info = json.load(f)

        print(f"[DEBUG] [GET-INFO] Donn√©es lues pour {username}: {user_info}")
        return user_info
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"User info not found for {username}")
    except Exception as e:
        print(f"[ERROR] Erreur get_user_info: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/badges/user/{username}")
def get_user_badges_endpoint(username: str):
    """R√©cup√®re tous les badges d'un utilisateur"""
    try:
        badges = gamification.get_user_badges(username)
        return {"status": "success", "badges": badges, "total": len(badges)}
    except Exception as e:
        print(f"[ERROR] Erreur get_user_badges: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/badges/all")
def get_all_badges_endpoint(badge_type: Optional[str] = None):
    """
    Retourne tous les badges disponibles
    Param√®tre optionnel: badge_type (fleur, etoile, trophee, badge)
    """
    try:
        badges = gamification.get_all_badges(badge_type)
        return {"status": "success", **badges}
    except Exception as e:
        print(f"[ERROR] Erreur get_all_badges: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/badges/stats/{username}")
def get_badge_stats_endpoint(username: str):
    """R√©cup√®re les statistiques de badges d'un utilisateur"""
    try:
        stats = gamification.get_badge_stats(username)
        return {"status": "success", "stats": stats}
    except Exception as e:
        print(f"[ERROR] Erreur get_badge_stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/badges/check/{username}/{badge_id}")
def check_badge_endpoint(username: str, badge_id: str):
    """V√©rifie si un utilisateur poss√®de un badge sp√©cifique"""
    try:
        has_it = gamification.has_badge(username, badge_id)
        return {"status": "success", "has_badge": has_it, "badge_id": badge_id}
    except Exception as e:
        print(f"[ERROR] Erreur check_badge: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/gamification/badges/check-automatic/{username}")
def check_automatic_badges_endpoint(username: str):
    """
    V√©rifie et attribue automatiquement les badges bas√©s sur les donn√©es RPO

    Badges automatiques:
    - Ventes totales: Le Cap des Six Chiffres (100k$), L'Ascension (125k$), Le Palier des Titans (300k$), etc.
    - Ventes hebdomadaires: Sprint de Vente (10k$/sem), Semaine de Feu (20k$/sem), etc.
    - Production hebdomadaire: Op√©ration 10K, Roue de production, Machine de Guerre, Ma√Ætre peintre
    """
    try:
        result = gamification.check_and_award_automatic_badges(username)
        return {
            "status": "success",
            "username": username,
            "awarded_badges": result.get('awarded_badges', []),
            "total_xp": result.get('total_xp', 0),
            "message": f"{len(result.get('awarded_badges', []))} badges attribu√©s"
        }
    except Exception as e:
        print(f"[ERROR] Erreur check_automatic_badges: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/gamification/quest-streak/{username}")
def get_quest_streak(username: str):
    """R√©cup√®re le streak de side quests d'un utilisateur"""
    try:
        # Pour l'instant, retourner un streak par d√©faut de 0
        # TODO: Impl√©menter la logique de tracking des side quests compl√©t√©es
        streak = gamification.get_quest_streak(username)
        return {
            "status": "success",
            "username": username,
            "streak": streak
        }
    except Exception as e:
        print(f"[ERROR] Erreur get_quest_streak: {e}")
        # Retourner 0 par d√©faut en cas d'erreur
        return {
            "status": "success",
            "username": username,
            "streak": 0
        }


@app.get("/api/gamification/quest-progress/{username}")
def get_quest_progress(username: str, quest_date: str):
    """
    R√©cup√®re la progression d'une side quest bas√©e sur les donn√©es RPO

    Args:
        username: Nom d'utilisateur
        quest_date: Date de deadline de la quest (format: YYYY-MM-DD)

    Returns:
        Donn√©es de progression pour la semaine de la quest
    """
    try:
        from QE.Backend.rpo import load_user_rpo_data, get_week_number_from_date
        from datetime import datetime, timedelta

        print(f"[DEBUG] Quest progress pour {username}, date: {quest_date}", flush=True)

        # Charger les donn√©es RPO
        rpo_data = load_user_rpo_data(username)

        # D√©terminer la semaine de la quest (bas√©e sur la deadline)
        # La deadline est un dimanche, donc on calcule le lundi de cette semaine
        deadline = datetime.strptime(quest_date, "%Y-%m-%d")

        # Trouver le lundi de cette semaine (deadline - 6 jours)
        monday = deadline - timedelta(days=6)
        monday_str = monday.strftime("%Y-%m-%d")

        print(f"[DEBUG] Deadline: {quest_date}, Lundi de la semaine: {monday_str}", flush=True)

        # Mapper la date au mois et semaine RPO
        month_idx, week_num = get_week_number_from_date(monday_str)
        month_key = str(month_idx)
        week_key = str(week_num)

        print(f"[DEBUG] Mois RPO: {month_key}, Semaine RPO: {week_key}", flush=True)

        # R√©cup√©rer les donn√©es de cette semaine
        week_data = rpo_data.get('weekly', {}).get(month_key, {}).get(week_key, {})

        print(f"[DEBUG] Donn√©es semaine trouv√©es: {week_data}", flush=True)

        # Extraire les m√©triques
        h_marketing = week_data.get('h_marketing', '-')
        estimation = week_data.get('estimation', 0)
        contract = week_data.get('contract', 0)
        dollar = week_data.get('dollar', 0)
        depot = week_data.get('depot', 0)
        peintre = week_data.get('peintre', 0)
        ca_cumul = week_data.get('ca_cumul', 0)
        produit = week_data.get('produit', 0)
        prod_horaire = week_data.get('prod_horaire', 0)
        satisfaction = week_data.get('satisfaction', 0)

        # Convertir h_marketing en nombre (g√©rer le cas '-')
        h_marketing_num = 0
        if h_marketing != '-' and h_marketing != '' and h_marketing is not None:
            try:
                h_marketing_num = float(h_marketing)
            except (ValueError, TypeError):
                h_marketing_num = 0

        # Calculer le taux marketing (estimations par heure de cette semaine)
        taux_marketing = 0
        if h_marketing_num > 0:
            taux_marketing = round(estimation / h_marketing_num, 2)

        # Calculer le streak
        streak = calculate_user_streak(username)

        return {
            "status": "success",
            "username": username,
            "quest_date": quest_date,
            "week_info": {
                "month_index": month_idx,
                "week_number": week_num,
                "monday": monday_str
            },
            "progress": {
                "h_marketing": h_marketing_num,
                "estimation": estimation,
                "contract": contract,
                "dollar": dollar,
                "depot": depot,
                "peintre": peintre,
                "ca_cumul": ca_cumul,
                "produit": produit,
                "prod_horaire": prod_horaire,
                "satisfaction": satisfaction,
                "taux_marketing": taux_marketing
            },
            "streak": streak
        }

    except Exception as e:
        print(f"[ERROR] Erreur get_quest_progress: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "message": str(e),
            "progress": {
                "h_marketing": 0,
                "estimation": 0,
                "contract": 0,
                "dollar": 0,
                "depot": 0,
                "peintre": 0,
                "ca_cumul": 0,
                "produit": 0,
                "prod_horaire": 0,
                "satisfaction": 0,
                "taux_marketing": 0
            }
        }


def calculate_user_streak(username: str):
    """
    Calcule le streak actuel de side quests compl√©t√©es cons√©cutivement.
    Le streak se reset √† 0 quand une quest dont la deadline est pass√©e n'est pas compl√©t√©e.

    Returns:
        int: Nombre de quests cons√©cutives compl√©t√©es
    """
    from datetime import datetime

    # Liste des quests (m√™me structure que check_all_sidequests.py)
    WEEKLY_QUESTS = [
        {"title": "Faire 12h de PAP durant la semaine Internationale", "deadline": "2026-01-12", "target": 12, "unit": "heures"},
        {"title": "Faire 12h de PAP durant la semaine", "deadline": "2026-01-19", "target": 12, "unit": "heures"},
        {"title": "Faire 12h de PAP durant la semaine", "deadline": "2026-01-26", "target": 12, "unit": "heures"},
        {"title": "Faire 3 estimations ou plus cette semaine", "deadline": "2026-02-02", "target": 3, "unit": "estimations"},
        {"title": "Avoir un taux marketing de 0,75 estimations par heure", "deadline": "2026-02-09", "target": 0.75, "unit": "taux"},
        {"title": "Faire 5 estimations cette semaine", "deadline": "2026-02-16", "target": 5, "unit": "estimations"},
        {"title": "Faire 5 estimations cette semaine", "deadline": "2026-02-23", "target": 5, "unit": "estimations"},
        {"title": "Faire 7 estimations cette semaine", "deadline": "2026-03-02", "target": 7, "unit": "estimations"},
        {"title": "Signer 5000$", "deadline": "2026-03-09", "target": 5000, "unit": "$"},
        {"title": "Collecter plus de 1500$ en d√©p√¥t", "deadline": "2026-03-16", "target": 1500, "unit": "depot"},
        {"title": "Signer 7500$", "deadline": "2026-03-23", "target": 7500, "unit": "$"},
        {"title": "Signer un contrat de plus de 4000$ avant taxes", "deadline": "2026-03-30", "target": 4000, "unit": "$"},
        {"title": "Profiter de la folie de P√¢ques pour signer 15000$ cette semaine", "deadline": "2026-04-06", "target": 15000, "unit": "$"},
        {"title": "Embaucher un premier peintre", "deadline": "2026-04-13", "target": 1, "unit": "peintre"},
        {"title": "Signer 10000$", "deadline": "2026-04-20", "target": 10000, "unit": "$"},
        {"title": "Signer 12000$", "deadline": "2026-04-27", "target": 12000, "unit": "$"},
        {"title": "Signer 12000$", "deadline": "2026-05-04", "target": 12000, "unit": "$"},
        {"title": "Signer 12000$", "deadline": "2026-05-11", "target": 12000, "unit": "$"},
        {"title": "Signer 12000$", "deadline": "2026-05-18", "target": 12000, "unit": "$"},
        {"title": "15 estimations cette semaine", "deadline": "2026-05-25", "target": 15, "unit": "estimations"},
        {"title": "Atteindre 100000$ de ventes cumulatif depuis le d√©but de l'ann√©e", "deadline": "2026-06-01", "target": 100000, "unit": "ca_cumul"},
        {"title": "Produire 5000$ de contrats", "deadline": "2026-06-08", "target": 5000, "unit": "produit"},
        {"title": "Productivit√© horaire de plus de 90", "deadline": "2026-06-15", "target": 90, "unit": "productivit√©"},
        {"title": "Faire 10h de PAP cette semaine", "deadline": "2026-06-22", "target": 10, "unit": "heures"},
        {"title": "Faire plus de 15 estimations cette semaine", "deadline": "2026-06-29", "target": 15, "unit": "estimations"},
        {"title": "Productivit√© horaire de plus de 100", "deadline": "2026-07-06", "target": 100, "unit": "productivit√©"},
        {"title": "Produire 15000$ cette semaine", "deadline": "2026-07-13", "target": 15000, "unit": "produit"},
        {"title": "Satisfaction client cumulative de plus de 4,5 √©toiles", "deadline": "2026-07-20", "target": 4.5, "unit": "√©toiles"},
        {"title": "10 estimations cette semaine", "deadline": "2026-07-27", "target": 10, "unit": "estimations"},
        {"title": "Signer 5000$", "deadline": "2026-08-03", "target": 5000, "unit": "$"},
        {"title": "Productivit√© horaire de 110", "deadline": "2026-08-10", "target": 110, "unit": "productivit√©"},
        {"title": "Produire 10000$", "deadline": "2026-08-17", "target": 10000, "unit": "produit"},
        {"title": "Produire 10000$", "deadline": "2026-08-24", "target": 10000, "unit": "produit"},
        {"title": "Faire 9h de PAP", "deadline": "2026-09-28", "target": 9, "unit": "heures"},
        {"title": "Signer 5000$", "deadline": "2026-10-05", "target": 5000, "unit": "$"},
        {"title": "Signer 10000$", "deadline": "2026-10-12", "target": 10000, "unit": "$"},
        {"title": "Signer 10000$", "deadline": "2026-10-19", "target": 10000, "unit": "$"},
        {"title": "Signer 5000$", "deadline": "2026-10-26", "target": 5000, "unit": "$"},
    ]

    today = datetime.now()
    streak = 0

    # Parcourir les quests dans l'ordre chronologique
    for quest in WEEKLY_QUESTS:
        deadline = datetime.strptime(quest['deadline'], '%Y-%m-%d')

        # Si la deadline est dans le futur, on arr√™te
        if deadline > today:
            break

        # V√©rifier si la quest est compl√©t√©e (directement via RPO sans appeler get_quest_progress)
        try:
            from QE.Backend.rpo import load_user_rpo_data, get_week_number_from_date
            from datetime import timedelta

            # Calculer le lundi de la semaine
            monday = deadline - timedelta(days=6)
            monday_str = monday.strftime('%Y-%m-%d')
            month_idx, week_num = get_week_number_from_date(monday_str)

            # Charger les donn√©es RPO
            rpo_data = load_user_rpo_data(username)
            week_data = rpo_data.get('weekly', {}).get(str(month_idx), {}).get(str(week_num), {})

            # Extraire les m√©triques selon le type de quest
            h_marketing = week_data.get('h_marketing', '-')
            estimation = week_data.get('estimation', 0)
            dollar = week_data.get('dollar', 0)
            depot = week_data.get('depot', 0)
            peintre = week_data.get('peintre', 0)
            ca_cumul = week_data.get('ca_cumul', 0)
            produit = week_data.get('produit', 0)
            prod_horaire = week_data.get('prod_horaire', 0)
            satisfaction = week_data.get('satisfaction', 0)

            # Convertir h_marketing en nombre
            try:
                h_marketing_num = float(h_marketing) if h_marketing != '-' else 0
            except:
                h_marketing_num = 0

            # Calculer le taux marketing de la semaine
            taux_marketing = 0
            if h_marketing_num > 0:
                taux_marketing = round(estimation / h_marketing_num, 2)

            # D√©terminer la progression selon le type
            current_progress = 0
            target = quest['target']

            if quest['unit'] == 'heures':
                current_progress = h_marketing_num
            elif quest['unit'] == 'estimations':
                current_progress = estimation
            elif quest['unit'] == '$':
                current_progress = dollar
            elif quest['unit'] == 'depot':
                current_progress = depot
            elif quest['unit'] == 'peintre':
                current_progress = peintre
            elif quest['unit'] == 'ca_cumul':
                current_progress = ca_cumul
            elif quest['unit'] == 'produit':
                current_progress = produit
            elif quest['unit'] == 'taux':
                current_progress = taux_marketing
            elif quest['unit'] == 'productivit√©':
                current_progress = prod_horaire
            elif quest['unit'] == '√©toiles':
                current_progress = satisfaction

            # V√©rifier si compl√©t√©e (>= 100%)
            percent = (current_progress / target * 100) if target > 0 else 0

            if percent >= 100:
                streak += 1
            else:
                streak = 0
        except Exception as e:
            # Erreur lors du chargement des donn√©es, on reset le streak
            print(f"[DEBUG] Erreur calcul quest {quest['deadline']}: {e}")
            streak = 0

    return streak


# ============================================================================
# FIN ROUTES GAMIFICATION
# ============================================================================


# ============================================================================
# ROUTES CENTRALE ADMIN - SYST√àME DYNAMIQUE
# ============================================================================

# Fichiers JSON pour stocker les sections (utiliser le disque persistant sur Render)
CENTRALE_ENTREPRENEUR_FILE = os.path.join(base_cloud, "centrale_entrepreneur_sections.json")
CENTRALE_COACH_FILE = os.path.join(base_cloud, "centrale_coach_sections.json")

def load_centrale_data(centrale_type: str = "entrepreneur"):
    """Charge les donn√©es de la centrale depuis le fichier JSON"""
    try:
        # S√©lectionner le bon fichier selon le type
        data_file = CENTRALE_COACH_FILE if centrale_type == "coach" else CENTRALE_ENTREPRENEUR_FILE

        os.makedirs(os.path.dirname(data_file), exist_ok=True)
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"sections": []}
    except Exception as e:
        print(f"[ERROR] Erreur chargement centrale data ({centrale_type}): {e}")
        return {"sections": []}

def save_centrale_data(data, centrale_type: str = "entrepreneur"):
    """Sauvegarde les donn√©es de la centrale dans le fichier JSON"""
    try:
        # S√©lectionner le bon fichier selon le type
        data_file = CENTRALE_COACH_FILE if centrale_type == "coach" else CENTRALE_ENTREPRENEUR_FILE

        os.makedirs(os.path.dirname(data_file), exist_ok=True)
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[ERROR] Erreur sauvegarde centrale data ({centrale_type}): {e}")
        return False

@app.get("/api/centrale/sections")
def get_centrale_sections(type: str = "entrepreneur"):
    """R√©cup√®re toutes les sections de la centrale"""
    try:
        data = load_centrale_data(type)
        return {"status": "success", "sections": data.get("sections", [])}
    except Exception as e:
        print(f"[ERROR] Erreur get_centrale_sections ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/sections")
def create_centrale_section(section_data: dict = Body(...), type: str = "entrepreneur"):
    """Cr√©e une nouvelle section"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Ajouter la nouvelle section
        sections.append(section_data)
        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success", "section": section_data}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur create_centrale_section ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/centrale/sections")
def update_centrale_section(section_data: dict = Body(...), type: str = "entrepreneur"):
    """Modifie une section existante"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Trouver et mettre √† jour la section
        section_id = section_data.get("id")
        for i, section in enumerate(sections):
            if section.get("id") == section_id:
                sections[i] = {**section, **section_data}
                break

        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success", "section": section_data}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur update_centrale_section ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/sections/save-all")
def save_all_centrale_sections(all_sections: dict = Body(...), type: str = "entrepreneur"):
    """Sauvegarde toutes les sections en une seule fois"""
    try:
        data = {"sections": all_sections.get("sections", [])}

        if save_centrale_data(data, type):
            return {"status": "success", "message": "Toutes les sections ont √©t√© sauvegard√©es"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur save_all_centrale_sections ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/centrale/sections/{section_id}")
def delete_centrale_section(section_id: str, type: str = "entrepreneur"):
    """Supprime une section"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Filtrer la section √† supprimer
        data["sections"] = [s for s in sections if s.get("id") != section_id]

        if save_centrale_data(data, type):
            return {"status": "success"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur delete_centrale_section ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/sections/{section_id}/rows")
def add_centrale_row(section_id: str, row_data: dict = Body(...), type: str = "entrepreneur"):
    """Ajoute une ligne √† une section"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Trouver la section et ajouter la ligne
        for section in sections:
            if section.get("id") == section_id:
                if "rows" not in section:
                    section["rows"] = []
                section["rows"].append(row_data)
                break

        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success", "row": row_data}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur add_centrale_row ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/centrale/sections/{section_id}/rows/{row_id}")
def update_centrale_row(section_id: str, row_id: str, row_data: dict = Body(...), type: str = "entrepreneur"):
    """Modifie une ligne d'une section"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Trouver la section et la ligne
        for section in sections:
            if section.get("id") == section_id:
                rows = section.get("rows", [])
                for i, row in enumerate(rows):
                    if row.get("id") == row_id:
                        rows[i] = {**row, **row_data}
                        break
                section["rows"] = rows
                break

        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur update_centrale_row ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/centrale/sections/{section_id}/rows/{row_id}")
def delete_centrale_row(section_id: str, row_id: str, type: str = "entrepreneur"):
    """Supprime une ligne d'une section"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        # Trouver la section et supprimer la ligne
        for section in sections:
            if section.get("id") == section_id:
                rows = section.get("rows", [])
                section["rows"] = [r for r in rows if r.get("id") != row_id]
                break

        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur delete_centrale_row ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/files/{section_id}/{row_id}")
async def upload_centrale_file(section_id: str, row_id: str, file: UploadFile = File(...), type: str = "entrepreneur"):
    """Upload un fichier pour une ligne"""
    try:
        # Cr√©er le dossier pour les fichiers de la centrale (s√©par√© par type) - utiliser le disque persistant
        upload_dir = os.path.join(base_cloud, "uploads", "centrale", type, section_id, row_id)
        os.makedirs(upload_dir, exist_ok=True)

        # Sauvegarder le fichier
        file_path = os.path.join(upload_dir, file.filename)
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # URL du fichier
        file_url = f"/uploads/centrale/{type}/{section_id}/{row_id}/{file.filename}"

        # Mettre √† jour les donn√©es
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        for section in sections:
            if section.get("id") == section_id:
                rows = section.get("rows", [])
                for row in rows:
                    if row.get("id") == row_id:
                        # Trouver la colonne fichier
                        for col in section.get("columns", []):
                            if col.get("type") == "fichier":
                                # S'assurer que c'est une liste (pas un string ou autre)
                                if not isinstance(row.get(col["name"]), list):
                                    row[col["name"]] = []
                                row[col["name"]].append({
                                    "name": file.filename,
                                    "url": file_url
                                })
                                break
                        break
                break

        data["sections"] = sections
        save_centrale_data(data, type)

        return {
            "status": "success",
            "file": {
                "name": file.filename,
                "url": file_url
            }
        }
    except Exception as e:
        print(f"[ERROR] Erreur upload_centrale_file ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/centrale/files/{section_id}/{row_id}/{filename}")
def delete_centrale_file(section_id: str, row_id: str, filename: str, type: str = "entrepreneur"):
    """Supprime un fichier"""
    try:
        # Supprimer le fichier physique (avec le bon type) - utiliser le disque persistant
        file_path = os.path.join(base_cloud, "uploads", "centrale", type, section_id, row_id, filename)
        if os.path.exists(file_path):
            os.remove(file_path)

        # Mettre √† jour les donn√©es
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        for section in sections:
            if section.get("id") == section_id:
                rows = section.get("rows", [])
                for row in rows:
                    if row.get("id") == row_id:
                        # Retirer le fichier de toutes les colonnes fichier
                        for col in section.get("columns", []):
                            if col.get("type") == "fichier" and col["name"] in row:
                                row[col["name"]] = [f for f in row[col["name"]] if f.get("name") != filename]
                        break
                break

        data["sections"] = sections
        save_centrale_data(data, type)

        return {"status": "success"}
    except Exception as e:
        print(f"[ERROR] Erreur delete_centrale_file ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/centrale/sections/{section_id}/rows/{row_id}/link")
def update_centrale_link(section_id: str, row_id: str, link_data: dict = Body(...), type: str = "entrepreneur"):
    """Modifie un lien d'une ligne"""
    try:
        data = load_centrale_data(type)
        sections = data.get("sections", [])

        col_name = link_data.get("colName")
        text = link_data.get("text")
        url = link_data.get("url")

        # Trouver la section et la ligne
        for section in sections:
            if section.get("id") == section_id:
                rows = section.get("rows", [])
                for row in rows:
                    if row.get("id") == row_id:
                        row[col_name] = {"text": text, "url": url}
                        break
                section["rows"] = rows
                break

        data["sections"] = sections

        if save_centrale_data(data, type):
            return {"status": "success"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur update_centrale_link ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Route pour servir les fichiers upload√©s (avec support du type dans l'URL)
@app.get("/uploads/centrale/{type}/{section_id}/{row_id}/{filename}")
def serve_centrale_file(type: str, section_id: str, row_id: str, filename: str):
    """Sert un fichier upload√© depuis le disque persistant"""
    file_path = os.path.join(base_cloud, "uploads", "centrale", type, section_id, row_id, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    raise HTTPException(status_code=404, detail="Fichier non trouv√©")

# ============================================================================
# ROUTES CENTRALE - MONDAY BOARDS
# ============================================================================

# Fichiers de donn√©es pour les boards Monday (utiliser le disque persistant)
CENTRALE_BOARDS_COACH_FILE = os.path.join(base_cloud, "centrale_boards_coach.json")
CENTRALE_BOARDS_ENTREPRENEUR_FILE = os.path.join(base_cloud, "centrale_boards_entrepreneur.json")

def load_boards_data(centrale_type: str = "entrepreneur"):
    """Charge les boards de la centrale depuis le fichier JSON"""
    try:
        data_file = CENTRALE_BOARDS_COACH_FILE if centrale_type == "coach" else CENTRALE_BOARDS_ENTREPRENEUR_FILE
        os.makedirs(os.path.dirname(data_file), exist_ok=True)
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"boards": []}
    except Exception as e:
        print(f"[ERROR] Erreur chargement boards data ({centrale_type}): {e}")
        return {"boards": []}

def save_boards_data(data, centrale_type: str = "entrepreneur"):
    """Sauvegarde les boards de la centrale dans le fichier JSON"""
    try:
        data_file = CENTRALE_BOARDS_COACH_FILE if centrale_type == "coach" else CENTRALE_BOARDS_ENTREPRENEUR_FILE
        os.makedirs(os.path.dirname(data_file), exist_ok=True)
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[ERROR] Erreur sauvegarde boards data ({centrale_type}): {e}")
        return False

@app.get("/api/centrale/boards")
def get_centrale_boards(type: str = "entrepreneur"):
    """R√©cup√®re tous les boards de la centrale"""
    try:
        data = load_boards_data(type)
        return {"status": "success", "boards": data.get("boards", [])}
    except Exception as e:
        print(f"[ERROR] Erreur get_centrale_boards ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/boards")
def create_centrale_board(board_data: dict = Body(...), type: str = "entrepreneur"):
    """Cr√©e un nouveau board"""
    try:
        data = load_boards_data(type)
        boards = data.get("boards", [])

        # Ajouter le nouveau board
        boards.append(board_data)
        data["boards"] = boards

        if save_boards_data(data, type):
            return {"status": "success", "board": board_data}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur create_centrale_board ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/centrale/boards/{board_id}")
def update_centrale_board(board_id: str, board_data: dict = Body(...), type: str = "entrepreneur"):
    """Met √† jour un board"""
    try:
        data = load_boards_data(type)
        boards = data.get("boards", [])

        # Trouver et mettre √† jour le board
        for i, board in enumerate(boards):
            if board.get("id") == board_id:
                boards[i] = board_data
                break

        data["boards"] = boards

        if save_boards_data(data, type):
            return {"status": "success", "board": board_data}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur update_centrale_board ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/centrale/boards/{board_id}")
def delete_centrale_board(board_id: str, type: str = "entrepreneur"):
    """Supprime un board"""
    try:
        data = load_boards_data(type)
        boards = data.get("boards", [])

        # Filtrer le board √† supprimer
        boards = [b for b in boards if b.get("id") != board_id]
        data["boards"] = boards

        if save_boards_data(data, type):
            return {"status": "success"}
        else:
            raise HTTPException(status_code=500, detail="Erreur sauvegarde")
    except Exception as e:
        print(f"[ERROR] Erreur delete_centrale_board ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/centrale/boards/upload-file")
async def upload_board_file(
    file: UploadFile = File(...),
    board_id: str = Form(...),
    group_id: str = Form(...),
    row_id: str = Form(...),
    column_id: str = Form(...),
    type: str = Form("entrepreneur")
):
    """Upload un fichier pour une cellule de board"""
    try:
        # Cr√©er le dossier pour les fichiers du board - utiliser le disque persistant
        upload_dir = os.path.join(base_cloud, "uploads", "centrale_boards", type, board_id, group_id, row_id)
        os.makedirs(upload_dir, exist_ok=True)

        # Sauvegarder le fichier
        file_path = os.path.join(upload_dir, file.filename)
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # URL du fichier
        file_url = f"/uploads/centrale_boards/{type}/{board_id}/{group_id}/{row_id}/{file.filename}"

        return {
            "status": "success",
            "file": {
                "type": "file",
                "name": file.filename,
                "url": file_url,
                "size": len(content)
            }
        }
    except Exception as e:
        print(f"[ERROR] Erreur upload_board_file ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/centrale/boards/delete-file")
def delete_board_file(
    board_id: str = Query(...),
    group_id: str = Query(...),
    row_id: str = Query(...),
    filename: str = Query(...),
    type: str = Query("entrepreneur")
):
    """Supprime un fichier d'une cellule de board"""
    try:
        # Supprimer le fichier physique - utiliser le disque persistant
        file_path = os.path.join(base_cloud, "uploads", "centrale_boards", type, board_id, group_id, row_id, filename)
        if os.path.exists(file_path):
            os.remove(file_path)
            return {"status": "success"}
        else:
            raise HTTPException(status_code=404, detail="Fichier non trouv√©")
    except Exception as e:
        print(f"[ERROR] Erreur delete_board_file ({type}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# FIN ROUTES CENTRALE
# ============================================================================

# ============================================================================
# ROUTES PR√âF√âRENCES DE LANGUE
# ============================================================================

@app.post("/save-language-preference")
async def save_language_preference(request: Request):
    """Sauvegarde la pr√©f√©rence de langue de l'utilisateur"""
    try:
        data = await request.json()
        username = data.get('username')
        language = data.get('language', 'fr')

        if not username:
            raise HTTPException(status_code=400, detail="Username manquant")

        # Charger le fichier account de l'utilisateur
        account_file = os.path.join(base_cloud, "accounts", f"{username}.json")

        if not os.path.exists(account_file):
            raise HTTPException(status_code=404, detail="Compte utilisateur non trouv√©")

        # Lire le fichier account
        with open(account_file, 'r', encoding='utf-8') as f:
            account_data = json.load(f)

        # Ajouter la pr√©f√©rence de langue
        account_data['language_preference'] = language

        # Sauvegarder le fichier account
        with open(account_file, 'w', encoding='utf-8') as f:
            json.dump(account_data, f, indent=2, ensure_ascii=False)

        print(f"[LANG] Pr√©f√©rence de langue sauvegard√©e pour {username}: {language}")

        return {"status": "success", "language": language}

    except Exception as e:
        print(f"[ERROR] Erreur save_language_preference: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/get-language-preference")
async def get_language_preference(username: str = Query(...)):
    """R√©cup√®re la pr√©f√©rence de langue de l'utilisateur"""
    try:
        if not username:
            raise HTTPException(status_code=400, detail="Username manquant")

        # Charger le fichier account de l'utilisateur
        account_file = os.path.join(base_cloud, "accounts", f"{username}.json")

        if not os.path.exists(account_file):
            raise HTTPException(status_code=404, detail="Compte utilisateur non trouv√©")

        # Lire le fichier account
        with open(account_file, 'r', encoding='utf-8') as f:
            account_data = json.load(f)

        # R√©cup√©rer la pr√©f√©rence de langue (par d√©faut: fran√ßais)
        language = account_data.get('language_preference', 'fr')

        print(f"[LANG] Pr√©f√©rence de langue charg√©e pour {username}: {language}")

        return {"status": "success", "language": language}

    except Exception as e:
        print(f"[ERROR] Erreur get_language_preference: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# FIN ROUTES PR√âF√âRENCES DE LANGUE
# ============================================================================


# [START] D√©marrage de l'application
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080, log_level="info")



